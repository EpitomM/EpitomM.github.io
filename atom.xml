<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://epitomm.github.io</id>
    <title>SSM</title>
    <updated>2020-04-17T06:08:56.622Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://epitomm.github.io"/>
    <link rel="self" href="https://epitomm.github.io/atom.xml"/>
    <subtitle>热心善良的老学姐</subtitle>
    <logo>https://epitomm.github.io/images/avatar.png</logo>
    <icon>https://epitomm.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, SSM</rights>
    <entry>
        <title type="html"><![CDATA[leetcode53. 最大子序和]]></title>
        <id>https://epitomm.github.io/post/leetcode53-zui-da-zi-xu-he/</id>
        <link href="https://epitomm.github.io/post/leetcode53-zui-da-zi-xu-he/">
        </link>
        <updated>2020-04-16T14:01:03.000Z</updated>
        <content type="html"><![CDATA[<h2 id="问题描述">问题描述</h2>
<p>给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p>
<h2 id="示例">示例:</h2>
<p>输入: [-2,1,-3,4,-1,2,1,-5,4],<br>
输出: 6</p>
<p>解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。</p>
<p>进阶:<br>
如果你已经实现复杂度为 O(n) 的解法，尝试使用更为精妙的分治法求解。</p>
<h2 id="分析">分析</h2>
<table>
<thead>
<tr>
<th style="text-align:center"><strong>当前数字</strong></th>
<th style="text-align:center"><strong>连续子序列最大和 maxSum</strong></th>
<th style="text-align:center"><strong>子序列当前累加和 cur</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">-8</td>
<td style="text-align:center"></td>
<td style="text-align:center">-6</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">3</td>
<td style="text-align:center">-3 &lt; 0, 更新 cur = 3</td>
</tr>
<tr>
<td style="text-align:center">-2</td>
<td style="text-align:center"></td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">-10</td>
<td style="text-align:center"></td>
<td style="text-align:center">-5</td>
</tr>
</tbody>
</table>
<ul>
<li>第一个数：2。连续子序列最大和 <code>maxSum = 2</code>；子序列当前累加和 <code>cur=2</code>；</li>
<li>第二个数：-8。<code>2 - 8 = -6 &lt; maxSum</code>，不更新 maxSum</li>
<li>第三个数：3。<code>-6 + 3 = -3 &lt; maxSum</code>，不更新 maxSum
<ul>
<li>如果不加 -6，而是让 3 自成一个子序列，<code>3 &gt; maxSum</code></li>
<li>maxSum = 3；cur = 3</li>
<li>如果前面累加的和为负数或零，对后面的求和不会有正向贡献，因此可以舍弃前面这段子序列的和，重新开始一个新的子序列。当前连续子序列的和记为 cur</li>
<li><code>if ( cur&lt;= 0 )</code>，就从当前元素重新开始一个新的子序列，当前和 cur 更新为当前的元素值 <code>cur = a[i];</code> 否则子序列就继续向前相加 <code>cur = cur + a[i]</code> 。每次子序列的和更新后，都要和最大值 maxSum 对比，以此更新最大值 <code>maxSum = max(maxSum, cur)</code>，这样遍历完数组，就能找到连续子序列的最大和</li>
</ul>
</li>
<li>第四个数：-2。<code>3 - 2 = 1</code>，<code>cur=1 &gt; 0</code>，于是保留 <code>cur=1</code>。<code>cur=1 &lt; maxSum=3</code>，不更新 maxSum</li>
<li>第五个数：4。<code>1+4=5 &gt; maxSum</code>，保留 <code>cur=5</code>，更新 maxSum=5</li>
<li>第六个数：-10。<code>5-10=-5 &lt; 5</code>，不更新 maxSum</li>
</ul>
<h3 id="复杂度分析">复杂度分析</h3>
<ul>
<li>T = O(n)<br>
遍历数组一遍，时间复杂度为 O(n)。</li>
<li>S = O(1)<br>
没有使用额外的存储空间，空间复杂度为 O(1)</li>
</ul>
<h2 id="代码">代码</h2>
<pre><code>class Solution {

  // Time: O(n), Space: O(1)
  public int maxSubArray(int[] nums) {
      // 初始化子序列最大和 max 和 子序列当前累加和
      int max = Integer.MIN_VALUE, cur = 0;
    // for 循环遍历数组
    for (int i = 0; i &lt; nums.length; ++i) {
      // 累加和 &lt;= 0，则用当前元素值 nums[i] 更新累加和，表示开始一个新的子序列；否则继续累加当前元素的值
      cur = cur &lt;= 0 ? nums[i] : (cur + nums[i]);
      // 更新当前子序列的最大值
      max = Math.max(max, cur);
    }
    return max;
  }

}
</code></pre>
<h2 id="来源">来源</h2>
<p>来源：力扣（LeetCode）<br>
链接：https://leetcode-cn.com/problems/maximum-subarray</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[深入学习并发编程中的synchronized]]></title>
        <id>https://epitomm.github.io/post/shen-ru-xue-xi-bing-fa-bian-cheng-zhong-de-synchronized/</id>
        <link href="https://epitomm.github.io/post/shen-ru-xue-xi-bing-fa-bian-cheng-zhong-de-synchronized/">
        </link>
        <updated>2020-04-15T03:54:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="第一章并发编程中的三个问题">第一章：并发编程中的三个问题</h1>
<h2 id="可见性">可见性</h2>
<p>可见性（Visibility）：是指<strong>一个线程对共享变量进行修改，另一个线程立即得到修改后的最新值</strong>。</p>
<h3 id="可见性演示">可见性演示</h3>
<p>案例演示：一个线程根据 <code>boolean</code> 类型的标记 <code>flag</code>， <code>while</code> 循环，另一个线程改变这个 <code>flag</code> 变量的值，这个线程并不会停止循环。</p>
<pre><code>package com.itheima.demo01_concurrent_problem;

/**
 *目标:演示可见性问题
 *     1.创建一个共享变量
 *     2.创建一个线程不断读取共享变量
 *     3.创建一饿线程修改共享变量
 */
public class Test01Visibility {
    // 1.创建一个共享变量
    private static boolean flag = true;

    public static void main(String[] args) throws InterruptedException {
        // 2.创建一个线程不断读取共享变量
        new Thread(() -&gt; {
            while (flag) {

            }
        }).start();

        Thread.sleep(2000);

        // 3.创建一个线程修改共享变量
        new Thread(() -&gt; {
            flag = false;
            System.out.println(&quot;线程修改了变量的值为false&quot;);
        }).start();
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>线程修改了变量的值为false
（阻塞···）
</code></pre>
<h3 id="小结">小结</h3>
<p>并发编程时，会出现可见性问题，当一个线程对共享变量进行了修改，另外的线程并没有立即看到修改后的最新值。</p>
<h2 id="原子性">原子性</h2>
<p>原子性（Atomicity）：<strong>在一次或多次操作中，要么所有的操作都执行并且不会受其他因素干扰而中断，要么所有的操作都不执行</strong>。</p>
<h3 id="原子性演示">原子性演示</h3>
<p>案例演示:5个线程各执行1000次 i++;</p>
<pre><code>package com.itheima.demo01_concurrent_problem;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;

/**
 * 目标:演示原子性问题
 *     1.定义一个共享变量number
 *     2.对number进行1000的++操作
 *     3.使用5个线程来进行
 */
public class Test02Atomicity {
    // 1.定义一个共享变量number
    private static int number = 0;

    public static void main(String[] args) throws InterruptedException {
        // 2.对number进行1000的++操作
        Runnable increment = () -&gt; {
            for (int i = 0; i &lt; 1000; i++) {
                number++;
            }
        };
        List&lt;Thread&gt; list = new ArrayList&lt;&gt;();
        // 3.使用5个线程来进行
        for (int i = 0; i &lt; 5; i++) {
            Thread t = new Thread(increment);
            t.start();
            list.add(t);
        }

        for (Thread t : list) {
            t.join();
        }

        System.out.println(&quot;number = &quot; + number);
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>number = 4955
</code></pre>
<p>使用<code>javap</code>反汇编<code>class</code>文件，得到下面的字节码指令：<br>
<img src="https://epitomm.github.io/post-images/%E5%8E%9F%E5%AD%90%E6%80%A7%E6%BC%94%E7%A4%BA.png" alt="图片" loading="lazy"></p>
<p>其中，对于 <code>number++</code> 而言（number 为静态变量），实际会产生如下的 JVM 字节码指令：</p>
<pre><code>9: getstatic #12    // 从类信息中加载 12 号 static 变量
12: iconst_1         // 把 int 类型常量 1 压入操作数栈
13: iadd               // 将操作数栈顶和次栈顶元素弹出并相加
14: putstatic #12 // 设置 12 号 static 变量
</code></pre>
<p>由此可见<code>number++</code>是由多条语句组成，以上多条指令在一个线程的情况下是不会出问题的，但是在多线程情况下就可能会出现问题。比如一个线程在执行<code>13: iadd</code>时，另一个线程又执行<code>9: getstatic</code>。会导致两次<code>number++</code>，实际上只加了1。</p>
<h3 id="小结-2">小结</h3>
<p>并发编程时，会出现原子性问题，当一个线程对共享变量操作到一半时，另外的线程也有可能来操作共享变量，干扰了前一个线程的操作。</p>
<h2 id="有序性">有序性</h2>
<p>有序性（Ordering）：是指程序中代码的执行顺序，Java在编译时和运行时会对代码进行优化，会导致<strong>程序最终的执行顺序不一定就是我们编写代码时的顺序</strong>。</p>
<pre><code>public static void main(String[] args) {
    int a = 10;
    int b = 20;
}
</code></pre>
<h3 id="有序性演示">有序性演示</h3>
<p><code>jcstress</code>是<code>Java</code>并发压测工具。<a href="https://wiki.openjdk.java.net/display/CodeTools/jcstress">https://wiki.openjdk.java.net/display/CodeTools/jcstress</a></p>
<p>修改pom文件，添加依赖：</p>
<pre><code>&lt;dependency&gt; 
  &lt;groupId&gt;org.openjdk.jcstress&lt;/groupId&gt; 
  &lt;artifactId&gt;jcstress-core&lt;/artifactId&gt; 
  &lt;version&gt;${jcstress.version}&lt;/version&gt; 
&lt;/dependency&gt;  
</code></pre>
<p>代码<br>
Test03Orderliness.java</p>
<pre><code>import org.openjdk.jcstress.annotations.*;
import org.openjdk.jcstress.infra.results.I_Result;
@JCStressTest
@Outcome(id = {&quot;1&quot;, &quot;4&quot;}, expect = Expect.ACCEPTABLE, desc = &quot;ok&quot;)
@Outcome(id = &quot;0&quot;, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;danger&quot;)
@State
public class Test03Orderliness {
    int num = 0;
    boolean ready = false;
    // 线程一执行的代码
    @Actor
    public void actor1(I_Result r) {
        if(ready) {
            r.r1 = num + num;
        } else {
            r.r1 = 1;
        }
    }
    // 线程2执行的代码
    @Actor
    public void actor2(I_Result r) {
        num = 2;
        ready = true;
    }
}
</code></pre>
<ul>
<li><code>I_Result</code> 是一个对象，有一个属性 <code>r1</code> 用来保存结果，在多线程情况下可能出现几种结果？
<ul>
<li>情况1：线程1先执行<code>actor1</code>，这时<code>ready = false</code>，所以进入else分支结果为1。</li>
<li>情况2：线程2执行到<code>actor2</code>，执行了<code>num = 2;</code>和<code>ready = true</code>，线程1执行，这回进入 if 分支，结果为 4。</li>
<li>情况3：线程2先执行<code>actor2</code>，只执行<code>num = 2</code>；但没来得及执行 <code>ready = true</code>，线程1执行，还是进入 else分支，结果为1。</li>
<li><strong>还有一种结果0</strong>。代码重排序将 <code>actor2</code> 中 <code>num = 2</code> 和 <code>ready = true</code> 反序。先执行 <code>actor2</code> 中的 <code>ready = true</code>，然后执行 <code>actor1</code> 中 if 判断，结果为 0 + 0 = 0。</li>
</ul>
</li>
</ul>
<p>运行测试：</p>
<pre><code>mvn clean install 
java -jar target/jcstress.jar
</code></pre>
<h3 id="小结-3">小结</h3>
<p>程序代码在执行过程中的先后顺序，由于<code>Java</code>在编译期以及运行期的优化，导致了代码的执行顺序未必就是开发者编写代码时的顺序。</p>
<h1 id="第二章java内存模型jmm">第二章：Java内存模型(JMM)</h1>
<p>在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型。</p>
<h2 id="计算机结构">计算机结构</h2>
<h3 id="计算机结构简介">计算机结构简介</h3>
<p>冯诺依曼，提出计算机由五大组成部分，<strong>输入设备，输出设备，存储器，控制器，运算器</strong>。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<p style = "text-align:center">计算机结构</p>
<h3 id="cpu">CPU</h3>
<p>中央处理器，是计算机的<strong>控制和运算</strong>的核心，我们的程序最终都会变成指令让CPU去执行，处理程序中的数据。<br>
<img src="https://epitomm.github.io/post-images/CPU.png" alt="图片" loading="lazy"></p>
<p style = "text-align:center">CPU</p>
<h3 id="内存">内存</h3>
<p>我们的程序都是在内存中运行的，<strong>内存会保存程序运行时的数据</strong>，供CPU处理。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E5%86%85%E5%AD%98.png" alt="图片" loading="lazy"></figure>
<p style = "text-align:center">内存</p>
<h3 id="缓存">缓存</h3>
<p><strong>CPU的运算速度和内存的访问速度相差比较大</strong>。这就导致CPU每次操作内存都要耗费很多等待时间。内存的读写速度成为了计算机运行的瓶颈。于是就有了在CPU和主内存之间增加缓存的设计。最靠近CPU 的缓存称为L1，然后依次是 L2，L3和主内存，CPU缓存模型如图下图所示。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/CPU%E7%BC%93%E5%AD%98%E6%A8%A1%E5%9E%8B.png" alt="图片" loading="lazy"></figure>
<p style = "text-align:center">CPU 缓存模型</p>
<p>CPU Cache分成了三个级别: L1， L2， L3。级别越小越接近CPU，速度也更快，同时也代表着容量越小。</p>
<ol>
<li>L1是最接近CPU的，它容量最小，例如32K，速度最快，每个核上都有一个L1 Cache。</li>
<li>L2 Cache 更大一些，例如256K，速度要慢一些，一般情况下每个核上都有一个独立的L2 Cache。</li>
<li>L3 Cache是三级缓存中最大的一级，例如12MB，同时也是缓存中最慢的一级，在同一个CPU插槽之间的核共享一个L3 Cache。<br>
<img src="https://epitomm.github.io/post-images/CPU%E5%8F%82%E6%95%B0.png" alt="图片" loading="lazy"></li>
</ol>
<blockquote>
<p>Latency：延迟</p>
</blockquote>
<p>Cache的出现是为了解决<strong>CPU直接访问内存效率低下</strong>问题的，程序在运行的过程中，CPU接收到指令后，它会最先向CPU中的一级缓存（L1 Cache）去寻找相关的数据，如果命中缓存，CPU进行计算时就可以直接对CPU Cache中的数据进行读取和写入，当运算结束之后，再将CPU Cache中的最新数据刷新到主内存当中，CPU通过直接访问Cache的方式替代直接访问主存的方式极大地提高了CPU 的吞吐能力。但是由于一级缓存（L1 Cache）容量较小，所以不可能每次都命中。这时CPU会继续向下一级的二级缓存（L2 Cache）寻找，同样的道理，当所需要的数据在二级缓存中也没有的话，会继续转向L3 Cache、内存(主存)和硬盘。</p>
<h3 id="小结-4">小结</h3>
<p>计算机的主要组成：CPU，内存，输入设备，输出设备。</p>
<h2 id="java内存模型">Java内存模型</h2>
<p>Java Memory Molde (Java内存模型/JMM)，千万不要和Java内存结构混淆</p>
<p>关于“Java内存模型”的权威解释，请参考 <a href="https://download.oracle.com/otn-pub/jcp/memory_model-1.0-pfd-spec-oth-JSpec/memory_model-1_0-pfd-spec.pdf?AuthParam=1581232382_a0e88fb559ae2cdd224df3335e1eb9d3">https://download.oracle.com/otn-pub/jcp/memory_model-1.0-pfd-spec-oth-JSpec/memory_model-1_0-pfd-spec.pdf</a>。</p>
<p>Java 内存模型，是 Java 虚拟机规范中所定义的一种内存模型，Java 内存模型是标准化的，屏蔽掉了底层不同计算机的区别。</p>
<p>Java内存模型是一套规范，描述了Java程序中各种变量(线程共享变量)的访问规则，以及在JVM中将变量存储到内存和从内存中读取变量这样的底层细节，具体如下。</p>
<ul>
<li>主内存</li>
</ul>
<p>主内存是<strong>所有线程都共享</strong>的，都能访问的。所有的<strong>共享变量</strong>都存储于主内存。</p>
<ul>
<li>工作内存</li>
</ul>
<p><strong>每一个线程有自己的工作内存</strong>，工作内存只存储该线程对<strong>共享变量的副本</strong>。线程对变量的所有的操作(读，取)都必须在工作内存中完成，而不能直接读写主内存中的变量，不同线程之间也不能直接访问对方工作内存中的变量。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png" alt="图片" loading="lazy"></figure>
<p style = "text-align:center"> Java 内存模型</p>
<h3 id="java-内存模型的作用">Java 内存模型的作用</h3>
<p>Java内存模型是一套在多线程读写共享数据时，对共享数据的可见性、有序性、和原子性的规则和保障。</p>
<p>synchronized,volatile</p>
<h3 id="cpu缓存内存与-java-内存模型的关系">CPU缓存，内存与 Java 内存模型的关系</h3>
<p>通过对前面的CPU硬件内存架构、Java内存模型以及Java多线程的实现原理的了解，我们应该已经意识到，<strong>多线程的执行最终都会映射到硬件处理器上进行执行</strong>。</p>
<p>但 Java 内存模型和硬件内存架构并不完全一致。对于硬件内存来说只有寄存器、缓存内存、主内存的概念，并没有工作内存和主内存之分，也就是说 Java 内存模型对内存的划分对硬件内存并没有任何影响， 因为 JMM 只是一种抽象的概念，是一组规则，不管是工作内存的数据还是主内存的数据，对于计算机硬件来说都会存储在计算机主内存中，当然也有可能存储到CPU缓存或者寄存器中，因此总体上来说，Java内存模型和计算机硬件内存架构是一个相互交叉的关系，是一种<strong>抽象概念划分与真实物理硬件的交叉</strong>。</p>
<p><strong>JMM内存模型与CPU硬件内存架构的关系：</strong></p>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/JMM%E4%B8%8ECPU%E7%A1%AC%E4%BB%B6%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="图片" loading="lazy"></figure>
<p><strong>小结</strong></p>
<p>Java 内存模型是一套<strong>规范</strong>，描述了 <strong>Java 程序中各种变量(线程共享变量)的访问规则</strong>，以及在 JVM 中将变量存储到内存和从内存中读取变量这样的底层细节，Java 内存模型是对共享数据的可见性、有序性、和原子性的规则和保障。</p>
<h2 id="主内存与工作内存之间的数据交互过程">主内存与工作内存之间的数据交互过程</h2>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E4%B8%BB%E5%AD%98%E4%B8%8E%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AD%98%E7%9A%84%E4%BA%A4%E4%BA%92.png" alt="图片" loading="lazy"></figure>
<p>Java内存模型中定义了以下8种操作来完成，主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的。</p>
<p>对应如下的流程图：</p>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E4%B8%BB%E5%AD%98%E4%B8%8E%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AD%98%E5%85%B7%E4%BD%93%E7%9A%84%E4%BA%A4%E4%BA%92%E5%8D%8F%E8%AE%AE.png" alt="图片" loading="lazy"></figure>
<ul>
<li>read：从主内存读取共享变量（<code>boolean x= true</code>）</li>
<li>load：将共享变量（<code>boolean x = tru</code>e）放入工作内存的变量副本中</li>
<li>use：把工作内存中一个变量的<strong>值</strong>（true）传递给执行引擎</li>
<li>assign：把一个从执行引擎接收到的值赋给工作内存的变量</li>
<li>store：把工作内存的一个共享变量传送到主内存中</li>
<li>write：在 store 之后执行，把 store 得到的值放入主内存的变量中</li>
<li>lock：作用于主内存的变量</li>
<li>unlock</li>
</ul>
<p>注意:</p>
<ol>
<li>
<p>如果对一个变量执行lock操作，将会<strong>清空工作内存中此变量的值</strong></p>
</li>
<li>
<p>对一个变量执行unlock操作之前，必须先<strong>把此变量同步到主内存中</strong></p>
</li>
</ol>
<h3 id="小结-5">小结</h3>
<p>主内存与工作内存之间的数据交互过程</p>
<pre><code>lock -&gt; read -&gt; load -&gt; use -&gt; assign -&gt; store -&gt; write -&gt; unlock
</code></pre>
<h1 id="第三章synchronized保证三大特性">第三章：synchronized保证三大特性</h1>
<p>synchronized能够保证在同一时刻最多只有一个线程执行该段代码，以达到保证并发安全的效果。</p>
<pre><code>synchronized (锁对象) { 
    // 受保护资源; 
}
</code></pre>
<h2 id="synchronized与原子性">synchronized与原子性</h2>
<h3 id="使用synchronized保证原子性">使用synchronized保证原子性</h3>
<p>案例演示:5个线程各执行1000次 i++;</p>
<pre><code>import java.util.ArrayList;
/**
 案例演示:5个线程各执行1000次 i++; 
 */
public class Test01Atomicity {
    private static int number = 0;
    public static void main(String[] args) throws InterruptedException {
        Runnable increment = new Runnable() {
            @Override
            public void run() {
                for (int i = 0; i &lt; 1000; i++) {
                    synchronized (Test01Atomicity.class) {
                        number++;
                    }
                }
            }
        };
        ArrayList&lt;Thread&gt; ts = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 50; i++) {
            Thread t = new Thread(increment);
            t.start();
            ts.add(t);
        }
        for (Thread t : ts) {
            t.join();
        }
        System.out.println(&quot;number = &quot; + number);
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>number = 50000
</code></pre>
<p>主要代码：</p>
<pre><code>for (int i = 0; i &lt; 1000; i++) {
    synchronized (Test01Atomicity.class) {
        number++;
    }
}
</code></pre>
<h3 id="synchronized保证原子性的原理">synchronized保证原子性的原理</h3>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/synchronized%E4%BF%9D%E8%AF%81%E5%8E%9F%E5%AD%90%E6%80%A7%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"></figure>
<p>对<code>number++</code>;增加同步代码块后，保证同一时间只有一个线程操作<code>number++</code>;。就不会出现安全问题。</p>
<h3 id="小结-6">小结</h3>
<p>synchronized保证原子性的原理：synchronized保证只有一个线程拿到锁，能够进入同步代码块。</p>
<h2 id="synchronized与可见性">synchronized与可见性</h2>
<h3 id="使用synchronized保证可见性">使用synchronized保证可见性</h3>
<p>案例演示：一个线程根据boolean类型的标记flag， while循环，另一个线程改变这个flag变量的值，使用 synchronized 加锁这个线程会停止循环。</p>
<pre><code>/*
    目标:演示可见性问题
        1.创建一个共享变量
        2.创建一个线程不断读取共享变量
        3.创建一个线程修改共享变量
 */
public class Test01Visibility {
    // 1.创建一个使用 volatile 修饰的共享变量
    private static boolean flag = true;
    private static Object obj = new Object();
    public static void main(String[] args) throws InterruptedException {
        // 2.创建一个线程不断读取共享变量
        new Thread(() -&gt; {
            while (flag) {
                synchronized (obj){

                }
            }
        }).start();

        Thread.sleep(2000);

        // 3.创建一个线程修改共享变量
        new Thread(() -&gt; {
            flag = false;
            System.out.println(&quot;线程修改了变量的值为false&quot;);
        }).start();
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>线程修改了变量的值为false
</code></pre>
<p>分析：<br>
synchronized ：当线程 2 将 flag 的值改为 false 后，线程 1 再次执行 while 操作时：读取主内存变量到工作空间前，执行 Lock 操作，使工作内存内的共享变量失效，再次去主内存读取刷新共享变量的值。</p>
<p><strong>synchronized保证可见性的原理</strong><br>
<img src="https://epitomm.github.io/post-images/%E4%B8%BB%E5%AD%98%E4%B8%8E%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AD%98%E5%85%B7%E4%BD%93%E7%9A%84%E4%BA%A4%E4%BA%92%E5%8D%8F%E8%AE%AE.png" alt="图片" loading="lazy"></p>
<p>如果 while 方法内增加输出语句 <code>System.out.println(&quot;run = &quot; + run);</code>，即使不显式使用 <code>synchronized</code> 加锁也能终止死循环。</p>
<pre><code>/**
 案例演示:
 一个线程根据boolean类型的标记flag， while循环，另一个线程改变这个flag变量的值，
 另一个线程并不会停止循环.
 */
public class Test01Visibility {
    // 多个线程都会访问的数据，我们称为线程的共享数据
    private static boolean run = true;
    public static void main(String[] args) throws InterruptedException {
        Thread t1 = new Thread(() -&gt; {
            while (run) {
                // 增加对象共享数据的打印，println是同步方法
                System.out.println(&quot;run = &quot; + run);
            }
        });
        t1.start();
        Thread.sleep(1000);
        Thread t2 = new Thread(() -&gt; {
            run = false;
            System.out.println(&quot;时间到，线程2设置为false&quot;);
        });
        t2.start();
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>run = true
run = true
run = true
······
run = true
run = true
run = true
时间到，线程2设置为false
</code></pre>
<p>分析：<br>
使用 sout 输出，程序会停止，而不是一直阻塞，因为 sout 内部使用了 synchronized</p>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/sout.png" alt="图片" loading="lazy"></figure>
<h3 id="使用-volatile-保证可见性">使用 volatile 保证可见性</h3>
<pre><code>package com.itheima.demo02_concurrent_problem;

/*
    目标:演示可见性问题
        1.创建一个共享变量
        2.创建一个线程不断读取共享变量
        3.创建一个线程修改共享变量
 */
public class Test01Visibility {
    // 1.创建一个使用 volatile 修饰的共享变量
    private static volatile boolean flag = true;
    private static Object obj = new Object();
    public static void main(String[] args) throws InterruptedException {
        // 2.创建一个线程不断读取共享变量
        new Thread(() -&gt; {
            while (flag) {

            }
        }).start();

        Thread.sleep(2000);

        // 3.创建一个线程修改共享变量
        new Thread(() -&gt; {
            flag = false;
            System.out.println(&quot;线程修改了变量的值为false&quot;);
        }).start();
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>线程修改了变量的值为false
</code></pre>
<h3 id="小结-7">小结</h3>
<p>synchronized保证可见性的原理，执行synchronized时，会对应lock原子操作会刷新工作内存中共享变量的值</p>
<h2 id="synchronized与有序性">synchronized与有序性</h2>
<h3 id="为什么要重排序">为什么要重排序</h3>
<p>为了<strong>提高程序的执行效率</strong>，编译器和CPU会对程序中代码进行重排序。</p>
<h3 id="as-if-serial语义">as-if-serial语义</h3>
<p>as-if-serial语义的意思是：不管编译器和CPU如何重排序，必须保证在<strong>单线程情况下程序的结果是正确</strong>的。</p>
<p>以下数据有依赖关系，不能重排序。</p>
<p>写后读：</p>
<pre><code>int a = 1;
int b = a;
</code></pre>
<p>写后写：</p>
<pre><code>int a = 1;
int a = 2;
</code></pre>
<p>读后写：</p>
<pre><code>int a = 1;
int b = a;
int a = 2;
</code></pre>
<p>编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。</p>
<pre><code>int a = 1;
int b = 2;
int c = a + b;
</code></pre>
<p>上面3个操作的数据依赖关系如图所示：<br>
<img src="https://epitomm.github.io/post-images/%E4%B8%89%E4%B8%AA%E6%93%8D%E4%BD%9C%E6%95%B0%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB.png" alt="图片" loading="lazy"></p>
<p>如上图所示 a 和 c 之间存在数据依赖关系，同时 b 和 c 之间也存在数据依赖关系。因此在最终执行的指令序列中，c 不能被重排序到 a 和 b 的前面。但 a 和 b 之间没有数据依赖关系，编译器和处理器可以重排序 a 和 b 之间的执行顺序。下图是该程序的两种执行顺序。</p>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E4%B8%89%E4%B8%AA%E6%93%8D%E4%BD%9C%E6%95%B0%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB2.png" alt="图片" loading="lazy"></figure>
<pre><code>可以这样：
int a = 1;
int b = 2;
int c = a + b;

也可以重排序这样：
int b = 2;
int a = 1;
int c = a + b; 
</code></pre>
<h3 id="使用-synchronized-保证有序性">使用 synchronized 保证有序性</h3>
<pre><code>package com.itheima.demo02_concurrent_problem;

import org.openjdk.jcstress.annotations.*;
import org.openjdk.jcstress.infra.results.I_Result;
@JCStressTest
@Outcome(id = {&quot;1&quot;}, expect = Expect.ACCEPTABLE, desc = &quot;ok&quot;)
@Outcome(id = {&quot;4&quot;}, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;danger2&quot;)
@Outcome(id = &quot;0&quot;, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;danger&quot;)
@State
public class Test03Ordering {
    private Object obj = new Object();
    volatile int num = 0;
    volatile boolean ready = false;
    // 线程1执行的代码
    @Actor
    public void actor1(I_Result r) {
        synchronized (obj){
            if (ready) {
                r.r1 = num + num;
            } else {
                r.r1 = 1;
            }
        }
    }
    // 线程2执行的代码
    @Actor
    public void actor2(I_Result r) {
        synchronized (obj){
            num = 2;
            ready = true;
        }
    }
}
</code></pre>
<p>运行结果只有 1 和 4，没有 0。</p>
<h3 id="synchronized保证有序性的原理">synchronized保证有序性的原理</h3>
<p>synchronized后，虽然进行了重排序，保证<strong>只有一个线程会进入同步代码块</strong>，也能保证有序性。</p>
<h3 id="小结-8">小结</h3>
<p>synchronized 保证有序性的原理，我们加 synchronized 后，依然会发生重排序，只不过，我们有同步代码块，可以保证只有一个线程执行同步代码中的代码，保证有序性。</p>
<h1 id="第四章synchronized的特性">第四章：synchronized的特性</h1>
<h2 id="可重入特性">可重入特性</h2>
<p>一个线程可以多次执行 synchronized, 重复获取同一把锁。</p>
<pre><code>package com.itheima.demo03_synchronized_nature;

/**
 * 目标:演示 synchronized 可重入
 *     1.自定义一个线程类
 *     2.在线程类的run方法中使用嵌套的同步代码块
 *     3.使用两个线程来执行
 */
public class Demo01 {
    public static void main(String[] args) {
        new MyThread().start();
        new MyThread().start();
    }
    public static void test01() {
        synchronized (MyThread.class) {
            String name = Thread.currentThread().getName();
            System.out.println(name + &quot;进入了同步代码块2&quot;);
        }
    }
}
// 1.自定义一个线程类
class MyThread extends Thread {
    @Override
    public void run() {
        synchronized (MyThread.class) {
            System.out.println(getName() + &quot;进入了同步代码块1&quot;);

            Demo01.test01();
        }
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>Thread-0进入了同步代码块1
Thread-0进入了同步代码块2
Thread-1进入了同步代码块1
Thread-1进入了同步代码块2
</code></pre>
<h3 id="可重入原理">可重入原理</h3>
<p>synchronized 的锁对象中有一个计数器（recursions变量）会<strong>记录线程获得几次锁</strong>。</p>
<h3 id="可重入的好处">可重入的好处</h3>
<ol>
<li>可以避免死锁</li>
<li>可以让我们更好的来封装代码</li>
</ol>
<h3 id="小结-9">小结</h3>
<p>synchronized 是可重入锁，内部锁对象中会有一个计数器记录线程获取几次锁了，在执行完同步代码块时，计数器的数量会-1，直到计数器的数量为0，就释放这个锁。</p>
<h2 id="不可中断特性">不可中断特性</h2>
<p>一个线程获得锁后，另一个线程想要获得锁，必须处于阻塞或等待状态，如果第一个线程不释放锁，第二个线程会一直<strong>阻塞或等待，不可被中断</strong>。</p>
<h3 id="synchronized不可中断演示">synchronized不可中断演示</h3>
<p>synchronized 是不可中断，处于阻塞状态的线程会一直等待锁。</p>
<pre><code>/*
    目标:演示synchronized不可中断
    1.定义一个Runnable
    2.在Runnable定义同步代码块
    3.先开启一个线程来执行同步代码块,保证不退出同步代码块
    4.后开启一个线程来执行同步代码块(阻塞状态)
    5.停止第二个线程
*/
public class Demo02_Uninterruptible {
    private static Object obj = new Object();
    public static void main(String[] args) throws InterruptedException {
        // 1.定义一个Runnable
        Runnable run = () -&gt; {
            // 2.在Runnable定义同步代码块
            synchronized (obj) {
                String name = Thread.currentThread().getName();
                System.out.println(name + &quot;进入同步代码块&quot;);
                // 保证不退出同步代码块
                try {
                    Thread.sleep(888888);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        };
        // 3.先开启一个线程来执行同步代码块
        Thread t1 = new Thread(run);
        t1.start();
        Thread.sleep(1000);
        // 4.后开启一个线程来执行同步代码块(阻塞状态)
        Thread t2 = new Thread(run);
        t2.start();
        // 5.停止第二个线程
        System.out.println(&quot;停止线程前&quot;);
        t2.interrupt();
        System.out.println(&quot;停止线程后&quot;);
        System.out.println(t1.getState());
        System.out.println(t2.getState());
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>Thread-0进入同步代码块
停止线程前
停止线程后
TIMED_WAITING
BLOCKED//处于阻塞状态，不可被中断
</code></pre>
<h3 id="reentrantlock不可中断演示">ReentrantLock不可中断演示</h3>
<pre><code>package com.itheima.demo03_synchronized_nature;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 * 目标:演示Lock不可中断
 */
public class Demo03_Interruptible {
    private static Lock lock = new ReentrantLock();
    public static void main(String[] args) throws InterruptedException {
         test01();
    }

    // 演示Lock不可中断
    public static void test01() throws InterruptedException {
        Runnable run = () -&gt; {
            String name = Thread.currentThread().getName();
            try {
                lock.lock();
                System.out.println(name + &quot;获得锁,进入锁执行&quot;);
                Thread.sleep(88888);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                lock.unlock();
                System.out.println(name + &quot;释放锁&quot;);
            }
        };
        Thread t1 = new Thread(run);
        t1.start();
        Thread.sleep(1000);
        Thread t2 = new Thread(run);
        t2.start();

        System.out.println(&quot;停止t2线程前&quot;);
        t2.interrupt();
        System.out.println(&quot;停止t2线程后&quot;);
        Thread.sleep(1000);
        System.out.println(t1.getState());
        System.out.println(t2.getState());
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>Thread-0获得锁,进入锁执行
停止t2线程前
停止t2线程后
TIMED_WAITING
WAITING //t2 interrupt中断失败，一直处于等待状态
</code></pre>
<h3 id="reentrantlock可中断演示">ReentrantLock可中断演示</h3>
<pre><code>package com.itheima.demo03_synchronized_nature;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 * 目标:演示Lock可中断
 */
public class Demo03_Interruptible {
    private static Lock lock = new ReentrantLock();
    public static void main(String[] args) throws InterruptedException { 
        test02();
    }

    // 演示Lock可中断
    public static void test02() throws InterruptedException {
        Runnable run = () -&gt; {
            String name = Thread.currentThread().getName();
            boolean b = false;
            try {
                b = lock.tryLock(3, TimeUnit.SECONDS);
                if (b) {
                    System.out.println(name + &quot;获得锁,进入锁执行&quot;);
                    Thread.sleep(88888);
                } else {
                    System.out.println(name + &quot;在指定时间没有得到锁做其他操作&quot;);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                if (b) {
                    lock.unlock();
                    System.out.println(name + &quot;释放锁&quot;);
                }
            }
        };

        Thread t1 = new Thread(run);
        t1.start();
        Thread.sleep(1000);
        Thread t2 = new Thread(run);
        t2.start();
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>Thread-0获得锁,进入锁执行
Thread-1在指定时间没有得到锁做其他操作
(阻塞很久)
Thread-0释放锁
</code></pre>
<h3 id="小结-10">小结</h3>
<p>不可中断是指，当一个线程获得锁后，另一个线程一直处于阻塞或等待状态，前一个线程不释放锁，后一个线程会一直阻塞或等待，不可被中断。</p>
<p><code>synchronized</code> 属于不可被中断</p>
<p><code>Lock</code> 的 <code>lock</code> 方法是不可中断的</p>
<p><code>Lock</code> 的 <code>tryLock</code> 方法是可中断的</p>
<h1 id="第五章synchronized-原理">第五章：synchronized 原理</h1>
<h2 id="javap-反汇编">javap 反汇编</h2>
<p>我们编写一个简单的synchronized代码，如下：</p>
<pre><code>public class Demo01 {
    private static Object obj = new Object();
    public static void main(String[] args) {
        synchronized (obj) {
            System.out.println(&quot;1&quot;);
        }
    }
    public synchronized void test() {
        System.out.println(&quot;a&quot;);
    }
}
</code></pre>
<p>我们要看 synchronized 的原理，但是 synchronized 是一个关键字，看不到源码。我们可以将class文件进行反汇编。</p>
<p>JDK自带的一个工具： javap ，对字节码进行反汇编，查看字节码指令。</p>
<p>在 DOS 命令行输入：</p>
<pre><code>javap -p -v C:\Users\Only\悄悄的努力\AQS\synchronized资料\案例\Synchronized\target\classes\com\itheima\demo04_synchronized_monitor\Demo01
</code></pre>
<p>反汇编后的效果如下：</p>
<pre><code>  public static void main(java.lang.String[]);
    descriptor: ([Ljava/lang/String;)V
    flags: (0x0009) ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=3, args_size=1
         0: getstatic     #2                  // Field obj:Ljava/lang/Object;
         3: dup
         4: astore_1
         5: monitorenter
         6: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;
         9: ldc           #4                  // String 1
        11: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        14: aload_1
        15: monitorexit
        16: goto          24
        19: astore_2
        20: aload_1
        21: monitorexit
        22: aload_2
        23: athrow
        24: return
      Exception table:
         from    to  target type
             6    16    19   any
            19    22    19   any
      LineNumberTable:
        line 7: 0
        line 8: 6
        line 9: 14
        line 10: 24
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      25     0  args   [Ljava/lang/String;
      StackMapTable: number_of_entries = 2
        frame_type = 255 /* full_frame */
          offset_delta = 19
          locals = [ class &quot;[Ljava/lang/String;&quot;, class java/lang/Object ]
          stack = [ class java/lang/Throwable ]
        frame_type = 250 /* chop */
          offset_delta = 4

  public synchronized void test();
    descriptor: ()V
    flags: (0x0021) ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #6                  // String a
         5: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return
      LineNumberTable:
        line 13: 0
        line 14: 8
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0       9     0  this   Lcom/itheima/demo04_synchronized_monitor/Demo01;
  static {};
    descriptor: ()V
    flags: (0x0008) ACC_STATIC
    Code:
      stack=2, locals=0, args_size=0
         0: new           #7                  // class java/lang/Object
         3: dup
         4: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V
         7: putstatic     #2                  // Field obj:Ljava/lang/Object;
        10: return
      LineNumberTable:
        line 4: 0
}

SourceFile: &quot;Demo01.java&quot;
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E5%90%8C%E6%AD%A5%E4%BB%A3%E7%A0%81%E5%9D%97.png" alt="图片" loading="lazy"></figure>
<p>同步代码块</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/synchronized.png" alt="图片" loading="lazy"></figure>
<h3 id="monitorenter">monitorenter</h3>
<p><strong>首先我们来看一下JVM规范中对于monitorenter的描述：</strong></p>
<p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5.monitorenter">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5.monitorenter</a></p>
<blockquote>
<p>Each object is associated with a monitor. A monitor is locked if and only if it has an owner.<br>
The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref， as follows:<br>
If the entry count of the monitor associated with objectref is zero， the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.<br>
If the thread already owns the monitor associated with objectref， it reenters the monitor， incrementing its entry count.<br>
If another thread  already owns the monitor associated with objectref， the thread blocks until the monitor's entry count is zero， then tries again to gain ownership.</p>
</blockquote>
<p>翻译过来： 每一个对象都会和一个监视器 monitor 关联。监视器被占用时会被锁住，其他线程无法来获 取该 monitor。 当 JVM 执行某个线程的某个方法内部的 monitorenter 时，它会尝试去获取当前对象对应的 monitor 的所有权。其过程如下：</p>
<ol>
<li>若 monior 的进入数为 0，线程可以进入 monitor，并将 monitor 的进入数置为 1。当前线程成为 monitor 的owner（所有者）</li>
<li>若当前线程已拥有 monitor 的所有权，允许它重入 monitor，则进入 monitor 的进入数加 1</li>
<li>若其他线程已经占有 monitor 的所有权，那么当前尝试获取 monitor 的所有权的线程会被阻塞，直到 monitor 的进入数变为 0，才能重新尝试获取 monitor 的所有权。</li>
</ol>
<p><strong>monitorenter小结：</strong></p>
<p>synchronized 的锁对象会关联一个 monitor, 这个 monitor 不是我们主动创建的，是 JVM 的线程执行到这个同步代码块,发现锁对象没有 monitor 就会创建 monitor, monitor 内部有两个重要的成员变量 <strong>owner:拥有这把锁的线程</strong>, <strong>recursions会记录线程拥有锁的次数</strong>，当一个线程拥有 monito r后其他线程只能等待。</p>
<h3 id="monitorexit">monitorexit</h3>
<p><strong>首先我们来看一下JVM规范中对于monitorexit的描述：</strong></p>
<p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5.monitorexit">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5.monitorexit</a></p>
<blockquote>
<p>The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.<br>
The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero， the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.</p>
</blockquote>
<p>翻译过来：</p>
<ol>
<li>能执行 monitorexit 指令的线程一定是拥有当前对象的 monitor 的所有权的线程。</li>
<li>执行 monitorexit 时会将 monitor 的进入数减 1。当 monitor 的进入数减为 0 时，当前线程退出 monitor，不再拥有 monitor 的所有权，此时其他被这个 monitor 阻塞的线程可以尝试去获取这个 monitor 的所有权 。</li>
</ol>
<h4 id="monitorexit-释放锁">monitorexit 释放锁。</h4>
<p>monitorexit 插入在<strong>方法结束处</strong>和<strong>异常处</strong>，JVM保证每个 monitorenter 必须有对应的monitorexit。</p>
<h4 id="面试题-synchroznied-出现异常会释放锁吗">面试题 synchroznied 出现异常会释放锁吗?</h4>
<p>会释放锁</p>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/synchronized%E5%87%BA%E7%8E%B0%E5%BC%82%E5%B8%B8%E4%BC%9A%E9%87%8A%E6%94%BE%E9%94%81.png" alt="图片" loading="lazy"></figure>
<p>synchronized出现异常会释放锁</p>
<h3 id="同步方法">同步方法</h3>
<p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.11.10">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.11.10</a></p>
<p>可以看到同步方法在反汇编后，会增加 <code>ACC_SYNCHRONIZED</code> 修饰。会隐式调用 monitorenter 和 monitorexit。在执行同步方法前会调用 monitorenter，在执行完同步方法后会调用 monitorexit。</p>
<figure data-type="image" tabindex="14"><img src="https://epitomm.github.io/post-images/%E5%90%8C%E6%AD%A5%E6%96%B9%E6%B3%95.png" alt="图片" loading="lazy"></figure>
<p style = "text-align:center">同步方法</p>
<h3 id="小结-11">小结</h3>
<p>通过 javap 反汇编我们看到 synchronized 使用变成了 monitorenter 和 monitorexit 两个指令.每个锁对象都会关联一个 monitor(监视器,它才是真正的锁对象),它内部有两个重要的成员变量owner 会保存获得锁的线程，recursions 会保存线程获得锁的次数,当执行到 monitorexit 时,recursions 会 -1,当计数器减到 0 时这个线程就会释放锁。</p>
<h3 id="面试题synchronized与lock的区别">面试题：synchronized与Lock的区别</h3>
<ol>
<li>synchronized 是关键字，而 Lock 是一个接口。</li>
<li>synchronized 会自动释放锁，而 Lock 必须手动释放锁。</li>
<li>synchronized 是不可中断的，Lock 可以中断也可以不中断。</li>
<li>通过 Lock 可以知道线程有没有拿到锁（tryLock()的返回值），而 synchronized 不能。</li>
<li>synchronized 能锁住方法和代码块，而 Lock 只能锁住代码块。</li>
<li>Lock 可以使用读锁提高多线程读效率（ReentrantReadWriteLock）。</li>
<li>synchronized 是非公平锁，ReentrantLock 可以控制是否是公平锁。</li>
</ol>
<h2 id="深入jvm源码">深入JVM源码</h2>
<h3 id="jvm源码下载">JVM源码下载</h3>
<p><a href="http://openjdk.java.net/">http://openjdk.java.net/</a> --&gt; Mercurial --&gt; jdk8 --&gt; hotspot --&gt; zip</p>
<h3 id="ideclion-下载">IDE(Clion )下载</h3>
<p><a href="https://www.jetbrains.com/">https://www.jetbrains.com/</a></p>
<h3 id="monitor监视器锁">monitor监视器锁</h3>
<p>可以看出无论是 synchronized 代码块还是 synchronized 方法，其线程安全的语义实现最终依赖一个叫 monitor 的东西，那么这个神秘的东西是什么呢？下面让我们来详细介绍一下。</p>
<p>在 HotSpot 虚拟机中，monitor 是由 ObjectMonitor 实现的。其源码是用 C++ 来实现的，位于HotSpot 虚拟机源码 ObjectMonitor.hpp 文件中(src/share/vm/runtime/objectMonitor.hpp)。ObjectMonitor 主要数据结构如下：</p>
<pre><code>ObjectMonitor() { 
  _header = NULL; 
  _count = 0; 
  _waiters = 0， 
  _recursions = 0; // 线程的重入次数
  _object = NULL; // 存储该monitor的对象 
  _owner = NULL; // 标识拥有该monitor的线程 
  _WaitSet = NULL; // 处于wait状态的线程，会被加入到_WaitSet 
  _WaitSetLock = 0 ; 
  _Responsible = NULL; 
  _succ = NULL; 
  _cxq = NULL; // 多线程竞争锁时的单向列表 
  FreeNext = NULL; 
  _EntryList = NULL; // 处于等待锁block状态的线程，会被加入到该列表 
  _SpinFreq = 0; 
  _SpinClock = 0; 
  OwnerIsThread = 0; 
}
</code></pre>
<ol>
<li>_owner：初始时为NULL。当有<strong>线程占有该monitor</strong>时，owner 标记为该线程的唯一标识。当线程释放 monitor 时，owner又恢复为 NULL。owner 是一个临界资源，JVM 是通过 CAS 操作来保证其线程安全的。</li>
<li>_cxq：竞争队列，<strong>所有请求锁的线程</strong>首先会被放在这个队列中（单向链接）。_cxq 是一个临界资源，JVM 通过 CAS 原子指令来修改 _cxq 队列。修改前 _cxq 的旧值填入了 node 的 next 字段，_cxq 指向新值（新线程）。因此_cxq 是一个后进先出的 stack（栈）。</li>
<li>_EntryList：_cxq 队列中<strong>有资格成为候选资源的线程</strong>会被移动到该队列中。</li>
<li>_WaitSet：因为<strong>调用wait方法而被阻塞</strong>的线程会被放在该队列中。</li>
</ol>
<figure data-type="image" tabindex="15"><img src="https://epitomm.github.io/post-images/monitor%E7%9B%91%E8%A7%86%E5%99%A8.png" alt="图片" loading="lazy"></figure>
<p>每一个 Java 对象都可以与一个监视器 monitor 关联，我们可以把它理解成为一把锁，当一个线程想要执行一段被 synchronized 圈起来的同步方法或者代码块时，该线程得先获取到 synchronized 修饰的对象对应的 monitor。</p>
<p>我们的 Java 代码里不会显示地去创造这么一个 monitor 对象，我们也无需创建，事实上可以这么理解： monitor 并不是随着对象创建而创建的。我们是通过 synchronized 修饰符告诉 JVM 需要为我们的某个对象创建关联的 monitor 对象。每个线程都存在两个 ObjectMonitor 对象列表，分别为free 和 used 列表。 同时 JVM 中也维护着 global locklist。当线程需要 ObjectMonitor 对象时，首先从线程自身的 free 表中申请，若存在则使用，若不存在则从 global list 中申请。</p>
<p>ObjectMonitor 的数据结构中包含：_owner、_WaitSet 和 _EntryList，它们之间的关系转换可以用下图表示：</p>
<figure data-type="image" tabindex="16"><img src="https://epitomm.github.io/post-images/monitor%E7%9B%91%E8%A7%86%E5%99%A8%E9%94%812.png" alt="图片" loading="lazy"></figure>
<h3 id="monitor竞争">monitor竞争</h3>
<ul>
<li>什么时候会产生 monitor 竞争
<ul>
<li>两个线程同时执行 synchronized 时，会发生竞争。</li>
</ul>
</li>
</ul>
<p><strong>如何竞争</strong></p>
<ol>
<li>执行 monitorenter 时，会调用InterpreterRuntime.cpp</li>
</ol>
<p>(位于：src/share/vm/interpreter/interpreterRuntime.cpp) 的 InterpreterRuntime::monitorenter 函数。具体代码可参见 HotSpot 源码。</p>
<pre><code>IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))
#ifdef ASSERT
  thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
#endif
  if (PrintBiasedLockingStatistics) {
    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());
  }
  Handle h_obj(thread, elem-&gt;obj());
  assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()),
         &quot;must be NULL or an object&quot;);
  if (UseBiasedLocking) {//是否设置使用了偏向锁
    // Retry fast entry if bias is revoked to avoid unnecessary inflation
    ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK);
  } else {  // 使用重量级锁
    ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK);
  }
  assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()),
         &quot;must be NULL or an object&quot;);
</code></pre>
<ol>
<li>对于重量级锁，monitorenter 函数中会调用 ObjectSynchronizer::slow_enter</li>
<li>最终调用 ObjectMonitor::enter（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下：</li>
</ol>
<pre><code>void ATTR ObjectMonitor::enter(TRAPS) { 
  // The following code is ordered to check the most common cases first 
  // and to reduce RTS-&gt;RTO cache line upgrades on SPARC and IA32 processors. 
  Thread * const Self = THREAD ; 
  void * cur ; 
  
  // 通过CAS操作尝试把monitor的_owner字段设置为当前线程 
  cur = Atomic::cmpxchg_ptr (Self， &amp;_owner， NULL) ; 
  if (cur == NULL) { 
    // Either ASSERT _recursions == 0 or explicitly set _recursions = 0. 
    assert (_recursions == 0 ， &quot;invariant&quot;) ; 
    assert (_owner == Self， &quot;invariant&quot;) ; 
    // CONSIDER: set or assert OwnerIsThread == 1 
    return ; 
  }
  // 线程重入，recursions++ 
  if (cur == Self) { 
    // TODO-FIXME: check for integer overflow! BUGID 6557169. 
    _recursions ++ ; 
    return ; 
  }
  
  // 如果当前线程是第一次进入该monitor，设置_recursions为1，_owner为当前线程
  if (Self-&gt;is_lock_owned ((address)cur)) {
    assert (_recursions == 0， &quot;internal state error&quot;);
    _recursions = 1 ;
    // Commute owner from a thread-specific on-stack BasicLockObject address to
    // a full-fledged &quot;Thread *&quot;.
    _owner = Self ;
    OwnerIsThread = 1 ;
    return ;
  }
  
  // 省略一些代码
  for (;;) {
    jt-&gt;set_suspend_equivalent();
    // cleared by handle_special_suspend_equivalent_condition()
    // or java_suspend_self()
    
    // 如果获取锁失败，则阻塞，等待锁的释放，进入_cxq列表；
    EnterI (THREAD) ;
    
    if (!ExitSuspendEquivalent(jt)) break ;

  //
  // We have acquired the contended monitor， but while we were
  // waiting another thread suspended us. We don't want to enter
  // the monitor while suspended because that would surprise the
  // thread that suspended us.
  //
      _recursions = 0 ;
    _succ = NULL ;
    exit (false， Self) ;
  
    jt-&gt;java_suspend_self();
  }
  Self-&gt;set_current_pending_monitor(NULL);
}
</code></pre>
<p>此处省略锁的自旋优化等操作，统一放在后面synchronzied优化中说。<br>
以上代码的具体流程概括如下：</p>
<ol>
<li>通过CAS尝试把 monitor 的 owner 字段设置为当前线程。</li>
<li>如果设置之前的 owner 指向当前线程，说明当前线程再次进入monitor，即重入锁，执行 _recursions++ ，记录重入的次数。</li>
<li>如果当前线程是第一次进入该 monitor，设置 _recursions 为 1，_owner 为当前线程，该线程成功获得锁并返回。</li>
<li>如果获取锁失败，则等待锁的释放。</li>
</ol>
<h3 id="monitor等待">monitor等待</h3>
<p>竞争失败等待调用的是 ObjectMonitor 对象的 EnterI 方法（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下所示：</p>
<pre><code>void ATTR ObjectMonitor::EnterI (TRAPS) { 
  Thread * Self = THREAD ;
  
  // Try the lock - TATAS 
  if (TryLock (Self) &gt; 0) { 
    assert (_succ != Self , &quot;invariant&quot;) ; 
    assert (_owner == Self , &quot;invariant&quot;) ; 
    assert (_Responsible != Self , &quot;invariant&quot;) ; 
    return ; 
  }
  
  if (TrySpin (Self) &gt; 0) { 
    assert (_owner == Self , &quot;invariant&quot;) ; 
    assert (_succ != Self , &quot;invariant&quot;) ; 
    assert (_Responsible != Self , &quot;invariant&quot;) ; 
    return ; 
  }
  
  // 省略部分代码 
  
  // 当前线程被封装成ObjectWaiter对象node，状态设置成ObjectWaiter::TS_CXQ； 
  ObjectWaiter node(Self) ; 
  Self-&gt;_ParkEvent-&gt;reset() ; 
  node._prev = (ObjectWaiter *) 0xBAD ; 
  node.TState = ObjectWaiter::TS_CXQ ; 
  
  // 通过CAS把node节点push到_cxq列表中 
  ObjectWaiter * nxt ; 
  for (;;) { 
    node._next = nxt = _cxq ; 
    if (Atomic::cmpxchg_ptr (&amp;node， &amp;_cxq， nxt) == nxt) break ; 
    
    // Interference - the CAS failed because _cxq changed. Just retry. 
    // As an optional optimization we retry the lock. 
    if (TryLock (Self) &gt; 0) { 
      assert (_succ != Self ， &quot;invariant&quot;) ; 
      assert (_owner == Self ， &quot;invariant&quot;) ; 
      assert (_Responsible != Self ， &quot;invariant&quot;) ; 
      return ; 
    } 
  }
  
  // 省略部分代码 
  for (;;) { 
    // 线程在被挂起前做一下挣扎，看能不能获取到锁 
    if (TryLock (Self) &gt; 0) break ; 
    assert (_owner != Self， &quot;invariant&quot;) ; 
    if ((SyncFlags &amp; 2) &amp;&amp; _Responsible == NULL) { 
      Atomic::cmpxchg_ptr (Self， &amp;_Responsible， NULL) ; 
    }
    
    // park self 
    if (_Responsible == Self || (SyncFlags &amp; 1)) { 
      TEVENT (Inflated enter - park TIMED) ; 
      Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; 
      // Increase the RecheckInterval， but clamp the value. 
      RecheckInterval *= 8 ; 
      if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; 
    } else { 
      TEVENT (Inflated enter - park UNTIMED) 
      // 通过park将当前线程挂起，等待被唤醒 
      Self-&gt;_ParkEvent-&gt;park() ; 
    }
    // 被唤醒后尝试获取锁
    if (TryLock(Self) &gt; 0) break ; 
    // 省略部分代码 
  }
  
  // 省略部分代码 
}
</code></pre>
<p>当该线程被唤醒时，会从挂起的点继续执行，通过 ObjectMonitor::TryLock 尝试获取锁，TryLock方法实现如下：</p>
<pre><code>int ObjectMonitor::TryLock (Thread * Self) { 
  for (;;) { 
    void * own = _owner ; 
    if (own != NULL) return 0 ; 
    // CAS 尝试获取锁
    if (Atomic::cmpxchg_ptr (Self， &amp;_owner， NULL) == NULL) { 
      // Either guarantee _recursions == 0 or set _recursions = 0. 
      assert (_recursions == 0， &quot;invariant&quot;) ; 
      assert (_owner == Self， &quot;invariant&quot;) ; 
      // CONSIDER: set or assert that OwnerIsThread == 1 
      return 1 ; 
    }
    // The lock had been free momentarily， but we lost the race to the lock. 
    // Interference -- the CAS failed. 
    // We can either return -1 or retry. 
    // Retry doesn't make as much sense because the lock was just acquired. 
    if (true) return -1 ; 
  } 
}
</code></pre>
<p>以上代码的具体流程概括如下：</p>
<ol>
<li>当前线程被封装成 ObjectWaiter 对象 node，状态设置成 ObjectWaiter::TS_CXQ。</li>
<li>在 for 循环中，通过 CAS 把 node 节点 push 到 _cxq 列表中，同一时刻可能有多个线程把自己的 node 节点 pus h到 _cxq 列表中。</li>
<li>node 节点 push 到 _cxq 列表之后，通过自旋尝试获取锁，如果还是没有获取到锁，则通过 park 将当前线程挂起，等待被唤醒。</li>
<li>当该线程被唤醒时，会从挂起的点继续执行，通过 ObjectMonitor::TryLock 尝试获取锁。</li>
</ol>
<h3 id="monitor释放">monitor释放</h3>
<p>当某个持有锁的线程执行完同步代码块时，会进行锁的释放，给其它线程机会执行同步代码，在 HotSpot 中，通过退出 monitor 的方式实现锁的释放，并通知被阻塞的线程，具体实现位于 ObjectMonitor 的 exit 方法中。（位于：src/share/vm/runtime/objectMonitor.cpp），源码如下所示：</p>
<pre><code>void ATTR ObjectMonitor::exit(bool not_suspended， TRAPS) { 
  Thread * Self = THREAD ; 
  // 省略部分代码 
  // 重入锁
  if (_recursions != 0) { 
    _recursions--; // this is simple recursive enterTEVENT (Inflated exit - recursive) ; 
    return ; 
  }
  
  // 省略部分代码 
  // 等待的线程用 ObjectWaiter 包装，使用变量 w 存放被唤醒的线程
  ObjectWaiter * w = NULL ; 
  int QMode = Knob_QMode ; 
  
  // qmode = 2：直接绕过EntryList队列，从cxq队列中获取线程用于竞争锁 
  if (QMode == 2 &amp;&amp; _cxq != NULL) { 
    w = _cxq ; // _cxq 的链表头赋值给 w
    assert (w != NULL， &quot;invariant&quot;) ; 
    assert (w-&gt;TState == ObjectWaiter::TS_CXQ， &quot;Invariant&quot;) ; 
    ExitEpilog (Self， w) ; // 唤醒线程
    return ; 
  }
  
  // qmode =3：cxq队列插入EntryList尾部； 
  if (QMode == 3 &amp;&amp; _cxq != NULL) { 
    w = _cxq ; 
    for (;;) { 
      assert (w != NULL， &quot;Invariant&quot;) ; 
      ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL， 
      &amp;_cxq， w) ; 
      if (u == w) break ; 
      w = u ; 
    }
    assert (w != NULL ， &quot;invariant&quot;) ; 
    
    ObjectWaiter * q = NULL ; 
    ObjectWaiter * p ; 
    for (p = w ; p != NULL ; p = p-&gt;_next) { 
      guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ， &quot;Invariant&quot;) ; 
      p-&gt;TState = ObjectWaiter::TS_ENTER ; 
      p-&gt;_prev = q ; 
      q = p ; 
    }
    ObjectWaiter * Tail ; 
    for (Tail = _EntryList ; Tail != NULL &amp;&amp; Tail-&gt;_next != NULL ; Tail = Tail-&gt;_next) ; 
    if (Tail == NULL) { 
      _EntryList = w ; 
    } else { 
      Tail-&gt;_next = w ; 
      w-&gt;_prev = Tail ; 
    } 
  }
  
  // qmode =4：cxq队列插入到_EntryList头部 
  if (QMode == 4 &amp;&amp; _cxq != NULL) { 
    w = _cxq ; 
    for (;;) { 
      assert (w != NULL， &quot;Invariant&quot;) ; 
      ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL， 
      &amp;_cxq， w) ; 
      if (u == w) break ; 
      w = u ;
    }
    assert (w != NULL ， &quot;invariant&quot;) ; 
    
    ObjectWaiter * q = NULL ; 
    ObjectWaiter * p ; 
    for (p = w ; p != NULL ; p = p-&gt;_next) { 
      guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ， &quot;Invariant&quot;) ; 
      p-&gt;TState = ObjectWaiter::TS_ENTER ; 
      p-&gt;_prev = q ; 
      q = p ; 
    }
    if (_EntryList != NULL) { 
      q-&gt;_next = _EntryList ; 
      _EntryList-&gt;_prev = q ; 
    }
    _EntryList = w ; 
  }
  w = _EntryList ; 
  if (w != NULL) { 
    assert (w-&gt;TState == ObjectWaiter::TS_ENTER， &quot;invariant&quot;) ; 
    ExitEpilog (Self， w) ; 
    return ; 
  }
  w = _cxq ; 
  if (w == NULL) continue ; 
  for (;;) { 
    assert (w != NULL， &quot;Invariant&quot;) ; 
    ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL， &amp;_cxq，w) ; 
    if (u == w) break ; 
    w = u ; 
  }
  TEVENT (Inflated exit - drain cxq into EntryList) ; 
  assert (w != NULL ， &quot;invariant&quot;) ; 
  assert (_EntryList == NULL ， &quot;invariant&quot;) ; 
  if (QMode == 1) { 
    // QMode == 1 : drain cxq to EntryList， reversing order 
    // We also reverse the order of the list. 
    ObjectWaiter * s = NULL ; 
    ObjectWaiter * t = w ; 
    ObjectWaiter * u = NULL ; 
    while (t != NULL) { 
      guarantee (t-&gt;TState == ObjectWaiter::TS_CXQ， &quot;invariant&quot;) ; 
      t-&gt;TState = ObjectWaiter::TS_ENTER ; 
      u = t-&gt;_next ; 
      t-&gt;_prev = u ; 
      t-&gt;_next = s ; 
      s = t; 
      t = u ; 
    }
    _EntryList = s ; 
    assert (s != NULL， &quot;invariant&quot;) ;
  } else { 
    // QMode == 0 or QMode == 2 
    _EntryList = w ; 
    ObjectWaiter * q = NULL ; 
    ObjectWaiter * p ; 
    for (p = w ; p != NULL ; p = p-&gt;_next) { 
      guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ， &quot;Invariant&quot;) ; 
      p-&gt;TState = ObjectWaiter::TS_ENTER ; 
      p-&gt;_prev = q ; 
      q = p ; 
      } 
    }
    if (_succ != NULL) continue; 
    
    w = _EntryList ; 
    if (w != NULL) { 
      guarantee (w-&gt;TState == ObjectWaiter::TS_ENTER， &quot;invariant&quot;) ; 
      ExitEpilog (Self， w) ; // 唤醒线程
      return ; 
    } 
  } 
}
</code></pre>
<ol>
<li>退出同步代码块时会让 _recursions 减 1，当 _recursions 的值减为0时，说明线程释放了锁。</li>
<li>根据不同的策略（由QMode指定），从 _cxq 或 EntryList 中获取头节点，通过ObjectMonitor::ExitEpilog 方法唤醒该节点封装的线程，唤醒操作最终由 unpark 完成，实现如下：</li>
</ol>
<pre><code>void ObjectMonitor::ExitEpilog (Thread * Self， ObjectWaiter * Wakee) { 
  assert (_owner == Self， &quot;invariant&quot;) ; 
  
  _succ = Knob_SuccEnabled ? Wakee-&gt;_thread : NULL ; 
  ParkEvent * Trigger = Wakee-&gt;_event ; 
  
  Wakee = NULL ; 
  
  // Drop the lock 
  OrderAccess::release_store_ptr (&amp;_owner， NULL) ; 
  OrderAccess::fence() ; // ST _owner vs LD in 
  unpark() 
  if (SafepointSynchronize::do_call_back()) { 
    TEVENT (unpark before SAFEPOINT) ; 
  }
  
  DTRACE_MONITOR_PROBE(contended__exit， this， object()， Self); 
  Trigger-&gt;unpark() ; // 唤醒之前被pack()挂起的线程. 
  
  // Maintain stats and report events to JVMTI 
  if (ObjectMonitor::_sync_Parks != NULL) { 
    ObjectMonitor::_sync_Parks-&gt;inc() ; 
  } 
}
</code></pre>
<p>被唤醒的线程，会回到 void ATTR ObjectMonitor::EnterI (TRAPS) 的第600行，继续执行monitor 的竞争。</p>
<pre><code>// park self 
if (_Responsible == Self || (SyncFlags &amp; 1)) { 
  TEVENT (Inflated enter - park TIMED) ; 
  Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; 
  // Increase the RecheckInterval， but clamp the value. 
  RecheckInterval *= 8 ; 
  if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; 
} else { 
  TEVENT (Inflated enter - park UNTIMED) ; 
  Self-&gt;_ParkEvent-&gt;park() ; 
}
if (TryLock(Self) &gt; 0) break ;
</code></pre>
<h3 id="monitor是重量级锁">monitor是重量级锁</h3>
<p>可以看到 ObjectMonitor 的函数调用中会涉及到 Atomic::cmpxchg_ptr，Atomic::inc_ptr 等内核函数，执行同步代码块，没有竞争到锁的对象会 park() 被挂起，竞争到锁的线程会 unpark() 唤醒。这个时候就会存在操作系统<strong>用户态和内核态的转换</strong>，这种切换会消耗大量的系统资源。所以synchronized 是 Java 语言中是一个重量级(Heavyweight)的操作。</p>
<p>用户态和和内核态是什么东西呢？要想了解用户态和内核态还需要先了解一下 Linux 系统的体系架构：</p>
<figure data-type="image" tabindex="17"><img src="https://epitomm.github.io/post-images/Linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<p style = "text-align:center">Linux系统的体系架构</p>
<p>从上图可以看出，Linux操作系统的体系架构分为：用户空间（应用程序的活动空间）和内核。</p>
<p><strong>内核</strong>：本质上可以理解为一种软件，控制计算机的硬件资源，并提供上层应用程序运行的环境。</p>
<p><strong>用户空间</strong>：上层应用程序活动的空间。应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等。</p>
<p><strong>系统调用</strong>：为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即系统调用。</p>
<p>所有进程初始都运行于用户空间，此时即为用户运行状态（简称：用户态）；但是当它调用系统调用执行某些操作时，例如 I/O调用，此时需要陷入内核中运行，我们就称进程处于内核运行态（或简称为内核态）。 系统调用的过程可以简单理解为：</p>
<ol>
<li>用户态程序将一些数据值放在寄存器中， 或者使用参数创建一个堆栈， 以此表明需要操作系统提供的服务。</li>
<li>用户态程序执行系统调用。</li>
<li>CPU切换到内核态，并跳到位于内存指定位置的指令。</li>
<li>系统调用处理器(system call handler)会读取程序放入内存的数据参数，并执行程序请求的服务。</li>
<li>系统调用完成后，操作系统会重置CPU为用户态并返回系统调用的结果。</li>
</ol>
<p>由此可见用户态切换至内核态需要传递许多变量，同时内核还需要保护好用户态在切换时的一些寄存器值、变量等，以备内核态切换回用户态。<strong>这种切换就带来了大量的系统资源消耗</strong>，这就是在 synchronized 未优化之前，效率低的原因。</p>
<h1 id="第六章jdk6-synchronized优化">第六章：JDK6 synchronized优化</h1>
<h2 id="cas">CAS</h2>
<p>CAS的全称是： Compare And Swap(比较相同再交换)。是现代CPU广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。</p>
<p>CAS的作用：CAS可以将比较和交换转换为原子操作，这个<strong>原子操作直接由CPU保证</strong>。CAS可以保证共享变量赋值时的原子操作。CAS操作依赖3个值：内存中的值V，旧的预估值X，要修改的新值B，如果旧的预估值X等于内存中的值V，就将新的值B保存到内存中。</p>
<p><strong>CAS 和 volatile 实现无锁并发</strong></p>
<pre><code>package com.itheima.demo05_cas;
import java.util.ArrayList;
import java.util.concurrent.atomic.AtomicInteger;
public class Demo01 {
    public static void main(String[] args) throws InterruptedException {
        AtomicInteger atomicInteger = new AtomicInteger();
        Runnable mr = () -&gt; {
            for (int i = 0; i &lt; 1000; i++) {
                atomicInteger.incrementAndGet();
            }
        };
        ArrayList&lt;Thread&gt; ts = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 5; i++) {
            Thread t = new Thread(mr);
            t.start();
            ts.add(t);
        }
        for (Thread t : ts) {
            t.join();
        }
        System.out.println(&quot;atomicInteger = &quot; + atomicInteger.get());
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code>atomicInteger  = 5000
</code></pre>
<h3 id="cas原理">CAS原理</h3>
<p>通过刚才 AtomicInteger 的源码我们可以看到，Unsafe 类提供了原子操作。</p>
<p><strong>Unsafe类介绍</strong></p>
<p>Unsafe 类使 Java 拥有了像 C 语言的指针一样操作内存空间的能力，同时也带来了指针的问题。过度的使用 Unsafe 类会使得出错的几率变大，因此 Java 官方并不建议使用的，官方文档也几乎没有。Unsafe 对象不能直接调用，只能通过反射获得。</p>
<figure data-type="image" tabindex="18"><img src="https://epitomm.github.io/post-images/unsafe%E7%B1%BB.png" alt="图片" loading="lazy"></figure>
<pre><code>public class AtomicInteger extends Number implements java.io.Serializable {
    private static final long serialVersionUID = 6214790243416807050L;

    // setup to use Unsafe.compareAndSwapInt for updates
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    // value 的偏移地址
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));
        } catch (Exception ex) {
             throw new Error(ex); 
        }
    }
    // 数字保存在 value 中。根据 AtomicInteger 对象的内存地址 和 value 的偏移地址，找到 value 的值
    private volatile int value;
</code></pre>
<p><strong>Unsafe实现CAS</strong><br>
<img src="https://epitomm.github.io/post-images/unsafe%E5%AE%9E%E7%8E%B0CAS.png" alt="图片" loading="lazy"></p>
<h3 id="乐观锁和悲观锁">乐观锁和悲观锁</h3>
<p><strong>悲观锁</strong>从悲观的角度出发：</p>
<p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞。因此<strong>synchronized</strong>我们也将其称之为悲观锁。JDK中的<strong>ReentrantLock</strong>也是一种悲观锁。性能较差！</p>
<p><strong>乐观锁</strong>从乐观的角度出发:</p>
<p>总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，就算改了也没关系，再重试即可。所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去修改这个数据，如果没有人修改则更新，如果有人修改则重试。</p>
<p>CAS这种机制我们也可以将其称之为乐观锁。综合性能较好！</p>
<blockquote>
<p>CAS获取共享变量时，为了保证该变量的可见性，需要使用volatile修饰。结合CAS和volatile可以实现无锁并发，适用于竞争不激烈、多核 CPU 的场景下。</p>
<ol>
<li>因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一。</li>
<li>但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响。</li>
</ol>
</blockquote>
<h3 id="小结-12">小结</h3>
<ul>
<li><strong>CAS的作用?</strong>
<ul>
<li>Compare And Swap，CAS可以将比较和交换转换为原子操作，这个原子操作直接由处理器保证。</li>
</ul>
</li>
<li><strong>CAS的原理？</strong>
<ul>
<li>CAS需要3个值:内存地址V，旧的预期值A，要修改的新值B，如果内存地址V和旧的预期值A相等就修改内存地址值为B</li>
</ul>
</li>
</ul>
<h2 id="synchronized锁升级过程">synchronized锁升级过程</h2>
<p>高效并发是从 JDK5 到 JDK6 的一个重要改进，HotSpot 虛拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术，包括偏向锁( Biased Locking )、轻量级锁( Lightweight Locking )和如适应性自旋(Adaptive Spinning)、锁消除( Lock Elimination)、锁粗化( Lock Coarsening )等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。</p>
<p><strong>无锁 --&gt; 偏向锁 --&gt; 轻量级锁 –&gt; 重量级锁</strong></p>
<h2 id="java对象的布局">Java对象的布局</h2>
<p>术语参考: <a href="http://openjdk.java.net/groups/hotspot/docs/HotSpotGlossary.html">http://openjdk.java.net/groups/hotspot/docs/HotSpotGlossary.html</a></p>
<p>在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。如下图所示：</p>
<figure data-type="image" tabindex="19"><img src="https://epitomm.github.io/post-images/%E5%AF%B9%E8%B1%A1%E5%A4%B4.png" alt="图片" loading="lazy"></figure>
<h3 id="对象头">对象头</h3>
<p>当一个线程尝试访问 synchronized 修饰的代码块时，它首先要获得锁，那么这个锁到底存在哪里呢？是存在锁对象的对象头中的。</p>
<p>HotSpot 采用 instanceOopDesc 和 arrayOopDesc 来描述对象头，arrayOopDesc 对象用来描述数组类型。instanceOopDesc 的定义的在 Hotspot 源码的 instanceOop.hpp 文件中，另外，arrayOopDesc 的定义对应 arrayOop.hpp 。</p>
<pre><code>class instanceOopDesc : public oopDesc {
    public:
    // aligned header size.
    static int header_size() { return sizeof(instanceOopDesc)/HeapWordSize; }
    // If compressed, the offset of the fields of the instance may not be aligned.
    static int base_offset_in_bytes() {
    // offset computation code breaks if UseCompressedClassPointers
    // only is true
            return (UseCompressedOops &amp;&amp; UseCompressedClassPointers) ?
            klass_gap_offset_in_bytes() :
            sizeof(instanceOopDesc);
    }
    static bool contains_field_offset(int offset, int nonstatic_field_size) {
        int base_in_bytes = base_offset_in_bytes();
        return (offset &gt;= base_in_bytes &amp;&amp;
            (offset-base_in_bytes) &lt; nonstatic_field_size * heapOopSize);
    }
};
</code></pre>
<p>从 instanceOopDesc 代码中可以看到 instanceOopDesc 继承自 oopDesc，oopDesc 的定义在Hotspot 源码中的 oop.hpp 文件中。</p>
<pre><code>class oopDesc {
    friend class VMStructs;
   private:
    volatile markOop _mark;
    union _metadata {
        Klass* _klass;
        narrowKlass _compressed_klass;
    } _metadata;
// Fast access to barrier set. Must be initialized. 
    static BarrierSet* _bs;
// 省略其他代码 
};
</code></pre>
<p>在普通实例对象中，oopDesc 的定义包含两个成员，分别是 _mark 和 _metadata</p>
<p>_mark 表示<strong>对象标记</strong>、属于 markOop 类型，也就是接下来要讲解的 Mark World，它记录了<strong>对象和锁有关的信息</strong></p>
<p>_metadata 表示<strong>类元信息</strong>，类元信息存储的是<strong>对象指向它的类元数据(Klass)的首地址</strong>，其中 Klass 表示普通指针、 _compressed_klass 表示压缩类指针。</p>
<figure data-type="image" tabindex="20"><img src="https://epitomm.github.io/post-images/%E5%AF%B9%E8%B1%A1%E5%A4%B4.png" alt="图片" loading="lazy"></figure>
<p>对象头由两部分组成，一部分用于存储自身的运行时数据，称之为 Mark Word，另外一部分是类型指针，及对象指向它的类元数据的指针。</p>
<p><strong>Mark Word</strong></p>
<p>Mark Word用于存储<strong>对象自身的运行时数据</strong>，如<strong>哈希码（HashCode）、GC分代年龄、锁状态标志、 线程持有的锁、偏向线程ID、偏向时间戳</strong>等等，占用内存大小与虚拟机位长一致。Mark Word对应的类型是 markOop 。源码位于 markOop.hpp 中。</p>
<pre><code>// Bit-format of an object header (most significant first, big endian layout below): 
//
// 32 bits: 
// -------- 
// hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object) 
// size:32 ------------------------------------------&gt;| (CMS free block) 
// PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object) 
//
// 64 bits: 
// -------- 
// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object) 
// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object) 
// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object) 
// size:64 -----------------------------------------------------&gt;| (CMS free block) 
// [JavaThread* | epoch | age | 1 | 01] lock is biased toward given thread 
// [0 | epoch | age | 1 | 01] lock is anonymously biased 
//
// - the two lock bits are used to describe three states: locked/unlocked and monitor. 
//
// [ptr | 00] locked ptr points to real header on stack 
// [header | 0 | 01] unlocked regular object header 
// [ptr | 10] monitor inflated lock (header is wapped out) 
// [ptr | 11] marked used by markSweep to mark an object 
// not valid at any other time 
</code></pre>
<figure data-type="image" tabindex="21"><img src="https://epitomm.github.io/post-images/%E5%AF%B9%E8%B1%A1%E5%A4%B42.png" alt="图片" loading="lazy"></figure>
<p>在64位虚拟机下，Mark Word 是 64bit 大小的，其存储结构如下：</p>
<figure data-type="image" tabindex="22"><img src="https://epitomm.github.io/post-images/64%E4%BD%8D%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1%E5%A4%B4.png" alt="图片" loading="lazy"></figure>
<p>在32位虚拟机下，Mark Word 是 32bit 大小的，其存储结构如下：</p>
<figure data-type="image" tabindex="23"><img src="https://epitomm.github.io/post-images/32%E4%BD%8D%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1%E5%A4%B4.png" alt="图片" loading="lazy"></figure>
<p><strong>klass pointer</strong></p>
<p>这一部分用于存储对象的类型指针，该指针指向它的类元数据，JVM通过这个指针确定对象是<strong>哪个类的实例</strong>。该指针的位长度为 JVM 的一个字大小，即 32 位的 JVM 为 32 位，64 位的 JVM 为 64 位。</p>
<p>如果应用的对象过多，使用 64 位的指针将浪费大量内存，统计而言，64 位的 JVM 将会比 32 位的 JVM 多耗费 50% 的内存。为了节约内存可以使用选项 <code>-XX:+UseCompressedOops</code> 开启指针压缩，其中，oop 即 ordinary object pointer 普通对象指针。开启该选项后，下列指针将压缩至 32 位：</p>
<ol>
<li>每个Class的属性指针（即静态变量）</li>
<li>每个对象的属性指针（即对象变量）</li>
<li>普通对象数组的每个元素指针</li>
</ol>
<p>当然，也不是所有的指针都会压缩，一些特殊类型的指针 JVM 不会优化，比如指向 PermGen 的 Class 对象指针(JDK8 中指向元空间的 Class 对象指针)、本地变量、堆栈元素、入参、返回值和 NULL 指针等。</p>
<p>对象头 = Mark Word + 类型指针（未开启指针压缩的情况下）</p>
<p>在32位系统中，Mark Word = 4 bytes，类型指针 = 4bytes，对象头 = 8 bytes = 64 bits；</p>
<p>在64位系统中，Mark Word = 8 bytes，类型指针 = 8bytes，对象头 = 16 bytes = 128bits；</p>
<h3 id="实例数据">实例数据</h3>
<p>就是类中定义的成员变量。</p>
<h3 id="对齐填充">对齐填充</h3>
<p>对齐填充并不是必然存在的，也没有什么特别的意义，他仅仅起着占位符的作用，由于 HotSpot VM 的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头正好是8字节的倍数，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。</p>
<h3 id="查看java对象布局">查看Java对象布局</h3>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;
  &lt;artifactId&gt;jol-core&lt;/artifactId&gt;
  &lt;version&gt;0.9&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code>package com.itheima.demo06_object_layout;

public class LockObj {
    private int x;
    private boolean b;
}
</code></pre>
<pre><code>package com.itheima.demo06_object_layout;

import org.openjdk.jol.info.ClassLayout;

public class Demo01 {
    public static void main(String[] args) {
        LockObj obj = new LockObj();

        obj.hashCode();
        System.out.println(obj.hashCode());
        System.out.println(Integer.toHexString(obj.hashCode()));

        System.out.println(ClassLayout.parseInstance(obj).toPrintable());
    }
}
</code></pre>
<figure data-type="image" tabindex="24"><img src="https://epitomm.github.io/post-images/%E5%AF%B9%E8%B1%A1%E5%A4%B43.png" alt="图片" loading="lazy"></figure>
<h3 id="小结-13">小结</h3>
<p>Java对象由3部分组成，对象头，实例数据，对齐数据</p>
<p>对象头分成两部分：Mark World + Klass pointer</p>
<h2 id="偏向锁">偏向锁</h2>
<p>偏向锁是 JDK6 中的重要引进，因为HotSpot作者经过研究实践发现，在大多数情况下，<strong>锁不仅不存在多线程竞争，而且总是由同一线程多次获得</strong>，为了让线程获得锁的代价更低，引进了偏向锁。</p>
<p>偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，会在对象头存储锁偏向的线程ID，以后该线程进入和退出同步块时只需要检查是否为偏向锁、锁标志位以 ThreadID 即可。</p>
<figure data-type="image" tabindex="25"><img src="https://epitomm.github.io/post-images/%E5%81%8F%E5%90%91%E9%94%81.png" alt="图片" loading="lazy"></figure>
<p>不过<strong>一旦出现多个线程竞争时必须撤销偏向锁</strong>，所以撤销偏向锁消耗的性能必须小于之前节省下来的CAS原子操作的性能消耗，不然就得不偿失了。</p>
<h3 id="偏向锁原理">偏向锁原理</h3>
<p>当线程第一次访问同步块并获取锁时，偏向锁处理流程如下：</p>
<ol>
<li>虚拟机将会把对象头中的标志位设为“01”，即偏向模式。</li>
<li>同时使用 CAS 操作把获取到这个锁的线程的 ID 记录在对象的 Mark Word 之中 ，如果 CAS 操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高。</li>
</ol>
<figure data-type="image" tabindex="26"><img src="https://epitomm.github.io/post-images/%E5%81%8F%E5%90%91%E9%94%81.png" alt="图片" loading="lazy"></figure>
<p>持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以<strong>不再进行任何同步操作</strong>，偏向锁的效率高。</p>
<h3 id="偏向锁的撤销">偏向锁的撤销</h3>
<ol>
<li>偏向锁的撤销动作必须等待<strong>全局安全点</strong> （所有线程都停下来的点。举例：统计 9 点某地有多少人，9 点让所有人停下来，不能进出，开始统计）</li>
<li><strong>暂停拥有偏向锁的线程</strong>，判断锁对象是否处于被锁定状态</li>
<li>撤销偏向锁，恢复到无锁（标志位为 <strong>01</strong>）或轻量级锁（标志位为 <strong>00</strong>）的状态</li>
</ol>
<p>偏向锁在 Java6 之后是默认启用的，但在应用程序启动几秒钟之后才激活，可以使用 <code>-XX:BiasedLockingStartupDelay=0</code> 参数关闭延迟，如果确定应用程序中所有锁通常情况下处于竞争状态，可以通过 <code>XX:-UseBiasedLocking=false</code> 参数关闭偏向锁。</p>
<h3 id="偏向锁好处">偏向锁好处</h3>
<p>偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于<strong>一个线程反复获得同一锁</strong>的情况。偏向锁可以提高带有同步但无竞争的程序性能。</p>
<p>它同样是一个带有效益权衡性质的优化，也就是说，它并不一定总是对程序运行有利，如果程序中<strong>大多数的锁总是被多个不同的线程访问</strong>比如<strong>线程池</strong>，那偏向模式就是多余的。</p>
<p>在 JDK5 中偏向锁默认是关闭的，而到了 JDK6 中偏向锁已经默认开启。但在应用程序启动几秒钟之后才激活，可以使用 <code>-XX:BiasedLockingStartupDelay=0</code> 参数关闭延迟，如果确定应用程序中所有锁通常情况下处于竞争状态，可以通过 <code>XX:-UseBiasedLocking=false</code> 参数关闭偏向锁。</p>
<h3 id="小结-14">小结</h3>
<ul>
<li>偏向锁的原理是什么?</li>
</ul>
<p>当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，偏向锁设置为“1”，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中 ，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高。</p>
<ul>
<li>偏向锁的好处是什么?</li>
</ul>
<p>偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于<strong>一个线程反复获得同一锁</strong>的情况。偏向锁可以提高带有同步但无竞争的程序性能。</p>
<h2 id="轻量级锁">轻量级锁</h2>
<p>轻量级锁是 JDK6 之中加入的新型锁机制，它名字中的“轻量级”是相对于使用 monitor 的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的。</p>
<p>引入轻量级锁的目的：在<strong>多线程交替执行同步块</strong>的情况下，尽量避免重量级锁引起的性能消耗，但是如果多个线程在同一时刻进入临界区，会导致轻量级锁膨胀升级重量级锁，所以轻量级锁的出现并非是要替代重量级锁。</p>
<h3 id="轻量级锁原理">轻量级锁原理</h3>
<figure data-type="image" tabindex="27"><img src="https://epitomm.github.io/post-images/%E8%BD%BB%E9%87%8F%E7%BA%A7%E9%94%81%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"></figure>
<p>当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁，其步骤如下： 获取锁</p>
<ol>
<li>判断当前对象是否处于无锁状态（hashcode、0、01），如果是，则 JVM 首先将在当前线程的<strong>栈帧</strong>中建立一个名为<strong>锁记录</strong>（Lock Record）的空间，用于存储<strong>锁对象目前的 Mark Word 的拷贝</strong>（官方把这份拷贝加了一个 Displaced 前缀，即 Displaced Mark Word），将对象的 Mark Word 复制到栈帧中的 Lock Record 中，将 Lock Reocrd 中的 owner 指向当前对象。</li>
<li>JVM 利用 CAS 操作尝试<strong>将对象的 Mark Word 更新为指向 Lock Record 的指针</strong>，如果<strong>成功</strong>表示<strong>竞争到锁</strong>，则将锁标志位变成 00，执行同步操作。</li>
<li>如果失败则<strong>判断当前对象的 Mark Word 是否指向当前线程的栈帧</strong>，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成 10，后面等待的线程将会进入阻塞状态。</li>
</ol>
<p><img src="https://epitomm.github.io/post-images/%E8%BD%BB%E9%87%8F%E7%BA%A7%E9%94%81CAS%E6%93%8D%E4%BD%9C%E4%B9%8B%E5%89%8D%E5%A0%86%E6%A0%88%E4%B8%8E%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%8A%B6%E6%80%81.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/%E8%BD%BB%E9%87%8F%E7%BA%A7%E9%94%81CAS%E6%93%8D%E4%BD%9C%E4%B9%8B%E5%90%8E%E5%A0%86%E6%A0%88%E4%B8%8E%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%8A%B6%E6%80%81.png" alt="图片" loading="lazy"></p>
<h3 id="轻量级锁的释放">轻量级锁的释放</h3>
<p>轻量级锁的释放也是通过 CAS 操作来进行的，主要步骤如下：</p>
<ol>
<li>取出在获取轻量级锁保存在 Displaced Mark Word 中的数据。</li>
<li>用 CAS 操作将取出的数据替换当前对象的 Mark Word 中，如果成功，则说明释放锁成功。</li>
<li>如果 CAS 操作替换失败，说明有其他线程尝试获取该锁，则需要将轻量级锁需要膨胀升级为重量级锁。</li>
</ol>
<p>对于轻量级锁，其性能提升的依据是“对于绝大部分的锁，<strong>在整个生命周期内都是不会存在竞争的</strong>”，如果打破这个依据则除了互斥的开销外，还有额外的 CAS 操作，因此在有多线程竞争的情况下，轻量级锁比重量级锁更慢。</p>
<h3 id="轻量级锁好处">轻量级锁好处</h3>
<p>在多线程<strong>交替</strong>执行同步块的情况下，可以避免重量级锁引起的性能消耗。</p>
<h3 id="小结-15">小结</h3>
<ul>
<li>轻量级锁的原理是什么？</li>
</ul>
<p>将对象的 Mark Word 复制到栈帧中的 Lock Recod 中。Mark Word 更新为指向 Lock Record 的指针。</p>
<ul>
<li>轻量级锁好处是什么？</li>
</ul>
<p>在多线程交替执行同步块的情况下，可以避免重量级锁引起的性能消耗。</p>
<h2 id="自旋锁">自旋锁</h2>
<h3 id="自旋锁原理">自旋锁原理</h3>
<pre><code>synchronized (Demo01.class) {
  ...
  System.out.println(&quot;aaa&quot;);
}
</code></pre>
<p>前面我们讨论 monitor 实现锁的时候，知道monitor会阻塞和唤醒线程，线程的阻塞和唤醒需要CPU从用户态转为核心态，<strong>频繁的阻塞和唤醒对CPU来说是一件负担很重的工作</strong>，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，<strong>共享数据的锁定状态只会持续很短的一段时间</strong>，为了这段时间阻塞和唤醒线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个<strong>忙循环(自旋) ,</strong> 这项技术就是所谓的<strong>自旋锁</strong>。<br>
自旋锁在 JDK1.4.2 中就已经引入 ，只不过默认是关闭的，可以使用 <code>-XX:+UseSpinning</code> 参数开启，在 JDK6 中就已经改为默认开启了。自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，<strong>如果锁被占用的时间很短，自旋等待的效果就会非常好</strong>，反之，如果锁被占用的时间很长。那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果在多线程交替执行同步块的情况下，可以避免重量级锁引起的性能消耗。自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数 <code>-XX:PreBlockSpin</code>来更改。</p>
<h3 id="适应性自旋锁">适应性自旋锁</h3>
<p>在 JDK6 中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是<strong>由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定</strong>。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100次循环。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虛拟机就会变得越来越“聪明”了。</p>
<pre><code>int ObjectMonitor::TrySpin_VaryDuration (Thread * Self) {

    // Dumb, brutal spin.  Good for comparative measurements against adaptive spinning.
    // 固定次数的自旋锁
    int ctr = Knob_FixedSpin ;
    if (ctr != 0) {
        while (--ctr &gt;= 0) {
            if (TryLock (Self) &gt; 0) return 1 ;
            SpinPause () ;
        }
        return 0 ;
    }
    // 适应性自旋锁
    for (ctr = Knob_PreSpin + 1; --ctr &gt;= 0 ; ) {
      // 如果抢到了锁
      if (TryLock(Self) &gt; 0) {
        // Increase _SpinDuration ...
        // Note that we don't clamp SpinDuration precisely at SpinLimit.
        // Raising _SpurDuration to the poverty line is key.
        int x = _SpinDuration ;
        if (x &lt; Knob_SpinLimit) {
           if (x &lt; Knob_Poverty) x = Knob_Poverty ;
           // 修改自旋时间
           _SpinDuration = x + Knob_BonusB ;
        }
        return 1 ;
      }
      SpinPause () ;
    }

    // 省略部分代码
}
</code></pre>
<h2 id="锁消除">锁消除</h2>
<p>锁消除是指虚拟机即时编译器（JIT）在运行时，对<strong>一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁</strong>进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，<strong>堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行</strong>。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下要求同步呢?实际上有许多同步措施并不是程序员自己加入的，同步的代码在Java程序中的普遍程度也许超过了大部分读者的想象。下面这段非常简单的代码仅仅是输出3个字符串相加的结果，无论是源码字面上还是程序语义上都没有同步。</p>
<pre><code>public class Demo01 {
    public static void main(String[] args) {
        contactString(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;);
    }

    public static String contactString(String s1, String s2, String s3) {
        return new StringBuffer().append(s1).append(s2).append(s3).toString();
    }
}
@Override
public synchronized StringBuffer append(String str) {
    toStringCache = null;
    super.append(str);
    return this;
}
</code></pre>
<p>StringBuffffer 的 append() 是一个同步方法，锁就是 this 也就是(new StringBuilder())。虚拟机发现它的动态作用域被限制在 concatString() 方法内部。也就是说, new StringBuilder()对象的引用永远不会“逃逸”到 concatString() 方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。</p>
<h2 id="锁粗化">锁粗化</h2>
<p>原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对<strong>同一个对象反复加锁和解锁</strong>，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。</p>
<pre><code>public class Demo01 {
    public static void main(String[] args) {
        StringBuffer sb = new StringBuffer();
        for (int i = 0; i &lt; 100; i++) {
            sb.append(&quot;aa&quot;);
        }
        System.out.println(sb.toString());
    }
}
@Override
public synchronized StringBuffer append(String str) {
    toStringCache = null;
    super.append(str);
    return this;
 }
</code></pre>
<figure data-type="image" tabindex="28"><img src="https://epitomm.github.io/post-images/%E9%94%81%E7%B2%97%E5%8C%96.png" alt="图片" loading="lazy"></figure>
<h3 id="小结-16">小结</h3>
<p>什么是锁粗化？</p>
<p>JVM会探测到一连串细小的操作都使用同一个对象加锁，将同步代码块的范围放大，放到这串操作的外面，这样只需要加一次锁即可。</p>
<h2 id="平时写代码如何对synchronized优化">平时写代码如何对synchronized优化</h2>
<h3 id="减少-synchronized-的范围">减少 synchronized 的范围</h3>
<p>同步代码块中尽量短，减少同步代码块中代码的执行时间，减少锁的竞争。</p>
<pre><code>synchronized (Demo01.class) {
    System.out.println(&quot;aaa&quot;);
}
</code></pre>
<h3 id="降低synchronized锁的粒度">降低synchronized锁的粒度</h3>
<p>将一个锁拆分为多个锁提高并发度</p>
<pre><code>Hashtable hs = new Hashtable(); 
hs.put(&quot;aa&quot;, &quot;bb&quot;); 
hs.put(&quot;xx&quot;, &quot;yy&quot;);
</code></pre>
<figure data-type="image" tabindex="29"><img src="https://epitomm.github.io/post-images/Hashtable%E9%94%81%E5%AE%9A%E6%95%B4%E4%B8%AA%E5%93%88%E5%B8%8C%E8%A1%A8.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="30"><img src="https://epitomm.github.io/post-images/ConcurrentHashMap%E5%B1%80%E9%83%A8%E9%94%81%E5%AE%9A.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="31"><img src="https://epitomm.github.io/post-images/LinkedBlockingQueue%E5%85%A5%E9%98%9F%E5%87%BA%E9%98%9F%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E9%94%81.png" alt="图片" loading="lazy"></figure>
<p>LinkedBlockingQueue入队和出队使用不同的锁，相对于读写只有一个锁效率要高</p>
<figure data-type="image" tabindex="32"><img src="https://epitomm.github.io/post-images/LinkedBlockingQueue%E5%85%A5%E9%98%9F%E5%87%BA%E9%98%9F%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E9%94%812.png" alt="图片" loading="lazy"></figure>
<h3 id="读写分离">读写分离</h3>
<p><strong>读取时不加锁，写入和删除时加锁</strong></p>
<p>ConcurrentHashMap，CopyOnWriteArrayList 和 ConyOnWriteSet</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[leetcode191. 位1的个数]]></title>
        <id>https://epitomm.github.io/post/leetcode-191-wei-1-de-ge-shu/</id>
        <link href="https://epitomm.github.io/post/leetcode-191-wei-1-de-ge-shu/">
        </link>
        <updated>2020-04-14T12:12:18.000Z</updated>
        <content type="html"><![CDATA[<h2 id="问题描述">问题描述</h2>
<p>编写一个函数，输入是一个无符号整数，返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为汉明重量）。</p>
<h2 id="示例">示例</h2>
<p>示例 1：<br>
输入：00000000000000000000000000001011<br>
输出：3<br>
解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 '1'。</p>
<p>示例 2：<br>
输入：00000000000000000000000010000000<br>
输出：1<br>
解释：输入的二进制串 00000000000000000000000010000000 中，共有一位为 '1'。</p>
<p>示例 3：<br>
输入：11111111111111111111111111111101<br>
输出：31<br>
解释：输入的二进制串 11111111111111111111111111111101 中，共有 31 位为 '1'。</p>
<p>提示：<br>
请注意，在某些语言（如 Java）中，没有无符号整数类型。在这种情况下，输入和输出都将被指定为有符号整数类型，并且不应影响您的实现，因为无论整数是有符号的还是无符号的，其内部的二进制表示形式都是相同的。<br>
在 Java 中，编译器使用二进制补码记法来表示有符号整数。因此，在上面的 示例 3 中，输入表示有符号整数 -3。</p>
<h2 id="方法一">方法一</h2>
<h3 id="分析">分析</h3>
<p>利用与运算</p>
<pre><code>0 &amp; 0 = 0
0 &amp; 1 = 0
1 &amp; 0 = 0
1 &amp; 1 = 1
</code></pre>
<p>我们发现，1 与 任何数相与，结果为任何数。于是我们可以利用这个性质，首先初始化 count = 0，<strong>将二进制表达式中的每一位数字依次与 1 进行与运算</strong>，如果结果为 1，就代表此位二进制数为 1，count++；如果结果为 0，就代表此位二进制数为 0。最终返回 count 值即为二进制表达式中数字位数为 ‘1’ 的个数。</p>
<h3 id="实例分析">实例分析</h3>
<p>输入：00000000000000000000000000001011<br>
输出：3<br>
解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 '1'。<br>
<img src="https://epitomm.github.io/post-images/leetcode191_1.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/leetcode191_2.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/leetcode191_3.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/leetcode191_4.png" alt="图片" loading="lazy"></p>
<h3 id="代码">代码</h3>
<pre><code>public class Solution {
    // you need to treat n as an unsigned value
    public int hammingWeight(int n) {
        // 字符 '1' 的个数 count 初始化为 0
        int count = 0;
        // 初始化掩码为 1
        int mark = 1;
        // 循环直至掩码左移 32 为后为 0
        while(mark != 0){
            // 将数字 n 的二进制表达式中每一位数字依次与 1 进行与运算
            if((n &amp; mark) != 0){ // 如果结果不为0，表示此位为 1
                count ++;
            }
            // 掩码左移，让前一位对应的数字与 1 进行与运算
            mark &lt;&lt;= 1;
        }
        return count;
    }
}
</code></pre>
<h3 id="复杂度分析">复杂度分析</h3>
<ul>
<li>T = O(m)<br>
遍历每一位二进制位，所以时间复杂度为 O(m)，m 为二进制位数的个数</li>
<li>S = O(1)<br>
没有使用额外的空间，所以空间复杂度为 O(1)</li>
</ul>
<h2 id="方法二">方法二</h2>
<h3 id="实例分析-2">实例分析</h3>
<p>输入：00000000000000000000000000001011<br>
输出：3<br>
解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 '1'。</p>
<pre><code>n = 1011
n-1 = 1010
n &amp; n-1 = 1010
</code></pre>
<p>也就是说，对于整数 n ，n &amp; (n-1) 的效果是把 n 的二进制表示中最低位的 1 消除，有了这个特性，我们就只需不断去检查 n 是否为 0，不为 0 时，计数器 + 1，然后把它最低位的 1 消除，这样循环操作后，n 最后一定会变成 0，而计数器中保存的则是整数 n 二进制表示中 1 的个数 。<br>
<img src="https://epitomm.github.io/post-images/leetcode191_5.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/leetcode191_6.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/leetcode191_7.png" alt="图片" loading="lazy"></p>
<h3 id="代码-2">代码</h3>
<pre><code>public class Solution {
    // you need to treat n as an unsigned value
    public int hammingWeight(int n) {
        int count = 0;
        while(n!= 0){
            ++count;
            n = n &amp; (n-1);
        }
        return count;
    }
}
</code></pre>
<h3 id="复杂度">复杂度</h3>
<ul>
<li>T：O(k)<br>
k 表示整数二进制表示中 1 的个数</li>
<li>S：O(1)</li>
</ul>
<h2 id="来源">来源</h2>
<p>来源：力扣（LeetCode）<br>
链接：https://leetcode-cn.com/problems/number-of-1-bits</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis 哨兵]]></title>
        <id>https://epitomm.github.io/post/redis-shao-bing/</id>
        <link href="https://epitomm.github.io/post/redis-shao-bing/">
        </link>
        <updated>2020-04-13T04:48:14.000Z</updated>
        <content type="html"><![CDATA[<h1 id="哨兵简介">哨兵简介</h1>
<h2 id="主机宕机">主机“宕机”</h2>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E4%B8%BB%E6%9C%BA%E5%AE%95%E6%9C%BA.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>master 宕机，需要选取一个 slave 作为 master</p>
</blockquote>
<ul>
<li>将宕机的 master 下线</li>
<li>找一个slave作为master</li>
<li>通知所有的 slave 连接新的 master</li>
<li>启动新的master与slave</li>
<li>全量复制<em>N+部分复制</em>N</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E5%93%A8%E5%85%B5.png" alt="图片" loading="lazy"></figure>
<ul>
<li>谁来确认 master 宕机了</li>
<li>找一个主？怎么找法？</li>
<li>修改配置后，原始的主恢复了怎么办？</li>
</ul>
<h2 id="哨兵">哨兵</h2>
<p>哨兵(sentinel) 是一个<strong>分布式系统</strong>，用于对主从结构中的每台服务器进行<strong>监控</strong>，当出现故障时通过<strong>投票</strong>机制选择新的 master并将所有slave连接到新的master。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%93%A8%E5%85%B5.png" alt="图片" loading="lazy"></figure>
<h2 id="哨兵的作用">哨兵的作用</h2>
<ul>
<li>监控
<ul>
<li>不断的检查master和slave是否正常运行。</li>
<li>master存活检测、master与slave运行情况检测</li>
</ul>
</li>
<li>通知（提醒）
<ul>
<li>当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知。</li>
</ul>
</li>
<li>自动故障转移
<ul>
<li>断开master与slave连接，选取一个slave作为master，将其他slave连接到新的master，并告知客户端新的服务器地址</li>
</ul>
</li>
</ul>
<p>注意：</p>
<p>哨兵也是一台<strong>redis服务器</strong>，只是不提供数据服务</p>
<p>通常哨兵配置数量为<strong>单数</strong></p>
<h1 id="启用哨兵模式">启用哨兵模式</h1>
<h2 id="配置哨兵">配置哨兵</h2>
<p>清空 data 下数据</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z data]# rm -rf *
</code></pre>
<ul>
<li>配置一拖二的主从结构</li>
</ul>
<h3 id="1-一个-master">1. 一个 master</h3>
<p>（1）配置文件</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# vim redis-6379.conf 
port 6379
daemonize no
#logfile &quot;6379.log&quot;
dir /root/redis-5.0.7/data
dbfilename dump-6379.rdb
rdbcompression yes 
rdbchecksum yes 
appendonly yes
appendfsync everysec
appendfilename appendonly-6379.aof
bind 127.0.0.1
databases 16
</code></pre>
<p>（2）启动master:6379 redis 服务</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6379.conf
</code></pre>
<h3 id="2-两个-slave">2. 两个 slave</h3>
<p>（1）配置文件</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# vim redis-6380.conf 
port 6380
daemonize no
#logfile &quot;6379.log&quot;
dir &quot;/root/redis-5.0.7/data&quot;
replicaof 127.0.0.1 6379
[root@iZ2ze4u2bufi0915gyi843Z conf]# vim redis-6381.conf 
port 6381
daemonize no
#logfile &quot;6379.log&quot;
dir &quot;/root/redis-5.0.7/data&quot;
</code></pre>
<p>（2）启动 slave:6380、slave:6381 服务</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6380.conf
</code></pre>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6381.conf
</code></pre>
<h3 id="配置三个哨兵配置相同端口不同">配置三个哨兵（配置相同，端口不同）</h3>
<ul>
<li>参看sentinel.conf</li>
</ul>
<p>（1）查看 sentinel.conf 配置文件</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z redis-5.0.7]# cat sentinel.conf | grep -v &quot;#&quot; | grep -v &quot;^$&quot; // 过滤到注释和空行
port 26379
daemonize no
pidfile /var/run/redis-sentinel.pid
logfile &quot;&quot;
dir /tmp
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 30000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000
sentinel deny-scripts-reconfig yes
</code></pre>
<p><img src="https://epitomm.github.io/post-images/sentinel.conf.png" alt="图片" loading="lazy"><br>
sentinel.conf</p>
<p>（2）将配置文件 复制到 redis-5.0.7/conf 目录下</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z redis-5.0.7]#cat sentinel.conf | grep -v &quot;#&quot; | grep -v &quot;^$&quot; &gt; ./conf/sentinel-26379.conf
</code></pre>
<p>（3）修改 sentinel-26379.conf 配置文件</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# vim sentinel-26379.conf 
port 26379
daemonize no
dir /root/redis-5.0.7/data
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 30000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000
sentinel deny-scripts-reconfig yes
</code></pre>
<p>（4）复制生成 sentinel-26380.conf、 sentinel-26381.conf 两个配置文件</p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# sed 's/26379/26380/g' sentinel-26379.conf &gt; sentinel-26380.conf
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed 's/26379/26381/g' sentinel-26379.conf &gt; sentinel-26381.conf
</code></pre>
<h2 id="启动哨兵">启动哨兵</h2>
<pre><code>redis-sentinel sentinel-端口号.conf
</code></pre>
<p>启动三个哨兵：</p>
<pre><code>redis-sentinel sentinel-26379.conf

redis-sentinel sentinel-26380.conf

redis-sentinel sentinel-26381.conf
</code></pre>
<p>当 master:6379 下线后，哨兵投票选举出新的 master:6381</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BF%E5%90%8E%EF%BC%8C%E5%93%A8%E5%85%B5%E6%8A%95%E7%A5%A8%E9%80%89%E4%B8%BE%E6%96%B0%E7%9A%84master.png" alt="图片" loading="lazy"></figure>
<p>master 下线后，哨兵投票选举新的 master</p>
<h2 id="配置哨兵-2">配置哨兵</h2>
<table>
<thead>
<tr>
<th style="text-align:left">配置项</th>
<th style="text-align:center">范例</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">sentinel auth-pass    &lt;服务器名称&gt; <password></td>
<td style="text-align:center">sentinel auth-pass mymaster   itcast</td>
<td style="text-align:left">连接服务器口令</td>
</tr>
<tr>
<td style="text-align:left">sentinel down-after-milliseconds &lt;自定义服务名称&gt;&lt;主机地址&gt;&lt;端口&gt;&lt;主从服务器总量&gt;</td>
<td style="text-align:center">sentinel monitor mymaster    192.168.194.131 6381 1</td>
<td style="text-align:left">设置哨兵监听的主服务器信息，最后的参数决定了最终参与选举的服务器 数量（-1）</td>
</tr>
<tr>
<td style="text-align:left">sentinel down-after-milliseconds    &lt;服务名称&gt;&lt;毫秒数（整数）&gt;</td>
<td style="text-align:center">sentinel down-after  milliseconds mymaster 3000</td>
<td style="text-align:left">指定哨兵在监控Redis服务时，判定服务器挂掉的时间周期，默认30秒 （30000），也是主从切换的启动条件之一</td>
</tr>
<tr>
<td style="text-align:left">sentinel parallel-syncs    &lt;服务名称&gt;&lt;服务器数（整数）&gt;</td>
<td style="text-align:center">sentinel parallel-syncs    mymaster 1</td>
<td style="text-align:left">指定同时进行主从的slave数量，数值越大，要求网络资源越高，要求越小，同步时间越长</td>
</tr>
<tr>
<td style="text-align:left">sentinel failover-timeout    &lt;服务名称&gt;&lt;毫秒数（整数）&gt;</td>
<td style="text-align:center">sentinel failover-timeout    mymaster 9000</td>
<td style="text-align:left">指定出现故障后，故障切换的最大超时时间，超过该值，认定切换失败，默认3分钟</td>
</tr>
<tr>
<td style="text-align:left">sentinel notification-script    &lt;服务名称&gt;&lt;脚本路径&gt;</td>
<td style="text-align:center"></td>
<td style="text-align:left">服务器无法正常联通时，设定的执行脚本，通常调试使用。</td>
</tr>
</tbody>
</table>
<h1 id="哨兵工作原理">哨兵工作原理</h1>
<h2 id="主从切换">主从切换</h2>
<ul>
<li>哨兵在进行主从切换过程中经历三个阶段
<ul>
<li>监控</li>
<li>通知</li>
<li>故障转移</li>
</ul>
</li>
</ul>
<h2 id="阶段一监控阶段">阶段一：监控阶段</h2>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E7%9B%91%E6%8E%A7%E9%98%B6%E6%AE%B5.png" alt="图片" loading="lazy"></figure>
<ul>
<li>用于同步各个节点的状态信息
<ul>
<li>获取各个sentinel的状态（是否在线）</li>
<li>获取master的状态
<ul>
<li>master属性
<ul>
<li>runid</li>
<li>role：master</li>
</ul>
</li>
<li>各个slave的详细信息</li>
</ul>
</li>
<li>获取所有slave的状态（根据master中的slave信息）
<ul>
<li>slave属性
<ul>
<li>runid</li>
<li>role：slave</li>
<li>master_host、master_port</li>
<li>offset</li>
<li>......</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E7%9B%91%E6%8E%A7%E9%98%B6%E6%AE%B52.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>① 第一个哨兵进去的时候，只有 master 和 slave 可以连，哨兵先<strong>连接 master</strong>，发送 info 指令。<br>
② 为了方便后期 master 和 sentinel 命令交换，<strong>建立了一个 cmd 连接</strong>，专门用于发送命令。<br>
在这个过程中，保存了所有哨兵状态 SentinelState，在哨兵端把所有信息进行记录；在 master 端记录 redis 实例对应信息：SentinelRedisInstance<br>
③ sentinel 根据从 master 获取的 slaves 信息<strong>去与每一个 slave 进行连接</strong>，发送 info 命令。<br>
④ 下一个 sentinel 进入，<strong>发送 info 命令连接 master</strong>，发现 master 端的 SentinelRedisInstance 中的 sentinels 有信息，知道了在它之前有对应的 sentinel 与master 建立了连接。<br>
⑤ sentinel <strong>与 master 建立 cmd 连接</strong>。<br>
在 sentinel 端创建 SentinelState（包含两个 sentinel 节点信息）。<br>
为了保证两个 sentinel 信息同步，在两个 sentinel 之间建立沟通的桥梁进行发布订阅，向这个通道发送信息大家可以互联，为了保证连接，两个 sentinel 还会互相发送 ping 命令看对方是不是还在<br>
⑥ sentinel 与 slave 连接</p>
</blockquote>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E7%9B%91%E6%8E%A7%E9%98%B6%E6%AE%B53.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>当第三个节点进来时，除了连接 master 和 slaves，还需要与现存的 sentinel 进行连接，此时三个 sentinel 组成了一个小的网络，彼此间交换信息，在这个网络中：哪个哨兵拿到信息，快速扩散给大家，由于每个 sentinel 之间都是信任的，一旦有一个 sentinel 发送信息，其他哨兵接收，发现和自己的信息不一致，就更新掉。</p>
</blockquote>
<p>监控阶段的信息获取：sentinel 会向 master、slave、其他的 sentinel 要状态，sentinel 之间会组建对应的频道，大家在这里发布、订阅、同步信息。</p>
<h2 id="阶段二通知阶段">阶段二：通知阶段</h2>
<p>信息的长期维护阶段</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E9%80%9A%E7%9F%A5%E9%98%B6%E6%AE%B5.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>三个 sentinel 组成了一个小群体，它们之间进行信息互通，提供数据的 master 和 slave 正常工作，sentinel 会通过 cmd 连接获取它们对应的工作状态，通过发布 hello 信息来获取，无论是哪个 sentinel 拿到结果，都会在 sentinel 内部网络进行信息互通，告诉其他 sentinel。</p>
</blockquote>
<h2 id="阶段三故障转移阶段">阶段三：故障转移阶段</h2>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E9%98%B6%E6%AE%B5.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>① sentinel 向 master 发送 hello 指令，master 没有回复，sentinel 就不停给 master 发送 hello，发送了到了一定阶段后，sentinel 认为 master 掉线了，给 master 标记为 S_DOWN 状态。<br>
② sentinel1 把这个信息传递到内网中。如果是某个 sentinel 断了导致无法和 master 建立连接，该 sentinel 把 master 状态标记为 S_DOWN，并把信息发送到内网时，发送失败（此 sentinel 断线了）。<br>
③ 当内网中的其他 sentinel 接收到 master 挂掉的信息后，于是去围观不停地给 master 发送 hello，仍然没有回复，该 master 果然掉线了。<br>
④ 于是把它们接收到的结果信息也传送到内网中确认 sentinel1 说的对，master 果然挂了。<br>
⑤ 此时所有 sentinel 都认为 master 挂了，master 端的状态信息更改为：O_DOWN。事实上，只要半数以上的 sentinel 认为 master 挂了，状态就标记为 O_DOWN，不必要等所有 sentinel 都确认。</p>
</blockquote>
<p>主观下线：一个 sentinel 认为 master 挂了。</p>
<p>客观下线：半数以上 sentinel 认为 master 挂了。</p>
<h3 id="1-投票选举-sentinel-代表">1. 投票选举 sentinel 代表</h3>
<p>客观下线后，进入下一环节：开始清理队伍。清理队伍前，需选出一个 sentinel 作为代表去清理。</p>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E6%8A%95%E7%A5%A8%E9%80%89%E4%B8%BE%E5%93%A8%E5%85%B5%E4%BB%A3%E8%A1%A8.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>所有 sentinel 同时发送指令表示我要作为代表去清理队伍。<br>
发送的指令中携带以下信息：</p>
<ol>
<li>挂的 ip</li>
<li>挂的端口</li>
<li>竞选次数（我在这方面处理的经验：参与竞选的次数）</li>
<li>自己的 runid</li>
</ol>
</blockquote>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E5%93%A8%E5%85%B5%E6%8A%95%E7%A5%A82.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>那么到底应该选哪一个呢？<br>
投票机制<br>
每一个 sentinel 作为参选者，同时也是投票者，每人有一票，当 sentinel1 和 sentinel4 同时把信息发送到微信群中时，sentinel2 先接收到谁的就把票投给谁。</p>
</blockquote>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/%E5%93%A8%E5%85%B5%E6%8A%95%E7%A5%A83.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>所有信息沟通完毕会得到一个投票结果，假如有一个 sentinel 获得超过半数以上的票，就当选，如果没有得到这样的一个结果，就重新投一轮，每增加一轮，竞选次数+1.</p>
</blockquote>
<h3 id="2-sentinel-代表从备选-slave-中选择一个当-master">2. sentinel 代表从备选 slave 中选择一个当 master</h3>
<ul>
<li>服务器列表中挑选备选master
<ul>
<li>在线的</li>
<li>响应慢的</li>
<li>与原master断开时间久的</li>
<li>优先原则
<ul>
<li>优先级</li>
<li>offset</li>
<li>runid</li>
</ul>
</li>
</ul>
</li>
<li>发送指令（ sentinel ）
<ul>
<li>向新的master发送slaveof no one</li>
<li>向其他slave发送slaveof 新masterIP端口</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%93.png" alt="图片" loading="lazy"></figure>
<h3 id="主从切换过程总结">主从切换过程总结</h3>
<ul>
<li>监控
<ul>
<li>同步信息</li>
</ul>
</li>
<li>通知
<ul>
<li>保持联通</li>
</ul>
</li>
<li>故障转移
<ul>
<li>发现问题</li>
<li>竞选负责人</li>
<li>优选新master</li>
<li>新master上任，其他slave切换master，原master作为slave故障恢复后连接</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="14"><img src="https://epitomm.github.io/post-images/%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E8%BF%87%E7%A8%8B%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>主从切换过程日志信息</p>
<h1 id="总结">总结</h1>
<p><strong>哨兵模式</strong></p>
<ul>
<li>什么是哨兵 （监控整体工作过程）</li>
<li>哨兵模式搭建</li>
<li>哨兵工作原理
<ul>
<li>监控</li>
<li>通知</li>
<li>故障转移</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[dubbo]]></title>
        <id>https://epitomm.github.io/post/dubbo/</id>
        <link href="https://epitomm.github.io/post/dubbo/">
        </link>
        <updated>2020-04-10T14:34:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-基础知识">一、基础知识</h1>
<h2 id="1-分布式基础理论">1、分布式基础理论</h2>
<h3 id="11-什么是分布式系统">1.1）、什么是分布式系统？</h3>
<p>《分布式系统原理与范型》定义：</p>
<p>“分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像单个相关系统”</p>
<p>分布式系统（distributed system）是建立在网络之上的软件系统。</p>
<p>随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需<strong>一个治理系统</strong>确保架构有条不紊的演进。</p>
<h3 id="12-发展演变">1.2）、发展演变</h3>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%8F%91%E5%B1%95%E6%BC%94%E5%8F%98.png" alt="图片" loading="lazy"></figure>
<p><em>单一应用架构</em></p>
<p>当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。<br>
<img src="https://epitomm.github.io/post-images/%E5%8D%95%E4%B8%80%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></p>
<pre><code>适用于小型网站，小型管理系统，将所有功能都部署到一个功能里，简单易用。

缺点： 1、性能扩展比较难 （如果修改或添加某个功能，都需要把整个应用重新打包，重新放部署到 服务器）

       2、协同开发问题（所有人都去修改一个应用，容易乱）

       3、不利于升级维护
</code></pre>
<blockquote>
<p>将多个功能放到一个应用内，打包后放到服务器上即可。访问量增大，一个服务器无法承受时，再添加一个服务器同时跑这个应用。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E5%8D%95%E4%B8%80%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%842.png" alt="图片" loading="lazy"></figure>
<p><em>垂直应用架构</em></p>
<p>当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E5%9E%82%E7%9B%B4%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<pre><code>通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。

缺点： 公用模块无法重复利用，开发性的浪费
</code></pre>
<blockquote>
<p>将一个大应用拆分成几个独立的小应用，每一个应用都是从头到尾完成的（从页面到业务逻辑程序到数据库）。</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E5%9E%82%E7%9B%B4%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%842.png" alt="图片" loading="lazy"></figure>
<p>垂直应用架构</p>
<blockquote>
<p>当某一块应用的访问量比较大时，将这个应用多扩展几个服务器。</p>
</blockquote>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E5%9E%82%E7%9B%B4%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%843.png" alt="图片" loading="lazy"></figure>
<p>扩展某个小应用即可</p>
<blockquote>
<p>好处：1）分工合作容易，每个人负责开发维护不同的应用，互不干扰。<br>
2）性能扩展容易，比如“用户”应用的访问量增大， 就把它多放几台服务器，扩展的是某个小应用，其他小应用无需变动。<br>
缺点：1）由于每个小应用都是完整的（界面+业务逻辑+数据库），但是界面要求经常变化，每个界面的变化都会导致应用的重新部署。无法做到页面 和 业务逻辑 的分离<br>
2） 随着应用的逐步增多，垂直应用会越来越多，这样的情况下，不可能理想的应用和应用之间互相独立，订单模块需要用户模块和商品模块信息，应用之间交互，不可能完全独立。</p>
</blockquote>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E5%9E%82%E7%9B%B4%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%844.png" alt="图片" loading="lazy"></figure>
<p>界面与业务逻辑无法分离，各个应用间需要交互</p>
<p><em>分布式服务架构</em></p>
<p>当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的<strong>分布式服务框架(RPC)是关键</strong>。</p>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%841.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>将用户抽取成“用户界面” 和 “用户业务”，订单抽取成 “订单界面” 和 “订单业务” 等。<br>
当业务逻辑不变的情况下，如果只想修改界面，重启界面服务器即可，核心业务逻辑还在其他服务器上，无需变动。<br>
<img src="https://epitomm.github.io/post-images/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%842.png" alt="图片" loading="lazy"></p>
</blockquote>
<blockquote>
<p>用户界面放在 A 服务器上，用户业务放在 B 服务器上，订单业务放在 C 服务器上，如果 A 服务器（用户界面）需要调用 B 服务器（用户业务）的功能。如果写在一个应用内，A 调用 B，直接“方法 A . 方法 B” 即可，直接调用，进程类通讯，都在一个服务器上，都是同一个 tomcat，同一个进程类通讯。但如果是分布式服务架构，A 和 B 在两台服务器上，这样的不同服务器间的互相调用称为 RPC（远程过程调用）。分布式服务架构的难点：如何进行远程过程调用，如果拆分应用，提升业务的复用程度。<br>
随着业务的不断增多，分拆的业务越来越多，成千上万的服务器在跑不同的服务，出现的资源浪费问题愈加严重，比如用户业务访问量较小，但却有 100 台服务器在跑，就造成了浪费；而 商品业务 访问量很大，但却只有 10 台服务器在跑。应该有一个基于访问压力的调度中心能够实时监控数据动态调度，提高资源利用率，让更多的服务器去跑业务量更大的业务。</p>
</blockquote>
<p><em>流动计算架构</em></p>
<p>当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于<strong>提高机器利用率的资源调度和治理中心(SOA)[ Service Oriented Architecture]是关键</strong>。</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E6%B5%81%E5%8A%A8%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>采用流动计算架构，引入调度中心，负责维护服务间的复杂关系，实时管理集群，比如 A 服务器访问量大了，给 A 多增加几台服务器，假设 第一台 有 100 个请求，第二台 有 2 个请求，第三台有 10000 个请求，那么下次请求进来，就应该找比较闲的第二台服务器来处理请求，以此提高整个集群利用率。</p>
</blockquote>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E6%B5%81%E5%8A%A8%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%842.png" alt="图片" loading="lazy"></figure>
<p>流动计算架构</p>
<h3 id="13-rpc">1.3）、RPC</h3>
<p><em>什么叫RPC</em></p>
<p>RPC【Remote Procedure Call】是指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。</p>
<p><em>RPC基本原理</em></p>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/RPC%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>需求：A 服务器客户端（client）有一个小功能，想要调用 B 服务器的一个小功能。<br>
实现：A 服务器客户端（client）先找一个小助手（client stub），这个小助手一看，A 服务器想要调用 B 服务器上的功能，先跟 B 服务器在网络上建立一个 sockets 连接，将要调用 B 的一些信息（比如要调用 B 的某个方法的方法名、参数）传递给 B 模型，B 服务器上的小助手（server stub）收到这些信息，知道了 A 服务器想要调用 我的一个方法，执行这个方法后，将返回值依次传回 A 客户端。</p>
</blockquote>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/RPC%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%862.png" alt="图片" loading="lazy"></figure>
<p>RPC两个核心模块：通讯，序列化。</p>
<p>RPC 框架有很多如：dubbo、gRPC、Thrift、HSF(High Speed Service Framework)</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/RPC%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%863.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>A 服务器上有一个 hello()方法，想要调用 B 服务器上的 hi() 方法，同时传入一个 User  对象，B 服务器上的 hi() 方法执行完了以后，返回一个 String 给 A 服务器，A服务器调完 B服务器的方法后，收到 B 服务器的返回值并在控制台打印。<br>
调用过程：A 服务器客户端（Client） 想要 调用 B 服务器的代码，A 服务器上有一个小助手（Client Stub）这个小助手一看 A 服务器 要调用 B 服务器，先与 B 服务器建议连接，建立连接后，由于调用方法要传递参数，这个参数要发给 B 服务器，参数对象要在网络间传递需要先序列化 ，序列化后将要调用的信息传递给 B 服务器的小助手（Server Stub），B 服务器的小助手收到信息，一看有来自外界的 A 服务器想要调用我的 hi() 方法，同时还传递来了一个参数值，由于是序列化传递过来的，如果使用则需反序列化成对象，B服务器上的小助手调用 B 服务器上的方法，拿到反序列化的对象、一些属性值，方法调用完就会有一个返回值，返回值过来要在网络间传递数据，将返回的 String 对象序列化传递给 A 服务器的小助手，Client Stub 收到后再反序列化，输出。<br>
整个过程两个核心：建立连接、传递数据（序列化和反序列化）。所以，影响一个 RPC 框架性能的重要两点：能否快速地在各个服务器间建立连接；序列化/反序列化机制的速度。</p>
</blockquote>
<h2 id="2-dubbo核心概念">2、dubbo核心概念</h2>
<h3 id="21-简介">2.1）、简介</h3>
<p>Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。</p>
<p>官网：</p>
<p><a href="http://dubbo.apache.org/zh-cn/">http://dubbo.apache.org/zh-cn/</a></p>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/dubbo%E7%89%B9%E6%80%A7.png" alt="图片" loading="lazy"></figure>
<ol>
<li><strong>面向接口代理的高性能 RPC 调用</strong></li>
</ol>
<p>使用 dubbo 时，A 服务器 要调用 B 服务器上的代码，只需将 B 功能方法的接口 InterfaceB拿过来，调用接口所在的方法 InterfaceB.fun()，就会自动去找服务器 B 上的代码代码调用，屏蔽了远程的调用细节。类似在用 Mybatis ，操作数据库时，只需要写一个 mapper 接口，调用接口的方法即可。</p>
<ol start="2">
<li><strong>智能负载均衡</strong></li>
</ol>
<p>比如用户业务访问量很大，就需要多放几台服务器，“用户界面” 想要调用 “用户业务” 的功能，调用 “用户业务” 的哪一台服务器都可以，假设 第一台用户业务服务器当前有 100 个请求， 第二台用户业务服务器当前有 2 个请求， 第三台用户业务服务器当前有 1000 个请求， 第四台用户业务服务器当前有 10 个请求，就应该找一个非常空闲的服务器快速处理这次响应，这个机制就叫做<strong>负载均衡</strong>，让每个服务器都有一个很均衡的负载，不要让某一台服务器做太多的响应，把它压垮，也不要让某一台服务器太闲，资源浪费。</p>
<figure data-type="image" tabindex="14"><img src="https://epitomm.github.io/post-images/%E6%99%BA%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.png" alt="图片" loading="lazy"></figure>
<ol start="3">
<li><strong>服务自动注册与发现</strong></li>
</ol>
<p>想象这样一个场景：业务非常多，每一块的访问量都特别大，比如用户业务在 1、2、3、4 号服务器都有，支付业务在 9、11、13 号服务器都有，那么 订单web 想要调用支付业务，RPC 框架爱如何知道支付业务都在哪些服务器上呢？如果 11 号服务器出问题了，框架如何自动地知道这个事呢？引入<strong>注册中心</strong>机制。</p>
<p>为了能动态感知到每一个服务，可以将所有的服务都注册到注册中心，包括前端程序也可以都注册到注册中心内，注册中心相当于维护了一个 “业务 - 服务器” 清单，比如：用户业务：1、2、3、4 号服务器，如果 2 号服务器出问题了，就把它从清单中删掉。如果 订单web 要调用支付业务，先到注册中心的清单内找支付业务都在哪一台服务器上，然后随机选择或者选择请求量最少的一台服务器进行访问。</p>
<figure data-type="image" tabindex="15"><img src="https://epitomm.github.io/post-images/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83.png" alt="图片" loading="lazy"></figure>
<ol start="4">
<li><strong>高度可扩展</strong></li>
</ol>
<p>微内核 + 插件</p>
<ol start="5">
<li><strong>运行期流量调度</strong></li>
</ol>
<p>内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现<strong>灰度发布</strong>，同机房优先等功能。</p>
<p>灰度发布：一个用户服务在 100 台服务器上跑，用户服务做了开发升级，先选定 20 台服务器，让它们先用新版本的服务，剩下的 80 台使用旧版本的服务，等这 20 台用着都没问题了，再选 20 台，这样逐步过渡，直到 100 台全用到新的用户服务。配置不同的路由规则，请求进来后，让一部分请求用新升级的服务，剩下的来用旧的服务，通过这种方式从旧服务转化成新服务的过程就叫做<strong>灰度发布</strong>。</p>
<ol start="6">
<li><strong>可视化的服务治理和运维</strong></li>
</ol>
<p>通过可视化的 WEB 界面动态查询服务的信息、调整一些参数。</p>
<h3 id="22-基本概念">2.2）、基本概念</h3>
<figure data-type="image" tabindex="16"><img src="https://epitomm.github.io/post-images/dubbo%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.png" alt="图片" loading="lazy"></figure>
<p><strong>服务提供者（Provider）</strong>：暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务。</p>
<p><strong>服务消费者（Consumer）</strong>: 调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</p>
<p><strong>注册中心（Registry）</strong>：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</p>
<p><strong>监控中心（Monitor）</strong>：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</p>
<p><strong>框架容器（Container</strong>）</p>
<ul>
<li>调用关系说明
<ul>
<li>服务容器负责启动，加载，运行服务提供者。</li>
<li>服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。<br>
<img src="https://epitomm.github.io/post-images/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83.png" alt="图片" loading="lazy"></li>
</ul>
</li>
</ul>
<p>用户业务是实际的业务功能，web 界面要去调用这些业务功能，所以，用户业务是一个服务提供者（Provider），而 web 界面是服务消费者（Consumer）</p>
<blockquote>
<p>运行流程：容器 Container 启动，初始化 init ，服务提供者 Provider 将自己提供的信息注册 register 到注册中心 Registry ，注册中心就知道有哪些服务上线了，当服务消费者 Consumer 启动，从注册中心订阅 subscribe 自己所需要的服务，如果服务提供者发生变更（3 号服务器下线了），注册中心将这次变更推送 notify 给消费者，消费者拿到所有它能调用的服务，调用的时候可以同步调用 invoke 服务提供者提供的服务，如果消费者要调用的服务有多台服务器在提供，消费者根据负载均衡算法选择一个进行调用。每次的调用信息会定时地每隔一分钟将信息发送到监控中心 Monitor，监控中心就能监控到服务的状态。<br>
0、1、2 这三步是在初始化、启动应用时完成的。<br>
3、5 是异步过程，<br>
4 服务消费者调用服务提供者提供的功能是一个同步的调用。<br>
了解了 dubbo 框架，在编写 dubbo 应用时：</p>
<ol>
<li>先写一个服务提供者，将服务提供者提供的服务注册到注册中心；</li>
<li>编写一个服务消费者，消费者从注册中心订阅提供者提供的服务；</li>
<li>测试消费者如何调用提供者提供的功能。</li>
</ol>
</blockquote>
<h2 id="3-dubbo环境搭建">3、dubbo环境搭建</h2>
<h3 id="31-windows-安装zookeeper">3.1）、【windows】-安装zookeeper</h3>
<table>
<thead>
<tr>
<th style="text-align:center">1、下载zookeeper网址 <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/">https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2、解压zookeeper解压运行zkServer.cmd ，初次运行会报错，没有zoo.cfg配置文件</td>
</tr>
<tr>
<td style="text-align:center">3、修改zoo.cfg配置文件将conf下的zoo_sample.cfg复制一份改名为zoo.cfg即可。注意几个重要位置：dataDir=./   临时数据存储的目录（可写相对路径）clientPort=2181   zookeeper的端口号修改完成后再次启动zookeeper</td>
</tr>
<tr>
<td style="text-align:center">4、使用zkCli.cmd测试ls /：列出zookeeper根下保存的所有节点create –e /atguigu 123：创建一个atguigu节点，值为123get /atguigu：获取/atguigu节点的值</td>
</tr>
</tbody>
</table>
<p>注：记录一个小 bug</p>
<p>问题：【zookeeper】报错-Dzookeeper.log.dir=xxx&quot;' 不是内部或外部命令，也不是可运行的程序 或批处理文件的解决</p>
<p>解决：修改zkServer.cmd文件。将 call %JAVA% 改成 java</p>
<pre><code>java &quot;-Dzookeeper.log.dir=%ZOO_LOG_DIR%&quot; &quot;-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%&quot; -cp &quot;%CLASSPATH%&quot; %ZOOMAIN% &quot;%ZOOCFG%&quot; %*
</code></pre>
<p>参考博客：<a href="https://blog.csdn.net/pangdongh/article/details/90208230">https://blog.csdn.net/pangdongh/article/details/90208230</a></p>
<h3 id="32-windows-安装dubbo-admin管理控制台">3.2）、【windows】-安装dubbo-admin管理控制台</h3>
<p>dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。</p>
<p>但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。</p>
<p>1、下载dubbo-admin</p>
<p><a href="https://github.com/apache/incubator-dubbo-ops">https://github.com/apache/incubator-dubbo-ops</a></p>
<figure data-type="image" tabindex="17"><img src="https://epitomm.github.io/post-images/dubbo-admin%E4%B8%8B%E8%BD%BD.png" alt="图片" loading="lazy"></figure>
<p>2、进入目录，修改dubbo-admin配置</p>
<p>修改 src\main\resources\application.properties 指定zookeeper地址</p>
<figure data-type="image" tabindex="18"><img src="https://epitomm.github.io/post-images/dubbo-admin%E9%85%8D%E7%BD%AE.png" alt="图片" loading="lazy"></figure>
<p>3、打包dubbo-admin</p>
<pre><code>mvn clean package -Dmaven.test.skip=true 
</code></pre>
<p>4、运行dubbo-admin</p>
<pre><code>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar
</code></pre>
<p><strong>注意：【有可能控制台看着启动了，但是网页打不开，需要在控制台按下ctrl+c即可】</strong></p>
<p>默认使用root/root 登陆</p>
<figure data-type="image" tabindex="19"><img src="https://epitomm.github.io/post-images/%E8%BF%90%E8%A1%8Cdubbo-admin.png" alt="图片" loading="lazy"></figure>
<h3 id="33-linux-安装zookeeper">3.3）、【linux】-安装zookeeper</h3>
<p><em>1、安装jdk</em></p>
<p>1、下载jdk</p>
<p><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>
<figure data-type="image" tabindex="20"><img src="https://epitomm.github.io/post-images/%E4%B8%8B%E8%BD%BDjdk.png" alt="图片" loading="lazy"></figure>
<p>不要使用wget命令获取jdk链接，这是默认不同意，导致下载来的jdk压缩内容错误</p>
<p>2、上传到服务器并解压</p>
<figure data-type="image" tabindex="21"><img src="https://epitomm.github.io/post-images/jdk%E8%A7%A3%E5%8E%8B.png" alt="图片" loading="lazy"></figure>
<p>3、设置环境变量</p>
<pre><code>/usr/local/java/jdk1.8.0_171
</code></pre>
<figure data-type="image" tabindex="22"><img src="https://epitomm.github.io/post-images/%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F.png" alt="图片" loading="lazy"></figure>
<p>文件末尾加入下面配置</p>
<pre><code>export JAVA_HOME=/usr/local/java/jdk1.8.0_171

export JRE_HOME=${JAVA_HOME}/jre

export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib

export PATH=${JAVA_HOME}/bin:$PATH
</code></pre>
<figure data-type="image" tabindex="23"><img src="https://epitomm.github.io/post-images/jdk%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F2.png" alt="图片" loading="lazy"></figure>
<p>4、使环境变量生效&amp;测试JDK</p>
<figure data-type="image" tabindex="24"><img src="https://epitomm.github.io/post-images/jdk%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%94%9F%E6%95%88.png" alt="图片" loading="lazy"></figure>
<p><em>2、安装zookeeper</em></p>
<p>1、下载zookeeper</p>
<p>网址 <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/">https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/</a></p>
<p>wget <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz">https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz</a></p>
<p>2、解压</p>
<figure data-type="image" tabindex="25"><img src="https://epitomm.github.io/post-images/%E8%A7%A3%E5%8E%8Bzk.png" alt="图片" loading="lazy"></figure>
<p>3、移动到指定位置并改名为zookeeper</p>
<figure data-type="image" tabindex="26"><img src="https://epitomm.github.io/post-images/zk%E7%A7%BB%E5%8A%A8%E5%91%BD%E5%90%8D.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="27"><img src="https://epitomm.github.io/post-images/zk%E6%9F%A5%E7%9C%8B%E7%9B%AE%E5%BD%95.png" alt="图片" loading="lazy"></figure>
<p><em>3、开机启动zookeeper</em></p>
<p>1）-复制如下脚本</p>
<pre><code>#!/bin/bash

#chkconfig:2345 20 90

#description:zookeeper

#processname:zookeeper

ZK_PATH=/usr/local/zookeeper

export JAVA_HOME=/usr/local/java/jdk1.8.0_171

case $1 in

         start) sh  $ZK_PATH/bin/zkServer.sh start;;

         stop)  sh  $ZK_PATH/bin/zkServer.sh stop;;

         status) sh  $ZK_PATH/bin/zkServer.sh status;;

         restart) sh $ZK_PATH/bin/zkServer.sh restart;;

         *)  echo &quot;require start|stop|status|restart&quot;  ;;

esac
</code></pre>
<figure data-type="image" tabindex="28"><img src="https://epitomm.github.io/post-images/%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8zk.png" alt="图片" loading="lazy"></figure>
<p>2）-把脚本注册为Service</p>
<figure data-type="image" tabindex="29"><img src="https://epitomm.github.io/post-images/%E8%84%9A%E6%9C%AC%E6%B3%A8%E5%86%8C%E4%B8%BAservice.png" alt="图片" loading="lazy"></figure>
<p>3）-增加权限</p>
<figure data-type="image" tabindex="30"><img src="https://epitomm.github.io/post-images/%E5%A2%9E%E5%8A%A0%E6%9D%83%E9%99%90.png" alt="图片" loading="lazy"></figure>
<p><em>4、配置zookeeper</em></p>
<p>1、初始化zookeeper配置文件</p>
<p>拷贝/usr/local/zookeeper/conf/zoo_sample.cfg</p>
<p>到同一个目录下改个名字叫zoo.cfg</p>
<figure data-type="image" tabindex="31"><img src="https://epitomm.github.io/post-images/%E5%88%9D%E5%A7%8B%E5%8C%96zk%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.png" alt="图片" loading="lazy"></figure>
<p>2、启动zookeeper</p>
<figure data-type="image" tabindex="32"><img src="https://epitomm.github.io/post-images/%E5%90%AF%E5%8A%A8zk.png" alt="图片" loading="lazy"></figure>
<h3 id="34-linux-安装dubbo-admin管理控制台">3.4）、【linux】-安装dubbo-admin管理控制台</h3>
<p><em>1、安装Tomcat8（旧版dubbo-admin是war，新版是jar不需要安装Tomcat）</em></p>
<p>1、下载Tomcat8并解压</p>
<p><a href="https://tomcat.apache.org/download-80.cgi">https://tomcat.apache.org/download-80.cgi</a></p>
<p>wget <a href="http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz">http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz</a></p>
<p>2、解压移动到指定位置</p>
<figure data-type="image" tabindex="33"><img src="https://epitomm.github.io/post-images/%E8%A7%A3%E5%8E%8Btomcat.png" alt="图片" loading="lazy"></figure>
<p>3、开机启动tomcat8</p>
<figure data-type="image" tabindex="34"><img src="https://epitomm.github.io/post-images/%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8tomcat.png" alt="图片" loading="lazy"></figure>
<p>复制如下脚本</p>
<pre><code>#!/bin/bash

#chkconfig:2345 21 90

#description:apache-tomcat-8

#processname:apache-tomcat-8

CATALANA_HOME=/opt/apache-tomcat-8.5.32

export JAVA_HOME=/opt/java/jdk1.8.0_171

case $1 in

start)

    echo &quot;Starting Tomcat...&quot;  

    $CATALANA_HOME/bin/startup.sh

    ;;

stop)

    echo &quot;Stopping Tomcat...&quot;  

    $CATALANA_HOME/bin/shutdown.sh

    ;;

restart)

    echo &quot;Stopping Tomcat...&quot;  

    $CATALANA_HOME/bin/shutdown.sh

    sleep 2

    echo  

    echo &quot;Starting Tomcat...&quot;  

    $CATALANA_HOME/bin/startup.sh

    ;;

*)

    echo &quot;Usage: tomcat {start|stop|restart}&quot;  

    ;; esac
</code></pre>
<p>4、注册服务&amp;添加权限</p>
<figure data-type="image" tabindex="35"><img src="https://uploader.shimo.im/f/sgrlw1jLRksvtDuA.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="36"><img src="https://uploader.shimo.im/f/yFBPAQA9wQcuLiLK.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>5、启动服务&amp;访问tomcat测试</p>
<figure data-type="image" tabindex="37"><img src="https://uploader.shimo.im/f/PCItXvgg0c8lpyxk.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="38"><img src="https://uploader.shimo.im/f/UkCJSOTip08WixDn.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、安装dubbo-admin</em></p>
<p>dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。</p>
<p>但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。</p>
<p>1、下载dubbo-admin</p>
<p><a href="https://github.com/apache/incubator-dubbo-ops">https://github.com/apache/incubator-dubbo-ops</a></p>
<figure data-type="image" tabindex="39"><img src="https://uploader.shimo.im/f/NB3VdgOwTJUVLKd7.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>2、进入目录，修改dubbo-admin配置</p>
<p>修改 src\main\resources\application.properties 指定zookeeper地址</p>
<figure data-type="image" tabindex="40"><img src="https://uploader.shimo.im/f/Ky405QqumK4BCVLb.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3、打包dubbo-admin</p>
<pre><code>mvn clean package -Dmaven.test.skip=true 
</code></pre>
<p>4、运行dubbo-admin</p>
<pre><code>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar
</code></pre>
<p>默认使用root/root 登陆</p>
<figure data-type="image" tabindex="41"><img src="https://uploader.shimo.im/f/QwVB9l4fvmYkh6a2.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="4-dubbo-helloworld">4、dubbo-helloworld</h2>
<h3 id="41-提出需求">4.1）、提出需求</h3>
<p>某个电商系统，订单服务需要调用用户服务获取某个用户的所有地址；</p>
<p>我们现在 需要创建两个服务模块进行测试</p>
<table>
<thead>
<tr>
<th style="text-align:center">模块</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">订单服务web模块</td>
<td style="text-align:center">创建订单等</td>
</tr>
<tr>
<td style="text-align:center">用户服务service模块</td>
<td style="text-align:center">查询用户地址等</td>
</tr>
</tbody>
</table>
<p>测试预期结果：</p>
<p>订单服务web模块在A服务器，用户服务模块在B服务器，A可以远程调用B的功能。</p>
<figure data-type="image" tabindex="42"><img src="https://uploader.shimo.im/f/zu5t5nNfM7A5kcbM.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="42-工程架构">4.2）、工程架构</h3>
<p>根据 dubbo《服务化最佳实践》</p>
<p><em>1、分包</em></p>
<p>建议将服务接口，服务模型，服务异常等均放在 API 包中，因为服务模型及异常也是 API 的一部分，同时，这样做也符合分包原则：重用发布等价原则(REP)，共同重用原则(CRP)。</p>
<p>如果需要，也可以考虑在 API 包中放置一份 spring 的引用配置，这样使用方，只需在 spring 加载过程中引用此配置即可，配置建议放在模块的包目录下，以免冲突，如：com/alibaba/china/xxx/dubbo-reference.xml。</p>
<p><em>2、粒度</em></p>
<p>服务接口尽可能大粒度，每个服务方法应代表一个功能，而不是某功能的一个步骤，否则将面临分布式事务问题，Dubbo 暂未提供分布式事务支持。</p>
<p>服务接口建议以业务场景为单位划分，并对相近业务做抽象，防止接口数量爆炸。</p>
<p>不建议使用过于抽象的通用接口，如：Map query(Map)，这样的接口没有明确语义，会给后期维护带来不便。</p>
<figure data-type="image" tabindex="43"><img src="https://uploader.shimo.im/f/JGqDnycGLrAYNogH.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="43-创建模块">4.3）、创建模块</h3>
<p><em>1、gmall-interface：公共接口层（model，service，exception…）</em></p>
<p>作用：定义公共接口，也可以导入公共依赖</p>
<p>1、Bean模型</p>
<pre><code>public class UserAddress implements Serializable{
    private Integer id;
    private String userAddress;
    private String userId;
    private String consignee;
    private String phoneNum;
    private String isDefault;
    // getter、setter、Constructure、toString
}
</code></pre>
<p>2、Service接口<br>
UserService</p>
<pre><code>package com.atguigu.gmall.service;

import com.atguigu.gmall.bean.UserAddress;
import java.util.List;
// 用户服务
public interface UserService {
   /**
    * 按照用户id返回所有的收货地址
    * @param userId
    * @return
    */
   public List&lt;UserAddress&gt; getUserAddressList(String userId);
}
</code></pre>
<p>OrderService</p>
<pre><code>// 订单服务
public interface OrderService {
   /**
    * 初始化订单
    * @param userId
    */
   public void initOrder(String userId);
}
</code></pre>
<figure data-type="image" tabindex="44"><img src="https://uploader.shimo.im/f/wyNzvleAZIggOiT2.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、gmall-user：用户模块（对用户接口的实现）</em></p>
<p>1、pom.xml</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.atguigu.gmall&lt;/groupId&gt;
        &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>2、Service</p>
<pre><code>public class UserServiceImpl implements UserService {
		
	@Override
	public List&lt;UserAddress&gt; getUserAddressList(String userId) {
		// TODO Auto-generated method stub
		return userAddressDao.getUserAddressById(userId);
	}
}
</code></pre>
<p><em>4、gmall-order-web：订单模块（调用用户模块）</em><br>
1、pom.xml</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.atguigu.gmall&lt;/groupId&gt;
        &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>2、测试</p>
<pre><code>public class OrderService {	
	UserService userService;	
	/**
	 * 初始化订单，查询用户的所有地址并返回
	 * @param userId
	 * @return
	 */
	public List&lt;UserAddress&gt; initOrder(String userId){
		return userService.getUserAddressList(userId);
	}
}
</code></pre>
<p>现在这样是无法进行调用的。我们gmall-order-web引入了gmall-interface，但是interface的实现是gmall-user，我们并没有引入，而且实际他可能还在别的服务器中。</p>
<h3 id="44-使用dubbo改造">4.4）、使用dubbo改造</h3>
<p><em>1、改造gmall-user作为服务提供者</em></p>
<p>1）导入 dubbo 依赖（2.6.2）、导入操作 zookeeper 的客户端（curator）</p>
<pre><code>		&lt;!-- 引入dubbo --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;com.alibaba&lt;/groupId&gt;
			&lt;artifactId&gt;dubbo&lt;/artifactId&gt;
			&lt;version&gt;2.6.2&lt;/version&gt;
		&lt;/dependency&gt;
	&lt;!-- 由于我们使用zookeeper作为注册中心，所以需要操作zookeeper
	dubbo 2.6以前的版本引入zkclient操作zookeeper 
	dubbo 2.6及以后的版本引入curator操作zookeeper
	下面两个zk客户端根据dubbo版本2选1即可
		&lt;dependency&gt;
			&lt;groupId&gt;com.101tec&lt;/groupId&gt;
			&lt;artifactId&gt;zkclient&lt;/artifactId&gt;
			&lt;version&gt;0.10&lt;/version&gt;
		&lt;/dependency&gt;
    --&gt;
		&lt;!-- curator-framework --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
			&lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
			&lt;version&gt;2.12.0&lt;/version&gt;
		&lt;/dependency&gt;
</code></pre>
<p>2）配置提供者</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:dubbo=&quot;http://dubbo.apache.org/schema/dubbo&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans-4.3.xsd        http://dubbo.apache.org/schema/dubbo        http://dubbo.apache.org/schema/dubbo/dubbo.xsd&quot;&gt;

    &lt;!-- 1.指定当前服务/应用的名字（同样的服务名字相同，不要和别的服务同名） --&gt;
    &lt;dubbo:application name=&quot;user-service-provider&quot;  /&gt;

    &lt;!-- 2.指定注册中心的位置 --&gt;
    &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;

    &lt;!-- 3.指定通信规则（通信协议、通信端口） --&gt;
    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;

    &lt;!-- 4.暴露服务 ref：指向服务的真正实现对象--&gt;
    &lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl&quot; /&gt;

    &lt;!-- 服务的实现  --&gt;
    &lt;bean id=&quot;userServiceImpl&quot; class=&quot;com.atguigu.gmall.service.impl.UserServiceImpl&quot; /&gt;
&lt;/beans&gt;
</code></pre>
<p>3）启动服务</p>
<pre><code>package com.atguigu.gmall;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import java.io.IOException;
public class MainApplication {
    public static void main(String[] args) throws IOException {
        ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext(&quot;provider.xml&quot;);
        ioc.start();
        System.in.read();
    }
}
</code></pre>
<figure data-type="image" tabindex="45"><img src="https://uploader.shimo.im/f/STJJRpsgwTkLRkmY.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>4）测试</p>
<figure data-type="image" tabindex="46"><img src="https://uploader.shimo.im/f/reVohj16x2sHjsEN.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、改造gmall-order-web作为服务消费者</em></p>
<p>1）引入dubbo</p>
<pre><code>		&lt;!-- 引入dubbo --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;com.alibaba&lt;/groupId&gt;
			&lt;artifactId&gt;dubbo&lt;/artifactId&gt;
			&lt;version&gt;2.6.2&lt;/version&gt;
		&lt;/dependency&gt;
	&lt;!-- 由于我们使用zookeeper作为注册中心，所以需要引入zkclient或curator操作zookeeper --&gt;
		&lt;!-- curator-framework --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
			&lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
			&lt;version&gt;2.12.0&lt;/version&gt;
		&lt;/dependency&gt;
</code></pre>
<p>2）配置消费者信息</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:dubbo=&quot;http://dubbo.apache.org/schema/dubbo&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans-4.3.xsd
       http://dubbo.apache.org/schema/dubbo
       http://dubbo.apache.org/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;
    &lt;!-- 1.指定当前服务/应用的名字（同样的服务名字相同，不要和别的服务同名 --&gt;
    &lt;dubbo:application name=&quot;order-service-consumer&quot;  /&gt;

    &lt;!-- 2.注册中心地址 --&gt;
    &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;

    &lt;!-- 3.声明需要调用的远程服务的接口 --&gt;
    &lt;dubbo:reference interface=&quot;com.atguigu.gmall.service.UserService&quot; id=&quot;userService&quot; /&gt;
    &lt;!-- 包扫描 --&gt;
    &lt;context:component-scan base-package=&quot;com.atguigu.gmall.service.impl&quot;&gt;&lt;/context:component-scan&gt;
&lt;/beans&gt;
</code></pre>
<p>3）Service 注解</p>
<pre><code>package com.atguigu.gmall.service.impl;

import com.atguigu.gmall.bean.UserAddress;
import com.atguigu.gmall.service.OrderService;
import com.atguigu.gmall.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;

/**
 * 1.让服务提供者注册到注册中心（暴露服务）
 *  1）导入 dubbo 依赖（2.6.2）、导入操作 zookeeper 的客户端（curator）
 *  2）配置服务提供者
 * 2.让消费者去注册中心订阅服务提供者的地址
 */
@Service
public class OrderServiceImpl implements OrderService {
    @Autowired
    UserService userService;
    @Override
    public void initOrder(String userId) {
        // 1. 查询用户收货地址
        List&lt;UserAddress&gt; list = userService.getUserAddressList(userId);
        System.out.println(list);
    }
}
</code></pre>
<p>4）main方法测试</p>
<pre><code>package com.atguigu.gmall;

import com.atguigu.gmall.service.OrderService;
import org.springframework.context.support.ClassPathXmlApplicationContext;

import java.io.IOException;

public class MainApplication {
    public static void main(String[] args) throws IOException {
        ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;consumer.xml&quot;);
        OrderService orderService = applicationContext.getBean(OrderService.class);
        orderService.initOrder(&quot;1&quot;);
        System.out.println(&quot;调用结束...&quot;);

        System.in.read();
    }
}
</code></pre>
<p><em>3、测试调用</em><br>
访问gmall-order-web的initOrder请求，会调用UserService获取用户地址；</p>
<p>调用成功。说明我们order已经可以调用远程的UserService了；</p>
<p>运行结果：</p>
<pre><code>用户 id ：1
北京市昌平区宏福科技园综合楼3层
深圳市宝安区西部硅谷大厦B座3层（深圳分校）
调用结束...
</code></pre>
<figure data-type="image" tabindex="47"><img src="https://uploader.shimo.im/f/60BuhhwD1HUmxziW.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>4、注解版</em></p>
<p>1、服务提供方</p>
<pre><code>&lt;dubbo:application name=&quot;gmall-user&quot;&gt;&lt;/dubbo:application&gt;  
&lt;dubbo:registry address=&quot;zookeeper://118.24.44.169:2181&quot; /&gt;  
&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;
&lt;dubbo:annotation package=*&quot;com.atguigu.gmall.user.impl&quot;/&gt;  

import com.alibaba.dubbo.config.annotation.Service;
import com.atguigu.gmall.bean.UserAddress;  
import com.atguigu.gmall.service.UserService;  
import com.atguigu.gmall.user.mapper.UserAddressMapper;

@Service //使用dubbo提供的service注解，注册暴露服务
public class UserServiceImpl implements UserService {	
     @Autowired		
    UserAddressMapper userAddressMapper; 
</code></pre>
<p>2、服务消费方</p>
<pre><code>&lt;dubbo:application name=&quot;gmall-order-web&quot;&gt;&lt;/dubbo:application&gt;  
&lt;dubbo:registry address=&quot;zookeeper://118.24.44.169:2181&quot; /&gt;  
&lt;dubbo:annotation package=&quot;com.atguigu.gmall.order.controller&quot;/&gt;

@Controller  
public class OrderController {  	  	
    @Reference  //使用dubbo提供的reference注解引用远程服务  	
    UserService userService; 
</code></pre>
<h2 id="5-监控中心">5、监控中心</h2>
<h3 id="51-dubbo-admin">5.1）、dubbo-admin</h3>
<p>图形化的服务管理页面；安装时需要指定注册中心地址，即可从注册中心中获取到所有的提供者/消费者进行配置管理</p>
<h3 id="52-dubbo-monitor-simple">5.2）、dubbo-monitor-simple</h3>
<p>简单的监控中心；</p>
<p><em>1、安装</em></p>
<table>
<thead>
<tr>
<th style="text-align:center">1、下载 dubbo-ops  <a href="https://github.com/apache/incubator-dubbo-ops">https://github.com/apache/incubator-dubbo-ops</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2、修改配置指定注册中心地址进入 dubbo-monitor-simple\src\main\resources\conf修改 dubbo.properties文件</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="48"><img src="https://uploader.shimo.im/f/hiBXL60A0HIHytCX.png!thumbnail" alt="图片" loading="lazy"></figure>
<table>
<thead>
<tr>
<th style="text-align:left">3、打包dubbo-monitor-simplemvn clean package -Dmaven.test.skip=true</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">4、解压 tar.gz 文件，并运行start.bat</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="49"><img src="https://uploader.shimo.im/f/3VuJjpqB1NQs3dTZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<table>
<thead>
<tr>
<th style="text-align:left">如果缺少servlet-api，自行导入servlet-api再访问监控中心</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">5、启动访问8080</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="50"><img src="https://uploader.shimo.im/f/8yKt4JScy58YqdVP.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、监控中心配置</em></p>
<table>
<thead>
<tr>
<th>所有服务配置连接监控中心，进行监控统计    <!-- 监控中心协议，如果为protocol="registry"，表示从注册中心发现监控中心地址，否则直连监控中心 -->  	<a href="dubbo:monitor%C2%A0protocol=%22registry%22">dubbo:monitor protocol=&quot;registry&quot;</a>&lt;/dubbo:monitor&gt;</th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>Simple Monitor 挂掉不会影响到 Consumer 和 Provider 之间的调用，所以用于生产环境不会有风险。</p>
<p>Simple Monitor 采用磁盘存储统计信息，请注意安装机器的磁盘限制，如果要集群，建议用mount共享磁盘。</p>
<h2 id="6-整合springboot">6、整合SpringBoot</h2>
<p>1）引入<strong>spring-boot-starter以及dubbo和curator的依赖</strong></p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt;
    &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;0.2.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>注意starter版本适配：<br>
<img src="https://uploader.shimo.im/f/d2JLjRxIZZsumBaC.png!thumbnail" alt="图片" loading="lazy"></p>
<p>2）配置application.properties</p>
<p><em>提供者配置：</em></p>
<pre><code>dubbo.application.name=gmall-user
dubbo.registry.protocol=zookeeper
dubbo.registry.address=192.168.67.159:2181
dubbo.scan.base-package=com.atguigu.gmall
dubbo.protocol.name=dubbo
dubbo.protocol.port=20880
dubbo.monitor.protocol=registry
## application.name就是服务名，不能跟别的dubbo提供端重复
## registry.protocol  是指定注册中心协议
## registry.address 是注册中心的地址加端口号
## protocol.name 是分布式固定是dubbo,不要改。
## base-package  注解方式要扫描的包
</code></pre>
<p><em>消费者配置：</em></p>
<pre><code>server.port=8081

dubbo.application.name=gmall-order-web
dubbo.registry.protocol=zookeeper
dubbo.registry.address=192.168.67.159:2181
dubbo.scan.base-package=com.atguigu.gmall
dubbo.protocol.name=dubbo
dubbo.monitor.protocol=registry
</code></pre>
<p>3、dubbo注解<br>
@Service、@Reference</p>
<p><strong>【如果没有在配置中写dubbo.scan.base-package,还需要在启动类使用@EnableDubbo注解】</strong></p>
<p>消费者：</p>
<pre><code>@Reference
UserService userService;
</code></pre>
<p>服务提供者：</p>
<pre><code>@com.alibaba.dubbo.config.annotation.Service // 暴露服务
@Service
public class UserServiceImpl implements UserService {
</code></pre>
<h1 id="二-dubbo配置">二、dubbo配置</h1>
<h2 id="1-配置原则">1、配置原则</h2>
<figure data-type="image" tabindex="51"><img src="https://uploader.shimo.im/f/B1hW7n2x1bYU1d7w.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>JVM 启动 -D 参数优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。</p>
<p>XML 次之，如果在 XML 中有配置，则 dubbo.properties 中的相应配置项无效。</p>
<p>Properties 最后，相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。</p>
<h2 id="2-重试次数">2、重试次数</h2>
<p>失败自动切换，当出现失败，重试其它服务器，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。</p>
<p>重试次数配置如下：</p>
<pre><code>&lt;dubbo:service retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference&gt;
    &lt;dubbo:method name=&quot;findFoo&quot; retries=&quot;2&quot; /&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<blockquote>
<p>幂等操作（执行多次和执行一次效果相同：查询、删除、修改）可设置重试次数，非幂等操作（执行多次和执行一次效果不同：新增）不宜设置重试次数</p>
</blockquote>
<h2 id="3-超时时间">3、超时时间</h2>
<p>由于网络或服务端不可靠，会导致调用出现一种不确定的中间状态（超时）。为了避免超时导致客户端资源（线程）挂起耗尽，必须设置超时时间。</p>
<blockquote>
<p>服务消费方引用服务提供方时，可能有雨网络等原因，服务提供方要执行一个方法可能有很长时间，如果很长时间都没有返回，导致大量线程阻塞，可能会引起性能下降，为了解决这个问题，可以指定超时时间，只要这个方法在指定时间内没有返回，就立即终止，不让大量线程阻塞。设置单位 ms</p>
</blockquote>
<h3 id="1-dubbo消费端">1、Dubbo消费端</h3>
<p>全局超时配置</p>
<pre><code>&lt;dubbo:consumer timeout=&quot;5000&quot; /&gt;
</code></pre>
<p>指定接口以及特定方法超时配置</p>
<pre><code>&lt;dubbo:reference interface=&quot;com.foo.BarService&quot; timeout=&quot;2000&quot;&gt;
    &lt;dubbo:method name=&quot;sayHello&quot; timeout=&quot;3000&quot; /&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<h3 id="2-dubbo服务端">2、Dubbo服务端</h3>
<p>全局超时配置</p>
<pre><code>&lt;dubbo:provider timeout=&quot;5000&quot; /&gt;
</code></pre>
<p>指定接口以及特定方法超时配置</p>
<pre><code>&lt;dubbo:provider interface=&quot;com.foo.BarService&quot; timeout=&quot;2000&quot;&gt;
    &lt;dubbo:method name=&quot;sayHello&quot; timeout=&quot;3000&quot; /&gt;
&lt;/dubbo:provider&gt;
</code></pre>
<h3 id="3-配置原则">3、配置原则</h3>
<p>dubbo推荐在Provider上尽量多配置Consumer端属性：</p>
<p>1、作服务的提供者，比服务使用方更清楚服务性能参数，如调用的超时时间，合理的重试次数，等等</p>
<p>2、在Provider配置后，Consumer不配置则会使用Provider的配置值，即Provider配置可以作为Consumer的缺省值。否则，Consumer会使用Consumer端的全局设置，这对于Provider不可控的，并且往往是不合理的</p>
<p>配置的覆盖规则：</p>
<ol>
<li>
<p>方法级别配置优于接口级别，即小Scope优先</p>
</li>
<li>
<p>Consumer端配置 优于 Provider配置 优于 全局配置，</p>
</li>
</ol>
<p>3) 最后是Dubbo Hard Code的配置值（见配置文档）</p>
<figure data-type="image" tabindex="52"><img src="https://uploader.shimo.im/f/5xoy9sunaRc44qdE.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="4-版本号">4、版本号</h2>
<p>当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。</p>
<p>可以按照以下的步骤进行版本迁移：</p>
<p>在低压力时间段，先升级一半提供者为新版本</p>
<p>再将所有消费者升级为新版本</p>
<p>然后将剩下的一半提供者升级为新版本</p>
<p>老版本服务提供者配置：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; version=&quot;1.0.0&quot; /&gt;
</code></pre>
<p>新版本服务提供者配置：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; version=&quot;2.0.0&quot; /&gt;
</code></pre>
<p>老版本服务消费者配置：</p>
<pre><code>&lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;1.0.0&quot; /&gt;
</code></pre>
<p>新版本服务消费者配置：</p>
<pre><code>&lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;2.0.0&quot; /&gt;
</code></pre>
<p>如果不需要区分版本，可以按照以下的方式配置：</p>
<pre><code>&lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;*&quot; /&gt;
</code></pre>
<h2 id="5-启动时检查">5、启动时检查</h2>
<p>Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check=&quot;true&quot;。</p>
<p>可以通过 check=&quot;false&quot; 关闭检查，比如，测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动。</p>
<p>另外，如果你的 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请关闭 check，否则服务临时不可用时，会抛出异常，拿到 null 引用，如果 check=&quot;false&quot;，总是会返回引用，当服务恢复时，能自动连上。</p>
<h3 id="示例">示例</h3>
<p><strong>通过 spring 配置文件</strong></p>
<p>关闭某个服务的启动时检查 (没有提供者时报错)：如果启动时没有提供者可以成功启动，但调用时因没有提供者调用失败会抛出异常</p>
<pre><code>&lt;dubbo:reference interface=&quot;com.foo.BarService&quot; check=&quot;false&quot; /&gt;
</code></pre>
<p>配置当前消费者的统一规则，所有的服务启动时都不检查：</p>
<pre><code>&lt;dubbo:consumer check=&quot;false&quot; /&gt;
</code></pre>
<p>关闭注册中心启动时检查 (注册订阅失败时报错)：</p>
<pre><code>&lt;dubbo:registry check=&quot;false&quot; /&gt;
</code></pre>
<p><strong>通过 dubbo.properties</strong></p>
<pre><code>dubbo.reference.com.foo.BarService.check=false
dubbo.reference.check=false
dubbo.consumer.check=false
dubbo.registry.check=false
</code></pre>
<h2 id="6-多版本">6、多版本</h2>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/multi-versions.html">http://dubbo.apache.org/zh-cn/docs/user/demos/multi-versions.html</a></p>
<blockquote>
<p>使用场景：某一个接口功能出现了不兼容的升级，先让一部分人使用新功能，另外一部分人还是先用旧版本，如果新功能版本都稳定了，再把所有老版本替换成新版本。</p>
</blockquote>
<p>服务提供方提供新旧两个版本供消费者使用</p>
<pre><code>&lt;!-- 4.暴露服务 ref：指向服务的真正实现对象--&gt;
&lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl01&quot; version=&quot;1.0.0&quot;/&gt;
&lt;!-- 服务的实现  --&gt;
&lt;bean id=&quot;userServiceImpl01&quot; class=&quot;com.atguigu.gmall.service.impl.UserServiceImpl&quot; /&gt;
&lt;!-- 连接监控中心 --&gt;
&lt;dubbo:monitor protocol=&quot;registry&quot;&gt;&lt;/dubbo:monitor&gt;
&lt;!-- 检测多版本 --&gt;
&lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl02&quot; version=&quot;2.0.0&quot;/&gt;
&lt;bean id=&quot;userServiceImpl02&quot; class=&quot;com.atguigu.gmall.service.impl.UserServiceImpl2&quot; /&gt;
</code></pre>
<p>服务消费方可选择哪一个版本</p>
<pre><code>&lt;!-- 3.声明需要调用的远程服务的接口 --&gt;
&lt;dubbo:reference interface=&quot;com.atguigu.gmall.service.UserService&quot; id=&quot;userService&quot; check=&quot;false&quot; version=&quot;2.0.0&quot;/&gt;
</code></pre>
<blockquote>
<p>由此实现灰度发布。</p>
</blockquote>
<h2 id="7-本地存根">7、本地存根</h2>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html">http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html</a></p>
<p>远程服务后，客户端通常只剩下接口，而实现全在服务器端，但提供方有些时候想在客户端也执行部分逻辑，比如：做 ThreadLocal 缓存，提前验证参数，调用失败后伪造容错数据等等，此时就需要在 API 中带上 Stub，客户端生成 Proxy 实例，会把 Proxy 通过构造函数传给 Stub <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fn1">[1]</a>，然后把 Stub 暴露给用户，Stub 可以决定要不要去调 Proxy。</p>
<figure data-type="image" tabindex="53"><img src="https://uploader.shimo.im/f/fCMOKYxIU74ZSiof.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在 spring 配置文件中按以下方式配置：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; stub=&quot;true&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; stub=&quot;com.foo.BarServiceStub&quot; /&gt;
</code></pre>
<p>提供 Stub 的实现 <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fn2">[2]</a>：</p>
<pre><code>package com.foo;
public class BarServiceStub implements BarService {
    private final BarService barService;
    
    // 构造函数传入真正的远程代理对象
    public BarServiceStub(BarService barService){
        this.barService = barService;
    }
 
    public String sayHello(String name) {
        // 此代码在客户端执行, 你可以在客户端做ThreadLocal本地缓存，或预先验证参数是否合法，等等
        try {
            return barService.sayHello(name);
        } catch (Exception e) {
            // 你可以容错，可以做任何AOP拦截事项
            return &quot;容错数据&quot;;
        }
    }
}
</code></pre>
<p>Stub 必须有可传入 Proxy 的构造函数。 <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fnref1">↩︎</a></p>
<ol>
<li>在 interface 旁边放一个 Stub 实现，它实现 BarService 接口，并有一个传入远程 BarService 实例的构造函数 <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fnref2">↩︎</a></li>
</ol>
<h2 id="8-springboot-与-dubbo-整合的三种方式">8、Springboot 与 dubbo 整合的三种方式</h2>
<p><strong>（1） application.properties</strong></p>
<p>导入 dubb-starter，在 application.properties 中配置属性，使用 @Service 暴露服务；使用 @Reference 引用服务</p>
<p>（注意 @EnableDubbo 开启基于注解的 dubbo 或在 properties 文件中包扫描）</p>
<p><strong>（2）保留 dubbo xml配置文件</strong></p>
<p>导入 dubb-starter，使用 @ImportResource 导入配置文件即可（不再使用 @EnableDubbo 注解，转而使用 @ImportResource(locations=&quot;classpath:provider.xml&quot;)</p>
<p>暴露 Service 也不再使用 @Service 了，因为 xml 中已经设置了暴露服务）</p>
<p><strong>（3）使用注解 API 方式</strong></p>
<p>将每一个组件手动创建到容器中，让 dubbo 来扫描其他的组件</p>
<pre><code>  @EnableDubbo(scanBasePackages=&quot;com.atguigu.gmall&quot;)
</code></pre>
<pre><code>package com.atguigu.gmall.config;

import com.alibaba.dubbo.config.*;
import com.atguigu.gmall.service.UserService;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.ArrayList;
import java.util.List;

@Configuration
public class MyDubboConfig {

//        &lt;dubbo:application name=&quot;boot-user-service-provider&quot;  /&gt;
    @Bean
    public ApplicationConfig applicationConfig(){
        ApplicationConfig config = new ApplicationConfig();
        config.setName(&quot;boot-user-service-provider&quot;);
        return config;
    }

    // &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;
    @Bean
    public RegistryConfig registryConfig(){
        System.out.println(&quot;--------&quot;);
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol(&quot;zookeeper&quot;);
        registryConfig.setAddress(&quot;127.0.0.1:2181&quot;);
        return registryConfig;
    }

    //&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20882&quot; /&gt;
    @Bean
    public ProtocolConfig protocolConfig(){
        ProtocolConfig config = new ProtocolConfig();
        config.setName(&quot;dubbo&quot;);
        config.setPort(20882);
        return config;
    }

    //    &lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl01&quot;&gt;
    //        &lt;dubbo:method name=&quot;getUserAddressList&quot; timeout=&quot;1000&quot;&gt;&lt;/dubbo:method&gt;
    //    &lt;/dubbo:service&gt;
    @Bean
    public ServiceConfig&lt;UserService&gt; serviceConfig(UserService userService){
        ServiceConfig&lt;UserService&gt; config = new ServiceConfig&lt;&gt;();
        config.setInterface(UserService.class);
        config.setRef(userService);

        // 配置每一个 method 信息
        MethodConfig methodConfig = new MethodConfig();
        methodConfig.setName(&quot;getUserAddressList&quot;);
        methodConfig.setTimeout(1000);

        // 将 method 的设置关联到 servie 中
        List&lt;MethodConfig&gt; methods = new ArrayList&lt;&gt;();
        methods.add(methodConfig);
        config.setMethods(methods);

        return config;
    }

}
</code></pre>
<h1 id="三-高可用">三、高可用</h1>
<h2 id="1-zookeeper宕机与dubbo直连">1、zookeeper宕机与dubbo直连</h2>
<p>现象：zookeeper注册中心（zkServer.cmd）宕机，还可以消费dubbo暴露的服务。</p>
<p>原因：</p>
<p>健壮性</p>
<ul>
<li>监控中心宕掉不影响使用，只是丢失部分采样数据</li>
<li>数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务</li>
<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台</li>
<li><strong>注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯</strong></li>
<li>服务提供者无状态，任意一台宕掉后，不影响使用</li>
<li>服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复</li>
</ul>
<p><strong>高可用：通过设计，减少系统不能提供服务的时间；</strong></p>
<p><strong>dubbo 直连（绕过注册中心）</strong></p>
<pre><code>@Reference(url = &quot;127.0.0.1:20882&quot;)
UserService userService;
</code></pre>
<h2 id="2-集群下dubbo负载均衡配置">2、集群下dubbo负载均衡配置</h2>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/loadbalance.html">http://dubbo.apache.org/zh-cn/docs/user/demos/loadbalance.html</a></p>
<p>在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。</p>
<h3 id="负载均衡策略">负载均衡策略</h3>
<p><strong>Random LoadBalance</strong></p>
<p>随机，按权重设置随机概率。</p>
<p>在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。</p>
<figure data-type="image" tabindex="54"><img src="https://uploader.shimo.im/f/t9CCH4EHEeoW2iry.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>基于权重的随机负载均衡机制：orderService 想要调用 userService，userService 分别在 1、2、3 台机器内，分别为每一台机器的服务设置权重为 100、200、50，总权重 350，那么对于 1 号机器来说，它的概率就是 100/350 = 2/7，在负载均衡的情况下，大量请求过来，大约有 2/7 的请求会来到 1 号机器。第一次请求来调用的是 1 号机器，第二次来有可能还调用 1 号机器，但总体上，按照大量请求概率分布来看，1 号机器会占 2/7 的概率。</p>
</blockquote>
<p><strong>RoundRobin LoadBalance</strong></p>
<p>轮循，按公约后的权重设置轮循比率。</p>
<p>存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</p>
<figure data-type="image" tabindex="55"><img src="https://uploader.shimo.im/f/fnw0VbVMqhIoKq6S.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>轮询负载均衡机制：orderService 想要调用 userService，第一个请求过来先用 1 号 userService 服务，第二个请求过来使用 2 号 userService 服务，下一个请求过来使用 3 号userService 服务，再下一次 1 号，再下一次 2 号...... 依次轮询。<br>
基于权重的轮询负载均衡机制：为每个服务设置权重，3 台服务器的权重分别为 2/7、4/7、1/7，按照轮询机制，第一个请求到来使用 1 号服务器，第二个请求使用 2 号服务器，第三个请求使用 3 号服务器，第四个请求使用 1 号服务器，第五个请求使用 2 号服务器，第六个请求本应使用 3 号服务器，<strong>但是</strong>，由于 3 号服务器的权重是 1/7（如果有 7 个请求，则 7 个之中的 1 个使用 3 号服务器），已经有第三个请求使用了 3 号服务器，第一个、第四个请求已经使用了 两次 1 号服务器，所以第六个请求只能使用 2 号服务器，同理，第七个请求也使用 2 号服务器。<br>
<strong>LeastActive LoadBalance</strong></p>
</blockquote>
<p>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。</p>
<p>使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</p>
<figure data-type="image" tabindex="56"><img src="https://uploader.shimo.im/f/S8G9zCwCrP81SVr3.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>最少活跃数：orderService 要调用 userService，在确定要使用几号 userService前，根据 “每一个服务器统计的上一次的调用时间”：三台服务器上一次请求的处理时间分别为 100ms、1000ms、300ms，说明 1 号服务器处理最快，于是此次请求会来到 1 号服务器。</p>
</blockquote>
<p><strong>ConsistentHash LoadBalance</strong></p>
<p>一致性 Hash，相同参数的请求总是发到同一提供者。</p>
<p>当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。算法参见：<a href="http://en.wikipedia.org/wiki/Consistent_hashing">http://en.wikipedia.org/wiki/Consistent_hashing</a></p>
<p>缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt;</p>
<p>缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt;</p>
<figure data-type="image" tabindex="57"><img src="https://uploader.shimo.im/f/TKBZTSuulaQxa01m.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>一致性 hash：orderService 想要调用 userService，都是调用的同一个 getUser 方法，将参数 hash 后的不同值分不到不同的服务器上。</p>
</blockquote>
<h3 id="负载均衡配置">负载均衡配置</h3>
<p>服务端服务级别，暴露服务时</p>
<pre><code>&lt;dubbo:service interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;
</code></pre>
<p>客户端服务级别，消费时</p>
<pre><code>&lt;dubbo:reference interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;
</code></pre>
<p>服务端方法级别</p>
<pre><code>&lt;dubbo:service interface=&quot;...&quot;&gt;
    &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt;
&lt;/dubbo:service&gt;
</code></pre>
<p>客户端方法级别</p>
<pre><code>&lt;dubbo:reference interface=&quot;...&quot;&gt;
    &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<h2 id="3-整合hystrix服务熔断与降级处理">3、整合hystrix，服务熔断与降级处理</h2>
<h3 id="1-服务降级">1、服务降级</h3>
<p><strong>什么是服务降级？</strong></p>
<p><strong>当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。</strong></p>
<p>可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。</p>
<p>向注册中心写入动态配置覆盖规则：</p>
<pre><code>RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();
Registry registry = registryFactory.getRegistry(URL.valueOf(&quot;zookeeper://10.20.153.10:2181&quot;));
registry.register(URL.valueOf(&quot;override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null&quot;));
</code></pre>
<p>其中：</p>
<ul>
<li>mock=force:return+null 表示消费方对该服务的方法调用都<strong>直接返回 null 值，不发起远程调用</strong>。用来屏蔽不重要服务不可用时对调用方的影响。</li>
<li>还可以改为 mock=fail:return+null 表示消费方对该服务的方法<strong>调用在失败后，再返回 null 值</strong>，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。</li>
</ul>
<h3 id="2-集群容错">2、集群容错</h3>
<p>在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。</p>
<p><strong>集群容错模式</strong></p>
<p><strong>Failover Cluster</strong></p>
<p>失败自动切换，当<strong>出现失败，重试其它服务器</strong>。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。</p>
<blockquote>
<p>A 服务调用 B 服务，B 服务超时后，配置一个重试次数，可以重新切换到能提供 B服务的其他机器。</p>
</blockquote>
<p>重试次数配置如下：</p>
<pre><code>&lt;dubbo:service retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference&gt;
    &lt;dubbo:method name=&quot;findFoo&quot; retries=&quot;2&quot; /&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<p><strong>Failfast Cluster</strong></p>
<p>快速失败，只发起一次调用，<strong>失败立即报错</strong>。通常用于非幂等性的写操作，比如新增记录。</p>
<blockquote>
<p>A 服务调用 B服务，只发起一次调用，失败立即报错。</p>
</blockquote>
<p><strong>Failsafe Cluster</strong></p>
<p>失败安全，出现异常时，直接<strong>忽略</strong>。通常用于写入审计日志等操作。</p>
<p><strong>Failback Cluster</strong></p>
<p><strong>失败自动恢复，后台记录失败请求，定时重发</strong>。通常用于消息通知操作。</p>
<blockquote>
<p>A 服务调用 B 服务，失败后可以后台记录一下，隔一段时间定时再调用一次。适用于：一定要成功的服务调用</p>
</blockquote>
<p><strong>Forking Cluster</strong></p>
<p>并行调用多个服务器，只要一个成功即返回。通常用于<strong>实时性要求较高</strong>的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。</p>
<blockquote>
<p>A 服务调用 B服务，有可能会失败，能提供 B 服务的在三台服务器上，同时给这三台服务器都发起请求，只要其中一个服务器响应成功就可以使用。</p>
</blockquote>
<p><strong>Broadcast Cluster</strong></p>
<p>广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。</p>
<blockquote>
<p>A 服务调用 B服务，B 服务的提供者有四台机器，每一台机器都调用一遍，只要有任意一台出现错误，都认为这次调用是失败的。</p>
</blockquote>
<p><strong>集群模式配置</strong></p>
<p>按照以下示例在服务提供方和消费方配置集群模式</p>
<pre><code>&lt;dubbo:service cluster=&quot;failsafe&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference cluster=&quot;failsafe&quot; /&gt;
</code></pre>
<h3 id="3-整合hystrix">3、整合hystrix</h3>
<p>Hystrix 旨在通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能</p>
<p><em>1、配置spring-cloud-starter-netflix-hystrix</em></p>
<p>spring boot官方提供了对hystrix的集成，直接在pom.xml里加入依赖：</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
  &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
  &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>然后在Application类上增加@EnableHystrix来启用hystrix starter：</p>
<pre><code>@SpringBootApplication
@EnableHystrix
public class ProviderApplication {
</code></pre>
<p><em>2、配置Provider端</em></p>
<p>在Dubbo的Provider上增加@HystrixCommand配置，这样子调用就会经过Hystrix代理。</p>
<pre><code>@Service(version = &quot;1.0.0&quot;)
public class HelloServiceImpl implements HelloService {
    @HystrixCommand(commandProperties = {
     @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;, value = &quot;10&quot;),
     @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;) })
    @Override
    public String sayHello(String name) {
        // System.out.println(&quot;async provider received: &quot; + name);
        // return &quot;annotation: hello, &quot; + name;
        throw new RuntimeException(&quot;Exception to show hystrix enabled.&quot;);
    }
}
</code></pre>
<p><em>3、配置Consumer端</em></p>
<p>对于Consumer端，则可以增加一层method调用，并在method上配置@HystrixCommand。当调用出错时，会走到fallbackMethod = &quot;reliable&quot;的调用里。</p>
<pre><code>    @Reference(version = &quot;1.0.0&quot;)
    private HelloService demoService;
    @HystrixCommand(fallbackMethod = &quot;reliable&quot;)
    public String doSayHello(String name) {
        return demoService.sayHello(name);
    }
    public String reliable(String name) {
        return &quot;hystrix fallback value&quot;;
    }
</code></pre>
<h1 id="四-dubbo原理">四、dubbo原理</h1>
<h2 id="1-rpc原理">1、RPC原理</h2>
<figure data-type="image" tabindex="58"><img src="https://uploader.shimo.im/f/VT5w26Fy18AWw61q.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>一次完整的RPC调用流程（同步调用，异步另说）如下：</p>
<p>**1）服务消费方（client）调用以本地调用方式调用服务； **</p>
<p>2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；</p>
<p>3）client stub找到服务地址，并将消息发送到服务端；</p>
<p>4）server stub收到消息后进行解码；</p>
<p>5）server stub根据解码结果调用本地的服务；</p>
<p>6）本地服务执行并将结果返回给server stub；</p>
<p>7）server stub将返回结果打包成消息并发送至消费方；</p>
<p>8）client stub接收到消息，并进行解码；</p>
<p><strong>9）服务消费方得到最终结果。</strong></p>
<p>RPC框架的目标就是要2~8这些步骤都封装起来，这些细节对用户来说是透明的，不可见的。</p>
<h2 id="2-netty通信原理">2、netty通信原理</h2>
<p>Netty是一个异步事件驱动的网络应用程序框架， 用于快速开发可维护的高性能协议服务器和客户端。它极大地简化并简化了TCP和UDP套接字服务器等网络编程。</p>
<p>BIO：(Blocking IO)</p>
<figure data-type="image" tabindex="59"><img src="https://uploader.shimo.im/f/2W5W02pWhRc1tfWH.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>BIO：阻塞式 IO。每一个请求进来，开一个 Socket 开一个线程来处理数据，读取到数据后业务逻辑操作完成后返回。服务器收到很多请求，同时操作，在这个业务逻辑完成前这个线程不能得到释放，服务器就不能同时处理大量请求，因为有大量线程在阻塞，等待业务逻辑的完成。</p>
</blockquote>
<p>NIO (Non-Blocking IO)</p>
<figure data-type="image" tabindex="60"><img src="https://uploader.shimo.im/f/i2Hhf1AEfLE0e9rK.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>Channel：通道，通道里面有 Buffer 用来进行数据传输。<br>
一个 Selector 注册进了很多通道，每个请求使用通道进行数据传递通信，Selector 通过监听多个通道，当发现某一个通道里的数据准备好了，Selector 执行相应操作。</p>
</blockquote>
<p>Selector 一般称 为<strong>选择器</strong> ，也可以翻译为 <strong>多路复用器，</strong></p>
<p>Connect（连接就绪）、Accept（接受就绪）、Read（读就绪）、Write（写就绪）</p>
<p>Netty基本原理：</p>
<figure data-type="image" tabindex="61"><img src="https://uploader.shimo.im/f/M16PnkZ6fGY7YG8J.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>Netty 服务器启动（ServerBootstrap.bind），绑定监听某一个端口，比如 dubbo 的20880端口，这样所有给这个端口发的数据 netty 就能收到，启动后初始化服务器的通道（NioServerSockerChannel），注册到 selector，selector 负责监听 accept 事件（当通道接收准备就绪后，处理通道里的信息），netty 与客户端建立连接， 生成 NioSocketChannel，把这个  通道注册到 Selector 里面，这个 selector 监听 read、write 事件（通道中数据读、写准备就绪），读写准备就绪后来处理这个事件，抛给用户队列，netty 把这个任务队列执行完</p>
</blockquote>
<h2 id="3-dubbo原理">3、dubbo原理</h2>
<h3 id="1-dubbo原理-框架设计">1、dubbo原理	-框架设计</h3>
<figure data-type="image" tabindex="62"><img src="https://uploader.shimo.im/f/mktdQ0QVP0s1eieu.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>dubbo 框架整体分层：</p>
<ol>
<li>Business 业务逻辑层：<br>
1.1 Service服务层：面向接口编程。接口、实现。想要远程调用只需要调用接口的方法，就自动调实现了。 对于用户编程，只需要关心这一层就结束了。<br>
2.RPC层：完成远程过程调用：<br>
2.1 Config 配置层，封装配置文件里解析出来的信息 ReferenceConfig、ServiceConfig；<br>
2.2 Proxy 服务代理层：利用代理的方式，生成客户端代理对象、服务端代理对象，代理对象互相调用方法；<br>
2.2 Registry 注册中心层：完成服务的发现和注册；很多服务要注册到注册中心，消费者要从注册中心订阅所需要的服务来调用；<br>
2.3 Cluster 路由层：负载均衡。invoker 调用者要调用很多的服务，服务在很多机器上跑，需要负载均衡；<br>
2.4 Monitor 监控层：每一次的调用信息都会向监控层发送一些数据；<br>
2.5 Protocol 远程调用层：封装 RPC 调用，RPC 调用核心的三个：Invoker、Protocol、Exporter；</li>
<li>Remoting 层：远程要调用就要跟 A、B两个服务器架起通信管道，通信以及在通信间传递数据<br>
3.1 Exchange 信息交换层：创建一个客户端 ExchangeClient、服务端 ExchangeServer<br>
两端架起网架进行数据的互联互通；<br>
3.2 Transport 传输层：真正传输数据用 Transporter 来封装传输的，Transporter 底层就是 netty 框架，netty 框架就是在这一层封装；<br>
3.3 Serialize 序列化层：序列化</li>
</ol>
</blockquote>
<ul>
<li>config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类</li>
<li>proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory</li>
<li>registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService</li>
<li>cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance</li>
<li>monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService</li>
<li>protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter</li>
<li>exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer</li>
<li>transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec</li>
<li>serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool</li>
</ul>
<h3 id="2-dubbo原理-启动解析-加载配置信息">2、dubbo原理	-启动解析、加载配置信息</h3>
<figure data-type="image" tabindex="63"><img src="https://uploader.shimo.im/f/iFVXso8DLkEuO0r6.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="3-dubbo原理-服务暴露">3、dubbo原理	-服务暴露</h3>
<figure data-type="image" tabindex="64"><img src="https://uploader.shimo.im/f/2ocFX7K06DopwxGs.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="4-dubbo原理-服务引用">4、dubbo原理	-服务引用</h3>
<figure data-type="image" tabindex="65"><img src="https://uploader.shimo.im/f/DxTlKd889QMR0jp1.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="5-dubbo原理-服务调用">5、dubbo原理	-服务调用</h3>
<figure data-type="image" tabindex="66"><img src="https://uploader.shimo.im/f/rugf4MklrfIiNoOW.png!thumbnail" alt="图片" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[记一个面试题 —— 实现一个读写锁]]></title>
        <id>https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-shi-xian-yi-ge-du-xie-suo/</id>
        <link href="https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-shi-xian-yi-ge-du-xie-suo/">
        </link>
        <updated>2020-04-10T05:57:59.000Z</updated>
        <content type="html"><![CDATA[<h1 id="用共享对象实现写优先的读者写者锁">用共享对象实现写优先的读者写者锁</h1>
<p>首先，我们实现一个读者/写者锁。类似于一个普通的互斥锁，一个读者/写者锁(RWLock)保护共享数据。然而，它会做如下的优化。为了最大化性能，一个 RWLock 允许多个“读者”线程同时访问共享数据。任意数量的线程可以在同一时间安全地读共享数据，只要没有线程在修改数据。然而，任意时刻，至多只能有 1 个写者线程可以持有 RWLock（读者线程只能读共享数据，写者线程既可以写也可以读共享数据）。当一个写者线程持有 RWLock，它可以安全地修改数据，因为锁保证了不会有其他的线程同时持有该锁。读者写者锁常常被用于数据库，它们被用于支持对数据库的更快的搜索查询，同时也支持不太频繁的更新。另一个常见的应用是在操作系统内核中，核心的数据结构常常被许多线程读但更新却不太频繁。为了将我们的互斥锁一般化为一个读者/写者锁，我们实现了一个新类型的共享对象，RWLock，来保护对共享数据的访问。RWLock 采用了我们标准化的同步构建模块：互斥锁和条件变量来实现。<br>
一个线程想要（原子地）读共享数据，其过程如下：</p>
<pre><code>rwLock-&gt;startRead();
read shared data
rwLock-&gt;doneRead();
</code></pre>
<p>类似的，一个线程想要（原子地）写共享数据，其过程如下：</p>
<pre><code>rwLock-&gt;startWrite();
Read and write shared data
rwLock-&gt;doneWrite();
</code></pre>
<p>为了设计 RWLock 类，我们首先定义它的接口（如上面代码所示），和它的共享状态。这里，对象的行为可以通过<strong>正在读和正在写的线程的数量和等待读和等代写的线程的数量</strong>来刻画。所以，我们需要 4 个整数来追踪这些值。 代码 5.9 展示了 RWLock 类的成员和接口. 接下来，我们通过提出以下的问题来添加同步变量，“什么时候方法需要等待？”首先，我们添加一个互斥锁：保证当有线程在访问 RWLock 的方法的时候，其他访问 RWLock 的方法的线程必须等待。接下来，我们观察到 startRead 或 startWrite 可能需要等待，因此我们为每种情况添加了一个条件变量：readGo 和 writeGo.</p>
<h2 id="读者写者锁的接口和成员变量">读者/写者锁的接口和成员变量</h2>
<pre><code>class RWLock{
    private:
        //Synchronization variables
        Lock lock;
        CV readGo;
        CV writeGo;

        // State variables
        int activeReaders;
        int activeWriters;
        int waitingReaders;
        int waitingWriters;
    public:
        RWLock();
        ~RWLock(){};
        void startRead();
        void doneRead();
        void startWrite();
        void doneWrite();
    private:
        bool readShouldWait();
        bool writeShouldWait();
} 
</code></pre>
<p>代码 5.9：  我们的读者/写者锁的接口和成员变量<br>
RWLock: doneRead 和 doneWrite 不需要等待（不包括获取互斥锁）。因此，这些方法不需要额外的条件变量。<br>
现在我们实现 RWLock。<br>
首先，我们先给每个方法添加上锁的获取和锁的释放。如下图所示：</p>
<pre><code>void RWLock :: startRead(){
    lock.acquire();

    lock.release();
}

void RWLock::doneRead(){
    lock.acquire();

    lock.release();
}
</code></pre>
<p>RWLock::startWrite 和 RWLock::doneWrite 也类似。</p>
<p>由于我们知道 startRead 和 startWrite 必须等待，因此我们可以在每个方法的中间写上while(…){wait();}的循环。然后，我们开始思考其中的细节，例如循环等待的判断条件。代码 5.10 展示了完整的解法。</p>
<h2 id="读者写者锁完整代码">读者写者锁完整代码</h2>
<pre><code>// Wait until no active or waiting writers,then proceed
void RWLock::startRead(){
    lock.acquire();
    waitingReaders++;
    while(readShouldWait()){
        readGo.Wait(&amp;lock);
    }
    waitingReaders--;
    activeReaders++;
    lock.release();
}

// Done reading.If no other active readers,a write may proceed.
void RWLock::doneRead(){
    lock.acquire();
    activeReaders--;
    if(activeReaders == 0 &amp;&amp; waitingWriters &gt; 0){
        writeGo.signal();
    }
    lock.release();
}

// Read waits if any active or waiting write(&quot;writers preferred&quot;).
bool RWLock::readShouldWait(){
    return (activeWriters &gt; 0 || waitingWriters &gt; 0);
}

// Wait until no active read or write then proceed;
void RWLock::startWrite(){
    lock.acquire();
    waitingWriterw++;
    while(writeShouldWait()){
        writeGo.Wait(&amp;lock);
    }
    waitingWriters--;
    activeWriters++;
    lock.release();
}

// Done writing. A waiting write or read may proceed.
void RWLock::doneWrite(){
    lock.acquire();
    activeWriters--;
    assert(activeWriters == 0);
    if(waitingWriters &gt; 0){
        writeGo.signal();
    }else{
        readGo.broadcast();
    }
    lock.release();
}

// Write waits for active read or write.
bool RWLock::writeShouldWait(){
    return(activeWriters &gt; 0 || activeReaders &gt; 0);
}
</code></pre>
<p>代码 5.10：  一个读者写者锁的实现</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis 持久化]]></title>
        <id>https://epitomm.github.io/post/redis-chi-jiu-hua/</id>
        <link href="https://epitomm.github.io/post/redis-chi-jiu-hua/">
        </link>
        <updated>2020-04-08T10:03:41.000Z</updated>
        <content type="html"><![CDATA[<h1 id="持久化简介">持久化简介</h1>
<h2 id="意外的断电">意外的断电</h2>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E6%96%AD%E7%94%B5.png" alt="图片" loading="lazy"></figure>
<h2 id="自动备份">“自动备份”</h2>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD.png" alt="图片" loading="lazy"></figure>
<h2 id="什么是持久化">什么是持久化</h2>
<p>利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化。</p>
<h2 id="为什么要进行持久化">为什么要进行持久化</h2>
<p>防止数据的意外丢失，确保数据安全性</p>
<h2 id="持久化过程保存什么">持久化过程保存什么</h2>
<ul>
<li>将当前数据状态进行保存，<strong>快照</strong>形式，存储数据结果，存储格式简单，关注点在<strong>数据</strong></li>
<li>将数据的操作过程进行保存，<strong>日志</strong>形式，存储操作过程，存储格式复杂，关注点在<strong>数据的操作过程</strong></li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/redis%E6%8C%81%E4%B9%85%E5%8C%96.png" alt="图片" loading="lazy"></figure>
<h1 id="rdb">RDB</h1>
<h2 id="rdb启动方式">RDB启动方式</h2>
<h2 id="谁什么时间干什么事情">谁，什么时间，干什么事情</h2>
<p>命令执行</p>
<ul>
<li>谁：redis操作者（用户）</li>
<li>什么时间：即时（随时进行）</li>
<li>干什么事情：保存数据</li>
</ul>
<h2 id="rdb启动方式-save指令">RDB启动方式 —— save指令</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>save 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>手动执行一次保存操作</p>
<p>redis-cli</p>
<pre><code>127.0.0.1:6379&gt; set name ssm
OK
127.0.0.1:6379&gt; save
OK
127.0.0.1:6379&gt; set age 20
OK
127.0.0.1:6379&gt; save
OK
127.0.0.1:6379&gt; 
</code></pre>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z data]# ll
total 4
-rw-r--r-- 1 root root 3918 Feb 25 21:23 6379.log
[root@iZ2ze4u2bufi0915gyi843Z data]# ll
total 8
-rw-r--r-- 1 root root 3969 Feb 25 21:24 6379.log
-rw-r--r-- 1 root root  107 Feb 25 21:24 dump.rdb
[root@iZ2ze4u2bufi0915gyi843Z data]# ll
total 8
-rw-r--r-- 1 root root 4020 Feb 25 21:24 6379.log
-rw-r--r-- 1 root root  114 Feb 25 21:24 dump.rdb
[root@iZ2ze4u2bufi0915gyi843Z data]# cat dump.rdb 
REDIS0009	redis-ver5.0.7
redis-bits󿿀򳨭e
              Uused-memx
</code></pre>
<h3 id="rdb启动方式-save指令相关配置">RDB启动方式 —— save指令相关配置</h3>
<ul>
<li>dbfilename dump.rdb
<ul>
<li>说明：设置本地数据库文件名，默认值为 dump.rdb</li>
<li>经验：通常设置为**dump-<strong><strong>端口号</strong></strong>.rdb **</li>
</ul>
</li>
<li>dir
<ul>
<li>说明：设置存储.rdb文件的路径</li>
<li>经验：通常设置成存储空间较大的目录中，目录名称**data **</li>
</ul>
</li>
<li>rdbcompression yes
<ul>
<li>说明：设置存储至本地数据库时是否<strong>压缩数据</strong>，默认为 yes，采用 LZF 压缩</li>
<li>经验：通常默认为开启状态，如果设置为no，可以节省 CPU 运行时间，但会使存储的文件变大（巨大）</li>
</ul>
</li>
<li>rdbchecksum yes
<ul>
<li>说明：设置是否进行RDB<strong>文件格式校验</strong>，该校验过程在写文件和读文件过程均进行</li>
<li>经验：通常默认为开启状态，如果设置为no，可以节约读写性过程约10%时间消耗，但是存储一定的数据损坏风险</li>
</ul>
</li>
</ul>
<h3 id="rdb启动方式-save指令工作原理">RDB启动方式 —— save指令工作原理</h3>
<p><img src="https://epitomm.github.io/post-images/Redis%E6%8C%87%E4%BB%A4save.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/Redis%E6%8C%87%E4%BB%A4save2.png" alt="图片" loading="lazy"></p>
<p><strong>注意：<strong>save指令的执行会</strong>阻塞</strong>当前Redis服务器，直到当前RDB过程完成为止，有可能会造成长时间阻塞，线上环境不建议使用。</p>
<h2 id="数据量过大单线程执行方式造成效率过低如何处理">数据量过大，单线程执行方式造成效率过低如何处理？</h2>
<h3 id="后台执行-bgsave">后台执行 （bgsave）</h3>
<ul>
<li>谁：redis操作者（用户）发起指令；redis服务器控制指令执行</li>
<li>什么时间：即时（发起）；合理的时间（执行）</li>
<li>干什么事情：保存数据</li>
</ul>
<h3 id="bgsave指令">bgsave指令</h3>
<ul>
<li>命令</li>
</ul>
<pre><code>bgsave 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>手动启动后台保存操作，但不是立即执行</p>
<h3 id="bgsave指令工作原理">bgsave指令工作原理</h3>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/bgsave.png" alt="图片" loading="lazy"></figure>
<p><strong>注意： <strong>bgsave命令是针对save阻塞问题做的优化。Redis内部所有涉及到RDB操作都采用bgsave的方式，save命令可以放弃使用</strong>。</strong></p>
<h3 id="bgsave指令相关配置">bgsave指令相关配置</h3>
<ul>
<li>dbfilename dump.rdb</li>
<li>dir</li>
<li>rdbcompression yes</li>
<li>rdbchecksum yes</li>
<li>stop-writes-on-bgsave-error yes
<ul>
<li>说明：后台存储过程中如果出现错误现象，是否停止保存操作</li>
<li>经验：通常默认为开启状态</li>
</ul>
</li>
</ul>
<h2 id="反复执行保存指令忘记了怎么办不知道数据产生了多少变化何时保存">反复执行保存指令，忘记了怎么办？不知道数据产生了多少变化，何时保存？</h2>
<h3 id="自动执行">自动执行</h3>
<ul>
<li>谁：redis服务器发起指令（基于条件）</li>
<li>什么时间：满足条件</li>
<li>干什么事情：保存数据</li>
</ul>
<h3 id="save配置">save配置</h3>
<ul>
<li>redis-6379.conf 内配置</li>
</ul>
<pre><code>save second changes 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>满足限定时间范围内key的变化数量达到指定数量即进行持久化</p>
<ul>
<li>参数
<ul>
<li>second：监控时间范围</li>
<li>changes：监控key的变化量</li>
</ul>
</li>
<li>位置
<ul>
<li>在conf文件中进行配置</li>
</ul>
</li>
<li>范例</li>
</ul>
<pre><code>save 900 1 
save 300 10 
save 60 10000
</code></pre>
<h3 id="save配置原理">save配置原理</h3>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/Redis%E6%8C%87%E4%BB%A4save3.png" alt="图片" loading="lazy"></figure>
<p>注意： save配置要根据实际业务情况进行设置，频度过高或过低都会出现性能问题，结果可能是灾难性的</p>
<p>save配置中对于second与changes设置通常具有互补对应关系，尽量不要设置成包含性关系</p>
<ul>
<li>save配置启动后执行的是bgsave操作</li>
</ul>
<h3 id="save配置相关配置">save配置相关配置</h3>
<ul>
<li>dbfilename dump.rdb</li>
<li>dir</li>
<li>rdbcompression yes</li>
<li>rdbchecksum yes</li>
</ul>
<h2 id="rdb三种启动方式对比">RDB三种启动方式对比</h2>
<table>
<thead>
<tr>
<th style="text-align:left">方式</th>
<th style="text-align:left">save指令</th>
<th style="text-align:left">bgsave指令（save配置）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读写</td>
<td style="text-align:left">同步</td>
<td style="text-align:left">异步</td>
</tr>
<tr>
<td style="text-align:left">阻塞客户端指令</td>
<td style="text-align:left">是</td>
<td style="text-align:left">否</td>
</tr>
<tr>
<td style="text-align:left">额外内存消耗</td>
<td style="text-align:left">否</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">启动新进程</td>
<td style="text-align:left">否</td>
<td style="text-align:left">是</td>
</tr>
</tbody>
</table>
<h2 id="rdb特殊启动形式">RDB特殊启动形式</h2>
<ul>
<li>全量复制</li>
</ul>
<p>在主从复制中详细讲解</p>
<ul>
<li>服务器运行过程中重启</li>
</ul>
<pre><code>debug reload 
</code></pre>
<ul>
<li>关闭服务器时指定保存数据</li>
</ul>
<pre><code>shutdown save 
</code></pre>
<p>默认情况下执行shutdown命令时，自动执行 bgsave(如果没有开启AOF持久化功能)</p>
<h2 id="rdb优点">RDB优点</h2>
<ul>
<li>RDB是一个紧凑压缩的<strong>二进制</strong>文件，**存储效率较高 **</li>
<li>RDB内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景</li>
<li>RDB<strong>恢复数据</strong>的<strong>速度</strong>要比AOF<strong>快</strong>很多</li>
<li>应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于<strong>灾难恢复</strong>。</li>
</ul>
<h2 id="rdb缺点">RDB缺点</h2>
<ul>
<li>RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性<strong>丢失数据</strong>（10点备份一次，11点备份一次，那么10点45的数据就丢失了）</li>
<li>bgsave指令每次运行要执行fork操作<strong>创建子进程</strong>，要**牺牲掉一些性能 **</li>
<li>Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现<strong>各版本</strong>服务之间数据格式<strong>无法兼容</strong>现象</li>
</ul>
<h1 id="aof">AOF</h1>
<h2 id="rdb存储的弊端">RDB存储的弊端</h2>
<ul>
<li>存储<strong>数据量较大</strong>，效率较低
<ul>
<li>基于<strong>快照</strong>思想，每次读写都是<strong>全部</strong>数据，当数据量巨大时，效率非常低</li>
</ul>
</li>
<li>大数据量下的**IO性能较低 **</li>
<li>基于fork创建<strong>子进程</strong>，<strong>内存</strong>产生额外<strong>消耗</strong></li>
<li>宕机带来的<strong>数据丢失</strong>风险 （快照是某个时间点的数据）</li>
</ul>
<h3 id="解决思路">解决思路</h3>
<ul>
<li>不写全数据，仅**记录部分数据 **</li>
<li>降低区分数据是否改变的难度，改记录数据为**记录操作过程 **</li>
<li>对所有操作均进行记录，<strong>排除丢失数据的风险</strong></li>
</ul>
<h2 id="aof概念">AOF概念</h2>
<ul>
<li>AOF(append only file)持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令达到恢复数据的目的。与RDB相比可以简单描述为改记录数据为记录数据产生的过程</li>
<li>AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式</li>
</ul>
<h2 id="aof写数据过程">AOF写数据过程</h2>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/AOF.png" alt="图片" loading="lazy"></figure>
<h3 id="aof写数据三种策略appendfsync">AOF写数据三种策略(****appendfsync)</h3>
<ul>
<li>always(每次）
<ul>
<li>每次写入操作均同步到AOF文件中，<strong>数据零误差</strong>，**性能较低 **，不建议使用。</li>
</ul>
</li>
<li>everysec（每秒）
<ul>
<li>每秒将缓冲区中的指令同步到AOF文件中，数据准确性较高，**性能较高 **，建议使用，也是默认配置</li>
<li>在系统突然宕机的情况下丢失1秒内的数据</li>
</ul>
</li>
<li>no（系统控制）
<ul>
<li>由操作系统控制每次同步到AOF文件的周期，整体过程<strong>不可控</strong></li>
</ul>
</li>
</ul>
<h2 id="aof功能开启">AOF功能开启</h2>
<ul>
<li>配置</li>
</ul>
<pre><code>appendonly yes|no 
</code></pre>
<ul>
<li>作用
<ul>
<li>是否开启AOF持久化功能，默认为不开启状态</li>
</ul>
</li>
<li>配置</li>
</ul>
<pre><code>appendfsync always|everysec|no 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>AOF写数据策略</p>
<h2 id="aof相关配置">AOF相关配置</h2>
<ul>
<li>配置</li>
</ul>
<pre><code>appendfilename filename 
</code></pre>
<ul>
<li>作用
<ul>
<li>AOF持久化文件名，默认文件名为appendonly.aof，建议配置为appendonly-端口号.aof</li>
</ul>
</li>
<li>配置</li>
</ul>
<pre><code>dir 
</code></pre>
<ul>
<li>作用
<ul>
<li>AOF持久化文件保存路径，与RDB持久化文件保持一致即可</li>
</ul>
</li>
</ul>
<h2 id="aof写数据遇到的问题">AOF写数据遇到的问题</h2>
<h3 id="如果连续执行如下指令该如何处理">如果连续执行如下指令该如何处理</h3>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/AOF%E4%BE%8B%E5%AD%90.png" alt="图片" loading="lazy"></figure>
<h3 id="aof重写">AOF重写</h3>
<p>随着命令不断写入AOF，<strong>文件会越来越大</strong>，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积。AOF文件重写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。简单说就是<strong>将对同一个数据的若干个条命令执行结果转化成最终结果数据对应的指令</strong>进行记录。</p>
<h3 id="aof重写作用">AOF重写作用</h3>
<ul>
<li>降低磁盘占用量，提高磁盘利用率</li>
<li>提高持久化效率，降低持久化写时间，提高IO性能</li>
<li>降低数据恢复用时，提高数据恢复效率</li>
</ul>
<h3 id="aof重写规则">AOF重写规则</h3>
<ul>
<li>进程内已超时的数据不再写入文件</li>
<li>忽略无效指令，重写时使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令
<ul>
<li>如del key1、 hdel key2、srem key3、set key4 111、set key4 222等</li>
</ul>
</li>
<li>对同一数据的多条写命令合并为一条命令
<ul>
<li>如lpush list1 a、lpush list1 b、 lpush list1 c 可以转化为：lpush list1 a b c。</li>
<li>为防止数据量过大造成客户端缓冲区溢出，对list、set、hash、zset等类型，每条指令最多写入64个元素</li>
</ul>
</li>
</ul>
<h3 id="aof重写方式">AOF重写方式</h3>
<ul>
<li>手动重写</li>
</ul>
<pre><code>bgrewriteaof 
</code></pre>
<ul>
<li>自动重写</li>
</ul>
<pre><code>auto-aof-rewrite-min-size size 
auto-aof-rewrite-percentage percentage
</code></pre>
<h3 id="aof手动重写-bgrewriteaof指令工作原理">AOF手动重写 —— bgrewriteaof指令工作原理</h3>
<p><img src="https://epitomm.github.io/post-images/bgsave%E6%8C%87%E4%BB%A4%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/bgrewriteaof%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"></p>
<h3 id="aof自动重写方式">AOF自动重写方式</h3>
<ul>
<li>自动重写触发条件设置</li>
</ul>
<pre><code>auto-aof-rewrite-min-size size 
auto-aof-rewrite-percentage percent 
</code></pre>
<ul>
<li>自动重写触发比对参数（ 运行指令info Persistence获取具体信息 ）</li>
</ul>
<pre><code>aof_current_size 
aof_base_size 
</code></pre>
<ul>
<li>自动重写触发条件</li>
</ul>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91%E9%87%8D%E5%86%99%E6%9D%A1%E4%BB%B6.png" alt="图片" loading="lazy"></figure>
<h3 id="aof重写流程">AOF重写流程</h3>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/AOF%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B1.png" alt="图片" loading="lazy"></figure>
<h3 id="aof重写流程-2">AOF重写流程</h3>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/AOF%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B2.png" alt="图片" loading="lazy"></figure>
<p>AOF缓冲区同步文件策略，由参数appendfsync控制</p>
<p>系统调用write和fsync说明：</p>
<ul>
<li>write操作会触发延迟写（delayed write）机制，Linux在内核提供页缓冲区用来提高硬盘IO性能。write操作在写入系统缓冲区后直接返回。同步硬盘操作依赖于系统调度机制，列如：缓冲区页空间写满或达到特定时间周期。同步文件之前，如果此时系统故障宕机，缓冲区内数据将丢失。</li>
<li>fsync针对单个文件操作（比如AOF文件），做强制硬盘同步，fsync将阻塞知道写入硬盘完成后返回，保证了数据持久化。</li>
</ul>
<p>除了write、fsync、Linx还提供了sync、fdatasync操作，具体API说明参见：</p>
<h1 id="rdb与aof区别">RDB与AOF区别</h1>
<table>
<thead>
<tr>
<th style="text-align:left">持久化方式</th>
<th style="text-align:left">RDB</th>
<th style="text-align:left">AOF</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">占用存储空间</td>
<td style="text-align:left">小（数据级：压缩）</td>
<td style="text-align:left">大（指令级：重写）</td>
</tr>
<tr>
<td style="text-align:left">存储速度</td>
<td style="text-align:left">慢</td>
<td style="text-align:left">快</td>
</tr>
<tr>
<td style="text-align:left">恢复速度</td>
<td style="text-align:left">快</td>
<td style="text-align:left">慢</td>
</tr>
<tr>
<td style="text-align:left">数据安全性</td>
<td style="text-align:left">会丢失数据</td>
<td style="text-align:left">依据策略决定</td>
</tr>
<tr>
<td style="text-align:left">资源消耗</td>
<td style="text-align:left">高 / 重量级</td>
<td style="text-align:left">低 / 轻量级</td>
</tr>
<tr>
<td style="text-align:left">启动优先级</td>
<td style="text-align:left">低</td>
<td style="text-align:left">高</td>
</tr>
</tbody>
</table>
<h3 id="rdb与aof的选择之惑">RDB与AOF的选择之惑</h3>
<ul>
<li>对<strong>数据非常敏感</strong>，建议使用默认的<strong>AOF</strong>持久化方案
<ul>
<li>AOF持久化策略使用everysecond，每秒钟fsync一次。该策略redis仍可以保持很好的处理性能，当出现问题时，最多丢失0-1秒内的数据。</li>
<li>注意：由于AOF文件存储体积较大，且恢复速度较慢</li>
</ul>
</li>
<li>数据呈现<strong>阶段有效性</strong>，建议使用<strong>RDB</strong>持久化方案
<ul>
<li>数据可以良好的做到阶段内无丢失（该阶段是开发者或运维人员手工维护的），且恢复速度较快，阶段点数据恢复通常采用RDB方案</li>
<li>注意：利用RDB实现紧凑的数据持久化会使Redis降的很低</li>
</ul>
</li>
<li>综合比对
<ul>
<li>RDB与AOF的选择实际上是在做一种权衡，每种都有利有弊</li>
<li>如不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用AOF</li>
<li>如能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用RDB</li>
<li>灾难恢复选用RDB</li>
<li>双保险策略，同时开启 RDB 和 AOF，重启后，Redis优先使用 AOF 来恢复数据，降低丢失数据的量</li>
</ul>
</li>
</ul>
<h1 id="持久化应用场景">持久化应用场景</h1>
<ul>
<li>Tips 1：<s>redis用于控制</s><strong><s>数据库表主键id</s></strong>~~，为数据库表主键提供生成策略，保障数据库表的主键唯一性 ~~【假如现在计算机停止工作，下一次启动要恢复时，不期望数据是从 redis 读取的。比如 id  如果用到 18 了，下一次恢复的时候从 18 恢复，大概率有问题，中间断的会导致 id 不连续，比如有一秒用了 19，但是 redis 没有记下来，下次从 18 恢复就会 id 重复。解决方案：从数据库读取，找出最大的 id ，然后加一使用。所以数据库主键 id 不建议持久化】</li>
<li>Tips 3：<s>redis应用于各种结构型和非结构型</s><strong><s>高热度数据访问加速</s></strong>~~ ~~（缓存里的数据要不要数据化？）【缓存中的数据从数据库读取加载来的，从 redis 读取出来和从数据库读出来没什么区别】</li>
<li>Tips 4：<s>redis 应用于</s><strong><s>购物车</s></strong><s>数据存储设计</s> 【购物车信息数据库内肯定要存，就导致 redis 和数据库内存的一样，所以 redis 就不额外存储】</li>
<li>Tips 5：redis 应用于<strong>抢购</strong>，限购类、限量发放优惠卷、激活码等业务的数据存储设计 【抢购：速度非常快，几秒钟内完成然后消失掉，如在这个过程中出现问题了，数据库可能没有持久化， 也可能记录了过程。 快速存储、快速消失的数据持久化】</li>
<li>Tips 6：redis 应用于具有<strong>操作先后顺序</strong>的数据控制 【临时任务，如果消息存储量不大，建议持久化】</li>
<li>Tips 7：redis 应用于<strong>最新消息展示</strong></li>
<li>Tips 9：<s>redis 应用于同类信息的</s><strong><s>关联搜索</s></strong>~~，二度关联搜索，深度关联搜索 ~~【关系网庞大，存到数据库】</li>
<li>Tips 12：redis 应用于基于<strong>黑名单</strong>与<strong>白名单</strong>设定的服务控制 【永久性存到数据库，临时性持久化】</li>
<li>Tips 13：redis 应用于计数器组合排序功能对应的<strong>排名 【20个主播一起主播，进行排名，主播结束数据就消失了，如果不持久化这个信息，它也不在数据库内存储就没有了。20万人在线观看，如果不持久化记录服务器一宕机就0人在线了，所以需持久化记录快速恢复】</strong></li>
<li>Tips 15：redis 应用于<strong>即时任务/消息队列</strong>执行管理</li>
<li>Tips 16：redis 应用于<strong>按次结算的服务控制</strong></li>
</ul>
<h1 id="总结">总结</h1>
<p>Redis持久化</p>
<ul>
<li>什么是持久化</li>
<li>RDB
<ul>
<li>save</li>
<li>bgsave</li>
<li>配置</li>
</ul>
</li>
<li>AOF
<ul>
<li>持久化写策略</li>
<li>重写</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[42道计算机网络面试高频题+答案，面试官喜欢的答案都在这里！]]></title>
        <id>https://epitomm.github.io/post/42-dao-ji-suan-ji-wang-luo-mian-shi-gao-pin-ti-da-an-mian-shi-guan-xi-huan-de-da-an-du-zai-zhe-li/</id>
        <link href="https://epitomm.github.io/post/42-dao-ji-suan-ji-wang-luo-mian-shi-gao-pin-ti-da-an-mian-shi-guan-xi-huan-de-da-an-du-zai-zhe-li/">
        </link>
        <updated>2020-04-03T04:48:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-谈下你对五层网络协议体系结构的理解">1、谈下你对五层网络协议体系结构的理解（*）</h1>
<p>学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。</p>
<figure data-type="image" tabindex="1"><img src="https://uploader.shimo.im/f/7hz3woCT4osuGDlM.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="1-应用层">1. 应用层</h2>
<figure data-type="image" tabindex="2"><img src="https://uploader.shimo.im/f/VgEj6OsBq3M4NeVo.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>应用层（application-layer）的任务是<strong>通过应用进程间的交互来完成特定网络应用</strong>。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。我们把应用层交互的数据单元称为报文。</p>
<h2 id="2-运输层">2. 运输层</h2>
<figure data-type="image" tabindex="3"><img src="https://uploader.shimo.im/f/vK8fB6Z7AYwmj7pZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>运输层（transport layer）的主要任务就是负责<strong>向两台主机进程之间的通信提供通用的数据传输服务</strong>。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。</p>
<figure data-type="image" tabindex="4"><img src="https://uploader.shimo.im/f/6lbS0Lrsgp4A08VN.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。</p>
<h2 id="3-网络层">3. 网络层</h2>
<figure data-type="image" tabindex="5"><img src="https://uploader.shimo.im/f/Zhp7yuBDGiAfWeXE.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是<strong>选择合适的网间路由和交换结点， 确保数据及时传送</strong>。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP / IP 体系结构中，由于网络层使用 IP 协议，因此<strong>分组</strong>也叫 <strong>IP 数据报</strong>，简称数据报。</p>
<h2 id="4-数据链路层">4. 数据链路层</h2>
<figure data-type="image" tabindex="6"><img src="https://uploader.shimo.im/f/xYbKq3tQOuQDgd28.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>数据链路层（data link layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，<strong>数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧</strong>。每一帧包括数据和必要的控制信息（如：同步信息，地址信息，差错控制等）。</p>
<figure data-type="image" tabindex="7"><img src="https://uploader.shimo.im/f/dBp0roAfwA0pkbOv.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://uploader.shimo.im/f/HyQygpuEJPwv7E1L.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://uploader.shimo.im/f/OXtDKDdN8Rkqt0O7.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出<strong>数据部分</strong>，上交给网络层。控制信息还使接收端能够检测到所收到的帧中<strong>有无差错</strong>。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用<strong>可靠性传输协议</strong>来纠正出现的差错。这种方法会使链路层的协议复杂些。</p>
<h2 id="5-物理层">5. 物理层</h2>
<figure data-type="image" tabindex="10"><img src="https://uploader.shimo.im/f/5W4Y12Sb37oiQxav.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在物理层上所传送的数据单位是<strong>比特</strong>。物理层（physical layer）的作用是实现相邻计算机节点之间<strong>比特流的透明传送</strong>，尽可能<strong>屏蔽掉具体传输介质和物理设备的差异</strong>。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。</p>
<h1 id="2-简单说下每一层对应的网络协议有哪些">2、简单说下每一层对应的网络协议有哪些？（**）</h1>
<blockquote>
<p>简单记住两三个常见的就行。</p>
</blockquote>
<p>计算机五层网络体系中涉及的协议非常多，下面就常用的做了列举：</p>
<figure data-type="image" tabindex="11"><img src="https://uploader.shimo.im/f/KEPmaUdZoIkiZWZS.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="3-arp-协议的工作原理">3、ARP 协议的工作原理？（*）</h1>
<figure data-type="image" tabindex="12"><img src="https://uploader.shimo.im/f/Imrbk2qiUVUV8c5K.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="mac-地址">MAC 地址</h2>
<figure data-type="image" tabindex="13"><img src="https://uploader.shimo.im/f/7hAVdUAX3KgOQISG.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://uploader.shimo.im/f/it41YFgMMpkXBCES.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>MAC 地址有时也被称为<strong>物理地址</strong>，但这不意味着 MAC 属于网络体系结构中的物理层，MAC 地址属于<strong>数据链路层</strong>。</p>
</blockquote>
<h2 id="ip-地址">IP 地址</h2>
<figure data-type="image" tabindex="15"><img src="https://uploader.shimo.im/f/fQTQYZC4YxIRcPuj.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://uploader.shimo.im/f/pUpJ0mXvAIkRKYb5.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="https://uploader.shimo.im/f/3UMQHY27Dno3U2Z0.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="https://uploader.shimo.im/f/14nXPBBhg9s7ViKb.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="https://uploader.shimo.im/f/MmcffwXZYTMTQYyN.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="arp-协议">ARP 协议</h2>
<figure data-type="image" tabindex="20"><img src="https://uploader.shimo.im/f/FJA5dMHkRC8QXQBQ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="21"><img src="https://uploader.shimo.im/f/mZ9TWqnTfQgqff8m.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="https://uploader.shimo.im/f/o2CuEUAoXKQrBgtv.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="23"><img src="https://uploader.shimo.im/f/yF69YY3Gh2wFp0k2.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://uploader.shimo.im/f/irwCT9nLdQ0WDlUr.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="25"><img src="https://uploader.shimo.im/f/CD4J1MjqhZYJM9Ro.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>ARP 只能在一段链路或一个网络上使用，不能跨网络使用。</p>
</blockquote>
<p><strong>网络层</strong>的 ARP 协议完成了 <strong>IP 地址与物理地址的映射</strong>。首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址：如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。</p>
<p>此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。</p>
<h1 id="4-谈下你对-ip-地址分类的理解">4、谈下你对 IP 地址分类的理解？</h1>
<p>IP 地址是指互联网协议地址，是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP 地址编址方案将 IP 地址空间划分为 A、B、C、D、E 五类，其中 A、B、C 是基本类，D、E 类作为多播和保留使用，为特殊地址。</p>
<figure data-type="image" tabindex="26"><img src="https://uploader.shimo.im/f/6TvJJC0SKC8N3fRi.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>每个 IP 地址包括两个标识码（ID），即网络 ID 和主机 ID。同一个物理网络上的所有主机都使用同一个网络 ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机 ID 与其对应。A~E 类地址的特点如下：</p>
<p>A 类地址：以 0 开头，第一个字节范围：0~127；</p>
<p>B 类地址：以 10 开头，第一个字节范围：128~191；</p>
<p>C 类地址：以 110 开头，第一个字节范围：192~223；</p>
<p>D 类地址：以 1110 开头，第一个字节范围为 224~239；</p>
<p>E 类地址：以 1111 开头，保留地址</p>
<figure data-type="image" tabindex="27"><img src="https://uploader.shimo.im/f/H8ZWz6fsJMkBBNBs.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="28"><img src="https://uploader.shimo.im/f/6O9LBeVjsNA3cjL1.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="29"><img src="https://uploader.shimo.im/f/lrFOgqmsEG806jNp.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="30"><img src="https://uploader.shimo.im/f/2IG540gBRwkMNP9e.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="31"><img src="https://uploader.shimo.im/f/G9oD9evG81EmL1QH.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="5-tcp-的主要特点是什么">5、TCP 的主要特点是什么？（*）</h1>
<ol>
<li>
<p>TCP 是<strong>面向连接</strong>的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；</p>
</li>
<li>
<p>每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是点对点的（<strong>一对一</strong>）；</p>
</li>
<li>
<p>TCP 提供<strong>可靠</strong>交付的服务。通过 TCP 连接传送的数据，无差错、不丢失、不重复、并且按序到达；</p>
</li>
<li>
<p>TCP 提供<strong>全双工</strong>通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；</p>
</li>
<li>
<p>面向<strong>字节流</strong>。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。</p>
</li>
</ol>
<h1 id="6-udp-的主要特点是什么">6、UDP 的主要特点是什么？</h1>
<ol>
<li>
<p>UDP 是<strong>无连接</strong>的；</p>
</li>
<li>
<p>UDP 使用尽最大努力交付，即<strong>不</strong>保证<strong>可靠</strong>交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；</p>
</li>
<li>
<p>UDP 是<strong>面向报文</strong>的；</p>
</li>
<li>
<p>UDP <strong>没有拥塞控制</strong>，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；</p>
</li>
<li>
<p>UDP 支持<strong>一对一、一对多、多对一和多对多</strong>的交互通信；</p>
</li>
<li>
<p>UDP 的<strong>首部开销小</strong>，只有 8 个字节，比 TCP 的 20 个字节的首部要短。</p>
</li>
</ol>
<h1 id="7-tcp-和-udp-的区别">7、TCP 和 UDP 的区别？（*）</h1>
<figure data-type="image" tabindex="32"><img src="https://uploader.shimo.im/f/cGEBZNflD9EjWCqz.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。</p>
<p>UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如：QQ 语音、 QQ 视频 、直播等等。</p>
<figure data-type="image" tabindex="33"><img src="https://uploader.shimo.im/f/mdhPaxpzb5oIJMW2.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="34"><img src="https://uploader.shimo.im/f/7u9g88OLoW4CdqQ7.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="35"><img src="https://uploader.shimo.im/f/fsJkcJYSPRs8C34V.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="36"><img src="https://uploader.shimo.im/f/fH5S3LGWfi0oHUxM.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="37"><img src="https://uploader.shimo.im/f/7Uwcb5rUdBsTs5Us.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="8-tcp-和-udp-分别对应的常见应用层协议有哪些">8、TCP 和 UDP 分别对应的常见应用层协议有哪些？</h1>
<ul>
<li>
<ol>
<li>TCP 对应的应用层协议</li>
</ol>
</li>
</ul>
<p>FTP：定义了文件传输协议，使用 21 端口。常说某某计算机开了 FTP 服务便是启动了文件传输服务。下载文件，上传主页，都要用到 FTP 服务。</p>
<p>Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于 DOS 模式下的通信服务。如以前的 BBS 是-纯字符界面的，支持 BBS 的服务器将 23 端口打开，对外提供服务。</p>
<p>SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么 SMTP 端口设置这个栏，服务器开放的是 25 号端口。</p>
<p>POP3：它是和 SMTP 对应，POP3 用于接收邮件。通常情况下，POP3 协议所用的是 110 端口。也是说，只要你有相应的使用 POP3 协议的程序（例如 Fo-xmail 或 Outlook），就可以不以 Web 方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163 邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。</p>
<p>HTTP：从 Web 服务器传输超文本到本地浏览器的传送协议。</p>
<ul>
<li>
<ol start="2">
<li>UDP 对应的应用层协议</li>
</ol>
</li>
</ul>
<p>DNS：用于域名解析服务，将域名地址转换为 IP 地址。DNS 用的是 53 号端口。</p>
<p>SNMP：简单网络管理协议，使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。</p>
<p>TFTP(Trival File Transfer Protocal)：简单文件传输协议，该协议在熟知端口 69 上使用 UDP 服务。</p>
<h1 id="9-详细说下-tcp-三次握手的过程">9、详细说下 TCP 三次握手的过程？（*）</h1>
<ul>
<li>
<ol>
<li>三次握手</li>
</ol>
</li>
</ul>
<p>TCP 建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 TCP 报文段。</p>
<figure data-type="image" tabindex="38"><img src="https://uploader.shimo.im/f/sVrpuVA01g4E8YtW.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>最初客户端和服务端都处于 CLOSED(关闭) 状态。本例中 A（Client） 主动打开连接，B（Server） 被动打开连接。</p>
<p>一开始，B 的 TCP 服务器进程首先创建传输控制块TCB，准备接受客户端进程的连接请求。然后服务端进程就处于 LISTEN(监听) 状态，等待客户端的连接请求。如有，立即作出响应。</p>
<p>第一次握手：A 的 TCP 客户端进程也是首先创建传输控制块 TCB。然后，在打算建立 TCP 连接时，向 B 发出连接请求报文段，这时首部中的同步位 SYN=1，同时选择一个初始序号 seq = x。TCP 规定，SYN 报文段（即 SYN = 1 的报文段）不能携带数据，但要消耗掉一个序号。这时，TCP 客户进程进入 SYN-SENT（同步已发送）状态。</p>
<p>第二次握手：B 收到连接请求报文后，如果同意建立连接，则向 A 发送确认。在确认报文段中应把 SYN 位和 ACK 位都置 1，确认号是 ack = x + 1，同时也为自己选择一个初始序号 seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时 TCP 服务端进程进入 SYN-RCVD（同步收到）状态。</p>
<p>第三次握手：TCP 客户进程收到 B 的确认后，还要向 B 给出确认。确认报文段的 ACK 置 1，确认号 ack = y +  1，而自己的序号 seq = x + 1。这时 ACK 报文段可以携带数据。但如果不携带数据则不消耗序号，这种情况下，下一个数据报文段的序号仍是 seq = x + 1。这时，TCP 连接已经建立，A 进入 ESTABLISHED（已建立连接）状态。</p>
<h1 id="10-为什么两次握手不可以呢">10、为什么两次握手不可以呢？（*）</h1>
<figure data-type="image" tabindex="39"><img src="https://uploader.shimo.im/f/FgFJfk6FgJQdTJko.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>为了防止已经失效的连接请求报文段突然又传送到了 B，因而产生错误。比如下面这种情况：A 发出的第一个连接请求报文段并没有丢失，而是在网路结点长时间滞留了，以致于延误到连接释放以后的某个时间段才到达 B。本来这是一个早已失效的报文段。但是 B 收到此失效的链接请求报文段后，就误认为 A 又发出一次新的连接请求。于是就向 A 发出确认报文段，同意建立连接。</p>
<p>对于上面这种情况，如果不进行第三次握手，B 发出确认后就认为新的运输连接已经建立了，并一直等待 A 发来数据。B 的许多资源就这样白白浪费了。</p>
<p>如果采用了三次握手，由于 A 实际上并没有发出建立连接请求，所以不会理睬 B 的确认，也不会向 B 发送数据。B 由于收不到确认，就知道 A 并没有要求建立连接。</p>
<h1 id="11-为什么不需要四次握手">11、为什么不需要四次握手？（*）</h1>
<p>有人可能会说 A 发出第三次握手的信息后在没有接收到 B 的请求就已经进入了连接状态，那如果 A 的这个确认包丢失或者滞留了怎么办？</p>
<p>我们需要明白一点，完全可靠的通信协议是不存在的。在经过三次握手之后，客户端和服务端已经可以确认之前的通信状况，都收到了确认信息。所以即便再增加握手次数也不能保证后面的通信完全可靠，所以是没有必要的。</p>
<h1 id="12-server-端收到-client-端的-syn-后为什么还要传回-syn">12、Server 端收到 Client 端的 SYN 后，为什么还要传回 SYN？</h1>
<p>接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。</p>
<p>SYN 是 TCP / IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符，在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误]）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。</p>
<h1 id="13-传了-syn为什么还要传-ack">13、传了 SYN，为什么还要传 ACK？</h1>
<p>双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。</p>
<h1 id="14-详细说下-tcp-四次挥手的过程">14、详细说下 TCP 四次挥手的过程？（*）</h1>
<p>据传输结束后，通信的双方都可以释放连接。现在 A 和 B 都处于 ESTABLISHED 状态。</p>
<figure data-type="image" tabindex="40"><img src="https://uploader.shimo.im/f/fJStbiea6HoBykQF.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>第一次挥手：A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP 连接。A 把连接释放报文段首部的终止控制位 FIN 置 1，其序号 seq = u（等于前面已传送过的数据的最后一个字节的序号加 1），这时 A 进入 FIN-WAIT-1（终止等待1）状态，等待 B 的确认。请注意：TCP 规定，FIN 报文段即使不携带数据，也将消耗掉一个序号。</p>
<p>第二次挥手：B 收到连接释放报文段后立即发出确认，确认号是 ack = u + 1，而这个报文段自己的序号是 v（等于 B 前面已经传送过的数据的最后一个字节的序号加1），然后 B 就进入 CLOSE-WAIT（关闭等待）状态。TCP 服务端进程这时应通知高层应用进程，因而从 A 到 B 这个方向的连接就释放了，这时的 TCP 连接处于半关闭（half-close）状态，即 A 已经没有数据要发送了，但 B 若发送数据，A 仍要接收。也就是说，从 B 到 A 这个方向的连接并未关闭，这个状态可能会持续一段时间。A 收到来自 B 的确认后，就进入 FIN-WAIT-2(终止等待2)状态，等待 B 发出的连接释放报文段。</p>
<p>第三次挥手：若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。这时 B 发出的连接释放报文段必须使 FIN = 1。假定 B 的序号为 w（在半关闭状态，B 可能又发送了一些数据）。B 还必须重复上次已发送过的确认号 ack = u + 1。这时 B 就进入 LAST-ACK(最后确认)状态，等待 A 的确认。</p>
<p>第四次挥手：A 在收到 B 的连接释放报文后，必须对此发出确认。在确认报文段中把 ACK 置 1，确认号 ack = w + 1，而自己的序号 seq = u + 1（前面发送的 FIN 报文段要消耗一个序号）。然后进入 TIME-WAIT(时间等待) 状态。请注意，现在 TCP 连接还没有释放掉。必须经过时间等待计时器设置的时间 2MSL（MSL：最长报文段寿命）后，A 才能进入到 CLOSED 状态，然后撤销传输控制块，结束这次 TCP 连接。当然如果 B 一收到 A 的确认就进入 CLOSED 状态，然后撤销传输控制块。所以在释放连接时，B 结束 TCP 连接的时间要早于 A。</p>
<h1 id="15-为什么-time-wait-状态必须等待-2msl-的时间呢">15、为什么 TIME-WAIT 状态必须等待 2MSL 的时间呢？（*）</h1>
<figure data-type="image" tabindex="41"><img src="https://uploader.shimo.im/f/IZd7Slvq5VQpgRyq.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li>
<p>为了保证 A 发送的最后一个 ACK 报文段能够到达 B。这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 FIN + ACK 报文段的确认。B 会超时重传这个 FIN+ACK 报文段，而 A 就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN+ACK 报文段。接着 A 重传一次确认，重新启动 2MSL 计时器。最后，A 和 B 都正常进入到 CLOSED 状态。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段，这样，B 就无法按照正常步骤进入 CLOSED 状态。</p>
</li>
<li>
<p>防止已失效的连接请求报文段出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。</p>
</li>
</ol>
<h1 id="16-为什么第二次跟第三次不能合并-第二次和第三次之间的等待是什么">16、为什么第二次跟第三次不能合并, 第二次和第三次之间的等待是什么?</h1>
<p>当服务器执行第二次挥手之后, 此时证明客户端不会再向服务端请求任何数据, 但是服务端可能还正在给客户端发送数据（可能是客户端上一次请求的资源还没有发送完毕），所以此时服务端会等待把之前未传输完的数据传输完毕之后再发送关闭请求。</p>
<h1 id="17-保活计时器的作用">17、保活计时器的作用？</h1>
<p>除时间等待计时器外，TCP 还有一个保活计时器（keepalive  timer）。设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。</p>
<p>服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔  75 秒钟发送一次。若连续发送 10个 探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。</p>
<h1 id="18-tcp-协议是如何保证可靠传输的">18、TCP 协议是如何保证可靠传输的？（*）</h1>
<ol>
<li>
<p><strong>数据包校验</strong>：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据；</p>
</li>
<li>
<p><strong>对失序数据包重排序</strong>：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层；</p>
</li>
<li>
<p><strong>丢弃重复数据</strong>：对于重复数据，能够丢弃重复数据；</p>
</li>
<li>
<p><strong>应答机制</strong>：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；</p>
</li>
<li>
<p><strong>超时重发</strong>：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；</p>
</li>
<li>
<p><strong>流量控制</strong>：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。</p>
</li>
</ol>
<h1 id="19-谈谈你对停止等待协议的理解">19、谈谈你对停止等待协议的理解？</h1>
<figure data-type="image" tabindex="42"><img src="https://uploader.shimo.im/f/ilbrX9885DshiTgj.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="43"><img src="https://uploader.shimo.im/f/I2PqsOrJ0BczTYUl.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认迟到、确认丢失和确认迟到。</p>
<figure data-type="image" tabindex="44"><img src="https://uploader.shimo.im/f/GwbkBys0LIYRMJgU.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="20-谈谈你对-arq-协议的理解">20、谈谈你对 ARQ 协议的理解？</h1>
<ul>
<li>自动重传请求 ARQ 协议</li>
</ul>
<p>停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。</p>
<ul>
<li>连续 ARQ 协议</li>
</ul>
<p>连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。</p>
<h1 id="21-谈谈你对滑动窗口的了解">21、谈谈你对滑动窗口的了解？（*）</h1>
<p>TCP 利用滑动窗口实现流量控制的机制。滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。</p>
<p>TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。</p>
<figure data-type="image" tabindex="45"><img src="https://uploader.shimo.im/f/HVPjgKO3S2Qq75tF.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="46"><img src="https://uploader.shimo.im/f/JRAM7qssAgUQ5Fnq.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="47"><img src="https://uploader.shimo.im/f/wblaPkbu32k96yVU.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="48"><img src="https://uploader.shimo.im/f/4MN4C6h3K30y3RjS.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="22-谈下你对流量控制的理解">22、谈下你对流量控制的理解？（*）</h1>
<p>TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</p>
<h1 id="23-谈下你对-tcp-拥塞控制的理解使用了哪些算法">23、谈下你对 TCP 拥塞控制的理解？使用了哪些算法？</h1>
<figure data-type="image" tabindex="49"><img src="https://uploader.shimo.im/f/Cxp9wJCABu8ya4XR.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="50"><img src="https://uploader.shimo.im/f/e1KHhdkCmu0JrJdy.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="51"><img src="https://uploader.shimo.im/f/A1Mt383YnYwRuMhl.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。在某段时间，若<strong>对网络中某一资源的需求超过了该资源所能提供的可用部分</strong>，网络的性能就要变坏。这种情况就叫<strong>拥塞</strong>。</p>
<p>拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致于过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。</p>
<p>为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。</p>
<p>TCP 的拥塞控制采用了四种算法，即：慢开始、拥塞避免、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如：主动队列管理 AQM），以减少网络拥塞的发生。</p>
<h2 id="慢开始">慢开始：</h2>
<figure data-type="image" tabindex="52"><img src="https://uploader.shimo.im/f/DwBr0f7gJWoRju09.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。<strong>cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍</strong>。</p>
<h2 id="拥塞避免">拥塞避免：</h2>
<figure data-type="image" tabindex="53"><img src="https://uploader.shimo.im/f/mnjZbVjUW7YioSgE.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="54"><img src="https://uploader.shimo.im/f/ZzBMLCrBW7AWgnTc.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="55"><img src="https://uploader.shimo.im/f/DhyXyH4VI3o4atqY.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="56"><img src="https://uploader.shimo.im/f/VSWKrfeo84Q3BEAg.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把<strong>发送方的 cwnd 加 1</strong>。</p>
<figure data-type="image" tabindex="57"><img src="https://uploader.shimo.im/f/a3mLciCHy54Vf9xL.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="快重传与快恢复">快重传与快恢复：</h2>
<figure data-type="image" tabindex="58"><img src="https://uploader.shimo.im/f/5JXdessxcTMMsAoG.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="59"><img src="https://uploader.shimo.im/f/lfhgzFCGEiQ7ZJNZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="60"><img src="https://uploader.shimo.im/f/YUstziH9Z0YCkxoZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="61"><img src="https://uploader.shimo.im/f/9Ej3t6jYGPA7arPd.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在 TCP/IP 中，快速重传和快恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。</p>
<p>有时，个别报文段会在网络中丢失，但实际上网络并未发生拥塞，这将导致发送方超时重传，并误认为网络发生了拥塞；发送方把拥塞窗口 cwnd 又设置为最小值 1，并错误地启动慢开始算法，因而降低了传输效率。采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。</p>
<p>所谓快重传，就是使发送方尽快进行重传，而不是等超时重传计时器超时再重传。</p>
<p>要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认；</p>
<p>即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。</p>
<p>发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传计时器超时再重传。</p>
<h1 id="24-什么是粘包">24、什么是粘包？</h1>
<p>在进行 Java NIO 学习时，可能会发现：如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况。</p>
<ol>
<li>
<p>TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界；</p>
</li>
<li>
<p>从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。</p>
</li>
</ol>
<p>基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。</p>
<p>接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。</p>
<h1 id="25-tcp-黏包是怎么产生的">25、TCP 黏包是怎么产生的？</h1>
<ul>
<li><strong>发送方产生粘包</strong></li>
</ul>
<p>采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。</p>
<ul>
<li><strong>接收方产生粘包</strong></li>
</ul>
<p>接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度）</p>
<p>​</p>
<h1 id="26-怎么解决拆包和粘包">26、怎么解决拆包和粘包？</h1>
<p>分包机制一般有两个通用的解决方法：</p>
<ol>
<li>
<p>特殊字符控制；</p>
</li>
<li>
<p>在包头首都添加数据包的长度。</p>
</li>
</ol>
<p>如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。</p>
<p>tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。</p>
<h1 id="27-你对-http-状态码有了解吗">27、你对 HTTP 状态码有了解吗？</h1>
<figure data-type="image" tabindex="62"><img src="https://uploader.shimo.im/f/g5uWYFy1vK00cvhl.png!thumbnail" alt="图片" loading="lazy"></figure>
<ul>
<li><strong>1XX 信息</strong></li>
</ul>
<ol>
<li>100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。</li>
</ol>
<ul>
<li><strong>2XX 成功</strong></li>
</ul>
<ol>
<li>
<p>200 OK</p>
</li>
<li>
<p>204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。</p>
</li>
<li>
<p>206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。</p>
</li>
</ol>
<ul>
<li><strong>3XX 重定向</strong></li>
</ul>
<ol>
<li>
<p>301 Moved Permanently ：永久性重定向；</p>
</li>
<li>
<p>302 Found ：临时性重定向；</p>
</li>
<li>
<p>303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。</p>
</li>
<li>
<p>304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。</p>
</li>
<li>
<p>307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。</p>
</li>
</ol>
<ul>
<li><strong>4XX 客户端错误</strong></li>
</ul>
<ol>
<li>
<p>400 Bad Request ：请求报文中存在语法错误。</p>
</li>
<li>
<p>401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。</p>
</li>
<li>
<p>403 Forbidden ：请求被拒绝。</p>
</li>
<li>
<p>404 Not Found</p>
</li>
</ol>
<ul>
<li><strong>5XX 服务器错误</strong></li>
</ul>
<ol>
<li>
<p>500 Internal Server Error ：服务器正在执行请求时发生错误；</p>
</li>
<li>
<p>503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。</p>
</li>
</ol>
<h1 id="28-http-状态码-301-和-302-代表的是什么有什么区别">28、HTTP 状态码 301 和 302 代表的是什么？有什么区别？</h1>
<p>301，302 都是 HTTP 状态的编码，都代表着某个 URL 发生了转移。</p>
<ul>
<li><strong>区别</strong>：</li>
</ul>
<p>301 redirect: 301 代表永久性转移（Permanently Moved）</p>
<p>302 redirect: 302 代表暂时性转移（Temporarily Moved）</p>
<h1 id="29-forward-和-redirect-的区别">29、forward 和 redirect 的区别？</h1>
<p>Forward 和 Redirect 代表了两种请求转发方式：直接转发和间接转发。</p>
<p>直接转发方式（Forward）：客户端和浏览器只发出<strong>一次请求</strong>，Servlet、HTML、JSP 或其它信息资源，由第二个信息资源响应该请求，在请求对象 request 中，保存的对象对于每个信息资源是共享的。</p>
<p>间接转发方式（Redirect）：实际是<strong>两次 HTTP 请求</strong>，服务器端在响应第一次请求的时候，让浏览器再向另外一个 URL 发出请求，从而达到转发的目的。</p>
<ul>
<li>举个通俗的例子：</li>
</ul>
<p>直接转发就相当于：“A 找 B 借钱，B 说没有，B 去找 C 借，借到借不到都会把消息传递给 A”；</p>
<p>间接转发就相当于：&quot;A 找 B 借钱，B 说没有，让 A 去找 C 借&quot;。</p>
<h1 id="30-http-方法有哪些">30、HTTP 方法有哪些？</h1>
<p>客户端发送的 请求报文 第一行为请求行，包含了方法字段。</p>
<ol>
<li>
<p>GET：获取资源，当前网络中绝大部分使用的都是 GET；</p>
</li>
<li>
<p>HEAD：获取报文首部，和 GET 方法类似，但是不返回报文实体主体部分；</p>
</li>
<li>
<p>POST：传输实体主体</p>
</li>
<li>
<p>PUT：上传文件，由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。</p>
</li>
<li>
<p>PATCH：对资源进行部分修改。PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。</p>
</li>
<li>
<p>OPTIONS：查询指定的 URL 支持的方法；</p>
</li>
<li>
<p>CONNECT：要求在与代理服务器通信时建立隧道。使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。</p>
</li>
<li>
<p>TRACE：追踪路径。服务器会将通信路径返回给客户端。发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。</p>
</li>
</ol>
<h1 id="31-说下-get-和-post-的区别">31、说下 GET 和 POST 的区别？（**）</h1>
<p>GET 和 POST 本质都是 HTTP 请求，只不过对它们的作用做了界定和适配，并且让他们适应各自的场景。</p>
<p>本质区别：GET 只是一次 HTTP请求，POST 先发请求头再发请求体，实际上是两次请求。</p>
<ol>
<li>
<p>从功能上讲，GET 一般用来从服务器上获取资源，POST 一般用来更新服务器上的资源；</p>
</li>
<li>
<p>从 REST 服务角度上说，GET 是幂等的，即读取同一个资源，总是得到相同的数据，而 POST 不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET 不会改变服务器上的资源，而 POST 会对服务器资源进行改变；</p>
</li>
<li>
<p>从请求参数形式上看，GET 请求的数据会附在 URL 之后，即将请求数据放置在 HTTP 报文的 请求头 中，以 ? 分割 URL 和传输数据，参数之间以 &amp; 相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用 BASE64 加密，得出如：%E4%BD%A0%E5%A5%BD，其中 ％XX 中的 XX 为该符号以 16 进制表示的 ASCII)；而 POST 请求会把提交的数据则放置在是 HTTP 请求报文的 请求体 中；</p>
</li>
<li>
<p>就安全性而言，POST 的安全性要比 GET 的安全性高，因为 GET 请求提交的数据将明文出现在 URL 上，而且 POST 请求参数则被包装到请求体中，相对更安全；</p>
</li>
<li>
<p>从请求的大小看，GET 请求的长度受限于浏览器或服务器对 URL 长度的限制，允许发送的数据量比较小，而 POST 请求则是没有大小限制的。</p>
</li>
</ol>
<h1 id="32-在浏览器中输入-url-地址到显示主页的过程">32、在浏览器中输入 URL 地址到显示主页的过程？（*）</h1>
<ol>
<li>
<p>DNS 解析：浏览器查询 DNS，获取域名对应的 IP 地址：具体过程包括浏览器搜索自身的 DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服务器进行查询等。对于向本地 DNS 服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；</p>
</li>
<li>
<p>TCP 连接：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手；</p>
</li>
<li>
<p>发送 HTTP 请求：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求；</p>
</li>
<li>
<p>服务器处理请求并返回 HTTP 报文：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；</p>
</li>
<li>
<p>浏览器解析渲染页面：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。</p>
</li>
<li>
<p>连接结束。</p>
</li>
</ol>
<h1 id="33-dns-的解析过程">33、DNS 的解析过程？（**）</h1>
<figure data-type="image" tabindex="63"><img src="https://uploader.shimo.im/f/jm7dKHGyA543S9Xk.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="64"><img src="https://uploader.shimo.im/f/LypWsW5YTq0QVvld.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li>
<p><strong>主机向本地域名服务器</strong>的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。</p>
</li>
<li>
<p><strong>本地域名服务器向根域名服务器</strong>的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，本地域名服务器得到了所要解析的 IP 地址或报错，然后把这个结果返回给发起查询的主机。</p>
</li>
</ol>
<h1 id="34-谈谈你对域名缓存的了解">34、谈谈你对域名缓存的了解？</h1>
<figure data-type="image" tabindex="65"><img src="https://uploader.shimo.im/f/xfZfIy82Vsc3MhHx.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="66"><img src="https://uploader.shimo.im/f/QPRdQphNRlkh30Na.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在<strong>域名服务器</strong>中广泛使用了<strong>高速缓存</strong>，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。</p>
<p>由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置<strong>计时器</strong>并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。</p>
<p>不仅在本地域名服务器中需要高速缓存，在<strong>主机</strong>中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，而且主机必须从缓存中删除无效的项。由于域名改动并不频繁，大多数网点不需花精力就能维护数据库的一致性。</p>
<h1 id="35-谈下你对-http-长连接和短连接的理解分别应用于哪些场景">35、谈下你对 HTTP 长连接和短连接的理解？分别应用于哪些场景？</h1>
<p>在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如：JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。</p>
<p>而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：</p>
<p>Connection:keep-alive</p>
<p>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。</p>
<p>Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如：Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。</p>
<h1 id="36-谈下-http-10-和-11-12-的主要变化">36、谈下 HTTP 1.0 和 1.1、1.2 的主要变化？</h1>
<ul>
<li><strong>HTTP1.1 的主要变化：</strong></li>
</ul>
<ol>
<li>
<p>HTTP1.0 经过多年发展，在 1.1 提出了改进。首先是提出了长连接，HTTP 可以在一次 TCP 连接中不断发送请求。</p>
</li>
<li>
<p>然后 HTTP1.1 支持只发送 header 而不发送 body。原因是先用 header 判断能否成功，再发数据，节约带宽，事实上，post 请求默认就是这样做的。</p>
</li>
<li>
<p>HTTP1.1 的 host 字段。由于虚拟主机可以支持多个域名，所以一般将域名解析后得到 host。</p>
</li>
</ol>
<ul>
<li><strong>HTTP2.0 的主要变化：</strong></li>
</ul>
<ol>
<li>
<p>HTTP2.0 支持多路复用，同一个连接可以并发处理多个请求，方法是把 HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组，而不需要一个个 HTTP请求顺序到达；</p>
</li>
<li>
<p>HTTP2.0 支持服务端推送，就是服务端在 HTTP 请求到达后，除了返回数据之外，还推送了额外的内容给客户端；</p>
</li>
<li>
<p>HTTP2.0 压缩了请求头，同时基本单位是二进制帧流，这样的数据占用空间更少；</p>
</li>
<li>
<p>HTTP2.0 适用于 HTTPS 场景，因为其在 HTTP和 TCP 中间加了一层 SSL 层。</p>
</li>
</ol>
<h1 id="37-https-的工作过程">37、HTTPS 的工作过程？（**）</h1>
<ol>
<li>
<p>客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了；</p>
</li>
<li>
<p>服务器从中选出一套加密算法和 hash 算法以及自己的身份信息（地址等）以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构；</p>
</li>
<li>
<p>客户端收到网站的证书之后要做下面的事情：</p>
</li>
</ol>
<ul>
<li>
<p>3.1 验证证书的合法性；</p>
</li>
<li>
<p>3.2 如果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密；</p>
</li>
<li>
<p>3.3 用约定好的 hash 算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器。</p>
</li>
</ul>
<ol start="4">
<li>服务器接收到客户端传送来的信息，要做下面的事情：</li>
</ol>
<ul>
<li>4.1 用私钥解析出密码，用密码解析握手消息，验证 hash 值是否和浏览器发来的一致；</li>
<li>4.2 使用密钥加密消息；</li>
</ul>
<ol start="5">
<li>如果计算法 hash 值一致，握手成功。</li>
</ol>
<h1 id="38-http-和-https-的区别"><strong>38、HTTP 和 HTTPS 的区别？</strong></h1>
<ol>
<li>
<p>开销：HTTPS 协议需要到 CA 申请证书，一般免费证书很少，需要交费；</p>
</li>
<li>
<p>资源消耗：HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 ssl 加密传输协议，需要消耗更多的 CPU 和内存资源；</p>
</li>
<li>
<p>端口不同：HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是  80，后者是 443；</p>
</li>
<li>
<p>安全性：HTTP 的连接很简单，是无状态的；HTTPS 协议是由 TSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。</p>
</li>
</ol>
<h1 id="39-https-的优缺点"><strong>39、HTTPS 的优缺点？</strong></h1>
<ul>
<li><strong>优点：</strong></li>
</ul>
<ol>
<li>
<p>使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</p>
</li>
<li>
<p>HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性；</p>
</li>
<li>
<p>HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</p>
</li>
</ol>
<ul>
<li><strong>缺点：</strong></li>
</ul>
<ol>
<li>
<p>HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近 50%，增加 10% 到 20% 的耗电；</p>
</li>
<li>
<p>HTTPS 连接缓存不如 HTTP 高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；</p>
</li>
<li>
<p>SSL 证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用；</p>
</li>
<li>
<p>SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗；</p>
</li>
<li>
<p>HTTPS 协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。</p>
</li>
</ol>
<h1 id="40-什么是数字签名"><strong>40、什么是数字签名？</strong></h1>
<p>为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。</p>
<h1 id="41-什么是数字证书"><strong>41、什么是数字证书？</strong></h1>
<p>对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。</p>
<h1 id="42-什么是对称加密和非对称加密"><strong>42、什么是对称加密和非对称加密？</strong></h1>
<p>对称密钥加密是指<strong>加密和解密使用同一个密钥</strong>的方式，这种方式存在的最大问题就是密钥发送问题，即如何<strong>安全地将密钥发给对方</strong>。</p>
<p>非对称加密指使用一对非对称密钥，即：公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的<strong>公钥</strong>进行<strong>加密</strong>处理，对方接收到加密信息后，使用自己的<strong>私钥</strong>进行<strong>解密</strong>。</p>
<p>由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性。但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。</p>
<p>附：计网思维导图<br>
<img src="https://epitomm.github.io/post-images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.png" alt="图片" loading="lazy"></p>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://mp.weixin.qq.com/s/Gy4ElItSvBoeQnN4YbMPGQ">https://mp.weixin.qq.com/s/Gy4ElItSvBoeQnN4YbMPGQ</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题 —— 由浅入深全面解析 ThreadLocal]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-threadlocal/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-threadlocal/">
        </link>
        <updated>2020-04-01T16:09:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-threadlocal-介绍">一、ThreadLocal 介绍</h1>
<h2 id="11-官方介绍">1.1 官方介绍</h2>
<pre><code>/**
 * This class provides thread-local variables.  These variables differ from
 * their normal counterparts in that each thread that accesses one (via its
 * {@code get} or {@code set} method) has its own, independently initialized
 * copy of the variable.  {@code ThreadLocal} instances are typically private
 * static fields in classes that wish to associate state with a thread (e.g.,
 * a user ID or Transaction ID).
 *
 * &lt;p&gt;For example, the class below generates unique identifiers local to each
 * thread.
 * A thread's id is assigned the first time it invokes {@code ThreadId.get()}
 * and remains unchanged on subsequent calls.
 * &lt;pre&gt;
 * import java.util.concurrent.atomic.AtomicInteger;
 *
 * public class ThreadId {
 *     // Atomic integer containing the next thread ID to be assigned
 *     private static final AtomicInteger nextId = new AtomicInteger(0);
 *
 *     // Thread local variable containing each thread's ID
 *     private static final ThreadLocal&amp;lt;Integer&amp;gt; threadId =
 *         new ThreadLocal&amp;lt;Integer&amp;gt;() {
 *             &amp;#64;Override protected Integer initialValue() {
 *                 return nextId.getAndIncrement();
 *         }
 *     };
 *
 *     // Returns the current thread's unique ID, assigning it if necessary
 *     public static int get() {
 *         return threadId.get();
 *     }
 * }
 * &lt;/pre&gt;
 * &lt;p&gt;Each thread holds an implicit reference to its copy of a thread-local
 * variable as long as the thread is alive and the {@code ThreadLocal}
 * instance is accessible; after a thread goes away, all of its copies of
 * thread-local instances are subject to garbage collection (unless other
 * references to these copies exist).
 *
 * @author  Josh Bloch and Doug Lea
 * @since   1.2
 */
</code></pre>
<p>从 Java 官方文档中的描述：<code>ThreadLocal</code>类用来提供<strong>线程内部的局部变量</strong>。这种变量在多线程环境下访问（通过<code>get</code>和<code>set</code>方法访问）时能保证各个线程的变量相对独立于其他线程内的变量。<code>ThreadLocal</code>实例通常来说都是<code>private static</code>类型的，用于关联线程和线程上下文。<br>
我们可以得知<code>ThreadLocal</code>的作用是：提供线程内的局部变量，不同的线程之间不会相互干扰，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或组件之间一些公共变量传递的复杂度。</p>
<p>总结：</p>
<ol>
<li>
<p>线程并发：在多并发的场景下</p>
</li>
<li>
<p>传递数据：我们可以通过 <code>ThreadLocal</code> 在同一线程，不同组件中传递公共变量</p>
</li>
<li>
<p>线程隔离：每个线程的变量都是独立的，不会互相影响。</p>
</li>
</ol>
<h2 id="12-基本使用">1.2 基本使用</h2>
<h3 id="121-常用方法">1.2.1 常用方法</h3>
<p>在使用之前，我们先来认识几个 <code>ThreadLoal</code> 的常用方法</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>方法声明</strong></th>
<th style="text-align:left"><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ThreadLocal()</td>
<td style="text-align:left">创建 ThreadLocal 对象</td>
</tr>
<tr>
<td style="text-align:left">public void set(T value)</td>
<td style="text-align:left">设置当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public T get()</td>
<td style="text-align:left">获取当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public void remove()</td>
<td style="text-align:left">移除当前线程绑定的局部变量</td>
</tr>
</tbody>
</table>
<h3 id="122-使用案列">1.2.2 使用案列</h3>
<pre><code>package com.ssm.threadlocal;
/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 */
public class MyDemo01 {
    private String content;
    private String getContent(){
        return content;
    }
    private void setContent(String content){
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo01 demo = new MyDemo01();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                System.out.println(&quot; ---------------- &quot;);
                System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>运行结果：部分线程取出的数据 与 它存入的数据不一样</p>
<pre><code> ---------------- 
 ---------------- 
线程2---&gt;线程3的数据
 ---------------- 
线程1---&gt;线程4的数据
 ---------------- 
线程4---&gt;线程4的数据
线程0---&gt;线程2的数据
 ---------------- 
线程3---&gt;线程4的数据
</code></pre>
<p>从结果可以看出多个线程在访问同一个变量的时候出现的异常，线程间的数据没有隔离。下面我们来看下采用 ThreadLocal 的方式来解决这个问题的例子。</p>
<pre><code>package com.ssm.threadlocal;

/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 *
 *      ThreadLocal:
 *          1.set()：将变量绑定到当前线程中；
 *          2.get()：获取当前线程绑定的变量
 */
public class MyDemo01 {
    ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();
    private String getContent(){
        return threadLocal.get();
    }
    private void setContent(String content){
        // 变量绑定到当前线程中
        threadLocal.set(content);
    }

    public static void main(String[] args) {
        MyDemo01 demo = new MyDemo01();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                System.out.println(&quot; ---------------- &quot;);
                System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code> ---------------- 
 ---------------- 
线程3---&gt;线程3的数据
 ---------------- 
线程2---&gt;线程2的数据
 ---------------- 
 ---------------- 
线程4---&gt;线程4的数据
线程0---&gt;线程0的数据
线程1---&gt;线程1的数据
</code></pre>
<p>从结果来看，这样很好的解决了多线程之间数据隔离的问题，十分方便。</p>
<h2 id="13-threadlocal-与-synchronized-关键字">1.3 ThreadLocal 与 synchronized 关键字</h2>
<h3 id="131-synchronized-同步方式">1.3.1 synchronized 同步方式</h3>
<p>这里可能有的朋友会觉得在上述例子中我们完全可以通过加锁来实现这个功能。我们首先来看一下用synchronized代码块实现的效果：</p>
<pre><code>package com.ssm.threadlocal;

/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 */
public class MyDemo02 {
    private String content;
    private String getContent(){
        return content;
    }
    private void setContent(String content){
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo02 demo = new MyDemo02();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                synchronized (MyDemo02.class){
                    demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                    System.out.println(&quot; ---------------- &quot;);
                    System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
                }

            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>从结果可以发现，加锁确实可以解决这个问题，但是在这里我们强调的是<strong>线程数据隔离</strong>的问题，并不是<strong>多线程共享数据的</strong>问题，在这个案例中使用<code>synchronized</code>关键字是不合适的。</p>
<h3 id="132-threadlocal-与-synchronized-关键字的区别">1.3.2 ThreadLocal 与 synchronized 关键字的区别</h3>
<p>虽然T<code>hreadLocal</code>模式与<code>synchronized</code>关键字都用于处理多线程并发访问变量的问题，不过两者处理问题的角度和思路不同。</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">synchronized</th>
<th style="text-align:left">ThreadLocal</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">原理</td>
<td style="text-align:left">同步机制采用 “<strong>以时间换空间</strong>” 的方式，只提供了一分变量，让不用的线程派对访问</td>
<td style="text-align:left">ThreadLocal 采用 “<strong>以空间换时间</strong>” 的方式，为每一个线程都提供了一份变量的副本，从而实现同时访问互不干扰</td>
</tr>
<tr>
<td style="text-align:left">侧重点</td>
<td style="text-align:left">多个线程之间访问资源的同步</td>
<td style="text-align:left">多线程中让每个线程之间的数据相互隔离</td>
</tr>
</tbody>
</table>
<p>总结：在刚刚的案例中，虽然使用<code>ThreadLocal</code>和<code>synchronized</code>都能解决问题，但是使用<code>ThreadLocal</code>更为合适，因为这样可以使程序拥有更高的并发性。</p>
<h1 id="二-运用场景_事务案例">二、 运用场景_事务案例</h1>
<p>​通过以上的介绍，我们已经基本了解<code>ThreadLocal</code>的特点。但是它具体是运用在什么场景中呢？ 接下来让我们看一个案例： 事务操作。</p>
<h2 id="21-转账案例">2.1 转账案例</h2>
<h3 id="211-场景构建">2.1.1 场景构建</h3>
<p>​这里我们先构建一个简单的转账场景： 有一个数据表<code>account</code>，里面有两个用户<code>Jack</code>和<code>Rose</code>，用户<code>Jack</code>  给用户<code>Rose</code> 转账。</p>
<p>案例的实现主要用<code>mysql</code>数据库，<code>JDBC</code> 和 <code>C3P0</code> 框架。以下是详细代码 ：</p>
<p>（1） 项目结构<br>
<img src="https://epitomm.github.io/post-images/001.png" alt="图片" loading="lazy"><br>
（2） 数据准备</p>
<pre><code class="language-sql">-- 使用数据库
use test;
-- 创建一张账户表
create table account(
	id int primary key auto_increment,
	name varchar(20),
	money double
);
-- 初始化数据
insert into account values(null, 'Jack', 1000);
insert into account values(null, 'Rose', 0);
</code></pre>
<p>（3） C3P0配置文件和工具类</p>
<pre><code class="language-xml">&lt;c3p0-config&gt;
  &lt;!-- 使用默认的配置读取连接池对象 --&gt;
  &lt;default-config&gt;
  	&lt;!--  连接参数 --&gt;
    &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt;
    &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt;
    &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt;
    &lt;property name=&quot;password&quot;&gt;1234&lt;/property&gt;
    
    &lt;!-- 连接池参数 --&gt;
    &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt;
    &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt;
    &lt;property name=&quot;checkoutTimeout&quot;&gt;3000&lt;/property&gt;
  &lt;/default-config&gt;

&lt;/c3p0-config&gt;
</code></pre>
<p>（4） 工具类 ： JdbcUtils</p>
<pre><code class="language-java">package com.itheima.transfer.utils;

import com.mchange.v2.c3p0.ComboPooledDataSource;
import java.sql.Connection;
import java.sql.SQLException;

public class JdbcUtils {
    // c3p0 数据库连接池对象属性
    private static final ComboPooledDataSource ds = new ComboPooledDataSource();
    // 获取连接
    public static Connection getConnection() throws SQLException {
        return ds.getConnection();
    }
    //释放资源
    public static void release(AutoCloseable... ios){
        for (AutoCloseable io : ios) {
            if(io != null){
                try {
                    io.close();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }
    
    
    public static void commitAndClose(Connection conn) {
        try {
            if(conn != null){
                //提交事务
                conn.commit();
                //释放连接
                conn.close();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void rollbackAndClose(Connection conn) {
        try {
            if(conn != null){
                //回滚事务
                conn.rollback();
                //释放连接
                conn.close();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>（5） dao层代码 ： AccountDao</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(String outUser, int money) throws SQLException {
        String sql = &quot;update account set money = money - ? where name = ?&quot;;

        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();

        JdbcUtils.release(pstm,conn);
    }

    public void in(String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;

        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();

        JdbcUtils.release(pstm,conn);
    }
}
</code></pre>
<p>（6） service层代码 ： AccountService</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import java.sql.SQLException;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        try {
            // 转出
            ad.out(outUser, money);
            // 转入
            ad.in(inUser, money);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>（7） web层代码 ： AccountWeb</p>
<pre><code class="language-java">package com.itheima.transfer.web;

import com.itheima.transfer.service.AccountService;

public class AccountWeb {

    public static void main(String[] args) {
        // 模拟数据 : Jack 给 Rose 转账 100
        String outUser = &quot;Jack&quot;;
        String inUser = &quot;Rose&quot;;
        int money = 100;

        AccountService as = new AccountService();
        boolean result = as.transfer(outUser, inUser, money);

        if (result == false) {
            System.out.println(&quot;转账失败!&quot;);
        } else {
            System.out.println(&quot;转账成功!&quot;);
        }
    }
}
</code></pre>
<h3 id="212-引入事务">2.1.2 引入事务</h3>
<p>​案例中的转账涉及两个DML操作： 一个转出，一个转入。这些操作是需要具备原子性的，不可分割。不然就有可能出现数据修改异常情况。</p>
<pre><code class="language-java">public class AccountService {
    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        try {
            // 转出
            ad.out(outUser, money);
            // 模拟转账过程中的异常
            int i = 1/0;
            // 转入
            ad.in(inUser, money);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>所以这里就需要操作事务，来保证转出和转入操作具备原子性，要么同时成功，要么同时失败。<br>
（1） JDBC中关于事务的操作的api</p>
<table>
<thead>
<tr>
<th>Connection接口的方法</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>void  setAutoCommit(false)</td>
<td>禁用事务自动提交（改为手动）</td>
</tr>
<tr>
<td>void  commit();</td>
<td>提交事务</td>
</tr>
<tr>
<td>void rollback();</td>
<td>回滚事务</td>
</tr>
</tbody>
</table>
<p>（2） <strong>开启事务的注意点</strong>:</p>
<ul>
<li>
<p>为了保证所有的操作在一个事务中,案例中使用的连接必须是同一个:  <code>service</code>层开启事务的<code>connection</code>需要跟<code>dao</code>层访问数据库的<code>connection</code>保持一致</p>
</li>
<li>
<p>线程并发情况下, 每个线程只能操作各自的 <code>connection</code></p>
</li>
</ul>
<h2 id="22-常规解决方案">2.2  常规解决方案</h2>
<h3 id="221-常规方案的实现">2.2.1 常规方案的实现</h3>
<p>基于上面给出的前提， 大家通常想到的解决方案是 ：</p>
<ul>
<li>传参: 从<code>service</code>层将<code>connection</code>对象向<code>dao</code>层传递</li>
<li>加锁</li>
</ul>
<p>以下是代码实现修改的部分：</p>
<p>（1 ) AccountService 类</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        //线程并发情况下,为了保证每个线程使用各自的connection,故加锁
        synchronized (AccountService.class) {

            Connection conn = null;
            try {
                conn = JdbcUtils.getConnection();
                //开启事务
                conn.setAutoCommit(false);
                // 转出
                ad.out(conn, outUser, money);
                // 模拟转账过程中的异常
//            int i = 1/0;
                // 转入
                ad.in(conn, inUser, money);
                //事务提交
                JdbcUtils.commitAndClose(conn);
            } catch (Exception e) {
                e.printStackTrace();
                //事务回滚
                JdbcUtils.rollbackAndClose(conn);
                return false;
            }
            return true;
        }
    }
}
</code></pre>
<p>（2) AccountDao 类 （这里需要注意的是： connection不能在dao层释放，要在service层，不然在dao层释放，service层就无法使用了）</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(Connection conn, String outUser, int money) throws SQLException{
        String sql = &quot;update account set money = money - ? where name = ?&quot;;
        //注释从连接池获取连接的代码,使用从service中传递过来的connection
//        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();
        //连接不能在这里释放,service层中还需要使用
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }

    public void in(Connection conn, String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;
//        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }
}
</code></pre>
<h3 id="222-常规方案的弊端">2.2.2 常规方案的弊端</h3>
<p>上述方式我们看到的确按要求解决了问题，但是仔细观察，会发现这样实现的弊端：</p>
<ol>
<li>
<p>直接从<code>service</code>层传递<code>connection</code>到<code>dao</code>层, 造成代码耦合度提高</p>
</li>
<li>
<p>加锁会造成线程失去并发性，程序性能降低</p>
</li>
</ol>
<h2 id="23-threadlocal解决方案">2.3 ThreadLocal解决方案</h2>
<h3 id="231-threadlocal方案的实现">2.3.1 ThreadLocal方案的实现</h3>
<p>像这种需要在项目中进行<strong>数据传递</strong>和<strong>线程隔离</strong>的场景，我们不妨用<code>ThreadLocal</code>来解决：</p>
<p>（1） 工具类的修改： 加入ThreadLocal</p>
<pre><code class="language-java">package com.itheima.transfer.utils;

import com.mchange.v2.c3p0.ComboPooledDataSource;
import java.sql.Connection;
import java.sql.SQLException;

public class JdbcUtils {
    //ThreadLocal对象 : 将connection绑定在当前线程中
    private static final ThreadLocal&lt;Connection&gt; tl = new ThreadLocal();

    // c3p0 数据库连接池对象属性
    private static final ComboPooledDataSource ds = new ComboPooledDataSource();

    // 获取连接
    public static Connection getConnection() throws SQLException {
        //取出当前线程绑定的connection对象
        Connection conn = tl.get();
        if (conn == null) {
            //如果没有，则从连接池中取出
            conn = ds.getConnection();
            //再将connection对象绑定到当前线程中
            tl.set(conn);
        }
        return conn;
    }

    //释放资源
    public static void release(AutoCloseable... ios) {
        for (AutoCloseable io : ios) {
            if (io != null) {
                try {
                    io.close();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public static void commitAndClose() {
        try {
            Connection conn = getConnection();
            //提交事务
            conn.commit();
            //解除绑定
            tl.remove();
            //释放连接
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void rollbackAndClose() {
        try {
            Connection conn = getConnection();
            //回滚事务
            conn.rollback();
            //解除绑定
            tl.remove();
            //释放连接
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>（2） AccountService类的修改：不需要传递connection对象</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();

        try {
            Connection conn = JdbcUtils.getConnection();
            //开启事务
            conn.setAutoCommit(false);
            // 转出 ： 这里不需要传参了 ！
            ad.out(outUser, money);
            // 模拟转账过程中的异常
//            int i = 1 / 0;
            // 转入
            ad.in(inUser, money);
            //事务提交
            JdbcUtils.commitAndClose();
        } catch (Exception e) {
            e.printStackTrace();
            //事务回滚
           JdbcUtils.rollbackAndClose();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>（3） AccountDao类的修改：照常使用</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(String outUser, int money) throws SQLException {
        String sql = &quot;update account set money = money - ? where name = ?&quot;;
        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();
        //照常使用
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }

    public void in(String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;
        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }
}
</code></pre>
<h3 id="232-threadlocal方案的好处">2.3.2 ThreadLocal方案的好处</h3>
<p>从上述的案例中我们可以看到， 在一些特定场景下，<code>ThreadLocal</code>方案有两个突出的优势：</p>
<ol>
<li>
<p>传递数据 ： 保存每个线程绑定的数据，在需要的地方可以直接获取, 避免参数直接传递带来的代码耦合问题</p>
</li>
<li>
<p>线程隔离 ： 各线程之间的数据相互隔离却又具备并发性，避免同步方式带来的性能损失</p>
</li>
</ol>
<h1 id="三-threadlocal的内部结构">三、ThreadLocal的内部结构</h1>
<p>通过以上的学习，我们对<code>ThreadLocal</code>的作用有了一定的认识。现在我们一起来看一下<code>ThreadLocal</code>的内部结构，探究它能够实现线程数据隔离的原理。</p>
<h2 id="31常见的误解">3.1常见的误解</h2>
<p>通常，如果我们不去看源代码的话，我猜 <code>ThreadLocal</code> 是这样子设计的：每个<code>ThreadLocal</code> 类都创建一个 <code>Map</code>，然后用线程作为<code>Map</code>的<code>key</code>，要存储的局部变量作为<code>Map</code>的<code>value</code>，这样就能达到各个线程的局部变量隔离的效果。这是最简单的设计方法，<code>JDK</code>最早期的<code>ThreadLocal</code>就是这样设计的。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E6%97%A9%E6%9C%9FThreadLocal.png" alt="图片" loading="lazy"></figure>
<h2 id="32-现在的设计">3.2 现在的设计</h2>
<p>但是，<code>JDK</code>后面优化了设计方案，<code>JDK8</code> 中 <code>ThreadLocal</code>的设计是：每个<code>Thread</code>维护一个<code>ThreadLocalMap</code> 哈希表，这个哈希表的<code>key</code>是<code>ThreadLocal</code>实例本身，<code>value</code>才是真正要存储的值<code>object</code>。</p>
<p>（1）每个<code>Thread</code>线程内部都有一个<code>Map（ThreadLocalMap）</code></p>
<p>（2）<code>Map</code>里面存储<code>ThreadLocal</code>对象（<code>key</code>）和线程的变量副本（<code>value</code>）</p>
<p>（3）<code>Thread</code>内部的<code>Map</code>是由<code>ThreadLocal</code>维护的，由ThreadLocal负责向map获取和设置线程的变量值。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/JDK8ThreadLocal.png" alt="图片" loading="lazy"></figure>
<h2 id="33-jdk8的设计方案两个好处">3.3 JDK8的设计方案两个好处</h2>
<ol>
<li>每个<code>Map</code>存储的<code>Entry</code>数量变少</li>
</ol>
<p>[在早期版本内，Map 的 Entry 数量由 Thread 决定；而 JDK8 中，Map 的 Entry 数量由 ThreadLocal 决定，一般情况下 ThreadLocal 数量是比 Thread 少的]</p>
<ol start="2">
<li>当<code>Thread</code>销毁的时候，<code>ThreadLocalMap</code>也会随之销毁，减少内存的使用</li>
</ol>
<p>[早期版本内，ThreadLocalMap 由 ThreadLocal 维护；而 JDK8 中，ThreadLocalMap 由 Thread 维护，当 Thread 销毁，ThreadLocalMap 也会销毁]</p>
<h1 id="四-threadlocal-的和核心方法源码">四、ThreadLocal 的和核心方法源码</h1>
<p>基于<code>ThreadLocal</code>的内部结构，我们继续分析它的核心方法源码，更深入的了解其操作原理。</p>
<p>除了构造方法之外，<code>ThreadLocal</code>对外暴露的方法有以下4个：</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法声明</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">protected T initialValue()</td>
<td style="text-align:left">返回当前线程局部变量的初始值</td>
</tr>
<tr>
<td style="text-align:left">public void set(T value)</td>
<td style="text-align:left">设置当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public T get()</td>
<td style="text-align:left">获取当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public void remove()</td>
<td style="text-align:left">移除当前线程绑定的局部变量</td>
</tr>
</tbody>
</table>
<p>以下是这4个方法的详细源码分析（为了保证思路清晰，<code>ThreadLocalMap</code>部分暂时不展开，下一个知识点详解）</p>
<h2 id="41-set方法">4.1 set方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 设置当前线程对应的 ThreadLocal 的值
 * @param value 将要保存在当前线程对应的ThreadLocal的值
 */
public void set(T value) {
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取当前线程对象中维护的 ThreadLocalMap 对象
    ThreadLocalMap map = getMap(t);
    // 判断 map 是否存在
    if (map != null)
        // 存在则调用 map.set 设置此实体 Entry
        map.set(this, value);
    else
        // 1）当前线程 Thread 不存在 ThreadLocalMap 对象
        // 2）则调用 createMap 进行 ThreadLocalMap 对象的初始化
        // 3）并将 t（当前线程）和value（t对应的值）作为第一个 entry 存放至 ThreadLocalMap 中
        createMap(t, value);
}
/**
 * 获取当前线程 Thread 对应维护的 ThreadLocalMap
 *
 * @param  t the current thread 当前线程
 * @return the map 对应维护的 ThreadLocalMap
 */

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

/**
 * 创建当前线程 Thread 对应维护的 ThreadLocalMap
 *
 * @param t the current thread 当前线程
 * @param firstValue value for the initial entry of the map 存放到 map 中第一个 entry 值 
 */
void createMap(Thread t, T firstValue) {
    // 这里的 this 是调用此方法的threadLocal
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线，并根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则将参数设置到<code>Map</code>中（当前<code>ThreadLocal</code>的引用作为<code>key</code>）</p>
<p>C.如果<code>Map</code>为空，则给该线程创建<code>Map</code>，并设置初始值</p>
<h2 id="42-get方法">4.2 get方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 返回当前线程中保存 ThreadLocal 的值
 * 当前线程没有此 ThreadLocal 变量
 * 则它会通过调用 {@link #initialValue} 方法进行初始化
 *
 * @return 返回当前线程对应此 ThreadLocal 的值
 */
public T get() {
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取当前线程中维护的 ThreadLocalMap 对象
    ThreadLocal.ThreadLocalMap map = getMap(t);
    // 如果此 map 存在
    if (map != null) {
        // 以当前的 ThreadLocal 为 key，调用 getEntry 获取对应的存储实体 e
        ThreadLocal.ThreadLocalMap.Entry e = map.getEntry(this);
        // 对 e 进行判空
        if (e != null) {
            @SuppressWarnings(&quot;unchecked&quot;)
            // 获取存储实体 e 对应的 value 值，即为我们想要的当前线程对应此 ThreadLocal 的值
            T result = (T)e.value;
            return result;
        }
    }
    /*
        初始化：有两种情况执行当前代码
        第一种情况：map 不存在，表示此线程没有维护的 ThreadLocalMap 对象
        第二种情况：map 存在，但是没有与当前 ThreadLocal 关联的 Entry
     */
    return setInitialValue();
}
/**
 * 初始化
 *
 * @return the initial value
 */
private T setInitialValue() {
    // 调用 initialValue 获取初始化的值
    // 此方法可以被子类重写，如果不重写默认返回 null
    T value = initialValue();
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取此线程对象中维护的 ThreadLocalMap 对象
    ThreadLocal.ThreadLocalMap map = getMap(t);
    // 判断 map 是否存在
    if (map != null)
        // 存在则调用 map.set 设置此实体 entry
        map.set(this, value);
    else
        // 1)当前线程 Thread 不存在 ThreadLocalMap 对象
        // 2)则调用 createMap 进行 ThreadLocalMap 对象的初始化
        // 3)并将 t(当前线程)和 value(t对应的值)作为第一个 entry 存放至 ThreadLocalMap 中
        createMap(t, value);
    // 返回设置的值 value
    return value;
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线程，根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则在<code>Map</code>中以<code>ThreadLocal</code>的引用作为<code>key</code>来在<code>Map</code>中获取对应的<code>Entry</code>，否则转到D</p>
<p>C.如果<code>e</code>不为<code>null</code>，则返回<code>e.value</code>，否则转到D</p>
<p>D.<code>Map</code>为空或者<code>e</code>为空，则通过<code>initiaValue</code>函数获取初始值<code>value</code>，然后用<code>ThreadLocal</code>的引用和<code>value</code>作为<code>firstKey</code>和<code>firstValue</code>创建一个新的<code>Map</code></p>
<p>总结：<strong>先获取当前线程的ThreadLocalMap变量，如果存在则返回值，不存在则创建并返回初始值</strong>。</p>
<h2 id="43-remove方法">4.3 remove方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 删除当前线程中保存的 ThreadLocal 对应的实体 entry
 */
public void remove() {
    // 获取当前线程对象中维护的 ThreadLocalMap
    ThreadLocal.ThreadLocalMap m = getMap(Thread.currentThread());
    // 如果此 map 存在
    if (m != null)
        // 存在则调用 map.remove
        // 以当前 ThreadLocal 为 key 删除对应的实体 entry
        m.remove(this);
}

        /**
         * 移除 key 为给定值的 Entry 节点
         */
        private void remove(ThreadLocal&lt;?&gt; key) {
            // 暂存 Entry 数组
            Entry[] tab = table;
            int len = tab.length;
            // 获取当前 key 对应的 Entry 在数组中的位置
            int i = key.threadLocalHashCode &amp; (len-1);
            for (Entry e = tab[i];
                 e != null;
                 e = tab[i = nextIndex(i, len)]) {
                if (e.get() == key) {
                    e.clear();
                    expungeStaleEntry(i);
                    return;
                }
            }
        }
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线程，并根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则移除当前<code>ThreadLocal</code>对象对应的<code>Entry</code></p>
<h2 id="44-initialvalue方法">4.4 initialValue方法</h2>
<pre><code>/**
 * 返回当前线程对应的ThreadLocal的初始值
 * 
 * 此方法的第一次调用发生在，当线程通过get方法访问此线程的ThreadLocal值时
 * 除非线程先调用了set方法，在这种情况下，initialvalue 才不会被这个线程调用。
 * 通常情况下，每个线程最多调用一次这个方法。
 * &lt;p&gt;这个方法仅仅简单的返回nu11{@code nu11}；
 * 如果程序员想ThreadLocal线程局部变量有一个除nu11以外的初始值，
 * 必须通过子类继承{@code ThreadLocal}的方式去重写此方法
 * 通常，可以通过匿名内部类的方式实现
 * 
 * @return 当前 ThreadLocal 的初始值
 */
protected T initialValue() {
    return null;
}
</code></pre>
<p>此方法的作用是返回该线程局部变量的初始值。<br>
（1）这个方法是一个延迟调用方法，从面的代码我们得知，在<code>set</code>方法还未调用而先调用了<code>get</code>方法时才执行，并且仅执行1次。</p>
<p>（2）这个方法缺省实现直接返回一个<code>null</code>。</p>
<p>（3）如果想要一个除<code>null</code>之外的初始值，可以重写此方法。（备注：该方法是一个<code>protected</code>的方法，显然是为了让子类覆盖而设计的）</p>
<h1 id="五-threadlocalmap源码分析">五、ThreadLocalMap源码分析</h1>
<p>在分析<code>ThreadLocal</code>方法的时候，我们了解到<code>ThreadLocal</code>的操作实际上是围绕<code>ThreadLocalMap</code>展开的。</p>
<p><code>ThreadLocalMap</code>的源码相对比较复杂，我们从以下三个方面进行讨论。</p>
<h2 id="51基本结构">5.1基本结构</h2>
<p><code>ThreadLocalMap</code>是<code>ThreadLocal</code>的内部类，没有实现<code>Map</code>接口，用独立的方式实现了<code>Map</code>的功能，其内部的<code>Entry</code>也是独立实现。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/ThreadLocal%E7%9A%84UML.png" alt="图片" loading="lazy"></figure>
<p>（1）成员变量</p>
<pre><code>/**
 * 初始容量 - 必须是 2 的整次幂
 */
private static final int INITIAL_CAPACITY = 16;

/**
 * 存放数据的 table，Entry类的定义在下面分析
 * 同样，数组长度必须是 2 的整次幂。
 */
private ThreadLocal.ThreadLocalMap.Entry[] table;

/**
 * 数组里面 entrys 的个数，可以用于判断 table 当前使用量是否超过阈值
 */
private int size = 0;

/**
 * 进行扩容的阈值，表使用量大于它的时候进行扩容。
 */
private int threshold; // Default to 0
</code></pre>
<p>跟HashMap类似，<code>INITIAL_CAPACITY</code>代表这个<code>Map</code>的初始容量；<code>table</code>是一个<code>Entry</code>类型的数组，用于存储数据；<code>size</code>代表表中的存储数目；<code>threshold</code> 代表需要扩容时对应 <code>size</code>的阈值。<br>
（2）存储结构-Entry</p>
<pre><code>/**
 * Entry 继承 WeakReference，并且用 ThreadLocal 作为 key
 * 如果 key 为 null(entry.get() == null)，意味着 key 不再被引用，
 * 因此这时候 entry 也可以从 table 中清除
 */
static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal&lt;?&gt; k, Object v) {
        super(k);
        value = v;
    }
}
</code></pre>
<p>在<code>ThreadLocalMa</code>p中，也是用<code>Entry</code>来保存<code>K-V</code>结构数据的。不过<code>Entry</code>中的<code>key</code>只能是<code>ThreadLocal</code>对象，这点在构造方法中已经限定死了。<br>
另外，<code>Entry</code>继承<code>WeakReference</code>，也就是<code>key（ThreadLocal）</code>是弱引用，其目的是将<code>ThreadLocal</code>对象的生命周期和线程生命周期解绑。</p>
<h2 id="52弱引用和内存泄漏">5.2弱引用和内存泄漏</h2>
<p>有些程序员在使用<code>ThreadLocal</code>的过程中会发现有内存泄漏的情况发生，就猜测这个内存泄漏跟<code>Entry</code>中使用了<strong>弱引用</strong>的<code>key</code>有关系。这个理解其实是不对的。</p>
<p>我们先来回顾这个问题中涉及的几个名词概念，再来分析问题。</p>
<h3 id="1内存泄漏相关概念">（1）内存泄漏相关概念</h3>
<ul>
<li>Memory overflow：内存溢出，没有足够的内存提供申请者使用。</li>
<li>Memory leak：内存泄漏是指程序中<strong>己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费</strong>，导致程序运行速度减慢甚至系统溃等严重后果。内存泄漏的堆积终将导致内存溢出。</li>
</ul>
<h3 id="2弱引用相关概念">（2）弱引用相关概念</h3>
<p>Java中的引用有4种类型：强、软、弱、虚。当前这个问题主要涉及到强引用和弱引用：</p>
<p><strong>强引用</strong>（&quot;Strong”Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾回收器就不会回收这种对象。</p>
<p><strong>弱引用</strong>（WeakReference），垃圾回收器一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。</p>
<h3 id="3如果key使用强引用">（3）如果key使用强引用</h3>
<p>假设<code>ThreadLocalMap</code>中的<code>key</code>使用了强引用，那么会出现内存泄漏吗？</p>
<p>此时<code>ThreadLocal</code>的内存图（实线表示强引用）如下：</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/key%E5%BC%BA%E5%BC%95%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<p>1.假设在业务代码中使用完<code>ThreadLocal</code>，<code>ThreadLocal Ref</code>被回收了。</p>
<p>2.但是因为<code>ThreadLocalMap</code>的<code>Entry</code>强引用了<code>ThreadLocal</code>，造成<code>ThreadLocal</code>无法被回收。</p>
<p>3.在没有手动删除这个<code>Entry</code>以及<code>CurrentThread</code>依然运行的前提下，始终有强引用链<code>TthreadRef-&gt;CurrentThread-&gt;ThreadLocalMap-&gt;Entry</code>，<code>Entry</code>就不会被回收（<code>Entry</code>中包括了<code>ThreadLocal</code>实例和<code>value</code>），<strong>导致<code>Entry</code>内存泄漏</strong>。</p>
<p>也就是说，<code>ThreadLocalMap</code>中的<code>key</code>使用了强引用，是无法完全避免内存泄漏的。</p>
<h3 id="4如果key使用弱引用">（4）如果key使用弱引用</h3>
<p>那么<code>ThreadLocalMap</code>中的<code>key</code>使用了弱引用，会出现内存泄漏吗？此时<code>ThreadLocal</code>的内存图（实线表示强引用，虚线表示弱引用）如下：</p>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/key%E5%BC%B1%E5%BC%95%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<p>同样假设在业务代码中使用完<code>ThreadLocal</code>，<code>ThreadLocal Ref</code>被回收了。</p>
<p>由于<code>ThreadLocalMap</code>只持有<code>ThreadLocal</code>的弱引用，没有任何强引用指向<code>Threadlocal</code>实例，所以<code>Threadlocal</code>就可以顺利被<code>gc</code>回收，此时<code>Entry</code>中的<code>key=null</code>。</p>
<p>但是在没有手动删除这个<code>Entry</code>以及<code>CurrentThread</code>依然运行的前提下，也存在有强引用链 <code>ThreadRef -&gt;CurrentThread-&gt;ThreadLocalMap-&gt;Entry-&gt;value</code>，<code>value</code>不会被回收，而这块<code>value</code>永远不会被访问到了，<strong>导致<code>value</code>内存泄漏</strong>。</p>
<p>也就是说，<code>ThreadLocalMap</code>中的<code>key</code>使用了弱引用，也有可能内存泄漏。</p>
<h3 id="5出现内存泄漏的真实原因">（5）出现内存泄漏的真实原因</h3>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/ThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9C%9F%E6%AD%A3%E5%8E%9F%E5%9B%A0.png" alt="图片" loading="lazy"></figure>
<p>比较以上两种情况，我们就会发现，内存泄漏的发生跟<code>ThreadLocalMap</code>中的<code>key</code>是否使用弱引用是没有关系的。那么内存泄漏的的真正原因是什么呢？</p>
<p>细心的同学会发现，在以上两种内存泄漏的情况中，都有两个前提：</p>
<p>1.没有手动删除这个<code>Entry</code></p>
<p>2.<code>CurrentThread</code>依然运行</p>
<p>第一点很好理解，只要在使用完<code>ThreadLocal</code>，调用其<code>remove</code>方法删除对应的<code>Entry</code>，就能避免内存泄漏。第二点稍微复杂一点，由于<code>ThreadLocalMap</code>是<code>Thread</code>的一个属性，被当前线程所引用，所以它的生命周期跟<code>Thread</code>一样长。那么在使用完<code>ThreadLocal</code>的使用，如果当前<code>Thread</code>也随之执行结束，<code>ThreadLocalMap</code>自然也会被<code>gc</code>回收，从根源上避免了内存泄漏。</p>
<p>综上，<code>ThreadLocal</code>内存泄漏的根源是：由于<code>ThreadLocalMap</code>的生命周期跟<code>Thread</code>一样长，如果没有手动删除对应<code>key</code>就会导致内存泄漏。</p>
<h3 id="6为什么使用弱引用">（6）为什么使用弱引用</h3>
<p>根据刚才的分析，我们知道了：无论使用<code>ThreadLocalMap</code>中的<code>key</code>使用哪种类型引用都无法完全避免内存泄漏，跟使用弱引用没有关系。要避免内存泄漏有两种方式：</p>
<p>1.使用完<code>ThreadLocal</code>，调用其<code>remove</code>方法删除对应的<code>Entry</code></p>
<p>2.使用完<code>ThreadLocal</code>，当前<code>Thread</code>也随之运行结束</p>
<p>相对第一种方式，第二种方式显然更不好控制，特别是使用线程池的时候，线程结束是不会销毁的。</p>
<p>也就是说，只要记得在使用完<code>ThreadLocal</code>及时的调用<code>remove</code>，无论<code>key</code>是强引用还是弱引用都不会有问题。</p>
<p><strong>那么为什么key要用弱引用呢？</strong></p>
<p>事实上，在<code>ThreadLocalMap</code>中的<code>set/getEntry</code>方法中，会对<code>key</code>为<code>nul</code>（也即是<code>ThreadLocal</code>为<code>null</code>）进行判断，如果为<code>null</code>的话，那么是会对<code>value</code>置为<code>null</code>的。</p>
<p>这就意味着使用完<code>ThreadLocal</code>，<code>CurrentThread</code>依然运行的前提下，就算忘记调用<code>remove</code>方法，弱引用比强引用可以多一层保障：弱引用的<code>ThreadLocal</code>会被回收，对应的<code>value</code>在下一次<code>ThreadLocalMap</code>调用<code>set</code>，<code>get</code>，<code>remove</code>中的任一方法的时候会被清除，从而避免内存泄漏。</p>
<h2 id="43hash冲突的解决">4.3hash冲突的解决</h2>
<p><code>hash</code>冲突的解决是<code>Map</code>中的一个重要内容。我们以<code>hash</code>冲突的解决为线索，来研究一下<code>ThreadLocalMap</code>的核心源码。</p>
<h3 id="1首先从threadlocal的set方法入手">（1）首先从ThreadLocal的set(）方法入手</h3>
<pre><code>public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<p>这个方法我们刚才分析过，其作用是设置当前线程绑定的局部变量：<br>
A.首先获取当前线程，并根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则将参数设置到<code>Map</code>中（当前<code>ThreadLocal</code>的引用作为<code>key</code>）</p>
<p>（这里调用了<code>ThreadLocalMap</code>的<code>set</code>方法）</p>
<p>C.如果<code>Map</code>为空，则给该线程创建<code>Map</code>，并设置初始值</p>
<p>（这里调用了<code>ThreadLocalMap</code>的构造方法）</p>
<h3 id="2构造方法threadlocalmapthreadlocal-firstkey-object-firstvalue">（2）构造方法ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue)</h3>
<pre><code>/**
 * @param firstKey 本地 ThreadLocal 实例(this)
 * @param firstValue 要保存的线程本地变量
 */
ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) {
    // 初始化 table
    table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY];
    // 计算索引（重点代码）
    int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);
    // 设置值
    table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue);
    size = 1;
    // 设置阈值
    setThreshold(INITIAL_CAPACITY);
}
</code></pre>
<p>构造函数首先创建一个长度为16的<code>Entry</code>数组，然后计算出<code>firstKey</code>对应的索引，然后存储到<code>table</code>中，并设置<code>size</code>和<code>threshold</code>。<br>
重点分析：<code>int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);</code></p>
<p>a.关于<code>firstkey.threadLocalHashcode</code>：</p>
<pre><code>private final int threadLocalHashCode = nextHashCode();
private static int nextHashCode() {
    return nextHashCode.getAndAdd(HASH_INCREMENT);
}
// AtomicInteger 是一个提供原子操作的 Integer类，通过线程安全的方式操作加减，适合高并发情况下的使用
private static AtomicInteger nextHashCode =
    new AtomicInteger();
// 特殊的 hash 值
private static final int HASH_INCREMENT = 0x61c88647;
</code></pre>
<p>这里定义了一个<code>Atomiclnteger</code>类型，每次获取当前值并加上<code>HASH_INCREMENT</code>，<code>HASH_INCREMENT=0x61c88647</code>，这个值跟斐波那契数列（黄金分割数）有关，其主要目的就是为了让哈希码能均匀的分布在2的n次方的数组里，也就是<code>Entry[]]table</code>中，这样做可以尽量避免<code>hash</code>冲突。</p>
<p>b.关于<code>&amp;（INITIAL_CAPACITY-1）</code></p>
<p>计算<code>hash</code>的时候里面采用了<code>hashCode&amp;(size-1)</code>的算法，这相当于取模运算<code>hashCode%size</code>的一个更高效的实现。正是因为这种算法，我们要求<code>size</code>必须是2的整次幂，这也能保证保证在索引不越界的前提下，使得<code>hash</code>发生冲突的次数减小。</p>
<h3 id="3threadlocalmap中的set方法">（3）ThreadLocalMap中的set方法</h3>
<pre><code>private void set(ThreadLocal&lt;?&gt; key, Object value) {

    // We don't use a fast path as with get() because it is at
    // least as common to use set() to create new entries as
    // it is to replace existing ones, in which case, a fast
    // path would fail more often than not.

    ThreadLocal.ThreadLocalMap.Entry[] tab = table;
    int len = tab.length;
    // 计算索引（重点代码）
    int i = key.threadLocalHashCode &amp; (len-1);

    /**
     * 使用线性探测法查找元素（重点代码）
     */
    for (ThreadLocal.ThreadLocalMap.Entry e = tab[i];
         e != null;
         e = tab[i = nextIndex(i, len)]) {
        ThreadLocal&lt;?&gt; k = e.get();
        // ThreadLocal 对应的 key 存在，直接覆盖之前的值
        if (k == key) {
            e.value = value;
            return;
        }

        // key 为 null，但是值不为 null，说明之前的 ThreadLocal 对象已经被回收了
        // 当前数组中的 Entry 是一个陈旧（stale）的元素
        if (k == null) {
            // 用新元素替换旧元素，这个方法进行了不少的垃圾清理动作，防止内存泄漏
            replaceStaleEntry(key, value, i);
            return;
        }
    }
    //ThreadLocal对应的key不存在并且没有找到陈旧的元素，则在空元素的位置创建一个新的Entry。
    tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value);
    int sz = ++size;
    /**
     * cleanSomeslots用于清除那些e.get()==nu11的元素，
     * 这种数据key关联的对象已经被回收，所以这个Entry（table[index]）可以被置nu11。
     * 如果没有清除任何entry，并且当前使用量达到了负载因子所定义（长度的2/3），那么进行
     * rehash（执行一次全表的扫描清理工作）
     */
    if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
        rehash();
}
// 获取环形数组的下一个索引
private static int nextIndex(int i, int len) {
    return ((i + 1 &lt; len) ? i + 1 : 0);
}
</code></pre>
<p>代码执行流程：<br>
A.首先还是根据<code>key</code>计算出索引i，然后查找位置上的<code>Entry</code>，<br>
B.若是<code>Entry</code>已经存在并且<code>key</code>等于传入的<code>key</code>，那么这时候直接给这个<code>Entry</code>赋新的<code>value</code>值<br>
C.若是<code>Entry</code>存在，但是<code>key</code>为<code>null</code>，则调用<code>replaceStaleEntry</code>来更换这个<code>key</code>为空的<code>Entry</code>，<br>
D.不断循环检测，直到遇到为<code>null</code>的地方，这时候要是还没在循环过程中<code>return</code>，那么就在这个<code>null</code>的位置新建一个<code>Entry</code>，并且插入，同时<code>size</code>增加1。</p>
<p>最后调用<code>cleanSomeSlots</code>，清理<code>key</code>为<code>null</code>的<code>Entry</code>，最后返回是否清理了<code>Entry</code>，接下来再判断<code>size</code>是否<code>&gt;=thresgold</code>达到了<code>rehash</code>的条件，达到的话就会调用<code>rehash</code>函数执行一次全表的扫描清理。</p>
<p><strong>重点分析</strong>：<code>ThreadLocalMap</code>使用<strong>线性探测法</strong>来解决哈希冲突的。</p>
<p>该方法一次探测下一个地址，直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出。</p>
<p>举个例子，假设当前<code>table</code>长度为16，也就是说如果计算出来<code>key</code>的<code>hash</code>值为14，如果<code>table</code>[14]上已经有值，并且其<code>key</code>与当前<code>key</code>不一致，那么就发生了<code>hash</code>冲突，这个时候将14+1得到15，取table[15]进行判断，这个时候如果还是冲突会回到0，取table[0]，以此类推，直到可以插入。</p>
<p>按照上面的描述，可以把<code>Entry[]table</code>看成一个环形数组。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Java 并发]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/">
        </link>
        <updated>2020-03-31T14:58:28.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java 并发的东西比较多，今天先总结一部分。</p>
</blockquote>
<h1 id="1什么是线程和进程">1.什么是线程和进程？</h1>
<ul>
<li>进程是 OS 资源分配的基本单位。进程拥有独立的虚拟地址空间。</li>
<li>线程是 CPU 调度的基本单位。线程共享进程的堆、方法区资源，但每个线程有自己的程序计数器、虚拟机栈、本地方法栈。</li>
</ul>
<h1 id="2并发和并行的区别">2.并发和并行的区别？</h1>
<ul>
<li>并发：统一时间段内，多个任务都在执行。</li>
<li>并行：同一时间内，多个任务同时执行。</li>
</ul>
<h1 id="3为什么要使用多线程">3.为什么要使用多线程？</h1>
<p>先从总体上来说：</p>
<ul>
<li>从计算机底层来说：线程可以比作是轻量级的进程，是程序执行的最小单位，<strong>线程间的切换和调度的成本远远小于进程</strong>另外，多核CPU时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。</li>
<li>从当代互联网发展趋势来说：现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。</li>
</ul>
<p>再深入到计算机底层来探讨：</p>
<ul>
<li>单核时代：在单核时代多线程主要是为了提高CPU和IO设备的综合利用率。举个例子：当只有一个线程的时候会导致CPU计算时，IO设备空闲；进行IO操作时，CPU空闲。我们可以简单地说这两者的利用率目前都是50%左右。但是当有两个线程的时候就不一样了，当一个线程执行CPU计算时，另外一个线程可以进行IO操作，这样两个的利用率就可以在理想情况下达到100%了。</li>
<li>多核时代：多核时代多线程主要是为了<strong>提高CPU利用率</strong>。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU只会一个CPU核心被利用到，而创建多个线程就可以让多个CPU核心被利用到，这样就提高了CPU的利用率。</li>
</ul>
<h1 id="4创建线程的方式">4.创建线程的方式</h1>
<ul>
<li>实现 Runnable 接口</li>
</ul>
<pre><code>// 1. 实现 Runnable 接口
class MyRunnable implements Runnbale{
  // 2. 实现 run 方法
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  // 3. 使用自定义 runnable 对象创建线程
  MyRunnable runnable = new MyRunnable();
  Thread thread = new Thread(runnable);
  // 4. start() 启动线程
  thread.start();
}
</code></pre>
<ul>
<li>实现 Callable 接口</li>
</ul>
<p>与 Runnable 相比，Callable 可以有返回值，返回值由 FutureTask 进行封装。</p>
<pre><code>// 1. 实现 Callable 接口，并声明泛型
class MyCallable implements Callable&lt;Integer&gt;{
  // 2. 重写 call 方法
  public Integer call(){
    return 123;
  }
}
</code></pre>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException{
  MyCallable callable = new MyCallable();
  // 3. 使用 FutureTask 封装 call 方法的返回值
  FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(callable);
  Thread thread = new Thread(ft);
  thread.start();
  System.out.println(ft.get());
}
</code></pre>
<ul>
<li>继承 Thread 类</li>
</ul>
<pre><code>class MyThread extends Thread{
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  MyThread thread = new MyThread();
  thread.start();
}
</code></pre>
<h2 id="继承-vs-实现接口">继承 vs 实现接口</h2>
<p>实现接口更好一些，因为：</p>
<ul>
<li>Java 不支持多重继承，因此继承了 Thread 类就无法集成其它类，但是可以实现多个接口。</li>
<li>适合多个线程进行资源共享（Runnable 类可以作为多个 Thread 构造方法的参数）</li>
<li>线程池内只能放入 Runnable 或 Callable 接口的实现类，不能放入继承 Thread 对象的类。</li>
</ul>
<h1 id="5runnable-接口和-callable-接口的区别">5.Runnable 接口和 Callable 接口的区别</h1>
<ul>
<li>Runnable 接口重写的是 run 方法，Callable 接口重写的是 call 方法</li>
<li>run 方法执行后不能有返回值，call 方法执行后可以有返回值。</li>
<li>call()方法可以抛出异常，run()方法不可以</li>
<li>运行Callable任务可以拿到一个Future对象，表示异步计算的结果 。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</li>
</ul>
<h1 id="6start-方法和-run-方法的区别">6.start() 方法和 run() 方法的区别</h1>
<p>new 一个 Thread，线程进入了新建状态</p>
<ul>
<li>start() 方法可以启动一个线程，将线程由新建状态切换到就绪态。</li>
<li>run() 方法不会启动一个线程，只会把它当做一个普通方法去执行。</li>
</ul>
<h1 id="7sleep-方法和-wait-方法有什么区别">7.sleep 方法和 wait 方法有什么区别？</h1>
<ul>
<li>wait() 是 Object 类的方法，而 sleep() 是 Thread 的静态方法。</li>
<li>sleep 和 wait 方法都可以用来放弃 CPU 一定时间，<strong>暂停线程的执行</strong>。</li>
<li><strong>是否释放锁</strong>：两者最主要的区别在于：sleep 方法不会释放锁，而 wait 方法会释放锁。</li>
<li><strong>用途</strong>：wait 通常用于线程间交互 / 通信，sleep 通常被用于暂停执行。</li>
<li><strong>是否会自动苏醒</strong>：wait 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。</li>
</ul>
<h1 id="8reentrantlock-和-synchronized-的比较">8.ReentrantLock 和 synchronized 的比较</h1>
<ul>
<li>锁的实现</li>
</ul>
<p>synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。</p>
<ul>
<li>性能</li>
</ul>
<p>新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 和 ReentrantLock 大致相同。</p>
<ul>
<li>等待可中断</li>
</ul>
<p>当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。</p>
<p>ReentrantLock 可中断，而 synchronized 不行。</p>
<ul>
<li>公平锁</li>
</ul>
<p>公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。</p>
<p>synchronized 是不公平锁，而 ReentrantLock 默认情况下也是非公平的，但是可以在构造函数中设置公平还是不公平锁。</p>
<ul>
<li>锁绑定多个条件</li>
</ul>
<p>一个 ReentrantLock 可以同时绑定多个 Conditino 对象</p>
<ul>
<li>使用选择</li>
</ul>
<p>除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一 种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。</p>
<h1 id="9cyclicbarrier和countdownlatch的区别">9.CyclicBarrier和CountDownLatch的区别</h1>
<h2 id="countdownlatch">CountDownLatch</h2>
<p>用来控制一个线程等待多个线程。</p>
<p>维护了一个计数器 cnt，<strong>每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒</strong>。</p>
<h2 id="cyclicbarrier">CyclicBarrier</h2>
<p>用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。</p>
<p>和 CountdownLatch 相似，都是通过维护计数器来实现的。<strong>线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行</strong>。</p>
<p>CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做<strong>循环屏障</strong>。</p>
<p>CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。</p>
<h1 id="10semaphore有什么作用">10.Semaphore有什么作用</h1>
<p>Semaphore就是一个信号量，它的作用是<strong>限制某段代码块的并发数</strong>。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。</p>
<h1 id="11volatile关键字的作用">11.volatile关键字的作用</h1>
<ul>
<li>保证了可见性，不能保证原子性</li>
</ul>
<p>立刻将缓存中的值写到内存；线程通过嗅探总线上传播过来的数据监测自己的缓存是否过期了，如果过期了，就把缓存内的值设置为失效，如果要修改时，就去主存读取新值。</p>
<ul>
<li>禁止指令重排</li>
</ul>
<h1 id="12使用-blockingqueue-生产者消费者问题">12.使用 BlockingQueue 生产者消费者问题</h1>
<pre><code>public class ProductConsumer{
  private static BlockingQueue&lt;String&gt; queue = new BlockingQueue&lt;&gt;();
  private static class Producer extends Thread{
    @Override
    public void run(){
      try{
        queue.put(&quot;product&quot;);
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;produce...&quot;);
    }
  }
  private static class Consumer extends Thread{
    @Override
    public void run(){
      try{
        String product = queue.take();
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;consume...&quot;)
    }
  }
  public static void main(String[] args) {
  for (int i = 0; i &lt; 2; i++) {
    Producer producer = new Producer();
    producer.start();
  }
  for (int i = 0; i &lt; 5; i++) {
    Consumer consumer = new Consumer();
    consumer.start();
  }
  for (int i = 0; i &lt; 3; i++) {
    Producer producer = new Producer();
    producer.start();
  } 
}
</code></pre>
<p>运行结果：</p>
<pre><code>produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. 
</code></pre>
<h1 id="13一个线程如果出现了运行时异常会怎么样">13.一个线程如果出现了运行时异常会怎么样</h1>
<p>如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：<strong>如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放</strong></p>
<h1 id="14threadlocal有什么用">14.ThreadLocal有什么用</h1>
<p>线程局部变量，<strong>以空间换时间</strong>，每个线程内都有一个，把数据进行隔离，解决多线程之间共享数据的安全问题。</p>
<h1 id="15wait方法和notifynotifyall方法在放弃对象监视器时有什么区别">15.wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别</h1>
<p>wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：<strong>wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器</strong>。</p>
<h1 id="16为什么要使用线程池">16.为什么要使用线程池</h1>
<p>来一个请求创建一个线程，执行结束再销毁线程，资源耗费太大，使用线程池达到对<strong>线程的复用</strong>。使用线程池还可以灵活地控制并发的数目。</p>
<h1 id="17怎么检测一个线程是否持有对象监视器">17.怎么检测一个线程是否持有对象监视器</h1>
<p>我也是在网上看到一道多线程面试题才知道有方法可以判断某个线程是否持有对象监视器：Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着&quot;某条线程&quot;指的是当前线程。</p>
<h1 id="18concurrenthashmap的并发度是什么">18.ConcurrentHashMap的并发度是什么</h1>
<p>ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？</p>
<h1 id="19futuretask是什么">19.FutureTask是什么</h1>
<p>在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。</p>
<pre><code>public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 
public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 
</code></pre>
<p>FutureTask 可用<strong>于异步获取执行结果</strong>或<strong>取消执行任务的场景</strong>。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。</p>
<h1 id="20aqs">20.AQS</h1>
<ol>
<li>概念</li>
</ol>
<ul>
<li>AbstractQueuedSynchronizer</li>
<li>同步发生器</li>
<li>构建 LOCK</li>
<li>JUC：java.util.current</li>
</ul>
<ol start="2">
<li>基本思想</li>
</ol>
<ul>
<li>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</li>
<li>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。</li>
</ul>
<p>CLH同步队列</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/CLH%E5%90%8C%E6%AD%A5%E9%98%9F%E5%88%97.png" alt="图片" loading="lazy"></figure>
<p>AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。</p>
<pre><code>private volatile int state;//共享变量，使用volatile修饰保证线程可见性
</code></pre>
<p>状态信息通过 protected 类型的getState，setState，compareAndSetState进行操作</p>
<pre><code>//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
</code></pre>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md</a><br>
<a href="https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg">https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg</a><br>
<a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/AQS.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/AQS.md</a></p>
]]></content>
    </entry>
</feed>