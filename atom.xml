<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://epitomm.github.io</id>
    <title>SSM</title>
    <updated>2020-04-10T15:20:01.836Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://epitomm.github.io"/>
    <link rel="self" href="https://epitomm.github.io/atom.xml"/>
    <subtitle>热心善良的老学姐</subtitle>
    <logo>https://epitomm.github.io/images/avatar.png</logo>
    <icon>https://epitomm.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, SSM</rights>
    <entry>
        <title type="html"><![CDATA[dubbo]]></title>
        <id>https://epitomm.github.io/post/dubbo/</id>
        <link href="https://epitomm.github.io/post/dubbo/">
        </link>
        <updated>2020-04-10T14:34:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-基础知识">一、基础知识</h1>
<h2 id="1-分布式基础理论">1、分布式基础理论</h2>
<h3 id="11-什么是分布式系统">1.1）、什么是分布式系统？</h3>
<p>《分布式系统原理与范型》定义：</p>
<p>“分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像单个相关系统”</p>
<p>分布式系统（distributed system）是建立在网络之上的软件系统。</p>
<p>随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需<strong>一个治理系统</strong>确保架构有条不紊的演进。</p>
<h3 id="12-发展演变">1.2）、发展演变</h3>
<figure data-type="image" tabindex="1"><img src="https://uploader.shimo.im/f/IyRP1JcK5MkLxOrk.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>单一应用架构</em></p>
<p>当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。</p>
<figure data-type="image" tabindex="2"><img src="https://uploader.shimo.im/f/h9vVEvvVrkwUVpFa.png!thumbnail" alt="图片" loading="lazy"></figure>
<pre><code>适用于小型网站，小型管理系统，将所有功能都部署到一个功能里，简单易用。

缺点： 1、性能扩展比较难 （如果修改或添加某个功能，都需要把整个应用重新打包，重新放部署到 服务器）

       2、协同开发问题（所有人都去修改一个应用，容易乱）

       3、不利于升级维护
</code></pre>
<blockquote>
<p>将多个功能放到一个应用内，打包后放到服务器上即可。访问量增大，一个服务器无法承受时，再添加一个服务器同时跑这个应用。</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://uploader.shimo.im/f/ACgpqL6hZ4k1gtdF.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>垂直应用架构</em></p>
<p>当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。</p>
<figure data-type="image" tabindex="4"><img src="https://uploader.shimo.im/f/wy9e5tzcxrMftTV9.png!thumbnail" alt="图片" loading="lazy"></figure>
<pre><code>通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。

缺点： 公用模块无法重复利用，开发性的浪费
</code></pre>
<blockquote>
<p>将一个大应用拆分成几个独立的小应用，每一个应用都是从头到尾完成的（从页面到业务逻辑程序到数据库）。</p>
</blockquote>
<figure data-type="image" tabindex="5"><img src="https://uploader.shimo.im/f/LxqQ9rmJeHgq1rxR.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>垂直应用架构</p>
<blockquote>
<p>当某一块应用的访问量比较大时，将这个应用多扩展几个服务器。</p>
</blockquote>
<figure data-type="image" tabindex="6"><img src="https://uploader.shimo.im/f/HLO4lTzREjsKgbec.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>扩展某个小应用即可</p>
<blockquote>
<p>好处：1）分工合作容易，每个人负责开发维护不同的应用，互不干扰。<br>
2）性能扩展容易，比如“用户”应用的访问量增大， 就把它多放几台服务器，扩展的是某个小应用，其他小应用无需变动。<br>
缺点：1）由于每个小应用都是完整的（界面+业务逻辑+数据库），但是界面要求经常变化，每个界面的变化都会导致应用的重新部署。无法做到页面 和 业务逻辑 的分离<br>
2） 随着应用的逐步增多，垂直应用会越来越多，这样的情况下，不可能理想的应用和应用之间互相独立，订单模块需要用户模块和商品模块信息，应用之间交互，不可能完全独立。</p>
</blockquote>
<figure data-type="image" tabindex="7"><img src="https://uploader.shimo.im/f/k9C8XgqLOlkkpGKb.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>界面与业务逻辑无法分离，各个应用间需要交互</p>
<p><em>分布式服务架构</em></p>
<p>当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的<strong>分布式服务框架(RPC)是关键</strong>。</p>
<figure data-type="image" tabindex="8"><img src="https://uploader.shimo.im/f/hgcwQzljhlMXdvEe.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>将用户抽取成“用户界面” 和 “用户业务”，订单抽取成 “订单界面” 和 “订单业务” 等。<br>
当业务逻辑不变的情况下，如果只想修改界面，重启界面服务器即可，核心业务逻辑还在其他服务器上，无需变动。</p>
</blockquote>
<figure data-type="image" tabindex="9"><img src="https://uploader.shimo.im/f/rBAuJXHaFnAj7kEs.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>用户界面放在 A 服务器上，用户业务放在 B 服务器上，订单业务放在 C 服务器上，如果 A 服务器（用户界面）需要调用 B 服务器（用户业务）的功能。如果写在一个应用内，A 调用 B，直接“方法 A . 方法 B” 即可，直接调用，进程类通讯，都在一个服务器上，都是同一个 tomcat，同一个进程类通讯。但如果是分布式服务架构，A 和 B 在两台服务器上，这样的不同服务器间的互相调用称为 RPC（远程过程调用）。分布式服务架构的难点：如何进行远程过程调用，如果拆分应用，提升业务的复用程度。<br>
随着业务的不断增多，分拆的业务越来越多，成千上万的服务器在跑不同的服务，出现的资源浪费问题愈加严重，比如用户业务访问量较小，但却有 100 台服务器在跑，就造成了浪费；而 商品业务 访问量很大，但却只有 10 台服务器在跑。应该有一个基于访问压力的调度中心能够实时监控数据动态调度，提高资源利用率，让更多的服务器去跑业务量更大的业务。</p>
</blockquote>
<p><em>流动计算架构</em></p>
<p>当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于<strong>提高机器利用率的资源调度和治理中心(SOA)[ Service Oriented Architecture]是关键</strong>。</p>
<figure data-type="image" tabindex="10"><img src="https://uploader.shimo.im/f/BDGCqfQ4l188yDJ5.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>采用流动计算架构，引入调度中心，负责维护服务间的复杂关系，实时管理集群，比如 A 服务器访问量大了，给 A 多增加几台服务器，假设 第一台 有 100 个请求，第二台 有 2 个请求，第三台有 10000 个请求，那么下次请求进来，就应该找比较闲的第二台服务器来处理请求，以此提高整个集群利用率。</p>
</blockquote>
<figure data-type="image" tabindex="11"><img src="https://uploader.shimo.im/f/kub3pZ5mp1YXMEEV.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>流动计算架构</p>
<h3 id="13-rpc">1.3）、RPC</h3>
<p><em>什么叫RPC</em></p>
<p>RPC【Remote Procedure Call】是指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。</p>
<p><em>RPC基本原理</em></p>
<figure data-type="image" tabindex="12"><img src="https://uploader.shimo.im/f/OGbOHN4XcyQx2kI7.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>需求：A 服务器客户端（client）有一个小功能，想要调用 B 服务器的一个小功能。<br>
实现：A 服务器客户端（client）先找一个小助手（client stub），这个小助手一看，A 服务器想要调用 B 服务器上的功能，先跟 B 服务器在网络上建立一个 sockets 连接，将要调用 B 的一些信息（比如要调用 B 的某个方法的方法名、参数）传递给 B 模型，B 服务器上的小助手（server stub）收到这些信息，知道了 A 服务器想要调用 我的一个方法，执行这个方法后，将返回值依次传回 A 客户端。</p>
</blockquote>
<figure data-type="image" tabindex="13"><img src="https://uploader.shimo.im/f/CFulLm9wpvIaXNtW.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>RPC两个核心模块：通讯，序列化。</p>
<p>RPC 框架有很多如：dubbo、gRPC、Thrift、HSF(High Speed Service Framework)</p>
<figure data-type="image" tabindex="14"><img src="https://uploader.shimo.im/f/TUHazdO6gdYgcqGx.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>A 服务器上有一个 hello()方法，想要调用 B 服务器上的 hi() 方法，同时传入一个 User  对象，B 服务器上的 hi() 方法执行完了以后，返回一个 String 给 A 服务器，A服务器调完 B服务器的方法后，收到 B 服务器的返回值并在控制台打印。<br>
调用过程：A 服务器客户端（Client） 想要 调用 B 服务器的代码，A 服务器上有一个小助手（Client Stub）这个小助手一看 A 服务器 要调用 B 服务器，先与 B 服务器建议连接，建立连接后，由于调用方法要传递参数，这个参数要发给 B 服务器，参数对象要在网络间传递需要先序列化 ，序列化后将要调用的信息传递给 B 服务器的小助手（Server Stub），B 服务器的小助手收到信息，一看有来自外界的 A 服务器想要调用我的 hi() 方法，同时还传递来了一个参数值，由于是序列化传递过来的，如果使用则需反序列化成对象，B服务器上的小助手调用 B 服务器上的方法，拿到反序列化的对象、一些属性值，方法调用完就会有一个返回值，返回值过来要在网络间传递数据，将返回的 String 对象序列化传递给 A 服务器的小助手，Client Stub 收到后再反序列化，输出。<br>
整个过程两个核心：建立连接、传递数据（序列化和反序列化）。所以，影响一个 RPC 框架性能的重要两点：能否快速地在各个服务器间建立连接；序列化/反序列化机制的速度。</p>
</blockquote>
<h2 id="2-dubbo核心概念">2、dubbo核心概念</h2>
<h3 id="21-简介">2.1）、简介</h3>
<p>Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。</p>
<p>官网：</p>
<p><a href="http://dubbo.apache.org/zh-cn/">http://dubbo.apache.org/zh-cn/</a></p>
<figure data-type="image" tabindex="15"><img src="https://uploader.shimo.im/f/R2QfiJXMiY84jRGe.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li><strong>面向接口代理的高性能 RPC 调用</strong></li>
</ol>
<p>使用 dubbo 时，A 服务器 要调用 B 服务器上的代码，只需将 B 功能方法的接口 InterfaceB拿过来，调用接口所在的方法 InterfaceB.fun()，就会自动去找服务器 B 上的代码代码调用，屏蔽了远程的调用细节。类似在用 Mybatis ，操作数据库时，只需要写一个 mapper 接口，调用接口的方法即可。</p>
<ol start="2">
<li><strong>智能负载均衡</strong></li>
</ol>
<p>比如用户业务访问量很大，就需要多放几台服务器，“用户界面” 想要调用 “用户业务” 的功能，调用 “用户业务” 的哪一台服务器都可以，假设 第一台用户业务服务器当前有 100 个请求， 第二台用户业务服务器当前有 2 个请求， 第三台用户业务服务器当前有 1000 个请求， 第四台用户业务服务器当前有 10 个请求，就应该找一个非常空闲的服务器快速处理这次响应，这个机制就叫做<strong>负载均衡</strong>，让每个服务器都有一个很均衡的负载，不要让某一台服务器做太多的响应，把它压垮，也不要让某一台服务器太闲，资源浪费。</p>
<figure data-type="image" tabindex="16"><img src="https://uploader.shimo.im/f/oyfJ2mKDKksILkRV.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol start="3">
<li><strong>服务自动注册与发现</strong></li>
</ol>
<p>想象这样一个场景：业务非常多，每一块的访问量都特别大，比如用户业务在 1、2、3、4 号服务器都有，支付业务在 9、11、13 号服务器都有，那么 订单web 想要调用支付业务，RPC 框架爱如何知道支付业务都在哪些服务器上呢？如果 11 号服务器出问题了，框架如何自动地知道这个事呢？引入<strong>注册中心</strong>机制。</p>
<p>为了能动态感知到每一个服务，可以将所有的服务都注册到注册中心，包括前端程序也可以都注册到注册中心内，注册中心相当于维护了一个 “业务 - 服务器” 清单，比如：用户业务：1、2、3、4 号服务器，如果 2 号服务器出问题了，就把它从清单中删掉。如果 订单web 要调用支付业务，先到注册中心的清单内找支付业务都在哪一台服务器上，然后随机选择或者选择请求量最少的一台服务器进行访问。</p>
<figure data-type="image" tabindex="17"><img src="https://uploader.shimo.im/f/N22P15DTFnY85BNk.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol start="4">
<li><strong>高度可扩展</strong></li>
</ol>
<p>微内核 + 插件</p>
<ol start="5">
<li><strong>运行期流量调度</strong></li>
</ol>
<p>内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现<strong>灰度发布</strong>，同机房优先等功能。</p>
<p>灰度发布：一个用户服务在 100 台服务器上跑，用户服务做了开发升级，先选定 20 台服务器，让它们先用新版本的服务，剩下的 80 台使用旧版本的服务，等这 20 台用着都没问题了，再选 20 台，这样逐步过渡，直到 100 台全用到新的用户服务。配置不同的路由规则，请求进来后，让一部分请求用新升级的服务，剩下的来用旧的服务，通过这种方式从旧服务转化成新服务的过程就叫做<strong>灰度发布</strong>。</p>
<ol start="6">
<li><strong>可视化的服务治理和运维</strong></li>
</ol>
<p>通过可视化的 WEB 界面动态查询服务的信息、调整一些参数。</p>
<h3 id="22-基本概念">2.2）、基本概念</h3>
<figure data-type="image" tabindex="18"><img src="https://uploader.shimo.im/f/rldWEV14ZqE0PvtZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><strong>服务提供者（Provider）</strong>：暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务。</p>
<p><strong>服务消费者（Consumer）</strong>: 调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</p>
<p><strong>注册中心（Registry）</strong>：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</p>
<p><strong>监控中心（Monitor）</strong>：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</p>
<p><strong>框架容器（Container</strong>）</p>
<ul>
<li>调用关系说明
<ul>
<li>服务容器负责启动，加载，运行服务提供者。</li>
<li>服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="19"><img src="https://uploader.shimo.im/f/HR89X3Oo5BQ6gjuj.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>用户业务是实际的业务功能，web 界面要去调用这些业务功能，所以，用户业务是一个服务提供者（Provider），而 web 界面是服务消费者（Consumer）</p>
<blockquote>
<p>运行流程：容器 Container 启动，初始化 init ，服务提供者 Provider 将自己提供的信息注册 register 到注册中心 Registry ，注册中心就知道有哪些服务上线了，当服务消费者 Consumer 启动，从注册中心订阅 subscribe 自己所需要的服务，如果服务提供者发生变更（3 号服务器下线了），注册中心将这次变更推送 notify 给消费者，消费者拿到所有它能调用的服务，调用的时候可以同步调用 invoke 服务提供者提供的服务，如果消费者要调用的服务有多台服务器在提供，消费者根据负载均衡算法选择一个进行调用。每次的调用信息会定时地每隔一分钟将信息发送到监控中心 Monitor，监控中心就能监控到服务的状态。<br>
0、1、2 这三步是在初始化、启动应用时完成的。<br>
3、5 是异步过程，<br>
4 服务消费者调用服务提供者提供的功能是一个同步的调用。<br>
了解了 dubbo 框架，在编写 dubbo 应用时：</p>
<ol>
<li>先写一个服务提供者，将服务提供者提供的服务注册到注册中心；</li>
<li>编写一个服务消费者，消费者从注册中心订阅提供者提供的服务；</li>
<li>测试消费者如何调用提供者提供的功能。</li>
</ol>
</blockquote>
<h2 id="3-dubbo环境搭建">3、dubbo环境搭建</h2>
<h3 id="31-windows-安装zookeeper">3.1）、【windows】-安装zookeeper</h3>
<table>
<thead>
<tr>
<th style="text-align:center">1、下载zookeeper网址 <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/">https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2、解压zookeeper解压运行zkServer.cmd ，初次运行会报错，没有zoo.cfg配置文件</td>
</tr>
<tr>
<td style="text-align:center">3、修改zoo.cfg配置文件将conf下的zoo_sample.cfg复制一份改名为zoo.cfg即可。注意几个重要位置：dataDir=./   临时数据存储的目录（可写相对路径）clientPort=2181   zookeeper的端口号修改完成后再次启动zookeeper</td>
</tr>
<tr>
<td style="text-align:center">4、使用zkCli.cmd测试ls /：列出zookeeper根下保存的所有节点create –e /atguigu 123：创建一个atguigu节点，值为123get /atguigu：获取/atguigu节点的值</td>
</tr>
</tbody>
</table>
<p>注：记录一个小 bug</p>
<p>问题：【zookeeper】报错-Dzookeeper.log.dir=xxx&quot;' 不是内部或外部命令，也不是可运行的程序 或批处理文件的解决</p>
<p>解决：修改zkServer.cmd文件。将 call %JAVA% 改成 java</p>
<pre><code>java &quot;-Dzookeeper.log.dir=%ZOO_LOG_DIR%&quot; &quot;-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%&quot; -cp &quot;%CLASSPATH%&quot; %ZOOMAIN% &quot;%ZOOCFG%&quot; %*
</code></pre>
<p>参考博客：<a href="https://blog.csdn.net/pangdongh/article/details/90208230">https://blog.csdn.net/pangdongh/article/details/90208230</a></p>
<h3 id="32-windows-安装dubbo-admin管理控制台">3.2）、【windows】-安装dubbo-admin管理控制台</h3>
<p>dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。</p>
<p>但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。</p>
<p>1、下载dubbo-admin</p>
<p><a href="https://github.com/apache/incubator-dubbo-ops">https://github.com/apache/incubator-dubbo-ops</a></p>
<figure data-type="image" tabindex="20"><img src="https://uploader.shimo.im/f/dyq0f6AsG9ob4r5T.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>2、进入目录，修改dubbo-admin配置</p>
<p>修改 src\main\resources\application.properties 指定zookeeper地址</p>
<figure data-type="image" tabindex="21"><img src="https://uploader.shimo.im/f/CjN6ZdYVLbIyLTLu.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3、打包dubbo-admin</p>
<pre><code>mvn clean package -Dmaven.test.skip=true 
</code></pre>
<p>4、运行dubbo-admin</p>
<pre><code>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar
</code></pre>
<p><strong>注意：【有可能控制台看着启动了，但是网页打不开，需要在控制台按下ctrl+c即可】</strong></p>
<p>默认使用root/root 登陆</p>
<figure data-type="image" tabindex="22"><img src="https://uploader.shimo.im/f/oMqXySQHAzwmrdaD.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="33-linux-安装zookeeper">3.3）、【linux】-安装zookeeper</h3>
<p><em>1、安装jdk</em></p>
<p>1、下载jdk</p>
<p><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>
<figure data-type="image" tabindex="23"><img src="https://uploader.shimo.im/f/4dOjjbVaC9wTnFtZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>不要使用wget命令获取jdk链接，这是默认不同意，导致下载来的jdk压缩内容错误</p>
<p>2、上传到服务器并解压</p>
<figure data-type="image" tabindex="24"><img src="https://uploader.shimo.im/f/VWrZ4IFf1HAP7LaV.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3、设置环境变量</p>
<pre><code>/usr/local/java/jdk1.8.0_171
</code></pre>
<figure data-type="image" tabindex="25"><img src="https://uploader.shimo.im/f/trnj2glzc50CeE2V.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>文件末尾加入下面配置</p>
<pre><code>export JAVA_HOME=/usr/local/java/jdk1.8.0_171

export JRE_HOME=${JAVA_HOME}/jre

export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib

export PATH=${JAVA_HOME}/bin:$PATH
</code></pre>
<figure data-type="image" tabindex="26"><img src="https://uploader.shimo.im/f/9TQb8orU5W8JblWa.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>4、使环境变量生效&amp;测试JDK</p>
<figure data-type="image" tabindex="27"><img src="https://uploader.shimo.im/f/YZceTesOROMuf60z.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、安装zookeeper</em></p>
<p>1、下载zookeeper</p>
<p>网址 <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/">https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/</a></p>
<p>wget <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz">https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz</a></p>
<p>2、解压</p>
<figure data-type="image" tabindex="28"><img src="https://uploader.shimo.im/f/lXUzgGE5Y70JWug0.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3、移动到指定位置并改名为zookeeper</p>
<figure data-type="image" tabindex="29"><img src="https://uploader.shimo.im/f/igeCYqDDuGokZ4fK.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="30"><img src="https://uploader.shimo.im/f/at4Y6l3Gy9ssrU7g.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>3、开机启动zookeeper</em></p>
<p>1）-复制如下脚本</p>
<pre><code>#!/bin/bash

#chkconfig:2345 20 90

#description:zookeeper

#processname:zookeeper

ZK_PATH=/usr/local/zookeeper

export JAVA_HOME=/usr/local/java/jdk1.8.0_171

case $1 in

         start) sh  $ZK_PATH/bin/zkServer.sh start;;

         stop)  sh  $ZK_PATH/bin/zkServer.sh stop;;

         status) sh  $ZK_PATH/bin/zkServer.sh status;;

         restart) sh $ZK_PATH/bin/zkServer.sh restart;;

         *)  echo &quot;require start|stop|status|restart&quot;  ;;

esac
</code></pre>
<figure data-type="image" tabindex="31"><img src="https://uploader.shimo.im/f/VkPIQDyMXmgQmzql.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>2）-把脚本注册为Service</p>
<figure data-type="image" tabindex="32"><img src="https://uploader.shimo.im/f/cRDEiCltdfo7wkit.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3）-增加权限</p>
<figure data-type="image" tabindex="33"><img src="https://uploader.shimo.im/f/4IFCQrCcz08aX3PH.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>4、配置zookeeper</em></p>
<p>1、初始化zookeeper配置文件</p>
<p>拷贝/usr/local/zookeeper/conf/zoo_sample.cfg</p>
<p>到同一个目录下改个名字叫zoo.cfg</p>
<figure data-type="image" tabindex="34"><img src="https://uploader.shimo.im/f/TfJsHy5ujp00aLDL.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>2、启动zookeeper</p>
<figure data-type="image" tabindex="35"><img src="https://uploader.shimo.im/f/FTSVAacP2WQAFXQ9.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="34-linux-安装dubbo-admin管理控制台">3.4）、【linux】-安装dubbo-admin管理控制台</h3>
<p><em>1、安装Tomcat8（旧版dubbo-admin是war，新版是jar不需要安装Tomcat）</em></p>
<p>1、下载Tomcat8并解压</p>
<p><a href="https://tomcat.apache.org/download-80.cgi">https://tomcat.apache.org/download-80.cgi</a></p>
<p>wget <a href="http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz">http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz</a></p>
<p>2、解压移动到指定位置</p>
<figure data-type="image" tabindex="36"><img src="https://uploader.shimo.im/f/GFKAW7gakD43OxRE.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3、开机启动tomcat8</p>
<figure data-type="image" tabindex="37"><img src="https://uploader.shimo.im/f/rRPJD94dzy0WSNeg.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>复制如下脚本</p>
<pre><code>#!/bin/bash

#chkconfig:2345 21 90

#description:apache-tomcat-8

#processname:apache-tomcat-8

CATALANA_HOME=/opt/apache-tomcat-8.5.32

export JAVA_HOME=/opt/java/jdk1.8.0_171

case $1 in

start)

    echo &quot;Starting Tomcat...&quot;  

    $CATALANA_HOME/bin/startup.sh

    ;;

stop)

    echo &quot;Stopping Tomcat...&quot;  

    $CATALANA_HOME/bin/shutdown.sh

    ;;

restart)

    echo &quot;Stopping Tomcat...&quot;  

    $CATALANA_HOME/bin/shutdown.sh

    sleep 2

    echo  

    echo &quot;Starting Tomcat...&quot;  

    $CATALANA_HOME/bin/startup.sh

    ;;

*)

    echo &quot;Usage: tomcat {start|stop|restart}&quot;  

    ;; esac
</code></pre>
<p>4、注册服务&amp;添加权限</p>
<figure data-type="image" tabindex="38"><img src="https://uploader.shimo.im/f/sgrlw1jLRksvtDuA.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="39"><img src="https://uploader.shimo.im/f/yFBPAQA9wQcuLiLK.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>5、启动服务&amp;访问tomcat测试</p>
<figure data-type="image" tabindex="40"><img src="https://uploader.shimo.im/f/PCItXvgg0c8lpyxk.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="41"><img src="https://uploader.shimo.im/f/UkCJSOTip08WixDn.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、安装dubbo-admin</em></p>
<p>dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。</p>
<p>但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。</p>
<p>1、下载dubbo-admin</p>
<p><a href="https://github.com/apache/incubator-dubbo-ops">https://github.com/apache/incubator-dubbo-ops</a></p>
<figure data-type="image" tabindex="42"><img src="https://uploader.shimo.im/f/NB3VdgOwTJUVLKd7.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>2、进入目录，修改dubbo-admin配置</p>
<p>修改 src\main\resources\application.properties 指定zookeeper地址</p>
<figure data-type="image" tabindex="43"><img src="https://uploader.shimo.im/f/Ky405QqumK4BCVLb.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>3、打包dubbo-admin</p>
<pre><code>mvn clean package -Dmaven.test.skip=true 
</code></pre>
<p>4、运行dubbo-admin</p>
<pre><code>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar
</code></pre>
<p>默认使用root/root 登陆</p>
<figure data-type="image" tabindex="44"><img src="https://uploader.shimo.im/f/QwVB9l4fvmYkh6a2.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="4-dubbo-helloworld">4、dubbo-helloworld</h2>
<h3 id="41-提出需求">4.1）、提出需求</h3>
<p>某个电商系统，订单服务需要调用用户服务获取某个用户的所有地址；</p>
<p>我们现在 需要创建两个服务模块进行测试</p>
<table>
<thead>
<tr>
<th style="text-align:center">模块</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">订单服务web模块</td>
<td style="text-align:center">创建订单等</td>
</tr>
<tr>
<td style="text-align:center">用户服务service模块</td>
<td style="text-align:center">查询用户地址等</td>
</tr>
</tbody>
</table>
<p>测试预期结果：</p>
<p>订单服务web模块在A服务器，用户服务模块在B服务器，A可以远程调用B的功能。</p>
<figure data-type="image" tabindex="45"><img src="https://uploader.shimo.im/f/zu5t5nNfM7A5kcbM.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="42-工程架构">4.2）、工程架构</h3>
<p>根据 dubbo《服务化最佳实践》</p>
<p><em>1、分包</em></p>
<p>建议将服务接口，服务模型，服务异常等均放在 API 包中，因为服务模型及异常也是 API 的一部分，同时，这样做也符合分包原则：重用发布等价原则(REP)，共同重用原则(CRP)。</p>
<p>如果需要，也可以考虑在 API 包中放置一份 spring 的引用配置，这样使用方，只需在 spring 加载过程中引用此配置即可，配置建议放在模块的包目录下，以免冲突，如：com/alibaba/china/xxx/dubbo-reference.xml。</p>
<p><em>2、粒度</em></p>
<p>服务接口尽可能大粒度，每个服务方法应代表一个功能，而不是某功能的一个步骤，否则将面临分布式事务问题，Dubbo 暂未提供分布式事务支持。</p>
<p>服务接口建议以业务场景为单位划分，并对相近业务做抽象，防止接口数量爆炸。</p>
<p>不建议使用过于抽象的通用接口，如：Map query(Map)，这样的接口没有明确语义，会给后期维护带来不便。</p>
<figure data-type="image" tabindex="46"><img src="https://uploader.shimo.im/f/JGqDnycGLrAYNogH.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="43-创建模块">4.3）、创建模块</h3>
<p><em>1、gmall-interface：公共接口层（model，service，exception…）</em></p>
<p>作用：定义公共接口，也可以导入公共依赖</p>
<p>1、Bean模型</p>
<pre><code>public class UserAddress implements Serializable{
    private Integer id;
    private String userAddress;
    private String userId;
    private String consignee;
    private String phoneNum;
    private String isDefault;
    // getter、setter、Constructure、toString
}
</code></pre>
<p>2、Service接口<br>
UserService</p>
<pre><code>package com.atguigu.gmall.service;

import com.atguigu.gmall.bean.UserAddress;
import java.util.List;
// 用户服务
public interface UserService {
   /**
    * 按照用户id返回所有的收货地址
    * @param userId
    * @return
    */
   public List&lt;UserAddress&gt; getUserAddressList(String userId);
}
</code></pre>
<p>OrderService</p>
<pre><code>// 订单服务
public interface OrderService {
   /**
    * 初始化订单
    * @param userId
    */
   public void initOrder(String userId);
}
</code></pre>
<figure data-type="image" tabindex="47"><img src="https://uploader.shimo.im/f/wyNzvleAZIggOiT2.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、gmall-user：用户模块（对用户接口的实现）</em></p>
<p>1、pom.xml</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.atguigu.gmall&lt;/groupId&gt;
        &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>2、Service</p>
<pre><code>public class UserServiceImpl implements UserService {
		
	@Override
	public List&lt;UserAddress&gt; getUserAddressList(String userId) {
		// TODO Auto-generated method stub
		return userAddressDao.getUserAddressById(userId);
	}
}
</code></pre>
<p><em>4、gmall-order-web：订单模块（调用用户模块）</em><br>
1、pom.xml</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.atguigu.gmall&lt;/groupId&gt;
        &lt;artifactId&gt;gmall-interface&lt;/artifactId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>2、测试</p>
<pre><code>public class OrderService {	
	UserService userService;	
	/**
	 * 初始化订单，查询用户的所有地址并返回
	 * @param userId
	 * @return
	 */
	public List&lt;UserAddress&gt; initOrder(String userId){
		return userService.getUserAddressList(userId);
	}
}
</code></pre>
<p>现在这样是无法进行调用的。我们gmall-order-web引入了gmall-interface，但是interface的实现是gmall-user，我们并没有引入，而且实际他可能还在别的服务器中。</p>
<h3 id="44-使用dubbo改造">4.4）、使用dubbo改造</h3>
<p><em>1、改造gmall-user作为服务提供者</em></p>
<p>1）导入 dubbo 依赖（2.6.2）、导入操作 zookeeper 的客户端（curator）</p>
<pre><code>		&lt;!-- 引入dubbo --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;com.alibaba&lt;/groupId&gt;
			&lt;artifactId&gt;dubbo&lt;/artifactId&gt;
			&lt;version&gt;2.6.2&lt;/version&gt;
		&lt;/dependency&gt;
	&lt;!-- 由于我们使用zookeeper作为注册中心，所以需要操作zookeeper
	dubbo 2.6以前的版本引入zkclient操作zookeeper 
	dubbo 2.6及以后的版本引入curator操作zookeeper
	下面两个zk客户端根据dubbo版本2选1即可
		&lt;dependency&gt;
			&lt;groupId&gt;com.101tec&lt;/groupId&gt;
			&lt;artifactId&gt;zkclient&lt;/artifactId&gt;
			&lt;version&gt;0.10&lt;/version&gt;
		&lt;/dependency&gt;
    --&gt;
		&lt;!-- curator-framework --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
			&lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
			&lt;version&gt;2.12.0&lt;/version&gt;
		&lt;/dependency&gt;
</code></pre>
<p>2）配置提供者</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:dubbo=&quot;http://dubbo.apache.org/schema/dubbo&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans-4.3.xsd        http://dubbo.apache.org/schema/dubbo        http://dubbo.apache.org/schema/dubbo/dubbo.xsd&quot;&gt;

    &lt;!-- 1.指定当前服务/应用的名字（同样的服务名字相同，不要和别的服务同名） --&gt;
    &lt;dubbo:application name=&quot;user-service-provider&quot;  /&gt;

    &lt;!-- 2.指定注册中心的位置 --&gt;
    &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;

    &lt;!-- 3.指定通信规则（通信协议、通信端口） --&gt;
    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;

    &lt;!-- 4.暴露服务 ref：指向服务的真正实现对象--&gt;
    &lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl&quot; /&gt;

    &lt;!-- 服务的实现  --&gt;
    &lt;bean id=&quot;userServiceImpl&quot; class=&quot;com.atguigu.gmall.service.impl.UserServiceImpl&quot; /&gt;
&lt;/beans&gt;
</code></pre>
<p>3）启动服务</p>
<pre><code>package com.atguigu.gmall;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import java.io.IOException;
public class MainApplication {
    public static void main(String[] args) throws IOException {
        ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext(&quot;provider.xml&quot;);
        ioc.start();
        System.in.read();
    }
}
</code></pre>
<figure data-type="image" tabindex="48"><img src="https://uploader.shimo.im/f/STJJRpsgwTkLRkmY.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>4）测试</p>
<figure data-type="image" tabindex="49"><img src="https://uploader.shimo.im/f/reVohj16x2sHjsEN.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、改造gmall-order-web作为服务消费者</em></p>
<p>1）引入dubbo</p>
<pre><code>		&lt;!-- 引入dubbo --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;com.alibaba&lt;/groupId&gt;
			&lt;artifactId&gt;dubbo&lt;/artifactId&gt;
			&lt;version&gt;2.6.2&lt;/version&gt;
		&lt;/dependency&gt;
	&lt;!-- 由于我们使用zookeeper作为注册中心，所以需要引入zkclient或curator操作zookeeper --&gt;
		&lt;!-- curator-framework --&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
			&lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
			&lt;version&gt;2.12.0&lt;/version&gt;
		&lt;/dependency&gt;
</code></pre>
<p>2）配置消费者信息</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:dubbo=&quot;http://dubbo.apache.org/schema/dubbo&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans-4.3.xsd
       http://dubbo.apache.org/schema/dubbo
       http://dubbo.apache.org/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;
    &lt;!-- 1.指定当前服务/应用的名字（同样的服务名字相同，不要和别的服务同名 --&gt;
    &lt;dubbo:application name=&quot;order-service-consumer&quot;  /&gt;

    &lt;!-- 2.注册中心地址 --&gt;
    &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;

    &lt;!-- 3.声明需要调用的远程服务的接口 --&gt;
    &lt;dubbo:reference interface=&quot;com.atguigu.gmall.service.UserService&quot; id=&quot;userService&quot; /&gt;
    &lt;!-- 包扫描 --&gt;
    &lt;context:component-scan base-package=&quot;com.atguigu.gmall.service.impl&quot;&gt;&lt;/context:component-scan&gt;
&lt;/beans&gt;
</code></pre>
<p>3）Service 注解</p>
<pre><code>package com.atguigu.gmall.service.impl;

import com.atguigu.gmall.bean.UserAddress;
import com.atguigu.gmall.service.OrderService;
import com.atguigu.gmall.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;

/**
 * 1.让服务提供者注册到注册中心（暴露服务）
 *  1）导入 dubbo 依赖（2.6.2）、导入操作 zookeeper 的客户端（curator）
 *  2）配置服务提供者
 * 2.让消费者去注册中心订阅服务提供者的地址
 */
@Service
public class OrderServiceImpl implements OrderService {
    @Autowired
    UserService userService;
    @Override
    public void initOrder(String userId) {
        // 1. 查询用户收货地址
        List&lt;UserAddress&gt; list = userService.getUserAddressList(userId);
        System.out.println(list);
    }
}
</code></pre>
<p>4）main方法测试</p>
<pre><code>package com.atguigu.gmall;

import com.atguigu.gmall.service.OrderService;
import org.springframework.context.support.ClassPathXmlApplicationContext;

import java.io.IOException;

public class MainApplication {
    public static void main(String[] args) throws IOException {
        ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;consumer.xml&quot;);
        OrderService orderService = applicationContext.getBean(OrderService.class);
        orderService.initOrder(&quot;1&quot;);
        System.out.println(&quot;调用结束...&quot;);

        System.in.read();
    }
}
</code></pre>
<p><em>3、测试调用</em><br>
访问gmall-order-web的initOrder请求，会调用UserService获取用户地址；</p>
<p>调用成功。说明我们order已经可以调用远程的UserService了；</p>
<p>运行结果：</p>
<pre><code>用户 id ：1
北京市昌平区宏福科技园综合楼3层
深圳市宝安区西部硅谷大厦B座3层（深圳分校）
调用结束...
</code></pre>
<figure data-type="image" tabindex="50"><img src="https://uploader.shimo.im/f/60BuhhwD1HUmxziW.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>4、注解版</em></p>
<p>1、服务提供方</p>
<pre><code>&lt;dubbo:application name=&quot;gmall-user&quot;&gt;&lt;/dubbo:application&gt;  
&lt;dubbo:registry address=&quot;zookeeper://118.24.44.169:2181&quot; /&gt;  
&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;
&lt;dubbo:annotation package=*&quot;com.atguigu.gmall.user.impl&quot;/&gt;  

import com.alibaba.dubbo.config.annotation.Service;
import com.atguigu.gmall.bean.UserAddress;  
import com.atguigu.gmall.service.UserService;  
import com.atguigu.gmall.user.mapper.UserAddressMapper;

@Service //使用dubbo提供的service注解，注册暴露服务
public class UserServiceImpl implements UserService {	
     @Autowired		
    UserAddressMapper userAddressMapper; 
</code></pre>
<p>2、服务消费方</p>
<pre><code>&lt;dubbo:application name=&quot;gmall-order-web&quot;&gt;&lt;/dubbo:application&gt;  
&lt;dubbo:registry address=&quot;zookeeper://118.24.44.169:2181&quot; /&gt;  
&lt;dubbo:annotation package=&quot;com.atguigu.gmall.order.controller&quot;/&gt;

@Controller  
public class OrderController {  	  	
    @Reference  //使用dubbo提供的reference注解引用远程服务  	
    UserService userService; 
</code></pre>
<h2 id="5-监控中心">5、监控中心</h2>
<h3 id="51-dubbo-admin">5.1）、dubbo-admin</h3>
<p>图形化的服务管理页面；安装时需要指定注册中心地址，即可从注册中心中获取到所有的提供者/消费者进行配置管理</p>
<h3 id="52-dubbo-monitor-simple">5.2）、dubbo-monitor-simple</h3>
<p>简单的监控中心；</p>
<p><em>1、安装</em></p>
<table>
<thead>
<tr>
<th style="text-align:center">1、下载 dubbo-ops  <a href="https://github.com/apache/incubator-dubbo-ops">https://github.com/apache/incubator-dubbo-ops</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2、修改配置指定注册中心地址进入 dubbo-monitor-simple\src\main\resources\conf修改 dubbo.properties文件</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="51"><img src="https://uploader.shimo.im/f/hiBXL60A0HIHytCX.png!thumbnail" alt="图片" loading="lazy"></figure>
<table>
<thead>
<tr>
<th style="text-align:left">3、打包dubbo-monitor-simplemvn clean package -Dmaven.test.skip=true</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">4、解压 tar.gz 文件，并运行start.bat</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="52"><img src="https://uploader.shimo.im/f/3VuJjpqB1NQs3dTZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<table>
<thead>
<tr>
<th style="text-align:left">如果缺少servlet-api，自行导入servlet-api再访问监控中心</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">5、启动访问8080</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="53"><img src="https://uploader.shimo.im/f/8yKt4JScy58YqdVP.png!thumbnail" alt="图片" loading="lazy"></figure>
<p><em>2、监控中心配置</em></p>
<table>
<thead>
<tr>
<th>所有服务配置连接监控中心，进行监控统计    <!-- 监控中心协议，如果为protocol="registry"，表示从注册中心发现监控中心地址，否则直连监控中心 -->  	<a href="dubbo:monitor%C2%A0protocol=%22registry%22">dubbo:monitor protocol=&quot;registry&quot;</a>&lt;/dubbo:monitor&gt;</th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>Simple Monitor 挂掉不会影响到 Consumer 和 Provider 之间的调用，所以用于生产环境不会有风险。</p>
<p>Simple Monitor 采用磁盘存储统计信息，请注意安装机器的磁盘限制，如果要集群，建议用mount共享磁盘。</p>
<h2 id="6-整合springboot">6、整合SpringBoot</h2>
<p>1）引入<strong>spring-boot-starter以及dubbo和curator的依赖</strong></p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt;
    &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;0.2.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>注意starter版本适配：<br>
<img src="https://uploader.shimo.im/f/d2JLjRxIZZsumBaC.png!thumbnail" alt="图片" loading="lazy"></p>
<p>2）配置application.properties</p>
<p><em>提供者配置：</em></p>
<pre><code>dubbo.application.name=gmall-user
dubbo.registry.protocol=zookeeper
dubbo.registry.address=192.168.67.159:2181
dubbo.scan.base-package=com.atguigu.gmall
dubbo.protocol.name=dubbo
dubbo.protocol.port=20880
dubbo.monitor.protocol=registry
## application.name就是服务名，不能跟别的dubbo提供端重复
## registry.protocol  是指定注册中心协议
## registry.address 是注册中心的地址加端口号
## protocol.name 是分布式固定是dubbo,不要改。
## base-package  注解方式要扫描的包
</code></pre>
<p><em>消费者配置：</em></p>
<pre><code>server.port=8081

dubbo.application.name=gmall-order-web
dubbo.registry.protocol=zookeeper
dubbo.registry.address=192.168.67.159:2181
dubbo.scan.base-package=com.atguigu.gmall
dubbo.protocol.name=dubbo
dubbo.monitor.protocol=registry
</code></pre>
<p>3、dubbo注解<br>
@Service、@Reference</p>
<p><strong>【如果没有在配置中写dubbo.scan.base-package,还需要在启动类使用@EnableDubbo注解】</strong></p>
<p>消费者：</p>
<pre><code>@Reference
UserService userService;
</code></pre>
<p>服务提供者：</p>
<pre><code>@com.alibaba.dubbo.config.annotation.Service // 暴露服务
@Service
public class UserServiceImpl implements UserService {
</code></pre>
<h1 id="二-dubbo配置">二、dubbo配置</h1>
<h2 id="1-配置原则">1、配置原则</h2>
<figure data-type="image" tabindex="54"><img src="https://uploader.shimo.im/f/B1hW7n2x1bYU1d7w.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>JVM 启动 -D 参数优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。</p>
<p>XML 次之，如果在 XML 中有配置，则 dubbo.properties 中的相应配置项无效。</p>
<p>Properties 最后，相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。</p>
<h2 id="2-重试次数">2、重试次数</h2>
<p>失败自动切换，当出现失败，重试其它服务器，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。</p>
<p>重试次数配置如下：</p>
<pre><code>&lt;dubbo:service retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference&gt;
    &lt;dubbo:method name=&quot;findFoo&quot; retries=&quot;2&quot; /&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<blockquote>
<p>幂等操作（执行多次和执行一次效果相同：查询、删除、修改）可设置重试次数，非幂等操作（执行多次和执行一次效果不同：新增）不宜设置重试次数</p>
</blockquote>
<h2 id="3-超时时间">3、超时时间</h2>
<p>由于网络或服务端不可靠，会导致调用出现一种不确定的中间状态（超时）。为了避免超时导致客户端资源（线程）挂起耗尽，必须设置超时时间。</p>
<blockquote>
<p>服务消费方引用服务提供方时，可能有雨网络等原因，服务提供方要执行一个方法可能有很长时间，如果很长时间都没有返回，导致大量线程阻塞，可能会引起性能下降，为了解决这个问题，可以指定超时时间，只要这个方法在指定时间内没有返回，就立即终止，不让大量线程阻塞。设置单位 ms</p>
</blockquote>
<h3 id="1-dubbo消费端">1、Dubbo消费端</h3>
<p>全局超时配置</p>
<pre><code>&lt;dubbo:consumer timeout=&quot;5000&quot; /&gt;
</code></pre>
<p>指定接口以及特定方法超时配置</p>
<pre><code>&lt;dubbo:reference interface=&quot;com.foo.BarService&quot; timeout=&quot;2000&quot;&gt;
    &lt;dubbo:method name=&quot;sayHello&quot; timeout=&quot;3000&quot; /&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<h3 id="2-dubbo服务端">2、Dubbo服务端</h3>
<p>全局超时配置</p>
<pre><code>&lt;dubbo:provider timeout=&quot;5000&quot; /&gt;
</code></pre>
<p>指定接口以及特定方法超时配置</p>
<pre><code>&lt;dubbo:provider interface=&quot;com.foo.BarService&quot; timeout=&quot;2000&quot;&gt;
    &lt;dubbo:method name=&quot;sayHello&quot; timeout=&quot;3000&quot; /&gt;
&lt;/dubbo:provider&gt;
</code></pre>
<h3 id="3-配置原则">3、配置原则</h3>
<p>dubbo推荐在Provider上尽量多配置Consumer端属性：</p>
<p>1、作服务的提供者，比服务使用方更清楚服务性能参数，如调用的超时时间，合理的重试次数，等等</p>
<p>2、在Provider配置后，Consumer不配置则会使用Provider的配置值，即Provider配置可以作为Consumer的缺省值。否则，Consumer会使用Consumer端的全局设置，这对于Provider不可控的，并且往往是不合理的</p>
<p>配置的覆盖规则：</p>
<ol>
<li>
<p>方法级别配置优于接口级别，即小Scope优先</p>
</li>
<li>
<p>Consumer端配置 优于 Provider配置 优于 全局配置，</p>
</li>
</ol>
<p>3) 最后是Dubbo Hard Code的配置值（见配置文档）</p>
<figure data-type="image" tabindex="55"><img src="https://uploader.shimo.im/f/5xoy9sunaRc44qdE.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="4-版本号">4、版本号</h2>
<p>当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。</p>
<p>可以按照以下的步骤进行版本迁移：</p>
<p>在低压力时间段，先升级一半提供者为新版本</p>
<p>再将所有消费者升级为新版本</p>
<p>然后将剩下的一半提供者升级为新版本</p>
<p>老版本服务提供者配置：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; version=&quot;1.0.0&quot; /&gt;
</code></pre>
<p>新版本服务提供者配置：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; version=&quot;2.0.0&quot; /&gt;
</code></pre>
<p>老版本服务消费者配置：</p>
<pre><code>&lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;1.0.0&quot; /&gt;
</code></pre>
<p>新版本服务消费者配置：</p>
<pre><code>&lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;2.0.0&quot; /&gt;
</code></pre>
<p>如果不需要区分版本，可以按照以下的方式配置：</p>
<pre><code>&lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;*&quot; /&gt;
</code></pre>
<h2 id="5-启动时检查">5、启动时检查</h2>
<p>Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check=&quot;true&quot;。</p>
<p>可以通过 check=&quot;false&quot; 关闭检查，比如，测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动。</p>
<p>另外，如果你的 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请关闭 check，否则服务临时不可用时，会抛出异常，拿到 null 引用，如果 check=&quot;false&quot;，总是会返回引用，当服务恢复时，能自动连上。</p>
<h3 id="示例">示例</h3>
<p><strong>通过 spring 配置文件</strong></p>
<p>关闭某个服务的启动时检查 (没有提供者时报错)：如果启动时没有提供者可以成功启动，但调用时因没有提供者调用失败会抛出异常</p>
<pre><code>&lt;dubbo:reference interface=&quot;com.foo.BarService&quot; check=&quot;false&quot; /&gt;
</code></pre>
<p>配置当前消费者的统一规则，所有的服务启动时都不检查：</p>
<pre><code>&lt;dubbo:consumer check=&quot;false&quot; /&gt;
</code></pre>
<p>关闭注册中心启动时检查 (注册订阅失败时报错)：</p>
<pre><code>&lt;dubbo:registry check=&quot;false&quot; /&gt;
</code></pre>
<p><strong>通过 dubbo.properties</strong></p>
<pre><code>dubbo.reference.com.foo.BarService.check=false
dubbo.reference.check=false
dubbo.consumer.check=false
dubbo.registry.check=false
</code></pre>
<h2 id="6-多版本">6、多版本</h2>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/multi-versions.html">http://dubbo.apache.org/zh-cn/docs/user/demos/multi-versions.html</a></p>
<blockquote>
<p>使用场景：某一个接口功能出现了不兼容的升级，先让一部分人使用新功能，另外一部分人还是先用旧版本，如果新功能版本都稳定了，再把所有老版本替换成新版本。</p>
</blockquote>
<p>服务提供方提供新旧两个版本供消费者使用</p>
<pre><code>&lt;!-- 4.暴露服务 ref：指向服务的真正实现对象--&gt;
&lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl01&quot; version=&quot;1.0.0&quot;/&gt;
&lt;!-- 服务的实现  --&gt;
&lt;bean id=&quot;userServiceImpl01&quot; class=&quot;com.atguigu.gmall.service.impl.UserServiceImpl&quot; /&gt;
&lt;!-- 连接监控中心 --&gt;
&lt;dubbo:monitor protocol=&quot;registry&quot;&gt;&lt;/dubbo:monitor&gt;
&lt;!-- 检测多版本 --&gt;
&lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl02&quot; version=&quot;2.0.0&quot;/&gt;
&lt;bean id=&quot;userServiceImpl02&quot; class=&quot;com.atguigu.gmall.service.impl.UserServiceImpl2&quot; /&gt;
</code></pre>
<p>服务消费方可选择哪一个版本</p>
<pre><code>&lt;!-- 3.声明需要调用的远程服务的接口 --&gt;
&lt;dubbo:reference interface=&quot;com.atguigu.gmall.service.UserService&quot; id=&quot;userService&quot; check=&quot;false&quot; version=&quot;2.0.0&quot;/&gt;
</code></pre>
<blockquote>
<p>由此实现灰度发布。</p>
</blockquote>
<h2 id="7-本地存根">7、本地存根</h2>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html">http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html</a></p>
<p>远程服务后，客户端通常只剩下接口，而实现全在服务器端，但提供方有些时候想在客户端也执行部分逻辑，比如：做 ThreadLocal 缓存，提前验证参数，调用失败后伪造容错数据等等，此时就需要在 API 中带上 Stub，客户端生成 Proxy 实例，会把 Proxy 通过构造函数传给 Stub <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fn1">[1]</a>，然后把 Stub 暴露给用户，Stub 可以决定要不要去调 Proxy。</p>
<figure data-type="image" tabindex="56"><img src="https://uploader.shimo.im/f/fCMOKYxIU74ZSiof.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在 spring 配置文件中按以下方式配置：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; stub=&quot;true&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:service interface=&quot;com.foo.BarService&quot; stub=&quot;com.foo.BarServiceStub&quot; /&gt;
</code></pre>
<p>提供 Stub 的实现 <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fn2">[2]</a>：</p>
<pre><code>package com.foo;
public class BarServiceStub implements BarService {
    private final BarService barService;
    
    // 构造函数传入真正的远程代理对象
    public BarServiceStub(BarService barService){
        this.barService = barService;
    }
 
    public String sayHello(String name) {
        // 此代码在客户端执行, 你可以在客户端做ThreadLocal本地缓存，或预先验证参数是否合法，等等
        try {
            return barService.sayHello(name);
        } catch (Exception e) {
            // 你可以容错，可以做任何AOP拦截事项
            return &quot;容错数据&quot;;
        }
    }
}
</code></pre>
<p>Stub 必须有可传入 Proxy 的构造函数。 <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fnref1">↩︎</a></p>
<ol>
<li>在 interface 旁边放一个 Stub 实现，它实现 BarService 接口，并有一个传入远程 BarService 实例的构造函数 <a href="http://dubbo.apache.org/zh-cn/docs/user/demos/local-stub.html#fnref2">↩︎</a></li>
</ol>
<h2 id="8-springboot-与-dubbo-整合的三种方式">8、Springboot 与 dubbo 整合的三种方式</h2>
<p><strong>（1） application.properties</strong></p>
<p>导入 dubb-starter，在 application.properties 中配置属性，使用 @Service 暴露服务；使用 @Reference 引用服务</p>
<p>（注意 @EnableDubbo 开启基于注解的 dubbo 或在 properties 文件中包扫描）</p>
<p><strong>（2）保留 dubbo xml配置文件</strong></p>
<p>导入 dubb-starter，使用 @ImportResource 导入配置文件即可（不再使用 @EnableDubbo 注解，转而使用 @ImportResource(locations=&quot;classpath:provider.xml&quot;)</p>
<p>暴露 Service 也不再使用 @Service 了，因为 xml 中已经设置了暴露服务）</p>
<p><strong>（3）使用注解 API 方式</strong></p>
<p>将每一个组件手动创建到容器中，让 dubbo 来扫描其他的组件</p>
<pre><code>  @EnableDubbo(scanBasePackages=&quot;com.atguigu.gmall&quot;)
</code></pre>
<pre><code>package com.atguigu.gmall.config;

import com.alibaba.dubbo.config.*;
import com.atguigu.gmall.service.UserService;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.ArrayList;
import java.util.List;

@Configuration
public class MyDubboConfig {

//        &lt;dubbo:application name=&quot;boot-user-service-provider&quot;  /&gt;
    @Bean
    public ApplicationConfig applicationConfig(){
        ApplicationConfig config = new ApplicationConfig();
        config.setName(&quot;boot-user-service-provider&quot;);
        return config;
    }

    // &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;
    @Bean
    public RegistryConfig registryConfig(){
        System.out.println(&quot;--------&quot;);
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol(&quot;zookeeper&quot;);
        registryConfig.setAddress(&quot;127.0.0.1:2181&quot;);
        return registryConfig;
    }

    //&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20882&quot; /&gt;
    @Bean
    public ProtocolConfig protocolConfig(){
        ProtocolConfig config = new ProtocolConfig();
        config.setName(&quot;dubbo&quot;);
        config.setPort(20882);
        return config;
    }

    //    &lt;dubbo:service interface=&quot;com.atguigu.gmall.service.UserService&quot; ref=&quot;userServiceImpl01&quot;&gt;
    //        &lt;dubbo:method name=&quot;getUserAddressList&quot; timeout=&quot;1000&quot;&gt;&lt;/dubbo:method&gt;
    //    &lt;/dubbo:service&gt;
    @Bean
    public ServiceConfig&lt;UserService&gt; serviceConfig(UserService userService){
        ServiceConfig&lt;UserService&gt; config = new ServiceConfig&lt;&gt;();
        config.setInterface(UserService.class);
        config.setRef(userService);

        // 配置每一个 method 信息
        MethodConfig methodConfig = new MethodConfig();
        methodConfig.setName(&quot;getUserAddressList&quot;);
        methodConfig.setTimeout(1000);

        // 将 method 的设置关联到 servie 中
        List&lt;MethodConfig&gt; methods = new ArrayList&lt;&gt;();
        methods.add(methodConfig);
        config.setMethods(methods);

        return config;
    }

}
</code></pre>
<h1 id="三-高可用">三、高可用</h1>
<h2 id="1-zookeeper宕机与dubbo直连">1、zookeeper宕机与dubbo直连</h2>
<p>现象：zookeeper注册中心（zkServer.cmd）宕机，还可以消费dubbo暴露的服务。</p>
<p>原因：</p>
<p>健壮性</p>
<ul>
<li>监控中心宕掉不影响使用，只是丢失部分采样数据</li>
<li>数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务</li>
<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台</li>
<li><strong>注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯</strong></li>
<li>服务提供者无状态，任意一台宕掉后，不影响使用</li>
<li>服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复</li>
</ul>
<p><strong>高可用：通过设计，减少系统不能提供服务的时间；</strong></p>
<p><strong>dubbo 直连（绕过注册中心）</strong></p>
<pre><code>@Reference(url = &quot;127.0.0.1:20882&quot;)
UserService userService;
</code></pre>
<h2 id="2-集群下dubbo负载均衡配置">2、集群下dubbo负载均衡配置</h2>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/loadbalance.html">http://dubbo.apache.org/zh-cn/docs/user/demos/loadbalance.html</a></p>
<p>在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。</p>
<h3 id="负载均衡策略">负载均衡策略</h3>
<p><strong>Random LoadBalance</strong></p>
<p>随机，按权重设置随机概率。</p>
<p>在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。</p>
<figure data-type="image" tabindex="57"><img src="https://uploader.shimo.im/f/t9CCH4EHEeoW2iry.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>基于权重的随机负载均衡机制：orderService 想要调用 userService，userService 分别在 1、2、3 台机器内，分别为每一台机器的服务设置权重为 100、200、50，总权重 350，那么对于 1 号机器来说，它的概率就是 100/350 = 2/7，在负载均衡的情况下，大量请求过来，大约有 2/7 的请求会来到 1 号机器。第一次请求来调用的是 1 号机器，第二次来有可能还调用 1 号机器，但总体上，按照大量请求概率分布来看，1 号机器会占 2/7 的概率。</p>
</blockquote>
<p><strong>RoundRobin LoadBalance</strong></p>
<p>轮循，按公约后的权重设置轮循比率。</p>
<p>存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</p>
<figure data-type="image" tabindex="58"><img src="https://uploader.shimo.im/f/fnw0VbVMqhIoKq6S.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>轮询负载均衡机制：orderService 想要调用 userService，第一个请求过来先用 1 号 userService 服务，第二个请求过来使用 2 号 userService 服务，下一个请求过来使用 3 号userService 服务，再下一次 1 号，再下一次 2 号...... 依次轮询。<br>
基于权重的轮询负载均衡机制：为每个服务设置权重，3 台服务器的权重分别为 2/7、4/7、1/7，按照轮询机制，第一个请求到来使用 1 号服务器，第二个请求使用 2 号服务器，第三个请求使用 3 号服务器，第四个请求使用 1 号服务器，第五个请求使用 2 号服务器，第六个请求本应使用 3 号服务器，<strong>但是</strong>，由于 3 号服务器的权重是 1/7（如果有 7 个请求，则 7 个之中的 1 个使用 3 号服务器），已经有第三个请求使用了 3 号服务器，第一个、第四个请求已经使用了 两次 1 号服务器，所以第六个请求只能使用 2 号服务器，同理，第七个请求也使用 2 号服务器。<br>
<strong>LeastActive LoadBalance</strong></p>
</blockquote>
<p>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。</p>
<p>使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</p>
<figure data-type="image" tabindex="59"><img src="https://uploader.shimo.im/f/S8G9zCwCrP81SVr3.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>最少活跃数：orderService 要调用 userService，在确定要使用几号 userService前，根据 “每一个服务器统计的上一次的调用时间”：三台服务器上一次请求的处理时间分别为 100ms、1000ms、300ms，说明 1 号服务器处理最快，于是此次请求会来到 1 号服务器。</p>
</blockquote>
<p><strong>ConsistentHash LoadBalance</strong></p>
<p>一致性 Hash，相同参数的请求总是发到同一提供者。</p>
<p>当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。算法参见：<a href="http://en.wikipedia.org/wiki/Consistent_hashing">http://en.wikipedia.org/wiki/Consistent_hashing</a></p>
<p>缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt;</p>
<p>缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt;</p>
<figure data-type="image" tabindex="60"><img src="https://uploader.shimo.im/f/TKBZTSuulaQxa01m.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>一致性 hash：orderService 想要调用 userService，都是调用的同一个 getUser 方法，将参数 hash 后的不同值分不到不同的服务器上。</p>
</blockquote>
<h3 id="负载均衡配置">负载均衡配置</h3>
<p>服务端服务级别，暴露服务时</p>
<pre><code>&lt;dubbo:service interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;
</code></pre>
<p>客户端服务级别，消费时</p>
<pre><code>&lt;dubbo:reference interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;
</code></pre>
<p>服务端方法级别</p>
<pre><code>&lt;dubbo:service interface=&quot;...&quot;&gt;
    &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt;
&lt;/dubbo:service&gt;
</code></pre>
<p>客户端方法级别</p>
<pre><code>&lt;dubbo:reference interface=&quot;...&quot;&gt;
    &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<h2 id="3-整合hystrix服务熔断与降级处理">3、整合hystrix，服务熔断与降级处理</h2>
<h3 id="1-服务降级">1、服务降级</h3>
<p><strong>什么是服务降级？</strong></p>
<p><strong>当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。</strong></p>
<p>可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。</p>
<p>向注册中心写入动态配置覆盖规则：</p>
<pre><code>RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();
Registry registry = registryFactory.getRegistry(URL.valueOf(&quot;zookeeper://10.20.153.10:2181&quot;));
registry.register(URL.valueOf(&quot;override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null&quot;));
</code></pre>
<p>其中：</p>
<ul>
<li>mock=force:return+null 表示消费方对该服务的方法调用都<strong>直接返回 null 值，不发起远程调用</strong>。用来屏蔽不重要服务不可用时对调用方的影响。</li>
<li>还可以改为 mock=fail:return+null 表示消费方对该服务的方法<strong>调用在失败后，再返回 null 值</strong>，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。</li>
</ul>
<h3 id="2-集群容错">2、集群容错</h3>
<p>在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。</p>
<p><strong>集群容错模式</strong></p>
<p><strong>Failover Cluster</strong></p>
<p>失败自动切换，当<strong>出现失败，重试其它服务器</strong>。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。</p>
<blockquote>
<p>A 服务调用 B 服务，B 服务超时后，配置一个重试次数，可以重新切换到能提供 B服务的其他机器。</p>
</blockquote>
<p>重试次数配置如下：</p>
<pre><code>&lt;dubbo:service retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference retries=&quot;2&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference&gt;
    &lt;dubbo:method name=&quot;findFoo&quot; retries=&quot;2&quot; /&gt;
&lt;/dubbo:reference&gt;
</code></pre>
<p><strong>Failfast Cluster</strong></p>
<p>快速失败，只发起一次调用，<strong>失败立即报错</strong>。通常用于非幂等性的写操作，比如新增记录。</p>
<blockquote>
<p>A 服务调用 B服务，只发起一次调用，失败立即报错。</p>
</blockquote>
<p><strong>Failsafe Cluster</strong></p>
<p>失败安全，出现异常时，直接<strong>忽略</strong>。通常用于写入审计日志等操作。</p>
<p><strong>Failback Cluster</strong></p>
<p><strong>失败自动恢复，后台记录失败请求，定时重发</strong>。通常用于消息通知操作。</p>
<blockquote>
<p>A 服务调用 B 服务，失败后可以后台记录一下，隔一段时间定时再调用一次。适用于：一定要成功的服务调用</p>
</blockquote>
<p><strong>Forking Cluster</strong></p>
<p>并行调用多个服务器，只要一个成功即返回。通常用于<strong>实时性要求较高</strong>的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。</p>
<blockquote>
<p>A 服务调用 B服务，有可能会失败，能提供 B 服务的在三台服务器上，同时给这三台服务器都发起请求，只要其中一个服务器响应成功就可以使用。</p>
</blockquote>
<p><strong>Broadcast Cluster</strong></p>
<p>广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。</p>
<blockquote>
<p>A 服务调用 B服务，B 服务的提供者有四台机器，每一台机器都调用一遍，只要有任意一台出现错误，都认为这次调用是失败的。</p>
</blockquote>
<p><strong>集群模式配置</strong></p>
<p>按照以下示例在服务提供方和消费方配置集群模式</p>
<pre><code>&lt;dubbo:service cluster=&quot;failsafe&quot; /&gt;
</code></pre>
<p>或</p>
<pre><code>&lt;dubbo:reference cluster=&quot;failsafe&quot; /&gt;
</code></pre>
<h3 id="3-整合hystrix">3、整合hystrix</h3>
<p>Hystrix 旨在通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能</p>
<p><em>1、配置spring-cloud-starter-netflix-hystrix</em></p>
<p>spring boot官方提供了对hystrix的集成，直接在pom.xml里加入依赖：</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
  &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
  &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>然后在Application类上增加@EnableHystrix来启用hystrix starter：</p>
<pre><code>@SpringBootApplication
@EnableHystrix
public class ProviderApplication {
</code></pre>
<p><em>2、配置Provider端</em></p>
<p>在Dubbo的Provider上增加@HystrixCommand配置，这样子调用就会经过Hystrix代理。</p>
<pre><code>@Service(version = &quot;1.0.0&quot;)
public class HelloServiceImpl implements HelloService {
    @HystrixCommand(commandProperties = {
     @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;, value = &quot;10&quot;),
     @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;) })
    @Override
    public String sayHello(String name) {
        // System.out.println(&quot;async provider received: &quot; + name);
        // return &quot;annotation: hello, &quot; + name;
        throw new RuntimeException(&quot;Exception to show hystrix enabled.&quot;);
    }
}
</code></pre>
<p><em>3、配置Consumer端</em></p>
<p>对于Consumer端，则可以增加一层method调用，并在method上配置@HystrixCommand。当调用出错时，会走到fallbackMethod = &quot;reliable&quot;的调用里。</p>
<pre><code>    @Reference(version = &quot;1.0.0&quot;)
    private HelloService demoService;
    @HystrixCommand(fallbackMethod = &quot;reliable&quot;)
    public String doSayHello(String name) {
        return demoService.sayHello(name);
    }
    public String reliable(String name) {
        return &quot;hystrix fallback value&quot;;
    }
</code></pre>
<h1 id="四-dubbo原理">四、dubbo原理</h1>
<h2 id="1-rpc原理">1、RPC原理</h2>
<figure data-type="image" tabindex="61"><img src="https://uploader.shimo.im/f/VT5w26Fy18AWw61q.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>一次完整的RPC调用流程（同步调用，异步另说）如下：</p>
<p>**1）服务消费方（client）调用以本地调用方式调用服务； **</p>
<p>2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；</p>
<p>3）client stub找到服务地址，并将消息发送到服务端；</p>
<p>4）server stub收到消息后进行解码；</p>
<p>5）server stub根据解码结果调用本地的服务；</p>
<p>6）本地服务执行并将结果返回给server stub；</p>
<p>7）server stub将返回结果打包成消息并发送至消费方；</p>
<p>8）client stub接收到消息，并进行解码；</p>
<p><strong>9）服务消费方得到最终结果。</strong></p>
<p>RPC框架的目标就是要2~8这些步骤都封装起来，这些细节对用户来说是透明的，不可见的。</p>
<h2 id="2-netty通信原理">2、netty通信原理</h2>
<p>Netty是一个异步事件驱动的网络应用程序框架， 用于快速开发可维护的高性能协议服务器和客户端。它极大地简化并简化了TCP和UDP套接字服务器等网络编程。</p>
<p>BIO：(Blocking IO)</p>
<figure data-type="image" tabindex="62"><img src="https://uploader.shimo.im/f/2W5W02pWhRc1tfWH.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>BIO：阻塞式 IO。每一个请求进来，开一个 Socket 开一个线程来处理数据，读取到数据后业务逻辑操作完成后返回。服务器收到很多请求，同时操作，在这个业务逻辑完成前这个线程不能得到释放，服务器就不能同时处理大量请求，因为有大量线程在阻塞，等待业务逻辑的完成。</p>
</blockquote>
<p>NIO (Non-Blocking IO)</p>
<figure data-type="image" tabindex="63"><img src="https://uploader.shimo.im/f/i2Hhf1AEfLE0e9rK.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>Channel：通道，通道里面有 Buffer 用来进行数据传输。<br>
一个 Selector 注册进了很多通道，每个请求使用通道进行数据传递通信，Selector 通过监听多个通道，当发现某一个通道里的数据准备好了，Selector 执行相应操作。</p>
</blockquote>
<p>Selector 一般称 为<strong>选择器</strong> ，也可以翻译为 <strong>多路复用器，</strong></p>
<p>Connect（连接就绪）、Accept（接受就绪）、Read（读就绪）、Write（写就绪）</p>
<p>Netty基本原理：</p>
<figure data-type="image" tabindex="64"><img src="https://uploader.shimo.im/f/M16PnkZ6fGY7YG8J.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>Netty 服务器启动（ServerBootstrap.bind），绑定监听某一个端口，比如 dubbo 的20880端口，这样所有给这个端口发的数据 netty 就能收到，启动后初始化服务器的通道（NioServerSockerChannel），注册到 selector，selector 负责监听 accept 事件（当通道接收准备就绪后，处理通道里的信息），netty 与客户端建立连接， 生成 NioSocketChannel，把这个  通道注册到 Selector 里面，这个 selector 监听 read、write 事件（通道中数据读、写准备就绪），读写准备就绪后来处理这个事件，抛给用户队列，netty 把这个任务队列执行完</p>
</blockquote>
<h2 id="3-dubbo原理">3、dubbo原理</h2>
<h3 id="1-dubbo原理-框架设计">1、dubbo原理	-框架设计</h3>
<figure data-type="image" tabindex="65"><img src="https://uploader.shimo.im/f/mktdQ0QVP0s1eieu.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>dubbo 框架整体分层：</p>
<ol>
<li>Business 业务逻辑层：<br>
1.1 Service服务层：面向接口编程。接口、实现。想要远程调用只需要调用接口的方法，就自动调实现了。 对于用户编程，只需要关心这一层就结束了。<br>
2.RPC层：完成远程过程调用：<br>
2.1 Config 配置层，封装配置文件里解析出来的信息 ReferenceConfig、ServiceConfig；<br>
2.2 Proxy 服务代理层：利用代理的方式，生成客户端代理对象、服务端代理对象，代理对象互相调用方法；<br>
2.2 Registry 注册中心层：完成服务的发现和注册；很多服务要注册到注册中心，消费者要从注册中心订阅所需要的服务来调用；<br>
2.3 Cluster 路由层：负载均衡。invoker 调用者要调用很多的服务，服务在很多机器上跑，需要负载均衡；<br>
2.4 Monitor 监控层：每一次的调用信息都会向监控层发送一些数据；<br>
2.5 Protocol 远程调用层：封装 RPC 调用，RPC 调用核心的三个：Invoker、Protocol、Exporter；</li>
<li>Remoting 层：远程要调用就要跟 A、B两个服务器架起通信管道，通信以及在通信间传递数据<br>
3.1 Exchange 信息交换层：创建一个客户端 ExchangeClient、服务端 ExchangeServer<br>
两端架起网架进行数据的互联互通；<br>
3.2 Transport 传输层：真正传输数据用 Transporter 来封装传输的，Transporter 底层就是 netty 框架，netty 框架就是在这一层封装；<br>
3.3 Serialize 序列化层：序列化</li>
</ol>
</blockquote>
<ul>
<li>config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类</li>
<li>proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory</li>
<li>registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService</li>
<li>cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance</li>
<li>monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService</li>
<li>protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter</li>
<li>exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer</li>
<li>transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec</li>
<li>serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool</li>
</ul>
<h3 id="2-dubbo原理-启动解析-加载配置信息">2、dubbo原理	-启动解析、加载配置信息</h3>
<figure data-type="image" tabindex="66"><img src="https://uploader.shimo.im/f/iFVXso8DLkEuO0r6.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="3-dubbo原理-服务暴露">3、dubbo原理	-服务暴露</h3>
<figure data-type="image" tabindex="67"><img src="https://uploader.shimo.im/f/2ocFX7K06DopwxGs.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="4-dubbo原理-服务引用">4、dubbo原理	-服务引用</h3>
<figure data-type="image" tabindex="68"><img src="https://uploader.shimo.im/f/DxTlKd889QMR0jp1.png!thumbnail" alt="图片" loading="lazy"></figure>
<h3 id="5-dubbo原理-服务调用">5、dubbo原理	-服务调用</h3>
<figure data-type="image" tabindex="69"><img src="https://uploader.shimo.im/f/rugf4MklrfIiNoOW.png!thumbnail" alt="图片" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[记一个面试题 —— 实现一个读写锁]]></title>
        <id>https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-shi-xian-yi-ge-du-xie-suo/</id>
        <link href="https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-shi-xian-yi-ge-du-xie-suo/">
        </link>
        <updated>2020-04-10T05:57:59.000Z</updated>
        <content type="html"><![CDATA[<h1 id="用共享对象实现写优先的读者写者锁">用共享对象实现写优先的读者写者锁</h1>
<p>首先，我们实现一个读者/写者锁。类似于一个普通的互斥锁，一个读者/写者锁(RWLock)保护共享数据。然而，它会做如下的优化。为了最大化性能，一个 RWLock 允许多个“读者”线程同时访问共享数据。任意数量的线程可以在同一时间安全地读共享数据，只要没有线程在修改数据。然而，任意时刻，至多只能有 1 个写者线程可以持有 RWLock（读者线程只能读共享数据，写者线程既可以写也可以读共享数据）。当一个写者线程持有 RWLock，它可以安全地修改数据，因为锁保证了不会有其他的线程同时持有该锁。读者写者锁常常被用于数据库，它们被用于支持对数据库的更快的搜索查询，同时也支持不太频繁的更新。另一个常见的应用是在操作系统内核中，核心的数据结构常常被许多线程读但更新却不太频繁。为了将我们的互斥锁一般化为一个读者/写者锁，我们实现了一个新类型的共享对象，RWLock，来保护对共享数据的访问。RWLock 采用了我们标准化的同步构建模块：互斥锁和条件变量来实现。<br>
一个线程想要（原子地）读共享数据，其过程如下：</p>
<pre><code>rwLock-&gt;startRead();
read shared data
rwLock-&gt;doneRead();
</code></pre>
<p>类似的，一个线程想要（原子地）写共享数据，其过程如下：</p>
<pre><code>rwLock-&gt;startWrite();
Read and write shared data
rwLock-&gt;doneWrite();
</code></pre>
<p>为了设计 RWLock 类，我们首先定义它的接口（如上面代码所示），和它的共享状态。这里，对象的行为可以通过正在读和<strong>正在写的线程的数量和等待读和等代写的线程的数量</strong>来刻画。所以，我们需要 4 个整数来追踪这些值。 代码 5.9 展示了 RWLock 类的成员和接口. 接下来，我们通过提出以下的问题来添加同步变量，“什么时候方法需要等待？”首先，我们添加一个互斥锁：保证当有线程在访问 RWLock 的方法的时候，其他访问 RWLock 的方法的线程必须等待。接下来，我们观察到 startRead 或 startWrite 可能需要等待，因此我们为每种情况添加了一个条件变量：readGo 和 writeGo.</p>
<pre><code>class RWLock{
    private:
        //Synchronization variables
        Lock lock;
        CV readGo;
        CV writeGo;

        // State variables
        int activeReaders;
        int activeWriters;
        int waitingReaders;
        int waitingWriters;
    public:
        RWLock();
        ~RWLock(){};
        void startRead();
        void doneRead();
        void startWrite();
        void doneWrite();
    private:
        bool readShouldWait();
        bool writeShouldWait();
} 
</code></pre>
<p>代码 5.9：  我们的读者/写者锁的接口和成员变量<br>
RWLock: doneRead 和 doneWrite 不需要等待（不包括获取互斥锁）。因此，这些方法不需要额外的条件变量。<br>
现在我们实现 RWLock。<br>
首先，我们先给每个方法添加上锁的获取和锁的释放。如下图所示：</p>
<pre><code>void RWLock :: startRead(){
    lock.acquire();

    lock.release();
}

void RWLock::doneRead(){
    lock.acquire();

    lock.release();
}
</code></pre>
<p>RWLock::startWrite 和 RWLock::doneWrite 也类似。</p>
<p>由于我们知道 startRead 和 startWrite 必须等待，因此我们可以在每个方法的中间写上while(…){wait();}的循环。然后，我们开始思考其中的细节，例如循环等待的判断条件。代码 5.10 展示了完整的解法。</p>
<pre><code>// Wait until no active or waiting writers,then proceed
void RWLock::startRead(){
    lock.acquire();
    waitingReaders++;
    while(readShouldWait()){
        readGo.Wait(&amp;lock);
    }
    waitingReaders--;
    activeReaders++;
    lock.release();
}

// Done reading.If no other active readers,a write may proceed.
void RWLock::doneRead(){
    lock.acquire();
    activeReaders--;
    if(activeReaders == 0 &amp;&amp; waitingWriters &gt; 0){
        writeGo.signal();
    }
    lock.release();
}

// Read waits if any active or waiting write(&quot;writers preferred&quot;).
bool RWLock::readShouldWait(){
    return (activeWriters &gt; 0 || waitingWriters &gt; 0);
}

// Wait until no active read or write then proceed;
void RWLock::startWrite(){
    lock.acquire();
    waitingWriterw++;
    while(writeShouldWait()){
        writeGo.Wait(&amp;lock);
    }
    waitingWriters--;
    activeWriters++;
    lock.release();
}

// Done writing. A waiting write or read may proceed.
void RWLock::doneWrite(){
    lock.acquire();
    activeWriters--;
    assert(activeWriters == 0);
    if(waitingWriters &gt; 0){
        writeGo.signal();
    }else{
        readGo.broadcast();
    }
    lock.release();
}

// Write waits for active read or write.
bool RWLock::writeShouldWait(){
    return(activeWriters &gt; 0 || activeReaders &gt; 0);
}
</code></pre>
<p>代码 5.10：  一个读者写者锁的实现</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis 持久化]]></title>
        <id>https://epitomm.github.io/post/redis-chi-jiu-hua/</id>
        <link href="https://epitomm.github.io/post/redis-chi-jiu-hua/">
        </link>
        <updated>2020-04-08T10:03:41.000Z</updated>
        <content type="html"><![CDATA[<h1 id="持久化简介">持久化简介</h1>
<h2 id="意外的断电">意外的断电</h2>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E6%96%AD%E7%94%B5.png" alt="图片" loading="lazy"></figure>
<h2 id="自动备份">“自动备份”</h2>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD.png" alt="图片" loading="lazy"></figure>
<h2 id="什么是持久化">什么是持久化</h2>
<p>利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化。</p>
<h2 id="为什么要进行持久化">为什么要进行持久化</h2>
<p>防止数据的意外丢失，确保数据安全性</p>
<h2 id="持久化过程保存什么">持久化过程保存什么</h2>
<ul>
<li>将当前数据状态进行保存，<strong>快照</strong>形式，存储数据结果，存储格式简单，关注点在<strong>数据</strong></li>
<li>将数据的操作过程进行保存，<strong>日志</strong>形式，存储操作过程，存储格式复杂，关注点在<strong>数据的操作过程</strong></li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/redis%E6%8C%81%E4%B9%85%E5%8C%96.png" alt="图片" loading="lazy"></figure>
<h1 id="rdb">RDB</h1>
<h2 id="rdb启动方式">RDB启动方式</h2>
<h2 id="谁什么时间干什么事情">谁，什么时间，干什么事情</h2>
<p>命令执行</p>
<ul>
<li>谁：redis操作者（用户）</li>
<li>什么时间：即时（随时进行）</li>
<li>干什么事情：保存数据</li>
</ul>
<h2 id="rdb启动方式-save指令">RDB启动方式 —— save指令</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>save 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>手动执行一次保存操作</p>
<p>redis-cli</p>
<pre><code>127.0.0.1:6379&gt; set name ssm
OK
127.0.0.1:6379&gt; save
OK
127.0.0.1:6379&gt; set age 20
OK
127.0.0.1:6379&gt; save
OK
127.0.0.1:6379&gt; 
</code></pre>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z data]# ll
total 4
-rw-r--r-- 1 root root 3918 Feb 25 21:23 6379.log
[root@iZ2ze4u2bufi0915gyi843Z data]# ll
total 8
-rw-r--r-- 1 root root 3969 Feb 25 21:24 6379.log
-rw-r--r-- 1 root root  107 Feb 25 21:24 dump.rdb
[root@iZ2ze4u2bufi0915gyi843Z data]# ll
total 8
-rw-r--r-- 1 root root 4020 Feb 25 21:24 6379.log
-rw-r--r-- 1 root root  114 Feb 25 21:24 dump.rdb
[root@iZ2ze4u2bufi0915gyi843Z data]# cat dump.rdb 
REDIS0009	redis-ver5.0.7
redis-bits󿿀򳨭e
              Uused-memx
</code></pre>
<h3 id="rdb启动方式-save指令相关配置">RDB启动方式 —— save指令相关配置</h3>
<ul>
<li>dbfilename dump.rdb
<ul>
<li>说明：设置本地数据库文件名，默认值为 dump.rdb</li>
<li>经验：通常设置为**dump-<strong><strong>端口号</strong></strong>.rdb **</li>
</ul>
</li>
<li>dir
<ul>
<li>说明：设置存储.rdb文件的路径</li>
<li>经验：通常设置成存储空间较大的目录中，目录名称**data **</li>
</ul>
</li>
<li>rdbcompression yes
<ul>
<li>说明：设置存储至本地数据库时是否<strong>压缩数据</strong>，默认为 yes，采用 LZF 压缩</li>
<li>经验：通常默认为开启状态，如果设置为no，可以节省 CPU 运行时间，但会使存储的文件变大（巨大）</li>
</ul>
</li>
<li>rdbchecksum yes
<ul>
<li>说明：设置是否进行RDB<strong>文件格式校验</strong>，该校验过程在写文件和读文件过程均进行</li>
<li>经验：通常默认为开启状态，如果设置为no，可以节约读写性过程约10%时间消耗，但是存储一定的数据损坏风险</li>
</ul>
</li>
</ul>
<h3 id="rdb启动方式-save指令工作原理">RDB启动方式 —— save指令工作原理</h3>
<p><img src="https://epitomm.github.io/post-images/Redis%E6%8C%87%E4%BB%A4save.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/Redis%E6%8C%87%E4%BB%A4save2.png" alt="图片" loading="lazy"></p>
<p><strong>注意：<strong>save指令的执行会</strong>阻塞</strong>当前Redis服务器，直到当前RDB过程完成为止，有可能会造成长时间阻塞，线上环境不建议使用。</p>
<h2 id="数据量过大单线程执行方式造成效率过低如何处理">数据量过大，单线程执行方式造成效率过低如何处理？</h2>
<h3 id="后台执行-bgsave">后台执行 （bgsave）</h3>
<ul>
<li>谁：redis操作者（用户）发起指令；redis服务器控制指令执行</li>
<li>什么时间：即时（发起）；合理的时间（执行）</li>
<li>干什么事情：保存数据</li>
</ul>
<h3 id="bgsave指令">bgsave指令</h3>
<ul>
<li>命令</li>
</ul>
<pre><code>bgsave 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>手动启动后台保存操作，但不是立即执行</p>
<h3 id="bgsave指令工作原理">bgsave指令工作原理</h3>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/bgsave.png" alt="图片" loading="lazy"></figure>
<p><strong>注意： <strong>bgsave命令是针对save阻塞问题做的优化。Redis内部所有涉及到RDB操作都采用bgsave的方式，save命令可以放弃使用</strong>。</strong></p>
<h3 id="bgsave指令相关配置">bgsave指令相关配置</h3>
<ul>
<li>dbfilename dump.rdb</li>
<li>dir</li>
<li>rdbcompression yes</li>
<li>rdbchecksum yes</li>
<li>stop-writes-on-bgsave-error yes
<ul>
<li>说明：后台存储过程中如果出现错误现象，是否停止保存操作</li>
<li>经验：通常默认为开启状态</li>
</ul>
</li>
</ul>
<h2 id="反复执行保存指令忘记了怎么办不知道数据产生了多少变化何时保存">反复执行保存指令，忘记了怎么办？不知道数据产生了多少变化，何时保存？</h2>
<h3 id="自动执行">自动执行</h3>
<ul>
<li>谁：redis服务器发起指令（基于条件）</li>
<li>什么时间：满足条件</li>
<li>干什么事情：保存数据</li>
</ul>
<h3 id="save配置">save配置</h3>
<ul>
<li>redis-6379.conf 内配置</li>
</ul>
<pre><code>save second changes 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>满足限定时间范围内key的变化数量达到指定数量即进行持久化</p>
<ul>
<li>参数
<ul>
<li>second：监控时间范围</li>
<li>changes：监控key的变化量</li>
</ul>
</li>
<li>位置
<ul>
<li>在conf文件中进行配置</li>
</ul>
</li>
<li>范例</li>
</ul>
<pre><code>save 900 1 
save 300 10 
save 60 10000
</code></pre>
<h3 id="save配置原理">save配置原理</h3>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/Redis%E6%8C%87%E4%BB%A4save3.png" alt="图片" loading="lazy"></figure>
<p>注意： save配置要根据实际业务情况进行设置，频度过高或过低都会出现性能问题，结果可能是灾难性的</p>
<p>save配置中对于second与changes设置通常具有互补对应关系，尽量不要设置成包含性关系</p>
<ul>
<li>save配置启动后执行的是bgsave操作</li>
</ul>
<h3 id="save配置相关配置">save配置相关配置</h3>
<ul>
<li>dbfilename dump.rdb</li>
<li>dir</li>
<li>rdbcompression yes</li>
<li>rdbchecksum yes</li>
</ul>
<h2 id="rdb三种启动方式对比">RDB三种启动方式对比</h2>
<table>
<thead>
<tr>
<th style="text-align:left">方式</th>
<th style="text-align:left">save指令</th>
<th style="text-align:left">bgsave指令（save配置）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读写</td>
<td style="text-align:left">同步</td>
<td style="text-align:left">异步</td>
</tr>
<tr>
<td style="text-align:left">阻塞客户端指令</td>
<td style="text-align:left">是</td>
<td style="text-align:left">否</td>
</tr>
<tr>
<td style="text-align:left">额外内存消耗</td>
<td style="text-align:left">否</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">启动新进程</td>
<td style="text-align:left">否</td>
<td style="text-align:left">是</td>
</tr>
</tbody>
</table>
<h2 id="rdb特殊启动形式">RDB特殊启动形式</h2>
<ul>
<li>全量复制</li>
</ul>
<p>在主从复制中详细讲解</p>
<ul>
<li>服务器运行过程中重启</li>
</ul>
<pre><code>debug reload 
</code></pre>
<ul>
<li>关闭服务器时指定保存数据</li>
</ul>
<pre><code>shutdown save 
</code></pre>
<p>默认情况下执行shutdown命令时，自动执行 bgsave(如果没有开启AOF持久化功能)</p>
<h2 id="rdb优点">RDB优点</h2>
<ul>
<li>RDB是一个紧凑压缩的<strong>二进制</strong>文件，**存储效率较高 **</li>
<li>RDB内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景</li>
<li>RDB<strong>恢复数据</strong>的<strong>速度</strong>要比AOF<strong>快</strong>很多</li>
<li>应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于<strong>灾难恢复</strong>。</li>
</ul>
<h2 id="rdb缺点">RDB缺点</h2>
<ul>
<li>RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性<strong>丢失数据</strong>（10点备份一次，11点备份一次，那么10点45的数据就丢失了）</li>
<li>bgsave指令每次运行要执行fork操作<strong>创建子进程</strong>，要**牺牲掉一些性能 **</li>
<li>Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现<strong>各版本</strong>服务之间数据格式<strong>无法兼容</strong>现象</li>
</ul>
<h1 id="aof">AOF</h1>
<h2 id="rdb存储的弊端">RDB存储的弊端</h2>
<ul>
<li>存储<strong>数据量较大</strong>，效率较低
<ul>
<li>基于<strong>快照</strong>思想，每次读写都是<strong>全部</strong>数据，当数据量巨大时，效率非常低</li>
</ul>
</li>
<li>大数据量下的**IO性能较低 **</li>
<li>基于fork创建<strong>子进程</strong>，<strong>内存</strong>产生额外<strong>消耗</strong></li>
<li>宕机带来的<strong>数据丢失</strong>风险 （快照是某个时间点的数据）</li>
</ul>
<h3 id="解决思路">解决思路</h3>
<ul>
<li>不写全数据，仅**记录部分数据 **</li>
<li>降低区分数据是否改变的难度，改记录数据为**记录操作过程 **</li>
<li>对所有操作均进行记录，<strong>排除丢失数据的风险</strong></li>
</ul>
<h2 id="aof概念">AOF概念</h2>
<ul>
<li>AOF(append only file)持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令达到恢复数据的目的。与RDB相比可以简单描述为改记录数据为记录数据产生的过程</li>
<li>AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式</li>
</ul>
<h2 id="aof写数据过程">AOF写数据过程</h2>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/AOF.png" alt="图片" loading="lazy"></figure>
<h3 id="aof写数据三种策略appendfsync">AOF写数据三种策略(****appendfsync)</h3>
<ul>
<li>always(每次）
<ul>
<li>每次写入操作均同步到AOF文件中，<strong>数据零误差</strong>，**性能较低 **，不建议使用。</li>
</ul>
</li>
<li>everysec（每秒）
<ul>
<li>每秒将缓冲区中的指令同步到AOF文件中，数据准确性较高，**性能较高 **，建议使用，也是默认配置</li>
<li>在系统突然宕机的情况下丢失1秒内的数据</li>
</ul>
</li>
<li>no（系统控制）
<ul>
<li>由操作系统控制每次同步到AOF文件的周期，整体过程<strong>不可控</strong></li>
</ul>
</li>
</ul>
<h2 id="aof功能开启">AOF功能开启</h2>
<ul>
<li>配置</li>
</ul>
<pre><code>appendonly yes|no 
</code></pre>
<ul>
<li>作用
<ul>
<li>是否开启AOF持久化功能，默认为不开启状态</li>
</ul>
</li>
<li>配置</li>
</ul>
<pre><code>appendfsync always|everysec|no 
</code></pre>
<ul>
<li>作用</li>
</ul>
<p>AOF写数据策略</p>
<h2 id="aof相关配置">AOF相关配置</h2>
<ul>
<li>配置</li>
</ul>
<pre><code>appendfilename filename 
</code></pre>
<ul>
<li>作用
<ul>
<li>AOF持久化文件名，默认文件名为appendonly.aof，建议配置为appendonly-端口号.aof</li>
</ul>
</li>
<li>配置</li>
</ul>
<pre><code>dir 
</code></pre>
<ul>
<li>作用
<ul>
<li>AOF持久化文件保存路径，与RDB持久化文件保持一致即可</li>
</ul>
</li>
</ul>
<h2 id="aof写数据遇到的问题">AOF写数据遇到的问题</h2>
<h3 id="如果连续执行如下指令该如何处理">如果连续执行如下指令该如何处理</h3>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/AOF%E4%BE%8B%E5%AD%90.png" alt="图片" loading="lazy"></figure>
<h3 id="aof重写">AOF重写</h3>
<p>随着命令不断写入AOF，<strong>文件会越来越大</strong>，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积。AOF文件重写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。简单说就是<strong>将对同一个数据的若干个条命令执行结果转化成最终结果数据对应的指令</strong>进行记录。</p>
<h3 id="aof重写作用">AOF重写作用</h3>
<ul>
<li>降低磁盘占用量，提高磁盘利用率</li>
<li>提高持久化效率，降低持久化写时间，提高IO性能</li>
<li>降低数据恢复用时，提高数据恢复效率</li>
</ul>
<h3 id="aof重写规则">AOF重写规则</h3>
<ul>
<li>进程内已超时的数据不再写入文件</li>
<li>忽略无效指令，重写时使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令
<ul>
<li>如del key1、 hdel key2、srem key3、set key4 111、set key4 222等</li>
</ul>
</li>
<li>对同一数据的多条写命令合并为一条命令
<ul>
<li>如lpush list1 a、lpush list1 b、 lpush list1 c 可以转化为：lpush list1 a b c。</li>
<li>为防止数据量过大造成客户端缓冲区溢出，对list、set、hash、zset等类型，每条指令最多写入64个元素</li>
</ul>
</li>
</ul>
<h3 id="aof重写方式">AOF重写方式</h3>
<ul>
<li>手动重写</li>
</ul>
<pre><code>bgrewriteaof 
</code></pre>
<ul>
<li>自动重写</li>
</ul>
<pre><code>auto-aof-rewrite-min-size size 
auto-aof-rewrite-percentage percentage
</code></pre>
<h3 id="aof手动重写-bgrewriteaof指令工作原理">AOF手动重写 —— bgrewriteaof指令工作原理</h3>
<p><img src="https://epitomm.github.io/post-images/bgsave%E6%8C%87%E4%BB%A4%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"><br>
<img src="https://epitomm.github.io/post-images/bgrewriteaof%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" alt="图片" loading="lazy"></p>
<h3 id="aof自动重写方式">AOF自动重写方式</h3>
<ul>
<li>自动重写触发条件设置</li>
</ul>
<pre><code>auto-aof-rewrite-min-size size 
auto-aof-rewrite-percentage percent 
</code></pre>
<ul>
<li>自动重写触发比对参数（ 运行指令info Persistence获取具体信息 ）</li>
</ul>
<pre><code>aof_current_size 
aof_base_size 
</code></pre>
<ul>
<li>自动重写触发条件</li>
</ul>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91%E9%87%8D%E5%86%99%E6%9D%A1%E4%BB%B6.png" alt="图片" loading="lazy"></figure>
<h3 id="aof重写流程">AOF重写流程</h3>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/AOF%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B1.png" alt="图片" loading="lazy"></figure>
<h3 id="aof重写流程-2">AOF重写流程</h3>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/AOF%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B2.png" alt="图片" loading="lazy"></figure>
<p>AOF缓冲区同步文件策略，由参数appendfsync控制</p>
<p>系统调用write和fsync说明：</p>
<ul>
<li>write操作会触发延迟写（delayed write）机制，Linux在内核提供页缓冲区用来提高硬盘IO性能。write操作在写入系统缓冲区后直接返回。同步硬盘操作依赖于系统调度机制，列如：缓冲区页空间写满或达到特定时间周期。同步文件之前，如果此时系统故障宕机，缓冲区内数据将丢失。</li>
<li>fsync针对单个文件操作（比如AOF文件），做强制硬盘同步，fsync将阻塞知道写入硬盘完成后返回，保证了数据持久化。</li>
</ul>
<p>除了write、fsync、Linx还提供了sync、fdatasync操作，具体API说明参见：</p>
<h1 id="rdb与aof区别">RDB与AOF区别</h1>
<table>
<thead>
<tr>
<th style="text-align:left">持久化方式</th>
<th style="text-align:left">RDB</th>
<th style="text-align:left">AOF</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">占用存储空间</td>
<td style="text-align:left">小（数据级：压缩）</td>
<td style="text-align:left">大（指令级：重写）</td>
</tr>
<tr>
<td style="text-align:left">存储速度</td>
<td style="text-align:left">慢</td>
<td style="text-align:left">快</td>
</tr>
<tr>
<td style="text-align:left">恢复速度</td>
<td style="text-align:left">快</td>
<td style="text-align:left">慢</td>
</tr>
<tr>
<td style="text-align:left">数据安全性</td>
<td style="text-align:left">会丢失数据</td>
<td style="text-align:left">依据策略决定</td>
</tr>
<tr>
<td style="text-align:left">资源消耗</td>
<td style="text-align:left">高 / 重量级</td>
<td style="text-align:left">低 / 轻量级</td>
</tr>
<tr>
<td style="text-align:left">启动优先级</td>
<td style="text-align:left">低</td>
<td style="text-align:left">高</td>
</tr>
</tbody>
</table>
<h3 id="rdb与aof的选择之惑">RDB与AOF的选择之惑</h3>
<ul>
<li>对<strong>数据非常敏感</strong>，建议使用默认的<strong>AOF</strong>持久化方案
<ul>
<li>AOF持久化策略使用everysecond，每秒钟fsync一次。该策略redis仍可以保持很好的处理性能，当出现问题时，最多丢失0-1秒内的数据。</li>
<li>注意：由于AOF文件存储体积较大，且恢复速度较慢</li>
</ul>
</li>
<li>数据呈现<strong>阶段有效性</strong>，建议使用<strong>RDB</strong>持久化方案
<ul>
<li>数据可以良好的做到阶段内无丢失（该阶段是开发者或运维人员手工维护的），且恢复速度较快，阶段点数据恢复通常采用RDB方案</li>
<li>注意：利用RDB实现紧凑的数据持久化会使Redis降的很低</li>
</ul>
</li>
<li>综合比对
<ul>
<li>RDB与AOF的选择实际上是在做一种权衡，每种都有利有弊</li>
<li>如不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用AOF</li>
<li>如能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用RDB</li>
<li>灾难恢复选用RDB</li>
<li>双保险策略，同时开启 RDB 和 AOF，重启后，Redis优先使用 AOF 来恢复数据，降低丢失数据的量</li>
</ul>
</li>
</ul>
<h1 id="持久化应用场景">持久化应用场景</h1>
<ul>
<li>Tips 1：<s>redis用于控制</s><strong><s>数据库表主键id</s></strong>~~，为数据库表主键提供生成策略，保障数据库表的主键唯一性 ~~【假如现在计算机停止工作，下一次启动要恢复时，不期望数据是从 redis 读取的。比如 id  如果用到 18 了，下一次恢复的时候从 18 恢复，大概率有问题，中间断的会导致 id 不连续，比如有一秒用了 19，但是 redis 没有记下来，下次从 18 恢复就会 id 重复。解决方案：从数据库读取，找出最大的 id ，然后加一使用。所以数据库主键 id 不建议持久化】</li>
<li>Tips 3：<s>redis应用于各种结构型和非结构型</s><strong><s>高热度数据访问加速</s></strong>~~ ~~（缓存里的数据要不要数据化？）【缓存中的数据从数据库读取加载来的，从 redis 读取出来和从数据库读出来没什么区别】</li>
<li>Tips 4：<s>redis 应用于</s><strong><s>购物车</s></strong><s>数据存储设计</s> 【购物车信息数据库内肯定要存，就导致 redis 和数据库内存的一样，所以 redis 就不额外存储】</li>
<li>Tips 5：redis 应用于<strong>抢购</strong>，限购类、限量发放优惠卷、激活码等业务的数据存储设计 【抢购：速度非常快，几秒钟内完成然后消失掉，如在这个过程中出现问题了，数据库可能没有持久化， 也可能记录了过程。 快速存储、快速消失的数据持久化】</li>
<li>Tips 6：redis 应用于具有<strong>操作先后顺序</strong>的数据控制 【临时任务，如果消息存储量不大，建议持久化】</li>
<li>Tips 7：redis 应用于<strong>最新消息展示</strong></li>
<li>Tips 9：<s>redis 应用于同类信息的</s><strong><s>关联搜索</s></strong>~~，二度关联搜索，深度关联搜索 ~~【关系网庞大，存到数据库】</li>
<li>Tips 12：redis 应用于基于<strong>黑名单</strong>与<strong>白名单</strong>设定的服务控制 【永久性存到数据库，临时性持久化】</li>
<li>Tips 13：redis 应用于计数器组合排序功能对应的<strong>排名 【20个主播一起主播，进行排名，主播结束数据就消失了，如果不持久化这个信息，它也不在数据库内存储就没有了。20万人在线观看，如果不持久化记录服务器一宕机就0人在线了，所以需持久化记录快速恢复】</strong></li>
<li>Tips 15：redis 应用于<strong>即时任务/消息队列</strong>执行管理</li>
<li>Tips 16：redis 应用于<strong>按次结算的服务控制</strong></li>
</ul>
<h1 id="总结">总结</h1>
<p>Redis持久化</p>
<ul>
<li>什么是持久化</li>
<li>RDB
<ul>
<li>save</li>
<li>bgsave</li>
<li>配置</li>
</ul>
</li>
<li>AOF
<ul>
<li>持久化写策略</li>
<li>重写</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[42道计算机网络面试高频题+答案，面试官喜欢的答案都在这里！]]></title>
        <id>https://epitomm.github.io/post/42-dao-ji-suan-ji-wang-luo-mian-shi-gao-pin-ti-da-an-mian-shi-guan-xi-huan-de-da-an-du-zai-zhe-li/</id>
        <link href="https://epitomm.github.io/post/42-dao-ji-suan-ji-wang-luo-mian-shi-gao-pin-ti-da-an-mian-shi-guan-xi-huan-de-da-an-du-zai-zhe-li/">
        </link>
        <updated>2020-04-03T04:48:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-谈下你对五层网络协议体系结构的理解">1、谈下你对五层网络协议体系结构的理解（*）</h1>
<p>学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。</p>
<figure data-type="image" tabindex="1"><img src="https://uploader.shimo.im/f/7hz3woCT4osuGDlM.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="1-应用层">1. 应用层</h2>
<figure data-type="image" tabindex="2"><img src="https://uploader.shimo.im/f/VgEj6OsBq3M4NeVo.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>应用层（application-layer）的任务是<strong>通过应用进程间的交互来完成特定网络应用</strong>。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。我们把应用层交互的数据单元称为报文。</p>
<h2 id="2-运输层">2. 运输层</h2>
<figure data-type="image" tabindex="3"><img src="https://uploader.shimo.im/f/vK8fB6Z7AYwmj7pZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>运输层（transport layer）的主要任务就是负责<strong>向两台主机进程之间的通信提供通用的数据传输服务</strong>。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。</p>
<figure data-type="image" tabindex="4"><img src="https://uploader.shimo.im/f/6lbS0Lrsgp4A08VN.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。</p>
<h2 id="3-网络层">3. 网络层</h2>
<figure data-type="image" tabindex="5"><img src="https://uploader.shimo.im/f/Zhp7yuBDGiAfWeXE.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是<strong>选择合适的网间路由和交换结点， 确保数据及时传送</strong>。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP / IP 体系结构中，由于网络层使用 IP 协议，因此<strong>分组</strong>也叫 <strong>IP 数据报</strong>，简称数据报。</p>
<h2 id="4-数据链路层">4. 数据链路层</h2>
<figure data-type="image" tabindex="6"><img src="https://uploader.shimo.im/f/xYbKq3tQOuQDgd28.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>数据链路层（data link layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，<strong>数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧</strong>。每一帧包括数据和必要的控制信息（如：同步信息，地址信息，差错控制等）。</p>
<figure data-type="image" tabindex="7"><img src="https://uploader.shimo.im/f/dBp0roAfwA0pkbOv.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://uploader.shimo.im/f/HyQygpuEJPwv7E1L.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://uploader.shimo.im/f/OXtDKDdN8Rkqt0O7.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出<strong>数据部分</strong>，上交给网络层。控制信息还使接收端能够检测到所收到的帧中<strong>有无差错</strong>。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用<strong>可靠性传输协议</strong>来纠正出现的差错。这种方法会使链路层的协议复杂些。</p>
<h2 id="5-物理层">5. 物理层</h2>
<figure data-type="image" tabindex="10"><img src="https://uploader.shimo.im/f/5W4Y12Sb37oiQxav.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在物理层上所传送的数据单位是<strong>比特</strong>。物理层（physical layer）的作用是实现相邻计算机节点之间<strong>比特流的透明传送</strong>，尽可能<strong>屏蔽掉具体传输介质和物理设备的差异</strong>。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。</p>
<h1 id="2-简单说下每一层对应的网络协议有哪些">2、简单说下每一层对应的网络协议有哪些？（**）</h1>
<blockquote>
<p>简单记住两三个常见的就行。</p>
</blockquote>
<p>计算机五层网络体系中涉及的协议非常多，下面就常用的做了列举：</p>
<figure data-type="image" tabindex="11"><img src="https://uploader.shimo.im/f/KEPmaUdZoIkiZWZS.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="3-arp-协议的工作原理">3、ARP 协议的工作原理？（*）</h1>
<figure data-type="image" tabindex="12"><img src="https://uploader.shimo.im/f/Imrbk2qiUVUV8c5K.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="mac-地址">MAC 地址</h2>
<figure data-type="image" tabindex="13"><img src="https://uploader.shimo.im/f/7hAVdUAX3KgOQISG.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://uploader.shimo.im/f/it41YFgMMpkXBCES.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>MAC 地址有时也被称为<strong>物理地址</strong>，但这不意味着 MAC 属于网络体系结构中的物理层，MAC 地址属于<strong>数据链路层</strong>。</p>
</blockquote>
<h2 id="ip-地址">IP 地址</h2>
<figure data-type="image" tabindex="15"><img src="https://uploader.shimo.im/f/fQTQYZC4YxIRcPuj.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://uploader.shimo.im/f/pUpJ0mXvAIkRKYb5.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="https://uploader.shimo.im/f/3UMQHY27Dno3U2Z0.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="https://uploader.shimo.im/f/14nXPBBhg9s7ViKb.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="https://uploader.shimo.im/f/MmcffwXZYTMTQYyN.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="arp-协议">ARP 协议</h2>
<figure data-type="image" tabindex="20"><img src="https://uploader.shimo.im/f/FJA5dMHkRC8QXQBQ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="21"><img src="https://uploader.shimo.im/f/mZ9TWqnTfQgqff8m.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="https://uploader.shimo.im/f/o2CuEUAoXKQrBgtv.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="23"><img src="https://uploader.shimo.im/f/yF69YY3Gh2wFp0k2.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://uploader.shimo.im/f/irwCT9nLdQ0WDlUr.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="25"><img src="https://uploader.shimo.im/f/CD4J1MjqhZYJM9Ro.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>ARP 只能在一段链路或一个网络上使用，不能跨网络使用。</p>
</blockquote>
<p><strong>网络层</strong>的 ARP 协议完成了 <strong>IP 地址与物理地址的映射</strong>。首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址：如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。</p>
<p>此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。</p>
<h1 id="4-谈下你对-ip-地址分类的理解">4、谈下你对 IP 地址分类的理解？</h1>
<p>IP 地址是指互联网协议地址，是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP 地址编址方案将 IP 地址空间划分为 A、B、C、D、E 五类，其中 A、B、C 是基本类，D、E 类作为多播和保留使用，为特殊地址。</p>
<figure data-type="image" tabindex="26"><img src="https://uploader.shimo.im/f/6TvJJC0SKC8N3fRi.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>每个 IP 地址包括两个标识码（ID），即网络 ID 和主机 ID。同一个物理网络上的所有主机都使用同一个网络 ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机 ID 与其对应。A~E 类地址的特点如下：</p>
<p>A 类地址：以 0 开头，第一个字节范围：0~127；</p>
<p>B 类地址：以 10 开头，第一个字节范围：128~191；</p>
<p>C 类地址：以 110 开头，第一个字节范围：192~223；</p>
<p>D 类地址：以 1110 开头，第一个字节范围为 224~239；</p>
<p>E 类地址：以 1111 开头，保留地址</p>
<figure data-type="image" tabindex="27"><img src="https://uploader.shimo.im/f/H8ZWz6fsJMkBBNBs.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="28"><img src="https://uploader.shimo.im/f/6O9LBeVjsNA3cjL1.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="29"><img src="https://uploader.shimo.im/f/lrFOgqmsEG806jNp.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="30"><img src="https://uploader.shimo.im/f/2IG540gBRwkMNP9e.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="31"><img src="https://uploader.shimo.im/f/G9oD9evG81EmL1QH.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="5-tcp-的主要特点是什么">5、TCP 的主要特点是什么？（*）</h1>
<ol>
<li>
<p>TCP 是<strong>面向连接</strong>的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；</p>
</li>
<li>
<p>每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是点对点的（<strong>一对一</strong>）；</p>
</li>
<li>
<p>TCP 提供<strong>可靠</strong>交付的服务。通过 TCP 连接传送的数据，无差错、不丢失、不重复、并且按序到达；</p>
</li>
<li>
<p>TCP 提供<strong>全双工</strong>通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；</p>
</li>
<li>
<p>面向<strong>字节流</strong>。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。</p>
</li>
</ol>
<h1 id="6-udp-的主要特点是什么">6、UDP 的主要特点是什么？</h1>
<ol>
<li>
<p>UDP 是<strong>无连接</strong>的；</p>
</li>
<li>
<p>UDP 使用尽最大努力交付，即<strong>不</strong>保证<strong>可靠</strong>交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；</p>
</li>
<li>
<p>UDP 是<strong>面向报文</strong>的；</p>
</li>
<li>
<p>UDP <strong>没有拥塞控制</strong>，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；</p>
</li>
<li>
<p>UDP 支持<strong>一对一、一对多、多对一和多对多</strong>的交互通信；</p>
</li>
<li>
<p>UDP 的<strong>首部开销小</strong>，只有 8 个字节，比 TCP 的 20 个字节的首部要短。</p>
</li>
</ol>
<h1 id="7-tcp-和-udp-的区别">7、TCP 和 UDP 的区别？（*）</h1>
<figure data-type="image" tabindex="32"><img src="https://uploader.shimo.im/f/cGEBZNflD9EjWCqz.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。</p>
<p>UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如：QQ 语音、 QQ 视频 、直播等等。</p>
<figure data-type="image" tabindex="33"><img src="https://uploader.shimo.im/f/mdhPaxpzb5oIJMW2.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="34"><img src="https://uploader.shimo.im/f/7u9g88OLoW4CdqQ7.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="35"><img src="https://uploader.shimo.im/f/fsJkcJYSPRs8C34V.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="36"><img src="https://uploader.shimo.im/f/fH5S3LGWfi0oHUxM.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="37"><img src="https://uploader.shimo.im/f/7Uwcb5rUdBsTs5Us.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="8-tcp-和-udp-分别对应的常见应用层协议有哪些">8、TCP 和 UDP 分别对应的常见应用层协议有哪些？</h1>
<ul>
<li>
<ol>
<li>TCP 对应的应用层协议</li>
</ol>
</li>
</ul>
<p>FTP：定义了文件传输协议，使用 21 端口。常说某某计算机开了 FTP 服务便是启动了文件传输服务。下载文件，上传主页，都要用到 FTP 服务。</p>
<p>Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于 DOS 模式下的通信服务。如以前的 BBS 是-纯字符界面的，支持 BBS 的服务器将 23 端口打开，对外提供服务。</p>
<p>SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么 SMTP 端口设置这个栏，服务器开放的是 25 号端口。</p>
<p>POP3：它是和 SMTP 对应，POP3 用于接收邮件。通常情况下，POP3 协议所用的是 110 端口。也是说，只要你有相应的使用 POP3 协议的程序（例如 Fo-xmail 或 Outlook），就可以不以 Web 方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163 邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。</p>
<p>HTTP：从 Web 服务器传输超文本到本地浏览器的传送协议。</p>
<ul>
<li>
<ol start="2">
<li>UDP 对应的应用层协议</li>
</ol>
</li>
</ul>
<p>DNS：用于域名解析服务，将域名地址转换为 IP 地址。DNS 用的是 53 号端口。</p>
<p>SNMP：简单网络管理协议，使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。</p>
<p>TFTP(Trival File Transfer Protocal)：简单文件传输协议，该协议在熟知端口 69 上使用 UDP 服务。</p>
<h1 id="9-详细说下-tcp-三次握手的过程">9、详细说下 TCP 三次握手的过程？（*）</h1>
<ul>
<li>
<ol>
<li>三次握手</li>
</ol>
</li>
</ul>
<p>TCP 建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 TCP 报文段。</p>
<figure data-type="image" tabindex="38"><img src="https://uploader.shimo.im/f/sVrpuVA01g4E8YtW.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>最初客户端和服务端都处于 CLOSED(关闭) 状态。本例中 A（Client） 主动打开连接，B（Server） 被动打开连接。</p>
<p>一开始，B 的 TCP 服务器进程首先创建传输控制块TCB，准备接受客户端进程的连接请求。然后服务端进程就处于 LISTEN(监听) 状态，等待客户端的连接请求。如有，立即作出响应。</p>
<p>第一次握手：A 的 TCP 客户端进程也是首先创建传输控制块 TCB。然后，在打算建立 TCP 连接时，向 B 发出连接请求报文段，这时首部中的同步位 SYN=1，同时选择一个初始序号 seq = x。TCP 规定，SYN 报文段（即 SYN = 1 的报文段）不能携带数据，但要消耗掉一个序号。这时，TCP 客户进程进入 SYN-SENT（同步已发送）状态。</p>
<p>第二次握手：B 收到连接请求报文后，如果同意建立连接，则向 A 发送确认。在确认报文段中应把 SYN 位和 ACK 位都置 1，确认号是 ack = x + 1，同时也为自己选择一个初始序号 seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时 TCP 服务端进程进入 SYN-RCVD（同步收到）状态。</p>
<p>第三次握手：TCP 客户进程收到 B 的确认后，还要向 B 给出确认。确认报文段的 ACK 置 1，确认号 ack = y +  1，而自己的序号 seq = x + 1。这时 ACK 报文段可以携带数据。但如果不携带数据则不消耗序号，这种情况下，下一个数据报文段的序号仍是 seq = x + 1。这时，TCP 连接已经建立，A 进入 ESTABLISHED（已建立连接）状态。</p>
<h1 id="10-为什么两次握手不可以呢">10、为什么两次握手不可以呢？（*）</h1>
<figure data-type="image" tabindex="39"><img src="https://uploader.shimo.im/f/FgFJfk6FgJQdTJko.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>为了防止已经失效的连接请求报文段突然又传送到了 B，因而产生错误。比如下面这种情况：A 发出的第一个连接请求报文段并没有丢失，而是在网路结点长时间滞留了，以致于延误到连接释放以后的某个时间段才到达 B。本来这是一个早已失效的报文段。但是 B 收到此失效的链接请求报文段后，就误认为 A 又发出一次新的连接请求。于是就向 A 发出确认报文段，同意建立连接。</p>
<p>对于上面这种情况，如果不进行第三次握手，B 发出确认后就认为新的运输连接已经建立了，并一直等待 A 发来数据。B 的许多资源就这样白白浪费了。</p>
<p>如果采用了三次握手，由于 A 实际上并没有发出建立连接请求，所以不会理睬 B 的确认，也不会向 B 发送数据。B 由于收不到确认，就知道 A 并没有要求建立连接。</p>
<h1 id="11-为什么不需要四次握手">11、为什么不需要四次握手？（*）</h1>
<p>有人可能会说 A 发出第三次握手的信息后在没有接收到 B 的请求就已经进入了连接状态，那如果 A 的这个确认包丢失或者滞留了怎么办？</p>
<p>我们需要明白一点，完全可靠的通信协议是不存在的。在经过三次握手之后，客户端和服务端已经可以确认之前的通信状况，都收到了确认信息。所以即便再增加握手次数也不能保证后面的通信完全可靠，所以是没有必要的。</p>
<h1 id="12-server-端收到-client-端的-syn-后为什么还要传回-syn">12、Server 端收到 Client 端的 SYN 后，为什么还要传回 SYN？</h1>
<p>接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。</p>
<p>SYN 是 TCP / IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符，在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误]）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。</p>
<h1 id="13-传了-syn为什么还要传-ack">13、传了 SYN，为什么还要传 ACK？</h1>
<p>双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。</p>
<h1 id="14-详细说下-tcp-四次挥手的过程">14、详细说下 TCP 四次挥手的过程？（*）</h1>
<p>据传输结束后，通信的双方都可以释放连接。现在 A 和 B 都处于 ESTABLISHED 状态。</p>
<figure data-type="image" tabindex="40"><img src="https://uploader.shimo.im/f/fJStbiea6HoBykQF.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>第一次挥手：A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP 连接。A 把连接释放报文段首部的终止控制位 FIN 置 1，其序号 seq = u（等于前面已传送过的数据的最后一个字节的序号加 1），这时 A 进入 FIN-WAIT-1（终止等待1）状态，等待 B 的确认。请注意：TCP 规定，FIN 报文段即使不携带数据，也将消耗掉一个序号。</p>
<p>第二次挥手：B 收到连接释放报文段后立即发出确认，确认号是 ack = u + 1，而这个报文段自己的序号是 v（等于 B 前面已经传送过的数据的最后一个字节的序号加1），然后 B 就进入 CLOSE-WAIT（关闭等待）状态。TCP 服务端进程这时应通知高层应用进程，因而从 A 到 B 这个方向的连接就释放了，这时的 TCP 连接处于半关闭（half-close）状态，即 A 已经没有数据要发送了，但 B 若发送数据，A 仍要接收。也就是说，从 B 到 A 这个方向的连接并未关闭，这个状态可能会持续一段时间。A 收到来自 B 的确认后，就进入 FIN-WAIT-2(终止等待2)状态，等待 B 发出的连接释放报文段。</p>
<p>第三次挥手：若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。这时 B 发出的连接释放报文段必须使 FIN = 1。假定 B 的序号为 w（在半关闭状态，B 可能又发送了一些数据）。B 还必须重复上次已发送过的确认号 ack = u + 1。这时 B 就进入 LAST-ACK(最后确认)状态，等待 A 的确认。</p>
<p>第四次挥手：A 在收到 B 的连接释放报文后，必须对此发出确认。在确认报文段中把 ACK 置 1，确认号 ack = w + 1，而自己的序号 seq = u + 1（前面发送的 FIN 报文段要消耗一个序号）。然后进入 TIME-WAIT(时间等待) 状态。请注意，现在 TCP 连接还没有释放掉。必须经过时间等待计时器设置的时间 2MSL（MSL：最长报文段寿命）后，A 才能进入到 CLOSED 状态，然后撤销传输控制块，结束这次 TCP 连接。当然如果 B 一收到 A 的确认就进入 CLOSED 状态，然后撤销传输控制块。所以在释放连接时，B 结束 TCP 连接的时间要早于 A。</p>
<h1 id="15-为什么-time-wait-状态必须等待-2msl-的时间呢">15、为什么 TIME-WAIT 状态必须等待 2MSL 的时间呢？（*）</h1>
<figure data-type="image" tabindex="41"><img src="https://uploader.shimo.im/f/IZd7Slvq5VQpgRyq.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li>
<p>为了保证 A 发送的最后一个 ACK 报文段能够到达 B。这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 FIN + ACK 报文段的确认。B 会超时重传这个 FIN+ACK 报文段，而 A 就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN+ACK 报文段。接着 A 重传一次确认，重新启动 2MSL 计时器。最后，A 和 B 都正常进入到 CLOSED 状态。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段，这样，B 就无法按照正常步骤进入 CLOSED 状态。</p>
</li>
<li>
<p>防止已失效的连接请求报文段出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。</p>
</li>
</ol>
<h1 id="16-为什么第二次跟第三次不能合并-第二次和第三次之间的等待是什么">16、为什么第二次跟第三次不能合并, 第二次和第三次之间的等待是什么?</h1>
<p>当服务器执行第二次挥手之后, 此时证明客户端不会再向服务端请求任何数据, 但是服务端可能还正在给客户端发送数据（可能是客户端上一次请求的资源还没有发送完毕），所以此时服务端会等待把之前未传输完的数据传输完毕之后再发送关闭请求。</p>
<h1 id="17-保活计时器的作用">17、保活计时器的作用？</h1>
<p>除时间等待计时器外，TCP 还有一个保活计时器（keepalive  timer）。设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。</p>
<p>服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔  75 秒钟发送一次。若连续发送 10个 探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。</p>
<h1 id="18-tcp-协议是如何保证可靠传输的">18、TCP 协议是如何保证可靠传输的？（*）</h1>
<ol>
<li>
<p><strong>数据包校验</strong>：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据；</p>
</li>
<li>
<p><strong>对失序数据包重排序</strong>：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层；</p>
</li>
<li>
<p><strong>丢弃重复数据</strong>：对于重复数据，能够丢弃重复数据；</p>
</li>
<li>
<p><strong>应答机制</strong>：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；</p>
</li>
<li>
<p><strong>超时重发</strong>：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；</p>
</li>
<li>
<p><strong>流量控制</strong>：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。</p>
</li>
</ol>
<h1 id="19-谈谈你对停止等待协议的理解">19、谈谈你对停止等待协议的理解？</h1>
<figure data-type="image" tabindex="42"><img src="https://uploader.shimo.im/f/ilbrX9885DshiTgj.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="43"><img src="https://uploader.shimo.im/f/I2PqsOrJ0BczTYUl.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认迟到、确认丢失和确认迟到。</p>
<figure data-type="image" tabindex="44"><img src="https://uploader.shimo.im/f/GwbkBys0LIYRMJgU.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="20-谈谈你对-arq-协议的理解">20、谈谈你对 ARQ 协议的理解？</h1>
<ul>
<li>自动重传请求 ARQ 协议</li>
</ul>
<p>停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。</p>
<ul>
<li>连续 ARQ 协议</li>
</ul>
<p>连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。</p>
<h1 id="21-谈谈你对滑动窗口的了解">21、谈谈你对滑动窗口的了解？（*）</h1>
<p>TCP 利用滑动窗口实现流量控制的机制。滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。</p>
<p>TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。</p>
<figure data-type="image" tabindex="45"><img src="https://uploader.shimo.im/f/HVPjgKO3S2Qq75tF.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="46"><img src="https://uploader.shimo.im/f/JRAM7qssAgUQ5Fnq.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="47"><img src="https://uploader.shimo.im/f/wblaPkbu32k96yVU.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="48"><img src="https://uploader.shimo.im/f/4MN4C6h3K30y3RjS.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="22-谈下你对流量控制的理解">22、谈下你对流量控制的理解？（*）</h1>
<p>TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</p>
<h1 id="23-谈下你对-tcp-拥塞控制的理解使用了哪些算法">23、谈下你对 TCP 拥塞控制的理解？使用了哪些算法？</h1>
<figure data-type="image" tabindex="49"><img src="https://uploader.shimo.im/f/Cxp9wJCABu8ya4XR.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="50"><img src="https://uploader.shimo.im/f/e1KHhdkCmu0JrJdy.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="51"><img src="https://uploader.shimo.im/f/A1Mt383YnYwRuMhl.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。在某段时间，若<strong>对网络中某一资源的需求超过了该资源所能提供的可用部分</strong>，网络的性能就要变坏。这种情况就叫<strong>拥塞</strong>。</p>
<p>拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致于过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。</p>
<p>为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。</p>
<p>TCP 的拥塞控制采用了四种算法，即：慢开始、拥塞避免、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如：主动队列管理 AQM），以减少网络拥塞的发生。</p>
<h2 id="慢开始">慢开始：</h2>
<figure data-type="image" tabindex="52"><img src="https://uploader.shimo.im/f/DwBr0f7gJWoRju09.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。<strong>cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍</strong>。</p>
<h2 id="拥塞避免">拥塞避免：</h2>
<figure data-type="image" tabindex="53"><img src="https://uploader.shimo.im/f/mnjZbVjUW7YioSgE.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="54"><img src="https://uploader.shimo.im/f/ZzBMLCrBW7AWgnTc.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="55"><img src="https://uploader.shimo.im/f/DhyXyH4VI3o4atqY.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="56"><img src="https://uploader.shimo.im/f/VSWKrfeo84Q3BEAg.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把<strong>发送方的 cwnd 加 1</strong>。</p>
<figure data-type="image" tabindex="57"><img src="https://uploader.shimo.im/f/a3mLciCHy54Vf9xL.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="快重传与快恢复">快重传与快恢复：</h2>
<figure data-type="image" tabindex="58"><img src="https://uploader.shimo.im/f/5JXdessxcTMMsAoG.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="59"><img src="https://uploader.shimo.im/f/lfhgzFCGEiQ7ZJNZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="60"><img src="https://uploader.shimo.im/f/YUstziH9Z0YCkxoZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="61"><img src="https://uploader.shimo.im/f/9Ej3t6jYGPA7arPd.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在 TCP/IP 中，快速重传和快恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。</p>
<p>有时，个别报文段会在网络中丢失，但实际上网络并未发生拥塞，这将导致发送方超时重传，并误认为网络发生了拥塞；发送方把拥塞窗口 cwnd 又设置为最小值 1，并错误地启动慢开始算法，因而降低了传输效率。采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。</p>
<p>所谓快重传，就是使发送方尽快进行重传，而不是等超时重传计时器超时再重传。</p>
<p>要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认；</p>
<p>即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。</p>
<p>发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传计时器超时再重传。</p>
<h1 id="24-什么是粘包">24、什么是粘包？</h1>
<p>在进行 Java NIO 学习时，可能会发现：如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况。</p>
<ol>
<li>
<p>TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界；</p>
</li>
<li>
<p>从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。</p>
</li>
</ol>
<p>基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。</p>
<p>接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。</p>
<h1 id="25-tcp-黏包是怎么产生的">25、TCP 黏包是怎么产生的？</h1>
<ul>
<li><strong>发送方产生粘包</strong></li>
</ul>
<p>采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。</p>
<ul>
<li><strong>接收方产生粘包</strong></li>
</ul>
<p>接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度）</p>
<p>​</p>
<h1 id="26-怎么解决拆包和粘包">26、怎么解决拆包和粘包？</h1>
<p>分包机制一般有两个通用的解决方法：</p>
<ol>
<li>
<p>特殊字符控制；</p>
</li>
<li>
<p>在包头首都添加数据包的长度。</p>
</li>
</ol>
<p>如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。</p>
<p>tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。</p>
<h1 id="27-你对-http-状态码有了解吗">27、你对 HTTP 状态码有了解吗？</h1>
<figure data-type="image" tabindex="62"><img src="https://uploader.shimo.im/f/g5uWYFy1vK00cvhl.png!thumbnail" alt="图片" loading="lazy"></figure>
<ul>
<li><strong>1XX 信息</strong></li>
</ul>
<ol>
<li>100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。</li>
</ol>
<ul>
<li><strong>2XX 成功</strong></li>
</ul>
<ol>
<li>
<p>200 OK</p>
</li>
<li>
<p>204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。</p>
</li>
<li>
<p>206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。</p>
</li>
</ol>
<ul>
<li><strong>3XX 重定向</strong></li>
</ul>
<ol>
<li>
<p>301 Moved Permanently ：永久性重定向；</p>
</li>
<li>
<p>302 Found ：临时性重定向；</p>
</li>
<li>
<p>303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。</p>
</li>
<li>
<p>304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。</p>
</li>
<li>
<p>307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。</p>
</li>
</ol>
<ul>
<li><strong>4XX 客户端错误</strong></li>
</ul>
<ol>
<li>
<p>400 Bad Request ：请求报文中存在语法错误。</p>
</li>
<li>
<p>401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。</p>
</li>
<li>
<p>403 Forbidden ：请求被拒绝。</p>
</li>
<li>
<p>404 Not Found</p>
</li>
</ol>
<ul>
<li><strong>5XX 服务器错误</strong></li>
</ul>
<ol>
<li>
<p>500 Internal Server Error ：服务器正在执行请求时发生错误；</p>
</li>
<li>
<p>503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。</p>
</li>
</ol>
<h1 id="28-http-状态码-301-和-302-代表的是什么有什么区别">28、HTTP 状态码 301 和 302 代表的是什么？有什么区别？</h1>
<p>301，302 都是 HTTP 状态的编码，都代表着某个 URL 发生了转移。</p>
<ul>
<li>**区别 **：</li>
</ul>
<p>301 redirect: 301 代表永久性转移（Permanently Moved）</p>
<p>302 redirect: 302 代表暂时性转移（Temporarily Moved）</p>
<h1 id="29-forward-和-redirect-的区别">29、forward 和 redirect 的区别？</h1>
<p>Forward 和 Redirect 代表了两种请求转发方式：直接转发和间接转发。</p>
<p>直接转发方式（Forward）：客户端和浏览器只发出<strong>一次请求</strong>，Servlet、HTML、JSP 或其它信息资源，由第二个信息资源响应该请求，在请求对象 request 中，保存的对象对于每个信息资源是共享的。</p>
<p>间接转发方式（Redirect）：实际是<strong>两次 HTTP 请求</strong>，服务器端在响应第一次请求的时候，让浏览器再向另外一个 URL 发出请求，从而达到转发的目的。</p>
<ul>
<li>举个通俗的例子：</li>
</ul>
<p>直接转发就相当于：“A 找 B 借钱，B 说没有，B 去找 C 借，借到借不到都会把消息传递给 A”；</p>
<p>间接转发就相当于：&quot;A 找 B 借钱，B 说没有，让 A 去找 C 借&quot;。</p>
<h1 id="30-http-方法有哪些">30、HTTP 方法有哪些？</h1>
<p>客户端发送的 请求报文 第一行为请求行，包含了方法字段。</p>
<ol>
<li>
<p>GET：获取资源，当前网络中绝大部分使用的都是 GET；</p>
</li>
<li>
<p>HEAD：获取报文首部，和 GET 方法类似，但是不返回报文实体主体部分；</p>
</li>
<li>
<p>POST：传输实体主体</p>
</li>
<li>
<p>PUT：上传文件，由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。</p>
</li>
<li>
<p>PATCH：对资源进行部分修改。PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。</p>
</li>
<li>
<p>OPTIONS：查询指定的 URL 支持的方法；</p>
</li>
<li>
<p>CONNECT：要求在与代理服务器通信时建立隧道。使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。</p>
</li>
<li>
<p>TRACE：追踪路径。服务器会将通信路径返回给客户端。发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。</p>
</li>
</ol>
<h1 id="31-说下-get-和-post-的区别">31、说下 GET 和 POST 的区别？（**）</h1>
<p>GET 和 POST 本质都是 HTTP 请求，只不过对它们的作用做了界定和适配，并且让他们适应各自的场景。</p>
<p>本质区别：GET 只是一次 HTTP请求，POST 先发请求头再发请求体，实际上是两次请求。</p>
<ol>
<li>
<p>从功能上讲，GET 一般用来从服务器上获取资源，POST 一般用来更新服务器上的资源；</p>
</li>
<li>
<p>从 REST 服务角度上说，GET 是幂等的，即读取同一个资源，总是得到相同的数据，而 POST 不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET 不会改变服务器上的资源，而 POST 会对服务器资源进行改变；</p>
</li>
<li>
<p>从请求参数形式上看，GET 请求的数据会附在 URL 之后，即将请求数据放置在 HTTP 报文的 请求头 中，以 ? 分割 URL 和传输数据，参数之间以 &amp; 相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用 BASE64 加密，得出如：%E4%BD%A0%E5%A5%BD，其中 ％XX 中的 XX 为该符号以 16 进制表示的 ASCII)；而 POST 请求会把提交的数据则放置在是 HTTP 请求报文的 请求体 中；</p>
</li>
<li>
<p>就安全性而言，POST 的安全性要比 GET 的安全性高，因为 GET 请求提交的数据将明文出现在 URL 上，而且 POST 请求参数则被包装到请求体中，相对更安全；</p>
</li>
<li>
<p>从请求的大小看，GET 请求的长度受限于浏览器或服务器对 URL 长度的限制，允许发送的数据量比较小，而 POST 请求则是没有大小限制的。</p>
</li>
</ol>
<h1 id="32-在浏览器中输入-url-地址到显示主页的过程">32、在浏览器中输入 URL 地址到显示主页的过程？（*）</h1>
<ol>
<li>
<p>DNS 解析：浏览器查询 DNS，获取域名对应的 IP 地址：具体过程包括浏览器搜索自身的 DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服务器进行查询等。对于向本地 DNS 服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；</p>
</li>
<li>
<p>TCP 连接：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手；</p>
</li>
<li>
<p>发送 HTTP 请求：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求；</p>
</li>
<li>
<p>服务器处理请求并返回 HTTP 报文：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；</p>
</li>
<li>
<p>浏览器解析渲染页面：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。</p>
</li>
<li>
<p>连接结束。</p>
</li>
</ol>
<h1 id="33-dns-的解析过程">33、DNS 的解析过程？（**）</h1>
<figure data-type="image" tabindex="63"><img src="https://uploader.shimo.im/f/jm7dKHGyA543S9Xk.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="64"><img src="https://uploader.shimo.im/f/LypWsW5YTq0QVvld.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li>
<p><strong>主机向本地域名服务器</strong>的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。</p>
</li>
<li>
<p><strong>本地域名服务器向根域名服务器</strong>的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，本地域名服务器得到了所要解析的 IP 地址或报错，然后把这个结果返回给发起查询的主机。</p>
</li>
</ol>
<h1 id="34-谈谈你对域名缓存的了解">34、谈谈你对域名缓存的了解？</h1>
<figure data-type="image" tabindex="65"><img src="https://uploader.shimo.im/f/xfZfIy82Vsc3MhHx.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="66"><img src="https://uploader.shimo.im/f/QPRdQphNRlkh30Na.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在<strong>域名服务器</strong>中广泛使用了<strong>高速缓存</strong>，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。</p>
<p>由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置<strong>计时器</strong>并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。</p>
<p>不仅在本地域名服务器中需要高速缓存，在<strong>主机</strong>中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，而且主机必须从缓存中删除无效的项。由于域名改动并不频繁，大多数网点不需花精力就能维护数据库的一致性。</p>
<h1 id="35-谈下你对-http-长连接和短连接的理解分别应用于哪些场景">35、谈下你对 HTTP 长连接和短连接的理解？分别应用于哪些场景？</h1>
<p>在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如：JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。</p>
<p>而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：</p>
<p>Connection:keep-alive</p>
<p>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。</p>
<p>Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如：Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。</p>
<h1 id="36-谈下-http-10-和-11-12-的主要变化">36、谈下 HTTP 1.0 和 1.1、1.2 的主要变化？</h1>
<ul>
<li><strong>HTTP1.1 的主要变化：</strong></li>
</ul>
<ol>
<li>
<p>HTTP1.0 经过多年发展，在 1.1 提出了改进。首先是提出了长连接，HTTP 可以在一次 TCP 连接中不断发送请求。</p>
</li>
<li>
<p>然后 HTTP1.1 支持只发送 header 而不发送 body。原因是先用 header 判断能否成功，再发数据，节约带宽，事实上，post 请求默认就是这样做的。</p>
</li>
<li>
<p>HTTP1.1 的 host 字段。由于虚拟主机可以支持多个域名，所以一般将域名解析后得到 host。</p>
</li>
</ol>
<ul>
<li><strong>HTTP2.0 的主要变化：</strong></li>
</ul>
<ol>
<li>
<p>HTTP2.0 支持多路复用，同一个连接可以并发处理多个请求，方法是把 HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组，而不需要一个个 HTTP请求顺序到达；</p>
</li>
<li>
<p>HTTP2.0 支持服务端推送，就是服务端在 HTTP 请求到达后，除了返回数据之外，还推送了额外的内容给客户端；</p>
</li>
<li>
<p>HTTP2.0 压缩了请求头，同时基本单位是二进制帧流，这样的数据占用空间更少；</p>
</li>
<li>
<p>HTTP2.0 适用于 HTTPS 场景，因为其在 HTTP和 TCP 中间加了一层 SSL 层。</p>
</li>
</ol>
<h1 id="37-https-的工作过程">37、HTTPS 的工作过程？（**）</h1>
<ol>
<li>
<p>客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了；</p>
</li>
<li>
<p>服务器从中选出一套加密算法和 hash 算法以及自己的身份信息（地址等）以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构；</p>
</li>
<li>
<p>客户端收到网站的证书之后要做下面的事情：</p>
</li>
</ol>
<ul>
<li>
<p>3.1 验证证书的合法性；</p>
</li>
<li>
<p>3.2 如果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密；</p>
</li>
<li>
<p>3.3 用约定好的 hash 算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器。</p>
</li>
</ul>
<ol start="4">
<li>服务器接收到客户端传送来的信息，要做下面的事情：</li>
</ol>
<ul>
<li>4.1 用私钥解析出密码，用密码解析握手消息，验证 hash 值是否和浏览器发来的一致；</li>
<li>4.2 使用密钥加密消息；</li>
</ul>
<ol start="5">
<li>如果计算法 hash 值一致，握手成功。</li>
</ol>
<h1 id="38-http-和-https-的区别"><strong>38、HTTP 和 HTTPS 的区别？</strong></h1>
<ol>
<li>
<p>开销：HTTPS 协议需要到 CA 申请证书，一般免费证书很少，需要交费；</p>
</li>
<li>
<p>资源消耗：HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 ssl 加密传输协议，需要消耗更多的 CPU 和内存资源；</p>
</li>
<li>
<p>端口不同：HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是  80，后者是 443；</p>
</li>
<li>
<p>安全性：HTTP 的连接很简单，是无状态的；HTTPS 协议是由 TSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。</p>
</li>
</ol>
<h1 id="39-https-的优缺点"><strong>39、HTTPS 的优缺点？</strong></h1>
<ul>
<li><strong>优点：</strong></li>
</ul>
<ol>
<li>
<p>使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</p>
</li>
<li>
<p>HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性；</p>
</li>
<li>
<p>HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</p>
</li>
</ol>
<ul>
<li><strong>缺点：</strong></li>
</ul>
<ol>
<li>
<p>HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近 50%，增加 10% 到 20% 的耗电；</p>
</li>
<li>
<p>HTTPS 连接缓存不如 HTTP 高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；</p>
</li>
<li>
<p>SSL 证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用；</p>
</li>
<li>
<p>SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗；</p>
</li>
<li>
<p>HTTPS 协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。</p>
</li>
</ol>
<h1 id="40-什么是数字签名"><strong>40、什么是数字签名？</strong></h1>
<p>为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。</p>
<h1 id="41-什么是数字证书"><strong>41、什么是数字证书？</strong></h1>
<p>对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。</p>
<h1 id="42-什么是对称加密和非对称加密"><strong>42、什么是对称加密和非对称加密？</strong></h1>
<p>对称密钥加密是指<strong>加密和解密使用同一个密钥</strong>的方式，这种方式存在的最大问题就是密钥发送问题，即如何<strong>安全地将密钥发给对方</strong>。</p>
<p>非对称加密指使用一对非对称密钥，即：公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的<strong>公钥</strong>进行<strong>加密</strong>处理，对方接收到加密信息后，使用自己的<strong>私钥</strong>进行<strong>解密</strong>。</p>
<p>由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性。但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。</p>
<p>附：计网思维导图<br>
<img src="https://epitomm.github.io/post-images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.png" alt="图片" loading="lazy"></p>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://mp.weixin.qq.com/s/Gy4ElItSvBoeQnN4YbMPGQ">https://mp.weixin.qq.com/s/Gy4ElItSvBoeQnN4YbMPGQ</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题 —— 由浅入深全面解析 Threadlocal]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-threadlocal/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-threadlocal/">
        </link>
        <updated>2020-04-01T16:09:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-threadlocal-介绍">一、ThreadLocal 介绍</h1>
<h2 id="11-官方介绍">1.1 官方介绍</h2>
<pre><code>/**
 * This class provides thread-local variables.  These variables differ from
 * their normal counterparts in that each thread that accesses one (via its
 * {@code get} or {@code set} method) has its own, independently initialized
 * copy of the variable.  {@code ThreadLocal} instances are typically private
 * static fields in classes that wish to associate state with a thread (e.g.,
 * a user ID or Transaction ID).
 *
 * &lt;p&gt;For example, the class below generates unique identifiers local to each
 * thread.
 * A thread's id is assigned the first time it invokes {@code ThreadId.get()}
 * and remains unchanged on subsequent calls.
 * &lt;pre&gt;
 * import java.util.concurrent.atomic.AtomicInteger;
 *
 * public class ThreadId {
 *     // Atomic integer containing the next thread ID to be assigned
 *     private static final AtomicInteger nextId = new AtomicInteger(0);
 *
 *     // Thread local variable containing each thread's ID
 *     private static final ThreadLocal&amp;lt;Integer&amp;gt; threadId =
 *         new ThreadLocal&amp;lt;Integer&amp;gt;() {
 *             &amp;#64;Override protected Integer initialValue() {
 *                 return nextId.getAndIncrement();
 *         }
 *     };
 *
 *     // Returns the current thread's unique ID, assigning it if necessary
 *     public static int get() {
 *         return threadId.get();
 *     }
 * }
 * &lt;/pre&gt;
 * &lt;p&gt;Each thread holds an implicit reference to its copy of a thread-local
 * variable as long as the thread is alive and the {@code ThreadLocal}
 * instance is accessible; after a thread goes away, all of its copies of
 * thread-local instances are subject to garbage collection (unless other
 * references to these copies exist).
 *
 * @author  Josh Bloch and Doug Lea
 * @since   1.2
 */
</code></pre>
<p>从 Java 官方文档中的描述：<code>ThreadLocal</code>类用来提供<strong>线程内部的局部变量</strong>。这种变量在多线程环境下访问（通过<code>get</code>和<code>set</code>方法访问）时能保证各个线程的变量相对独立于其他线程内的变量。<code>ThreadLocal</code>实例通常来说都是<code>private static</code>类型的，用于关联线程和线程上下文。<br>
我们可以得知<code>ThreadLocal</code>的作用是：提供线程内的局部变量，不同的线程之间不会相互干扰，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或组件之间一些公共变量传递的复杂度。</p>
<p>总结：</p>
<ol>
<li>
<p>线程并发：在多并发的场景下</p>
</li>
<li>
<p>传递数据：我们可以通过 <code>ThreadLocal</code> 在同一线程，不同组件中传递公共变量</p>
</li>
<li>
<p>线程隔离：每个线程的变量都是独立的，不会互相影响。</p>
</li>
</ol>
<h2 id="12-基本使用">1.2 基本使用</h2>
<h3 id="121-常用方法">1.2.1 常用方法</h3>
<p>在使用之前，我们先来认识几个 <code>ThreadLoal</code> 的常用方法</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>方法声明</strong></th>
<th style="text-align:left"><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ThreadLocal()</td>
<td style="text-align:left">创建 ThreadLocal 对象</td>
</tr>
<tr>
<td style="text-align:left">public void set(T value)</td>
<td style="text-align:left">设置当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public T get()</td>
<td style="text-align:left">获取当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public void remove()</td>
<td style="text-align:left">移除当前线程绑定的局部变量</td>
</tr>
</tbody>
</table>
<h3 id="122-使用案列">1.2.2 使用案列</h3>
<pre><code>package com.ssm.threadlocal;
/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 */
public class MyDemo01 {
    private String content;
    private String getContent(){
        return content;
    }
    private void setContent(String content){
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo01 demo = new MyDemo01();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                System.out.println(&quot; ---------------- &quot;);
                System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>运行结果：部分线程取出的数据 与 它存入的数据不一样</p>
<pre><code> ---------------- 
 ---------------- 
线程2---&gt;线程3的数据
 ---------------- 
线程1---&gt;线程4的数据
 ---------------- 
线程4---&gt;线程4的数据
线程0---&gt;线程2的数据
 ---------------- 
线程3---&gt;线程4的数据
</code></pre>
<p>从结果可以看出多个线程在访问同一个变量的时候出现的异常，线程间的数据没有隔离。下面我们来看下采用 ThreadLocal 的方式来解决这个问题的例子。</p>
<pre><code>package com.ssm.threadlocal;

/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 *
 *      ThreadLocal:
 *          1.set()：将变量绑定到当前线程中；
 *          2.get()：获取当前线程绑定的变量
 */
public class MyDemo01 {
    ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();
    private String getContent(){
        return threadLocal.get();
    }
    private void setContent(String content){
        // 变量绑定到当前线程中
        threadLocal.set(content);
    }

    public static void main(String[] args) {
        MyDemo01 demo = new MyDemo01();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                System.out.println(&quot; ---------------- &quot;);
                System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code> ---------------- 
 ---------------- 
线程3---&gt;线程3的数据
 ---------------- 
线程2---&gt;线程2的数据
 ---------------- 
 ---------------- 
线程4---&gt;线程4的数据
线程0---&gt;线程0的数据
线程1---&gt;线程1的数据
</code></pre>
<p>从结果来看，这样很好的解决了多线程之间数据隔离的问题，十分方便。</p>
<h2 id="13-threadlocal-与-synchronized-关键字">1.3 ThreadLocal 与 synchronized 关键字</h2>
<h3 id="131-synchronized-同步方式">1.3.1 synchronized 同步方式</h3>
<p>这里可能有的朋友会觉得在上述例子中我们完全可以通过加锁来实现这个功能。我们首先来看一下用synchronized代码块实现的效果：</p>
<pre><code>package com.ssm.threadlocal;

/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 */
public class MyDemo02 {
    private String content;
    private String getContent(){
        return content;
    }
    private void setContent(String content){
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo02 demo = new MyDemo02();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                synchronized (MyDemo02.class){
                    demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                    System.out.println(&quot; ---------------- &quot;);
                    System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
                }

            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>从结果可以发现，加锁确实可以解决这个问题，但是在这里我们强调的是<strong>线程数据隔离</strong>的问题，并不是<strong>多线程共享数据的</strong>问题，在这个案例中使用<code>synchronized</code>关键字是不合适的。</p>
<h3 id="132-threadlocal-与-synchronized-关键字的区别">1.3.2 ThreadLocal 与 synchronized 关键字的区别</h3>
<p>虽然T<code>hreadLocal</code>模式与<code>synchronized</code>关键字都用于处理多线程并发访问变量的问题，不过两者处理问题的角度和思路不同。</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">synchronized</th>
<th style="text-align:left">ThreadLocal</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">原理</td>
<td style="text-align:left">同步机制采用 “<strong>以时间换空间</strong>” 的方式，只提供了一分变量，让不用的线程派对访问</td>
<td style="text-align:left">ThreadLocal 采用 “<strong>以空间换时间</strong>” 的方式，为每一个线程都提供了一份变量的副本，从而实现同时访问互不干扰</td>
</tr>
<tr>
<td style="text-align:left">侧重点</td>
<td style="text-align:left">多个线程之间访问资源的同步</td>
<td style="text-align:left">多线程中让每个线程之间的数据相互隔离</td>
</tr>
</tbody>
</table>
<p>总结：在刚刚的案例中，虽然使用<code>ThreadLocal</code>和<code>synchronized</code>都能解决问题，但是使用<code>ThreadLocal</code>更为合适，因为这样可以使程序拥有更高的并发性。</p>
<h1 id="二-运用场景_事务案例">二、 运用场景_事务案例</h1>
<p>​通过以上的介绍，我们已经基本了解<code>ThreadLocal</code>的特点。但是它具体是运用在什么场景中呢？ 接下来让我们看一个案例： 事务操作。</p>
<h2 id="21-转账案例">2.1 转账案例</h2>
<h3 id="211-场景构建">2.1.1 场景构建</h3>
<p>​这里我们先构建一个简单的转账场景： 有一个数据表<code>account</code>，里面有两个用户<code>Jack</code>和<code>Rose</code>，用户<code>Jack</code>  给用户<code>Rose</code> 转账。</p>
<p>案例的实现主要用<code>mysql</code>数据库，<code>JDBC</code> 和 <code>C3P0</code> 框架。以下是详细代码 ：</p>
<p>（1） 项目结构<br>
<img src="https://epitomm.github.io/post-images/001.png" alt="图片" loading="lazy"><br>
（2） 数据准备</p>
<pre><code class="language-sql">-- 使用数据库
use test;
-- 创建一张账户表
create table account(
	id int primary key auto_increment,
	name varchar(20),
	money double
);
-- 初始化数据
insert into account values(null, 'Jack', 1000);
insert into account values(null, 'Rose', 0);
</code></pre>
<p>（3） C3P0配置文件和工具类</p>
<pre><code class="language-xml">&lt;c3p0-config&gt;
  &lt;!-- 使用默认的配置读取连接池对象 --&gt;
  &lt;default-config&gt;
  	&lt;!--  连接参数 --&gt;
    &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt;
    &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt;
    &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt;
    &lt;property name=&quot;password&quot;&gt;1234&lt;/property&gt;
    
    &lt;!-- 连接池参数 --&gt;
    &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt;
    &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt;
    &lt;property name=&quot;checkoutTimeout&quot;&gt;3000&lt;/property&gt;
  &lt;/default-config&gt;

&lt;/c3p0-config&gt;
</code></pre>
<p>（4） 工具类 ： JdbcUtils</p>
<pre><code class="language-java">package com.itheima.transfer.utils;

import com.mchange.v2.c3p0.ComboPooledDataSource;
import java.sql.Connection;
import java.sql.SQLException;

public class JdbcUtils {
    // c3p0 数据库连接池对象属性
    private static final ComboPooledDataSource ds = new ComboPooledDataSource();
    // 获取连接
    public static Connection getConnection() throws SQLException {
        return ds.getConnection();
    }
    //释放资源
    public static void release(AutoCloseable... ios){
        for (AutoCloseable io : ios) {
            if(io != null){
                try {
                    io.close();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }
    
    
    public static void commitAndClose(Connection conn) {
        try {
            if(conn != null){
                //提交事务
                conn.commit();
                //释放连接
                conn.close();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void rollbackAndClose(Connection conn) {
        try {
            if(conn != null){
                //回滚事务
                conn.rollback();
                //释放连接
                conn.close();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>（5） dao层代码 ： AccountDao</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(String outUser, int money) throws SQLException {
        String sql = &quot;update account set money = money - ? where name = ?&quot;;

        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();

        JdbcUtils.release(pstm,conn);
    }

    public void in(String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;

        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();

        JdbcUtils.release(pstm,conn);
    }
}
</code></pre>
<p>（6） service层代码 ： AccountService</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import java.sql.SQLException;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        try {
            // 转出
            ad.out(outUser, money);
            // 转入
            ad.in(inUser, money);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>（7） web层代码 ： AccountWeb</p>
<pre><code class="language-java">package com.itheima.transfer.web;

import com.itheima.transfer.service.AccountService;

public class AccountWeb {

    public static void main(String[] args) {
        // 模拟数据 : Jack 给 Rose 转账 100
        String outUser = &quot;Jack&quot;;
        String inUser = &quot;Rose&quot;;
        int money = 100;

        AccountService as = new AccountService();
        boolean result = as.transfer(outUser, inUser, money);

        if (result == false) {
            System.out.println(&quot;转账失败!&quot;);
        } else {
            System.out.println(&quot;转账成功!&quot;);
        }
    }
}
</code></pre>
<h3 id="212-引入事务">2.1.2 引入事务</h3>
<p>​案例中的转账涉及两个DML操作： 一个转出，一个转入。这些操作是需要具备原子性的，不可分割。不然就有可能出现数据修改异常情况。</p>
<pre><code class="language-java">public class AccountService {
    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        try {
            // 转出
            ad.out(outUser, money);
            // 模拟转账过程中的异常
            int i = 1/0;
            // 转入
            ad.in(inUser, money);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>所以这里就需要操作事务，来保证转出和转入操作具备原子性，要么同时成功，要么同时失败。<br>
（1） JDBC中关于事务的操作的api</p>
<table>
<thead>
<tr>
<th>Connection接口的方法</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>void  setAutoCommit(false)</td>
<td>禁用事务自动提交（改为手动）</td>
</tr>
<tr>
<td>void  commit();</td>
<td>提交事务</td>
</tr>
<tr>
<td>void rollback();</td>
<td>回滚事务</td>
</tr>
</tbody>
</table>
<p>（2） <strong>开启事务的注意点</strong>:</p>
<ul>
<li>
<p>为了保证所有的操作在一个事务中,案例中使用的连接必须是同一个:  <code>service</code>层开启事务的<code>connection</code>需要跟<code>dao</code>层访问数据库的<code>connection</code>保持一致</p>
</li>
<li>
<p>线程并发情况下, 每个线程只能操作各自的 <code>connection</code></p>
</li>
</ul>
<h2 id="22-常规解决方案">2.2  常规解决方案</h2>
<h3 id="221-常规方案的实现">2.2.1 常规方案的实现</h3>
<p>基于上面给出的前提， 大家通常想到的解决方案是 ：</p>
<ul>
<li>传参: 从<code>service</code>层将<code>connection</code>对象向<code>dao</code>层传递</li>
<li>加锁</li>
</ul>
<p>以下是代码实现修改的部分：</p>
<p>（1 ) AccountService 类</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        //线程并发情况下,为了保证每个线程使用各自的connection,故加锁
        synchronized (AccountService.class) {

            Connection conn = null;
            try {
                conn = JdbcUtils.getConnection();
                //开启事务
                conn.setAutoCommit(false);
                // 转出
                ad.out(conn, outUser, money);
                // 模拟转账过程中的异常
//            int i = 1/0;
                // 转入
                ad.in(conn, inUser, money);
                //事务提交
                JdbcUtils.commitAndClose(conn);
            } catch (Exception e) {
                e.printStackTrace();
                //事务回滚
                JdbcUtils.rollbackAndClose(conn);
                return false;
            }
            return true;
        }
    }
}
</code></pre>
<p>（2) AccountDao 类 （这里需要注意的是： connection不能在dao层释放，要在service层，不然在dao层释放，service层就无法使用了）</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(Connection conn, String outUser, int money) throws SQLException{
        String sql = &quot;update account set money = money - ? where name = ?&quot;;
        //注释从连接池获取连接的代码,使用从service中传递过来的connection
//        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();
        //连接不能在这里释放,service层中还需要使用
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }

    public void in(Connection conn, String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;
//        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }
}
</code></pre>
<h3 id="222-常规方案的弊端">2.2.2 常规方案的弊端</h3>
<p>上述方式我们看到的确按要求解决了问题，但是仔细观察，会发现这样实现的弊端：</p>
<ol>
<li>
<p>直接从<code>service</code>层传递<code>connection</code>到<code>dao</code>层, 造成代码耦合度提高</p>
</li>
<li>
<p>加锁会造成线程失去并发性，程序性能降低</p>
</li>
</ol>
<h2 id="23-threadlocal解决方案">2.3 ThreadLocal解决方案</h2>
<h3 id="231-threadlocal方案的实现">2.3.1 ThreadLocal方案的实现</h3>
<p>像这种需要在项目中进行<strong>数据传递</strong>和<strong>线程隔离</strong>的场景，我们不妨用<code>ThreadLocal</code>来解决：</p>
<p>（1） 工具类的修改： 加入ThreadLocal</p>
<pre><code class="language-java">package com.itheima.transfer.utils;

import com.mchange.v2.c3p0.ComboPooledDataSource;
import java.sql.Connection;
import java.sql.SQLException;

public class JdbcUtils {
    //ThreadLocal对象 : 将connection绑定在当前线程中
    private static final ThreadLocal&lt;Connection&gt; tl = new ThreadLocal();

    // c3p0 数据库连接池对象属性
    private static final ComboPooledDataSource ds = new ComboPooledDataSource();

    // 获取连接
    public static Connection getConnection() throws SQLException {
        //取出当前线程绑定的connection对象
        Connection conn = tl.get();
        if (conn == null) {
            //如果没有，则从连接池中取出
            conn = ds.getConnection();
            //再将connection对象绑定到当前线程中
            tl.set(conn);
        }
        return conn;
    }

    //释放资源
    public static void release(AutoCloseable... ios) {
        for (AutoCloseable io : ios) {
            if (io != null) {
                try {
                    io.close();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public static void commitAndClose() {
        try {
            Connection conn = getConnection();
            //提交事务
            conn.commit();
            //解除绑定
            tl.remove();
            //释放连接
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void rollbackAndClose() {
        try {
            Connection conn = getConnection();
            //回滚事务
            conn.rollback();
            //解除绑定
            tl.remove();
            //释放连接
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>（2） AccountService类的修改：不需要传递connection对象</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();

        try {
            Connection conn = JdbcUtils.getConnection();
            //开启事务
            conn.setAutoCommit(false);
            // 转出 ： 这里不需要传参了 ！
            ad.out(outUser, money);
            // 模拟转账过程中的异常
//            int i = 1 / 0;
            // 转入
            ad.in(inUser, money);
            //事务提交
            JdbcUtils.commitAndClose();
        } catch (Exception e) {
            e.printStackTrace();
            //事务回滚
           JdbcUtils.rollbackAndClose();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>（3） AccountDao类的修改：照常使用</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(String outUser, int money) throws SQLException {
        String sql = &quot;update account set money = money - ? where name = ?&quot;;
        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();
        //照常使用
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }

    public void in(String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;
        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }
}
</code></pre>
<h3 id="232-threadlocal方案的好处">2.3.2 ThreadLocal方案的好处</h3>
<p>从上述的案例中我们可以看到， 在一些特定场景下，<code>ThreadLocal</code>方案有两个突出的优势：</p>
<ol>
<li>
<p>传递数据 ： 保存每个线程绑定的数据，在需要的地方可以直接获取, 避免参数直接传递带来的代码耦合问题</p>
</li>
<li>
<p>线程隔离 ： 各线程之间的数据相互隔离却又具备并发性，避免同步方式带来的性能损失</p>
</li>
</ol>
<h1 id="三-threadlocal的内部结构">三、ThreadLocal的内部结构</h1>
<p>通过以上的学习，我们对<code>ThreadLocal</code>的作用有了一定的认识。现在我们一起来看一下<code>ThreadLocal</code>的内部结构，探究它能够实现线程数据隔离的原理。</p>
<h2 id="31常见的误解">3.1常见的误解</h2>
<p>通常，如果我们不去看源代码的话，我猜 <code>ThreadLocal</code> 是这样子设计的：每个<code>ThreadLocal</code> 类都创建一个 <code>Map</code>，然后用线程作为<code>Map</code>的<code>key</code>，要存储的局部变量作为<code>Map</code>的<code>value</code>，这样就能达到各个线程的局部变量隔离的效果。这是最简单的设计方法，<code>JDK</code>最早期的<code>ThreadLocal</code>就是这样设计的。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E6%97%A9%E6%9C%9FThreadLocal.png" alt="图片" loading="lazy"></figure>
<h2 id="32-现在的设计">3.2 现在的设计</h2>
<p>但是，<code>JDK</code>后面优化了设计方案，<code>JDK8</code> 中 <code>ThreadLocal</code>的设计是：每个<code>Thread</code>维护一个<code>ThreadLocalMap</code> 哈希表，这个哈希表的<code>key</code>是<code>ThreadLocal</code>实例本身，<code>value</code>才是真正要存储的值<code>object</code>。</p>
<p>（1）每个<code>Thread</code>线程内部都有一个<code>Map（ThreadLocalMap）</code></p>
<p>（2）<code>Map</code>里面存储<code>ThreadLocal</code>对象（<code>key</code>）和线程的变量副本（<code>value</code>）</p>
<p>（3）<code>Thread</code>内部的<code>Map</code>是由<code>ThreadLocal</code>维护的，由ThreadLocal负责向map获取和设置线程的变量值。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/JDK8ThreadLocal.png" alt="图片" loading="lazy"></figure>
<h2 id="33-jdk8的设计方案两个好处">3.3 JDK8的设计方案两个好处</h2>
<ol>
<li>每个<code>Map</code>存储的<code>Entry</code>数量变少</li>
</ol>
<p>[在早期版本内，Map 的 Entry 数量由 Thread 决定；而 JDK8 中，Map 的 Entry 数量由 ThreadLocal 决定，一般情况下 ThreadLocal 数量是比 Thread 少的]</p>
<ol start="2">
<li>当<code>Thread</code>销毁的时候，<code>ThreadLocalMap</code>也会随之销毁，减少内存的使用</li>
</ol>
<p>[早期版本内，ThreadLocalMap 由 ThreadLocal 维护；而 JDK8 中，ThreadLocalMap 由 Thread 维护，当 Thread 销毁，ThreadLocalMap 也会销毁]</p>
<h1 id="四-threadlocal-的和核心方法源码">四、ThreadLocal 的和核心方法源码</h1>
<p>基于<code>ThreadLocal</code>的内部结构，我们继续分析它的核心方法源码，更深入的了解其操作原理。</p>
<p>除了构造方法之外，<code>ThreadLocal</code>对外暴露的方法有以下4个：</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法声明</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">protected T initialValue()</td>
<td style="text-align:left">返回当前线程局部变量的初始值</td>
</tr>
<tr>
<td style="text-align:left">public void set(T value)</td>
<td style="text-align:left">设置当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public T get()</td>
<td style="text-align:left">获取当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public void remove()</td>
<td style="text-align:left">移除当前线程绑定的局部变量</td>
</tr>
</tbody>
</table>
<p>以下是这4个方法的详细源码分析（为了保证思路清晰，<code>ThreadLocalMap</code>部分暂时不展开，下一个知识点详解）</p>
<h2 id="41-set方法">4.1 set方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 设置当前线程对应的 ThreadLocal 的值
 * @param value 将要保存在当前线程对应的ThreadLocal的值
 */
public void set(T value) {
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取当前线程对象中维护的 ThreadLocalMap 对象
    ThreadLocalMap map = getMap(t);
    // 判断 map 是否存在
    if (map != null)
        // 存在则调用 map.set 设置此实体 Entry
        map.set(this, value);
    else
        // 1）当前线程 Thread 不存在 ThreadLocalMap 对象
        // 2）则调用 createMap 进行 ThreadLocalMap 对象的初始化
        // 3）并将 t（当前线程）和value（t对应的值）作为第一个 entry 存放至 ThreadLocalMap 中
        createMap(t, value);
}
/**
 * 获取当前线程 Thread 对应维护的 ThreadLocalMap
 *
 * @param  t the current thread 当前线程
 * @return the map 对应维护的 ThreadLocalMap
 */

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

/**
 * 创建当前线程 Thread 对应维护的 ThreadLocalMap
 *
 * @param t the current thread 当前线程
 * @param firstValue value for the initial entry of the map 存放到 map 中第一个 entry 值 
 */
void createMap(Thread t, T firstValue) {
    // 这里的 this 是调用此方法的threadLocal
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线，并根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则将参数设置到<code>Map</code>中（当前<code>ThreadLocal</code>的引用作为<code>key</code>）</p>
<p>C.如果<code>Map</code>为空，则给该线程创建<code>Map</code>，并设置初始值</p>
<h2 id="42-get方法">4.2 get方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 返回当前线程中保存 ThreadLocal 的值
 * 当前线程没有此 ThreadLocal 变量
 * 则它会通过调用 {@link #initialValue} 方法进行初始化
 *
 * @return 返回当前线程对应此 ThreadLocal 的值
 */
public T get() {
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取当前线程中维护的 ThreadLocalMap 对象
    ThreadLocal.ThreadLocalMap map = getMap(t);
    // 如果此 map 存在
    if (map != null) {
        // 以当前的 ThreadLocal 为 key，调用 getEntry 获取对应的存储实体 e
        ThreadLocal.ThreadLocalMap.Entry e = map.getEntry(this);
        // 对 e 进行判空
        if (e != null) {
            @SuppressWarnings(&quot;unchecked&quot;)
            // 获取存储实体 e 对应的 value 值，即为我们想要的当前线程对应此 ThreadLocal 的值
            T result = (T)e.value;
            return result;
        }
    }
    /*
        初始化：有两种情况执行当前代码
        第一种情况：map 不存在，表示此线程没有维护的 ThreadLocalMap 对象
        第二种情况：map 存在，但是没有与当前 ThreadLocal 关联的 Entry
     */
    return setInitialValue();
}
/**
 * 初始化
 *
 * @return the initial value
 */
private T setInitialValue() {
    // 调用 initialValue 获取初始化的值
    // 此方法可以被子类重写，如果不重写默认返回 null
    T value = initialValue();
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取此线程对象中维护的 ThreadLocalMap 对象
    ThreadLocal.ThreadLocalMap map = getMap(t);
    // 判断 map 是否存在
    if (map != null)
        // 存在则调用 map.set 设置此实体 entry
        map.set(this, value);
    else
        // 1)当前线程 Thread 不存在 ThreadLocalMap 对象
        // 2)则调用 createMap 进行 ThreadLocalMap 对象的初始化
        // 3)并将 t(当前线程)和 value(t对应的值)作为第一个 entry 存放至 ThreadLocalMap 中
        createMap(t, value);
    // 返回设置的值 value
    return value;
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线程，根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则在<code>Map</code>中以<code>ThreadLocal</code>的引用作为<code>key</code>来在<code>Map</code>中获取对应的<code>Entry</code>，否则转到D</p>
<p>C.如果<code>e</code>不为<code>null</code>，则返回<code>e.value</code>，否则转到D</p>
<p>D.<code>Map</code>为空或者<code>e</code>为空，则通过<code>initiaValue</code>函数获取初始值<code>value</code>，然后用<code>ThreadLocal</code>的引用和<code>value</code>作为<code>firstKey</code>和<code>firstValue</code>创建一个新的<code>Map</code></p>
<p>总结：<strong>先获取当前线程的ThreadLocalMap变量，如果存在则返回值，不存在则创建并返回初始值</strong>。</p>
<h2 id="43-remove方法">4.3 remove方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 删除当前线程中保存的 ThreadLocal 对应的实体 entry
 */
public void remove() {
    // 获取当前线程对象中维护的 ThreadLocalMap
    ThreadLocal.ThreadLocalMap m = getMap(Thread.currentThread());
    // 如果此 map 存在
    if (m != null)
        // 存在则调用 map.remove
        // 以当前 ThreadLocal 为 key 删除对应的实体 entry
        m.remove(this);
}

        /**
         * 移除 key 为给定值的 Entry 节点
         */
        private void remove(ThreadLocal&lt;?&gt; key) {
            // 暂存 Entry 数组
            Entry[] tab = table;
            int len = tab.length;
            // 获取当前 key 对应的 Entry 在数组中的位置
            int i = key.threadLocalHashCode &amp; (len-1);
            for (Entry e = tab[i];
                 e != null;
                 e = tab[i = nextIndex(i, len)]) {
                if (e.get() == key) {
                    e.clear();
                    expungeStaleEntry(i);
                    return;
                }
            }
        }
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线程，并根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则移除当前<code>ThreadLocal</code>对象对应的<code>Entry</code></p>
<h2 id="44-initialvalue方法">4.4 initialValue方法</h2>
<pre><code>/**
 * 返回当前线程对应的ThreadLocal的初始值
 * 
 * 此方法的第一次调用发生在，当线程通过get方法访问此线程的ThreadLocal值时
 * 除非线程先调用了set方法，在这种情况下，initialvalue 才不会被这个线程调用。
 * 通常情况下，每个线程最多调用一次这个方法。
 * &lt;p&gt;这个方法仅仅简单的返回nu11{@code nu11}；
 * 如果程序员想ThreadLocal线程局部变量有一个除nu11以外的初始值，
 * 必须通过子类继承{@code ThreadLocal}的方式去重写此方法
 * 通常，可以通过匿名内部类的方式实现
 * 
 * @return 当前 ThreadLocal 的初始值
 */
protected T initialValue() {
    return null;
}
</code></pre>
<p>此方法的作用是返回该线程局部变量的初始值。<br>
（1）这个方法是一个延迟调用方法，从面的代码我们得知，在<code>set</code>方法还未调用而先调用了<code>get</code>方法时才执行，并且仅执行1次。</p>
<p>（2）这个方法缺省实现直接返回一个<code>null</code>。</p>
<p>（3）如果想要一个除<code>null</code>之外的初始值，可以重写此方法。（备注：该方法是一个<code>protected</code>的方法，显然是为了让子类覆盖而设计的）</p>
<h1 id="五-threadlocalmap源码分析">五、ThreadLocalMap源码分析</h1>
<p>在分析<code>ThreadLocal</code>方法的时候，我们了解到<code>ThreadLocal</code>的操作实际上是围绕<code>ThreadLocalMap</code>展开的。</p>
<p><code>ThreadLocalMap</code>的源码相对比较复杂，我们从以下三个方面进行讨论。</p>
<h2 id="51基本结构">5.1基本结构</h2>
<p><code>ThreadLocalMap</code>是<code>ThreadLocal</code>的内部类，没有实现<code>Map</code>接口，用独立的方式实现了<code>Map</code>的功能，其内部的<code>Entry</code>也是独立实现。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/ThreadLocal%E7%9A%84UML.png" alt="图片" loading="lazy"></figure>
<p>（1）成员变量</p>
<pre><code>/**
 * 初始容量 - 必须是 2 的整次幂
 */
private static final int INITIAL_CAPACITY = 16;

/**
 * 存放数据的 table，Entry类的定义在下面分析
 * 同样，数组长度必须是 2 的整次幂。
 */
private ThreadLocal.ThreadLocalMap.Entry[] table;

/**
 * 数组里面 entrys 的个数，可以用于判断 table 当前使用量是否超过阈值
 */
private int size = 0;

/**
 * 进行扩容的阈值，表使用量大于它的时候进行扩容。
 */
private int threshold; // Default to 0
</code></pre>
<p>跟HashMap类似，<code>INITIAL_CAPACITY</code>代表这个<code>Map</code>的初始容量；<code>table</code>是一个<code>Entry</code>类型的数组，用于存储数据；<code>size</code>代表表中的存储数目；<code>threshold</code> 代表需要扩容时对应 <code>size</code>的阈值。<br>
（2）存储结构-Entry</p>
<pre><code>/**
 * Entry 继承 WeakReference，并且用 ThreadLocal 作为 key
 * 如果 key 为 null(entry.get() == null)，意味着 key 不再被引用，
 * 因此这时候 entry 也可以从 table 中清除
 */
static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal&lt;?&gt; k, Object v) {
        super(k);
        value = v;
    }
}
</code></pre>
<p>在<code>ThreadLocalMa</code>p中，也是用<code>Entry</code>来保存<code>K-V</code>结构数据的。不过<code>Entry</code>中的<code>key</code>只能是<code>ThreadLocal</code>对象，这点在构造方法中已经限定死了。<br>
另外，<code>Entry</code>继承<code>WeakReference</code>，也就是<code>key（ThreadLocal）</code>是弱引用，其目的是将<code>ThreadLocal</code>对象的生命周期和线程生命周期解绑。</p>
<h2 id="52弱引用和内存泄漏">5.2弱引用和内存泄漏</h2>
<p>有些程序员在使用<code>ThreadLocal</code>的过程中会发现有内存泄漏的情况发生，就猜测这个内存泄漏跟<code>Entry</code>中使用了<strong>弱引用</strong>的<code>key</code>有关系。这个理解其实是不对的。</p>
<p>我们先来回顾这个问题中涉及的几个名词概念，再来分析问题。</p>
<h3 id="1内存泄漏相关概念">（1）内存泄漏相关概念</h3>
<ul>
<li>Memory overflow：内存溢出，没有足够的内存提供申请者使用。</li>
<li>Memory leak：内存泄漏是指程序中<strong>己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费</strong>，导致程序运行速度减慢甚至系统溃等严重后果。内存泄漏的堆积终将导致内存溢出。</li>
</ul>
<h3 id="2弱引用相关概念">（2）弱引用相关概念</h3>
<p>Java中的引用有4种类型：强、软、弱、虚。当前这个问题主要涉及到强引用和弱引用：</p>
<p><strong>强引用</strong>（&quot;Strong”Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾回收器就不会回收这种对象。</p>
<p><strong>弱引用</strong>（WeakReference），垃圾回收器一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。</p>
<h3 id="3如果key使用强引用">（3）如果key使用强引用</h3>
<p>假设<code>ThreadLocalMap</code>中的<code>key</code>使用了强引用，那么会出现内存泄漏吗？</p>
<p>此时<code>ThreadLocal</code>的内存图（实线表示强引用）如下：</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/key%E5%BC%BA%E5%BC%95%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<p>1.假设在业务代码中使用完<code>ThreadLocal</code>，<code>ThreadLocal Ref</code>被回收了。</p>
<p>2.但是因为<code>ThreadLocalMap</code>的<code>Entry</code>强引用了<code>ThreadLocal</code>，造成<code>ThreadLocal</code>无法被回收。</p>
<p>3.在没有手动删除这个<code>Entry</code>以及<code>CurrentThread</code>依然运行的前提下，始终有强引用链<code>TthreadRef-&gt;CurrentThread-&gt;ThreadLocalMap-&gt;Entry</code>，<code>Entry</code>就不会被回收（<code>Entry</code>中包括了<code>ThreadLocal</code>实例和<code>value</code>），<strong>导致<code>Entry</code>内存泄漏</strong>。</p>
<p>也就是说，<code>ThreadLocalMap</code>中的<code>key</code>使用了强引用，是无法完全避免内存泄漏的。</p>
<h3 id="4如果key使用弱引用">（4）如果key使用弱引用</h3>
<p>那么<code>ThreadLocalMap</code>中的<code>key</code>使用了弱引用，会出现内存泄漏吗？此时<code>ThreadLocal</code>的内存图（实线表示强引用，虚线表示弱引用）如下：</p>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/key%E5%BC%B1%E5%BC%95%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<p>同样假设在业务代码中使用完<code>ThreadLocal</code>，<code>ThreadLocal Ref</code>被回收了。</p>
<p>由于<code>ThreadLocalMap</code>只持有<code>ThreadLocal</code>的弱引用，没有任何强引用指向<code>Threadlocal</code>实例，所以<code>Threadlocal</code>就可以顺利被<code>gc</code>回收，此时<code>Entry</code>中的<code>key=null</code>。</p>
<p>但是在没有手动删除这个<code>Entry</code>以及<code>CurrentThread</code>依然运行的前提下，也存在有强引用链 <code>ThreadRef -&gt;CurrentThread-&gt;ThreadLocalMap-&gt;Entry-&gt;value</code>，<code>value</code>不会被回收，而这块<code>value</code>永远不会被访问到了，<strong>导致<code>value</code>内存泄漏</strong>。</p>
<p>也就是说，<code>ThreadLocalMap</code>中的<code>key</code>使用了弱引用，也有可能内存泄漏。</p>
<h3 id="5出现内存泄漏的真实原因">（5）出现内存泄漏的真实原因</h3>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/ThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9C%9F%E6%AD%A3%E5%8E%9F%E5%9B%A0.png" alt="图片" loading="lazy"></figure>
<p>比较以上两种情况，我们就会发现，内存泄漏的发生跟<code>ThreadLocalMap</code>中的<code>key</code>是否使用弱引用是没有关系的。那么内存泄漏的的真正原因是什么呢？</p>
<p>细心的同学会发现，在以上两种内存泄漏的情况中，都有两个前提：</p>
<p>1.没有手动删除这个<code>Entry</code></p>
<p>2.<code>CurrentThread</code>依然运行</p>
<p>第一点很好理解，只要在使用完<code>ThreadLocal</code>，调用其<code>remove</code>方法删除对应的<code>Entry</code>，就能避免内存泄漏。第二点稍微复杂一点，由于<code>ThreadLocalMap</code>是<code>Thread</code>的一个属性，被当前线程所引用，所以它的生命周期跟<code>Thread</code>一样长。那么在使用完<code>ThreadLocal</code>的使用，如果当前<code>Thread</code>也随之执行结束，<code>ThreadLocalMap</code>自然也会被<code>gc</code>回收，从根源上避免了内存泄漏。</p>
<p>综上，<code>ThreadLocal</code>内存泄漏的根源是：由于<code>ThreadLocalMap</code>的生命周期跟<code>Thread</code>一样长，如果没有手动删除对应<code>key</code>就会导致内存泄漏。</p>
<h3 id="6为什么使用弱引用">（6）为什么使用弱引用</h3>
<p>根据刚才的分析，我们知道了：无论使用<code>ThreadLocalMap</code>中的<code>key</code>使用哪种类型引用都无法完全避免内存泄漏，跟使用弱引用没有关系。要避免内存泄漏有两种方式：</p>
<p>1.使用完<code>ThreadLocal</code>，调用其<code>remove</code>方法删除对应的<code>Entry</code></p>
<p>2.使用完<code>ThreadLocal</code>，当前<code>Thread</code>也随之运行结束</p>
<p>相对第一种方式，第二种方式显然更不好控制，特别是使用线程池的时候，线程结束是不会销毁的。</p>
<p>也就是说，只要记得在使用完<code>ThreadLocal</code>及时的调用<code>remove</code>，无论<code>key</code>是强引用还是弱引用都不会有问题。</p>
<p><strong>那么为什么key要用弱引用呢？</strong></p>
<p>事实上，在<code>ThreadLocalMap</code>中的<code>set/getEntry</code>方法中，会对<code>key</code>为<code>nul</code>（也即是<code>ThreadLocal</code>为<code>null</code>）进行判断，如果为<code>null</code>的话，那么是会对<code>value</code>置为<code>null</code>的。</p>
<p>这就意味着使用完<code>ThreadLocal</code>，<code>CurrentThread</code>依然运行的前提下，就算忘记调用<code>remove</code>方法，弱引用比强引用可以多一层保障：弱引用的<code>ThreadLocal</code>会被回收，对应的<code>value</code>在下一次<code>ThreadLocalMap</code>调用<code>set</code>，<code>get</code>，<code>remove</code>中的任一方法的时候会被清除，从而避免内存泄漏。</p>
<h2 id="43hash冲突的解决">4.3hash冲突的解决</h2>
<p><code>hash</code>冲突的解决是<code>Map</code>中的一个重要内容。我们以<code>hash</code>冲突的解决为线索，来研究一下<code>ThreadLocalMap</code>的核心源码。</p>
<h3 id="1首先从threadlocal的set方法入手">（1）首先从ThreadLocal的set(）方法入手</h3>
<pre><code>public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<p>这个方法我们刚才分析过，其作用是设置当前线程绑定的局部变量：<br>
A.首先获取当前线程，并根据当前线程获取一个<code>Map</code></p>
<p>B.如果获取的<code>Map</code>不为空，则将参数设置到<code>Map</code>中（当前<code>ThreadLocal</code>的引用作为<code>key</code>）</p>
<p>（这里调用了<code>ThreadLocalMap</code>的<code>set</code>方法）</p>
<p>C.如果<code>Map</code>为空，则给该线程创建<code>Map</code>，并设置初始值</p>
<p>（这里调用了<code>ThreadLocalMap</code>的构造方法）</p>
<h3 id="2构造方法threadlocalmapthreadlocal-firstkey-object-firstvalue">（2）构造方法ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue)</h3>
<pre><code>/**
 * @param firstKey 本地 ThreadLocal 实例(this)
 * @param firstValue 要保存的线程本地变量
 */
ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) {
    // 初始化 table
    table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY];
    // 计算索引（重点代码）
    int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);
    // 设置值
    table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue);
    size = 1;
    // 设置阈值
    setThreshold(INITIAL_CAPACITY);
}
</code></pre>
<p>构造函数首先创建一个长度为16的<code>Entry</code>数组，然后计算出<code>firstKey</code>对应的索引，然后存储到<code>table</code>中，并设置<code>size</code>和<code>threshold</code>。<br>
重点分析：<code>int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);</code></p>
<p>a.关于<code>firstkey.threadLocalHashcode</code>：</p>
<pre><code>private final int threadLocalHashCode = nextHashCode();
private static int nextHashCode() {
    return nextHashCode.getAndAdd(HASH_INCREMENT);
}
// AtomicInteger 是一个提供原子操作的 Integer类，通过线程安全的方式操作加减，适合高并发情况下的使用
private static AtomicInteger nextHashCode =
    new AtomicInteger();
// 特殊的 hash 值
private static final int HASH_INCREMENT = 0x61c88647;
</code></pre>
<p>这里定义了一个<code>Atomiclnteger</code>类型，每次获取当前值并加上<code>HASH_INCREMENT</code>，<code>HASH_INCREMENT=0x61c88647</code>，这个值跟斐波那契数列（黄金分割数）有关，其主要目的就是为了让哈希码能均匀的分布在2的n次方的数组里，也就是<code>Entry[]]table</code>中，这样做可以尽量避免<code>hash</code>冲突。</p>
<p>b.关于<code>&amp;（INITIAL_CAPACITY-1）</code></p>
<p>计算<code>hash</code>的时候里面采用了<code>hashCode&amp;(size-1)</code>的算法，这相当于取模运算<code>hashCode%size</code>的一个更高效的实现。正是因为这种算法，我们要求<code>size</code>必须是2的整次幂，这也能保证保证在索引不越界的前提下，使得<code>hash</code>发生冲突的次数减小。</p>
<h3 id="3threadlocalmap中的set方法">（3）ThreadLocalMap中的set方法</h3>
<pre><code>private void set(ThreadLocal&lt;?&gt; key, Object value) {

    // We don't use a fast path as with get() because it is at
    // least as common to use set() to create new entries as
    // it is to replace existing ones, in which case, a fast
    // path would fail more often than not.

    ThreadLocal.ThreadLocalMap.Entry[] tab = table;
    int len = tab.length;
    // 计算索引（重点代码）
    int i = key.threadLocalHashCode &amp; (len-1);

    /**
     * 使用线性探测法查找元素（重点代码）
     */
    for (ThreadLocal.ThreadLocalMap.Entry e = tab[i];
         e != null;
         e = tab[i = nextIndex(i, len)]) {
        ThreadLocal&lt;?&gt; k = e.get();
        // ThreadLocal 对应的 key 存在，直接覆盖之前的值
        if (k == key) {
            e.value = value;
            return;
        }

        // key 为 null，但是值不为 null，说明之前的 ThreadLocal 对象已经被回收了
        // 当前数组中的 Entry 是一个陈旧（stale）的元素
        if (k == null) {
            // 用新元素替换旧元素，这个方法进行了不少的垃圾清理动作，防止内存泄漏
            replaceStaleEntry(key, value, i);
            return;
        }
    }
    //ThreadLocal对应的key不存在并且没有找到陈旧的元素，则在空元素的位置创建一个新的Entry。
    tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value);
    int sz = ++size;
    /**
     * cleanSomeslots用于清除那些e.get()==nu11的元素，
     * 这种数据key关联的对象已经被回收，所以这个Entry（table[index]）可以被置nu11。
     * 如果没有清除任何entry，并且当前使用量达到了负载因子所定义（长度的2/3），那么进行
     * rehash（执行一次全表的扫描清理工作）
     */
    if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
        rehash();
}
// 获取环形数组的下一个索引
private static int nextIndex(int i, int len) {
    return ((i + 1 &lt; len) ? i + 1 : 0);
}
</code></pre>
<p>代码执行流程：<br>
A.首先还是根据<code>key</code>计算出索引i，然后查找位置上的<code>Entry</code>，<br>
B.若是<code>Entry</code>已经存在并且<code>key</code>等于传入的<code>key</code>，那么这时候直接给这个<code>Entry</code>赋新的<code>value</code>值<br>
C.若是<code>Entry</code>存在，但是<code>key</code>为<code>null</code>，则调用<code>replaceStaleEntry</code>来更换这个<code>key</code>为空的<code>Entry</code>，<br>
D.不断循环检测，直到遇到为<code>null</code>的地方，这时候要是还没在循环过程中<code>return</code>，那么就在这个<code>null</code>的位置新建一个<code>Entry</code>，并且插入，同时<code>size</code>增加1。</p>
<p>最后调用<code>cleanSomeSlots</code>，清理<code>key</code>为<code>null</code>的<code>Entry</code>，最后返回是否清理了<code>Entry</code>，接下来再判断<code>size</code>是否<code>&gt;=thresgold</code>达到了<code>rehash</code>的条件，达到的话就会调用<code>rehash</code>函数执行一次全表的扫描清理。</p>
<p><strong>重点分析</strong>：<code>ThreadLocalMap</code>使用<strong>线性探测法</strong>来解决哈希冲突的。</p>
<p>该方法一次探测下一个地址，直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出。</p>
<p>举个例子，假设当前<code>table</code>长度为16，也就是说如果计算出来<code>key</code>的<code>hash</code>值为14，如果<code>table</code>[14]上已经有值，并且其<code>key</code>与当前<code>key</code>不一致，那么就发生了<code>hash</code>冲突，这个时候将14+1得到15，取table[15]进行判断，这个时候如果还是冲突会回到0，取table[0]，以此类推，直到可以插入。</p>
<p>按照上面的描述，可以把<code>Entry[]table</code>看成一个环形数组。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Java 并发]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/">
        </link>
        <updated>2020-03-31T14:58:28.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java 并发的东西比较多，今天先总结一部分。</p>
</blockquote>
<h1 id="1什么是线程和进程">1.什么是线程和进程？</h1>
<ul>
<li>进程是 OS 资源分配的基本单位。进程拥有独立的虚拟地址空间。</li>
<li>线程是 CPU 调度的基本单位。线程共享进程的堆、方法区资源，但每个线程有自己的程序计数器、虚拟机栈、本地方法栈。</li>
</ul>
<h1 id="2并发和并行的区别">2.并发和并行的区别？</h1>
<ul>
<li>并发：统一时间段内，多个任务都在执行。</li>
<li>并行：同一时间内，多个任务同时执行。</li>
</ul>
<h1 id="3为什么要使用多线程">3.为什么要使用多线程？</h1>
<p>先从总体上来说：</p>
<ul>
<li>从计算机底层来说：线程可以比作是轻量级的进程，是程序执行的最小单位，<strong>线程间的切换和调度的成本远远小于进程</strong>另外，多核CPU时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。</li>
<li>从当代互联网发展趋势来说：现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。</li>
</ul>
<p>再深入到计算机底层来探讨：</p>
<ul>
<li>单核时代：在单核时代多线程主要是为了提高CPU和IO设备的综合利用率。举个例子：当只有一个线程的时候会导致CPU计算时，IO设备空闲；进行IO操作时，CPU空闲。我们可以简单地说这两者的利用率目前都是50%左右。但是当有两个线程的时候就不一样了，当一个线程执行CPU计算时，另外一个线程可以进行IO操作，这样两个的利用率就可以在理想情况下达到100%了。</li>
<li>多核时代：多核时代多线程主要是为了<strong>提高CPU利用率</strong>。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU只会一个CPU核心被利用到，而创建多个线程就可以让多个CPU核心被利用到，这样就提高了CPU的利用率。</li>
</ul>
<h1 id="4创建线程的方式">4.创建线程的方式</h1>
<ul>
<li>实现 Runnable 接口</li>
</ul>
<pre><code>// 1. 实现 Runnable 接口
class MyRunnable implements Runnbale{
  // 2. 实现 run 方法
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  // 3. 使用自定义 runnable 对象创建线程
  MyRunnable runnable = new MyRunnable();
  Thread thread = new Thread(runnable);
  // 4. start() 启动线程
  thread.start();
}
</code></pre>
<ul>
<li>实现 Callable 接口</li>
</ul>
<p>与 Runnable 相比，Callable 可以有返回值，返回值由 FutureTask 进行封装。</p>
<pre><code>// 1. 实现 Callable 接口，并声明泛型
class MyCallable implements Callable&lt;Integer&gt;{
  // 2. 重写 call 方法
  public Integer call(){
    return 123;
  }
}
</code></pre>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException{
  MyCallable callable = new MyCallable();
  // 3. 使用 FutureTask 封装 call 方法的返回值
  FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(callable);
  Thread thread = new Thread(ft);
  thread.start();
  System.out.println(ft.get());
}
</code></pre>
<ul>
<li>继承 Thread 类</li>
</ul>
<pre><code>class MyThread extends Thread{
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  MyThread thread = new MyThread();
  thread.start();
}
</code></pre>
<h2 id="继承-vs-实现接口">继承 vs 实现接口</h2>
<p>实现接口更好一些，因为：</p>
<ul>
<li>Java 不支持多重继承，因此继承了 Thread 类就无法集成其它类，但是可以实现多个接口。</li>
<li>适合多个线程进行资源共享（Runnable 类可以作为多个 Thread 构造方法的参数）</li>
<li>线程池内只能放入 Runnable 或 Callable 接口的实现类，不能放入继承 Thread 对象的类。</li>
</ul>
<h1 id="5runnable-接口和-callable-接口的区别">5.Runnable 接口和 Callable 接口的区别</h1>
<ul>
<li>Runnable 接口重写的是 run 方法，Callable 接口重写的是 call 方法</li>
<li>run 方法执行后不能有返回值，call 方法执行后可以有返回值。</li>
<li>call()方法可以抛出异常，run()方法不可以</li>
<li>运行Callable任务可以拿到一个Future对象，表示异步计算的结果 。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</li>
</ul>
<h1 id="6start-方法和-run-方法的区别">6.start() 方法和 run() 方法的区别</h1>
<p>new 一个 Thread，线程进入了新建状态</p>
<ul>
<li>start() 方法可以启动一个线程，将线程由新建状态切换到就绪态。</li>
<li>run() 方法不会启动一个线程，只会把它当做一个普通方法去执行。</li>
</ul>
<h1 id="7sleep-方法和-wait-方法有什么区别">7.sleep 方法和 wait 方法有什么区别？</h1>
<ul>
<li>wait() 是 Object 类的方法，而 sleep() 是 Thread 的静态方法。</li>
<li>sleep 和 wait 方法都可以用来放弃 CPU 一定时间，<strong>暂停线程的执行</strong>。</li>
<li><strong>是否释放锁</strong>：两者最主要的区别在于：sleep 方法不会释放锁，而 wait 方法会释放锁。</li>
<li><strong>用途</strong>：wait 通常用于线程间交互 / 通信，sleep 通常被用于暂停执行。</li>
<li><strong>是否会自动苏醒</strong>：wait 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。</li>
</ul>
<h1 id="8reentrantlock-和-synchronized-的比较">8.ReentrantLock 和 synchronized 的比较</h1>
<ul>
<li>锁的实现</li>
</ul>
<p>synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。</p>
<ul>
<li>性能</li>
</ul>
<p>新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 和 ReentrantLock 大致相同。</p>
<ul>
<li>等待可中断</li>
</ul>
<p>当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。</p>
<p>ReentrantLock 可中断，而 synchronized 不行。</p>
<ul>
<li>公平锁</li>
</ul>
<p>公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。</p>
<p>synchronized 是不公平锁，而 ReentrantLock 默认情况下也是非公平的，但是可以在构造函数中设置公平还是不公平锁。</p>
<ul>
<li>锁绑定多个条件</li>
</ul>
<p>一个 ReentrantLock 可以同时绑定多个 Conditino 对象</p>
<ul>
<li>使用选择</li>
</ul>
<p>除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一 种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。</p>
<h1 id="9cyclicbarrier和countdownlatch的区别">9.CyclicBarrier和CountDownLatch的区别</h1>
<h2 id="countdownlatch">CountDownLatch</h2>
<p>用来控制一个线程等待多个线程。</p>
<p>维护了一个计数器 cnt，<strong>每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒</strong>。</p>
<h2 id="cyclicbarrier">CyclicBarrier</h2>
<p>用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。</p>
<p>和 CountdownLatch 相似，都是通过维护计数器来实现的。<strong>线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行</strong>。</p>
<p>CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做<strong>循环屏障</strong>。</p>
<p>CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。</p>
<h1 id="10semaphore有什么作用">10.Semaphore有什么作用</h1>
<p>Semaphore就是一个信号量，它的作用是<strong>限制某段代码块的并发数</strong>。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。</p>
<h1 id="11volatile关键字的作用">11.volatile关键字的作用</h1>
<ul>
<li>保证了可见性，不能保证原子性</li>
</ul>
<p>立刻将缓存中的值写到内存；线程通过嗅探总线上传播过来的数据监测自己的缓存是否过期了，如果过期了，就把缓存内的值设置为失效，如果要修改时，就去主存读取新值。</p>
<ul>
<li>禁止指令重排</li>
</ul>
<h1 id="12使用-blockingqueue-生产者消费者问题">12.使用 BlockingQueue 生产者消费者问题</h1>
<pre><code>public class ProductConsumer{
  private static BlockingQueue&lt;String&gt; queue = new BlockingQueue&lt;&gt;();
  private static class Producer extends Thread{
    @Override
    public void run(){
      try{
        queue.put(&quot;product&quot;);
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;produce...&quot;);
    }
  }
  private static class Consumer extends Thread{
    @Override
    public void run(){
      try{
        String product = queue.take();
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;consume...&quot;)
    }
  }
  public static void main(String[] args) {
  for (int i = 0; i &lt; 2; i++) {
    Producer producer = new Producer();
    producer.start();
  }
  for (int i = 0; i &lt; 5; i++) {
    Consumer consumer = new Consumer();
    consumer.start();
  }
  for (int i = 0; i &lt; 3; i++) {
    Producer producer = new Producer();
    producer.start();
  } 
}
</code></pre>
<p>运行结果：</p>
<pre><code>produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. 
</code></pre>
<h1 id="13一个线程如果出现了运行时异常会怎么样">13.一个线程如果出现了运行时异常会怎么样</h1>
<p>如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：<strong>如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放</strong></p>
<h1 id="14threadlocal有什么用">14.ThreadLocal有什么用</h1>
<p>线程局部变量，<strong>以空间换时间</strong>，每个线程内都有一个，把数据进行隔离，解决多线程之间共享数据的安全问题。</p>
<h1 id="15wait方法和notifynotifyall方法在放弃对象监视器时有什么区别">15.wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别</h1>
<p>wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：<strong>wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器</strong>。</p>
<h1 id="16为什么要使用线程池">16.为什么要使用线程池</h1>
<p>来一个请求创建一个线程，执行结束再销毁线程，资源耗费太大，使用线程池达到对<strong>线程的复用</strong>。使用线程池还可以灵活地控制并发的数目。</p>
<h1 id="17怎么检测一个线程是否持有对象监视器">17.怎么检测一个线程是否持有对象监视器</h1>
<p>我也是在网上看到一道多线程面试题才知道有方法可以判断某个线程是否持有对象监视器：Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着&quot;某条线程&quot;指的是当前线程。</p>
<h1 id="18concurrenthashmap的并发度是什么">18.ConcurrentHashMap的并发度是什么</h1>
<p>ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？</p>
<h1 id="19futuretask是什么">19.FutureTask是什么</h1>
<p>在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。</p>
<pre><code>public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 
public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 
</code></pre>
<p>FutureTask 可用<strong>于异步获取执行结果</strong>或<strong>取消执行任务的场景</strong>。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。</p>
<h1 id="20aqs">20.AQS</h1>
<ol>
<li>概念</li>
</ol>
<ul>
<li>AbstractQueuedSynchronizer</li>
<li>同步发生器</li>
<li>构建 LOCK</li>
<li>JUC：java.util.current</li>
</ul>
<ol start="2">
<li>基本思想</li>
</ol>
<ul>
<li>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</li>
<li>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。</li>
</ul>
<p>CLH同步队列</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/CLH%E5%90%8C%E6%AD%A5%E9%98%9F%E5%88%97.png" alt="图片" loading="lazy"></figure>
<p>AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。</p>
<pre><code>private volatile int state;//共享变量，使用volatile修饰保证线程可见性
</code></pre>
<p>状态信息通过 protected 类型的getState，setState，compareAndSetState进行操作</p>
<pre><code>//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
</code></pre>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md</a><br>
<a href="https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg">https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg</a><br>
<a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/AQS.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/AQS.md</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[记一个面试题 —— Redis 一启动挂了怎么办]]></title>
        <id>https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-redis-yi-qi-dong-gua-liao-zen-me-ban/</id>
        <link href="https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-redis-yi-qi-dong-gua-liao-zen-me-ban/">
        </link>
        <updated>2020-03-30T08:43:04.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>面试官：Redis 一启动就挂了怎么办？<br>
答：添加 Redis 集群</p>
</blockquote>
<h1 id="集群简介">集群简介</h1>
<h2 id="现状问题">现状问题</h2>
<h3 id="业务发展过程中遇到的峰值瓶颈">业务发展过程中遇到的峰值瓶颈</h3>
<ul>
<li>redis提供的服务OPS可以达到10万/秒，当前业务OPS已经达到20万/秒</li>
<li>内存单机容量达到256G，当前业务需求内存容量1T</li>
<li>使用集群的方式可以快速解决上述问题</li>
</ul>
<h2 id="集群架构">集群架构</h2>
<ul>
<li>集群就是使用网络将若干台计算机联通起来，并提供统一的管理方式，使其对外呈现单机的服务效果</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<h2 id="集群作用">集群作用</h2>
<ul>
<li>分散单台服务器的访问压力，实现负载均衡</li>
<li>分散单台服务器的存储压力，实现可扩展性</li>
<li>降低单台服务器宕机带来的业务灾难</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E4%BD%9C%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<h1 id="redis集群结构设计">Redis集群结构设计</h1>
<h2 id="数据存储设计"><strong>数据存储设计</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>一个 key 放在 Redis 存储空间：单机方案。<br>
一个 key 对应多个存储空间，变成多台计算机了，应该怎样存储呢？</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A82.png" alt="图片" loading="lazy"></figure>
<ul>
<li>通过算法设计，计算出key应该保存的位置</li>
<li>将所有的存储空间计划切割成16384份，每台主机保存一部分
<ul>
<li>每份代表的是一个存储空间，不是一个key的保存空间</li>
</ul>
</li>
<li>将key按照计算出的结果放到对应的存储空间</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A83.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在有三个存储空间，突然又增加了一个存储空间。把原来的三个 Redis 存储空间都进行优化，每个存储空间拿出一部分给新的存储空间</p>
</blockquote>
<ul>
<li>增强可扩展性</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A85.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>旧的存储空间给新的存储空间 的 这一小块空间（也就是前面标记的37）叫做槽，用来放数据的空间区域。所谓的增加、删除 Redis 存储空间就是：改变槽所存储的位置不同。<br>
槽更换位置后，如何知道它被换到哪里了呢？<br>
内部通讯设计</p>
</blockquote>
<h2 id="集群内部通讯设计"><strong>集群内部通讯设计</strong></h2>
<ul>
<li>各个数据库相互通信，保存各个库中槽的编号数据</li>
<li>一次命中，直接返回</li>
<li>一次未命中，告知具体位置</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在有 A、B、C 三个机器互联，三个机器存储好了以后，会进行互联，互联的目的：谁那有什么样的东西一清二楚。每一台计算机都有一个账本，存储各个计算机里对应的存储空间的槽是几到几。</p>
</blockquote>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A12.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在来了一台计算机，发出一个 key 要访问 Redis，key 通过两个算法计算后得到 key 对应的存储槽在哪里，假定它访问的就是 A，一次命中，直接返回。假设它没有命中，会根据这个 key 对应的槽位置在 A 的小本子里面找，发现这个东西在 B 里面，于是就让这个 key 去 B 里面找，不是 A 去 B 里面找，而是这个连接请求客户端直接去 B 里面找。</p>
</blockquote>
<p>key 加密就是为了确定存储位置，保证最多两次命中</p>
<h2 id="总结">总结</h2>
<p>集群内存存储结构设计：</p>
<p>1.槽用来区分数据存储空间</p>
<p>2.key 加密后确定存储的位置</p>
<p>3.一次命中或两次命中就可以找到数据</p>
<h1 id="cluster集群结构搭建">cluster集群结构搭建</h1>
<h2 id="搭建方式">搭建方式</h2>
<ul>
<li>原生安装（单条命令）
<ul>
<li>配置服务器（3主3从）</li>
<li>建立通信（Meet）</li>
<li>分槽（Slot）</li>
<li>搭建主从（master-slave）</li>
</ul>
</li>
<li>工具安装（批处理）</li>
</ul>
<h2 id="cluster节点操作命令">Cluster节点操作命令</h2>
<ul>
<li>查看集群节点信息</li>
</ul>
<pre><code>cluster nodes 
</code></pre>
<ul>
<li>进入一个从节点 redis，切换其主节点</li>
</ul>
<pre><code>cluster replicate &lt;master-id&gt; 
</code></pre>
<ul>
<li>发现一个新节点，新增主节点</li>
</ul>
<pre><code>cluster meet ip:port 
</code></pre>
<ul>
<li>忽略一个没有solt的节点</li>
</ul>
<pre><code>cluster forget &lt;id&gt; 
</code></pre>
<ul>
<li>手动故障转移</li>
</ul>
<pre><code>cluster failover
</code></pre>
<h2 id="redis-trib命令">redis-trib命令</h2>
<ul>
<li>添加节点</li>
</ul>
<pre><code>redis-trib.rb add-node 
</code></pre>
<ul>
<li>删除节点</li>
</ul>
<pre><code>redis-trib.rb del-node 
</code></pre>
<ul>
<li>重新分片</li>
</ul>
<pre><code>redis-trib.rb reshard
</code></pre>
<h2 id="cluster配置">Cluster配置</h2>
<ul>
<li>添加节点</li>
</ul>
<pre><code>cluster-enabled yes|no 
</code></pre>
<ul>
<li>cluster配置文件名，该文件属于自动生成，仅用于快速查找文件并查询文件内容</li>
</ul>
<pre><code>cluster-config-file &lt;filename&gt; 
</code></pre>
<ul>
<li>节点服务响应超时时间，用于判定该节点是否下线或切换为从节点</li>
</ul>
<pre><code>cluster-node-timeout &lt;milliseconds&gt; 
</code></pre>
<ul>
<li>master连接的slave最小数量</li>
</ul>
<pre><code> cluster-migration-barrier &lt;count&gt;
</code></pre>
<ol>
<li>修改 redis.conf 配置文件</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# vim redis-6379.conf 
port 6379
daemonize no
#logfile &quot;6379.log&quot;
dir &quot;/root/redis-5.0.7/data&quot;
dbfilename &quot;dump-6379.rdb&quot;
rdbcompression yes
rdbchecksum yes
appendonly yes
appendfsync everysec
appendfilename &quot;appendonly-6379.aof&quot;
bind 127.0.0.1
databases 16

cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 10000
</code></pre>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6380/g&quot; redis-6379.conf &gt; redis-6380.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6381/g&quot; redis-6379.conf &gt; redis-6381.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6382/g&quot; redis-6379.conf &gt; redis-6382.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6383/g&quot; redis-6379.conf &gt; redis-6383.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6384/g&quot; redis-6379.conf &gt; redis-6384.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6385/g&quot; redis-6379.conf &gt; redis-6385.conf 
</code></pre>
<ol>
<li>启动 redis 客户端</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6379.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6380.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6381.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6382.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6383.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6384.conf 
</code></pre>
<ol>
<li>每个 reids 服务都以 cluster 节点呈现</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# ps -ef | grep redis-
root      9015  8373  0 18:44 pts/1    00:00:00 redis-server 127.0.0.1:6379 [cluster]
root      9019  8430  0 18:44 pts/5    00:00:00 redis-server 127.0.0.1:6380 [cluster]
root      9023  8411  0 18:45 pts/4    00:00:00 redis-server 127.0.0.1:6381 [cluster]
root      9028  8469  0 18:45 pts/6    00:00:00 redis-server 127.0.0.1:6382 [cluster]
root      9033  8488  0 18:45 pts/7    00:00:00 redis-server 127.0.0.1:6383 [cluster]
root      9037  8507  0 18:46 pts/8    00:00:00 redis-server 127.0.0.1:6384 [cluster]
root      9045  8545  0 18:46 pts/10   00:00:00 grep --color=auto redis-
</code></pre>
<ol>
<li>把这些  cluster 节点 连接在一起</li>
</ol>
<p>redis5.0之前的版本需要部署 ruby 和 gem：<a href="https://blog.51cto.com/wujianwei/2460638">部署ruby环境遇到的坑</a></p>
<p>redis5.0以上的版本可以使用redis-cli命令</p>
<p><a href="https://juejin.im/post/5d16206b518825597909b5f9">https://juejin.im/post/5d16206b518825597909b5f9</a></p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z redis-5.0.7]# src/redis-cli --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 --cluster-replicas 1
// --cluster-replicas 1：一个 master 连接一个 slave；2：一个 master 连接两个 slave
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="图片" loading="lazy"></figure>
<p>输入 yes 重写配置文件后：</p>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C2.png" alt="图片" loading="lazy"></figure>
<h2 id="解析-master-和-slave-日志信息">解析 master 和 slave 日志信息</h2>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4master%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master：6379 日志</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4slave%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave：6382 日志</p>
<h2 id="设置与获取数据">设置与获取数据</h2>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli
127.0.0.1:6379&gt; set name itheima   // 把 name 对应的 key 进行转化后，对应的槽在 6380，不能在 6379 set
(error) MOVED 5798 127.0.0.1:6380 
127.0 .0.1:6379&gt; set lll sss      //  lll 对应的 key 进行转化后，对应的槽在 6379，所以此处 set 成功
OK

[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli -c   // -c 专门用来操作 cluster 集群的
127.0.0.1:6379&gt; set name itheima
-&gt; Redirected to slot [5798] located at 127.0.0.1:6380  // 重定向到 5798 这个槽，这个槽在 6380 下
OK
127.0.0.1:6380&gt; get name
&quot;itheima&quot;
[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli -c -p 6382
127.0.0.1:6382&gt; get name
-&gt; Redirected to slot [5798] located at 127.0.0.1:6380
&quot;itheima&quot;
127.0.0.1:6380&gt; 
</code></pre>
<h2 id="主从下线与主从切换">主从下线与主从切换</h2>
<h3 id="slave6382-下线">slave:6382 下线</h3>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/slave%E4%B8%8B%E7%BA%BF%E4%B8%BB%E8%8A%82%E7%82%B9%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6381（slave:6382 的 master） 日志打印</p>
<figure data-type="image" tabindex="14"><img src="https://epitomm.github.io/post-images/slave%E4%B8%8B%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6379 日志打印</p>
<h3 id="slave6382-重新上线">slave:6382 重新上线</h3>
<figure data-type="image" tabindex="15"><img src="https://epitomm.github.io/post-images/slave%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6381（slave:6382 的 master） 日志打印<br>
<img src="https://epitomm.github.io/post-images/%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E7%9A%84master%E5%8F%98%E6%88%90slave%E4%BA%86.png" alt="图片" loading="lazy"></p>
<p>master:6379 日志打印</p>
<h3 id="master6379-下线">master:6379 下线</h3>
<figure data-type="image" tabindex="16"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BFslave%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave:6383（master:6379 的 slave）日志打印</p>
<p>查看 cluster 信息：</p>
<figure data-type="image" tabindex="17"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BFcluster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave:6383 自己当 master</p>
<h3 id="master6379-重新上线">master:6379 重新上线</h3>
<figure data-type="image" tabindex="18"><img src="https://epitomm.github.io/post-images/master%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p><strong>master:6383</strong>（slave:6379 的 master） 日志信息</p>
<figure data-type="image" tabindex="19"><img src="https://epitomm.github.io/post-images/%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E7%9A%84master%E5%8F%98%E6%88%90slave%E4%BA%86.png" alt="图片" loading="lazy"></figure>
<p>再次上线的 6379 变成 slave 了</p>
<h1 id="总结-2">总结</h1>
<p><strong>集群</strong></p>
<ul>
<li>集群简介</li>
<li>集群结构</li>
<li>cluster集群结构搭建</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试常问之缓存预热、缓存雪崩、缓存击穿、缓存穿透]]></title>
        <id>https://epitomm.github.io/post/mian-shi-chang-wen-zhi-huan-cun-chuan-tou-huan-cun-xue-beng/</id>
        <link href="https://epitomm.github.io/post/mian-shi-chang-wen-zhi-huan-cun-chuan-tou-huan-cun-xue-beng/">
        </link>
        <updated>2020-03-30T01:33:36.000Z</updated>
        <content type="html"><![CDATA[<h1 id="缓存预热">缓存预热</h1>
<h2 id="宕机">“宕机”</h2>
<p>服务器<strong>启动后迅速宕机</strong></p>
<h2 id="问题排查">问题排查</h2>
<ol>
<li>
<p>请求数量较高</p>
</li>
<li>
<p>主从之间数据吞吐量较大（不停地加载数据），数据同步操作频度较高</p>
</li>
</ol>
<blockquote>
<p>数据库读的频度高：服务器一启动，缓存中没有数据，自然就会给服务器带来压力，这时候如果请求比较多的话，redis 服务器就会宕机。</p>
</blockquote>
<h2 id="解决方案">解决方案</h2>
<p>前置准备工作：</p>
<ol>
<li>日常例行统计数据访问记录，统计访问频度较高的热点数据</li>
<li>利用LRU数据删除策略，构建数据留存队列
<ul>
<li>例如：storm与kafka配合</li>
</ul>
</li>
</ol>
<p>准备工作：</p>
<ol start="3">
<li>将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据</li>
<li>利用分布式多服务器同时进行数据读取，提速数据加载过程</li>
</ol>
<p>实施：</p>
<ol>
<li>使用脚本程序固定触发数据预热过程</li>
<li>如果条件允许，使用了CDN（内容分发网络），效果会更好</li>
</ol>
<h2 id="总结">总结</h2>
<p>缓存预热就是系统启动前，<strong>提前将相关的缓存数据直接加载到缓存系统</strong>。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p>
<h1 id="缓存雪崩">缓存雪崩</h1>
<h2 id="数据库服务器崩溃1">数据库服务器崩溃（1）</h2>
<ol>
<li>系统平稳运行过程中，忽然数据库连接量激增</li>
<li>应用服务器无法及时处理请求</li>
<li>大量408，500错误页面出现</li>
<li>客户反复刷新页面获取数据</li>
<li>数据库崩溃</li>
<li>应用服务器崩溃</li>
<li>重启应用服务器无效</li>
<li>Redis服务器崩溃</li>
<li>Redis集群崩溃</li>
<li>重启数据库后再次被瞬间流量放倒</li>
</ol>
<h2 id="问题排查-2">问题排查</h2>
<ol>
<li>在一个<span style="color:red">较短</span>的时间内，缓存中较多的<span style="color:red">key集中过期 </span></li>
<li>此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据</li>
<li>数据库同时接收到大量的请求无法及时处理</li>
<li>Redis大量请求被积压，开始出现超时现象</li>
<li>数据库流量激增，数据库崩溃</li>
<li>重启后仍然面对缓存中无数据可用</li>
<li>Redis服务器资源被严重占用，Redis服务器崩溃</li>
<li>Redis集群呈现崩塌，集群瓦解</li>
<li>应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃</li>
<li>应用服务器，redis，数据库全部重启，效果不理想</li>
</ol>
<h2 id="问题分析">问题分析</h2>
<ul>
<li>短时间范围内</li>
<li>大量key集中过期</li>
</ul>
<h2 id="解决方案道">解决方案（道）</h2>
<ol>
<li>更多的页面静态化处理</li>
<li>构建多级缓存架构</li>
</ol>
<ul>
<li>Nginx缓存+redis缓存+ehcache缓存</li>
</ul>
<ol start="3">
<li>检测Mysql严重耗时业务进行优化</li>
</ol>
<ul>
<li>对数据库的瓶颈排查：例如超时查询、耗时较高事务等</li>
</ul>
<ol start="4">
<li>灾难预警机制</li>
</ol>
<ul>
<li>监控redis服务器性能指标
<ul>
<li>CPU占用、CPU使用率</li>
<li>内存容量</li>
<li>查询平均响应时间</li>
<li>线程数</li>
</ul>
</li>
</ul>
<ol start="5">
<li>限流、降级</li>
</ol>
<ul>
<li>短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问</li>
</ul>
<h2 id="解决方案术">解决方案（术）</h2>
<ol>
<li>LRU与LFU切换</li>
<li>数据有效期策略调整</li>
</ol>
<ul>
<li>根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟</li>
<li>过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量</li>
</ul>
<ol start="3">
<li>超热数据使用永久key</li>
<li>定期维护（自动+人工）</li>
</ol>
<ul>
<li>对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时</li>
</ul>
<ol start="5">
<li>加锁</li>
</ol>
<ul>
<li>慎用！</li>
</ul>
<h2 id="总结-2">总结</h2>
<p>缓存雪崩就是<strong>瞬间过期数据量太大</strong>，导致对数据库服务器造成压力。如能够有<strong>效避免过期时间集中</strong>，可以有效解决雪崩现象的出现 （约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>大量 key 集中过期，更多向 mysql 发起请求</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-2.png" alt="图片" loading="lazy"></figure>
<h1 id="缓存击穿">缓存击穿</h1>
<h2 id="数据库服务器崩溃2">数据库服务器崩溃（2）</h2>
<ol>
<li>系统平稳运行过程中</li>
<li>数据库连接量瞬间激增</li>
<li>Redis服务器无大量key过期</li>
<li>Redis内存平稳，无波动</li>
<li>Redis服务器CPU正常</li>
<li>数据库崩溃</li>
</ol>
<h2 id="问题排查-3">问题排查</h2>
<ol>
<li>Redis中<strong>某个key过期，该key访问量巨大</strong></li>
<li>多个数据请求从服务器直接压到Redis后，均未命中</li>
<li>Redis在短时间内发起了大量对数据库中同一数据的访问</li>
</ol>
<h2 id="问题分析-2">问题分析</h2>
<ul>
<li>单个key高热数据</li>
<li>key过期</li>
</ul>
<h2 id="解决方案术-2">解决方案（术）</h2>
<ol>
<li>预先设定</li>
</ol>
<ul>
<li>以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长</li>
<li>注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势</li>
</ul>
<ol start="2">
<li>现场调整</li>
</ol>
<ul>
<li>监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key</li>
</ul>
<ol start="3">
<li>后台刷新数据</li>
</ol>
<ul>
<li>启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</li>
</ul>
<ol start="4">
<li>二级缓存</li>
</ol>
<ul>
<li>设置不同的失效时间，保障不会被同时淘汰就行</li>
</ul>
<ol start="5">
<li>加锁</li>
</ol>
<ul>
<li>分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</li>
</ul>
<h2 id="总结-3">总结</h2>
<p>缓存击穿就是<strong>单个高热数据过期的瞬间，数据访问量较大</strong>，未命中redis后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过期监控难度较高，配合雪崩处理策略即可。</p>
<h1 id="缓存穿透">缓存穿透</h1>
<h2 id="数据库服务器崩溃3">数据库服务器崩溃（3）</h2>
<ol>
<li>系统平稳运行过程中</li>
<li>应用服务器流量随时间增量较大</li>
<li>Redis服务器命中率随时间逐步降低</li>
<li>Redis内存平稳，内存无压力</li>
<li>Redis服务器CPU占用激增</li>
<li>数据库服务器压力激增</li>
<li>数据库崩溃</li>
</ol>
<h2 id="问题排查-4">问题排查</h2>
<ol>
<li>Redis中大面积出现未命中</li>
<li>出现非正常URL访问</li>
</ol>
<h2 id="问题分析-3">问题分析</h2>
<ul>
<li>获取的数据在数据库中也不存在，数据库查询未得到对应数据</li>
<li>Redis获取到null数据未进行持久化，直接返回</li>
<li>下次此类数据到达重复上述过程</li>
<li>出现黑客攻击服务器</li>
</ul>
<p><strong>解决方案（术）</strong></p>
<ol>
<li>缓存null</li>
</ol>
<ul>
<li>对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟</li>
</ul>
<ol start="2">
<li>白名单策略</li>
</ol>
<ul>
<li>提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时，放行，加载异常数据时直接拦截（效率偏低）</li>
<li>使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略）</li>
</ul>
<ol start="3">
<li>实施监控</li>
</ol>
<ul>
<li>实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比
<ul>
<li>非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象</li>
<li>活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象</li>
</ul>
</li>
<li>根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）</li>
</ul>
<ol start="4">
<li>key加密</li>
</ol>
<ul>
<li>问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验</li>
<li>例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问</li>
</ul>
<h2 id="总结-4">总结</h2>
<p>缓存击穿<strong>访问了不存在的数据</strong>，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。</p>
<p>无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。</p>
<h1 id="性能指标监控">性能指标监控</h1>
<h2 id="监控指标">监控指标</h2>
<ul>
<li>性能指标：Performance</li>
<li>内存指标：Memory</li>
<li>基本活动指标：Basic activity</li>
<li>持久性指标：Persistence</li>
<li>错误指标：Error</li>
</ul>
<h3 id="性能指标performance">性能指标：Performance</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">latency</td>
<td style="text-align:left">Redis响应一个请求的时间</td>
</tr>
<tr>
<td style="text-align:left">instantaneous_ops_per_sec</td>
<td style="text-align:left">平均每秒处理总数</td>
</tr>
<tr>
<td style="text-align:left">hit rate(calculate)</td>
<td style="text-align:left">缓存命中率（计算出来的）</td>
</tr>
</tbody>
</table>
<h3 id="内存指标memory">内存指标：Memory</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">used_memory</td>
<td style="text-align:left">已使用内存</td>
</tr>
<tr>
<td style="text-align:left">mem_fragmentation_ratio</td>
<td style="text-align:left">内存碎片化</td>
</tr>
<tr>
<td style="text-align:left">evicted_keys</td>
<td style="text-align:left">由于最大内存限制被移除的 key 的数量</td>
</tr>
<tr>
<td style="text-align:left">blocked_clients</td>
<td style="text-align:left">由于 BLPOP、BRPOP、or BRPOPLPUSH 而备受阻塞的客户端</td>
</tr>
</tbody>
</table>
<h3 id="基本活动指标basic-activity">基本活动指标：Basic activity</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">connected_clients</td>
<td style="text-align:left">客户端连接数</td>
</tr>
<tr>
<td style="text-align:left">connected_slaves</td>
<td style="text-align:left">Slave 数量</td>
</tr>
<tr>
<td style="text-align:left">master_last_io_seconds_ago</td>
<td style="text-align:left">最近一次主从交互之后的秒数</td>
</tr>
<tr>
<td style="text-align:left">keyspace</td>
<td style="text-align:left">数据库中的 key 值总数</td>
</tr>
</tbody>
</table>
<h3 id="持久性指标persistence">持久性指标：Persistence</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">rdb_last_save_time</td>
<td style="text-align:left">最后一次持久化保存到磁盘的时间戳</td>
</tr>
<tr>
<td style="text-align:left">rdb_changes_since_last_save</td>
<td style="text-align:left">自最后一次持久化依赖数据库的更改数</td>
</tr>
</tbody>
</table>
<h3 id="错误指标error">错误指标：Error</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">rejected_connections</td>
<td style="text-align:left">由于达到 maxclient 限制而被拒绝的连接数</td>
</tr>
<tr>
<td style="text-align:left">keyspace_misses</td>
<td style="text-align:left">key 值查找失败（没有命中）次数</td>
</tr>
<tr>
<td style="text-align:left">master_link_down_since_seconds</td>
<td style="text-align:left">主从断开的持续时间（以秒为单位）</td>
</tr>
</tbody>
</table>
<h2 id="监控方式">监控方式</h2>
<ul>
<li>工具
<ul>
<li>Cloud Insight Redis</li>
<li>Prometheus</li>
<li>Redis-stat</li>
<li>Redis-faina</li>
<li>RedisLive</li>
<li>zabbix</li>
</ul>
</li>
<li>命令
<ul>
<li>benchmark</li>
<li>redis cli
<ul>
<li>monitor</li>
<li>showlog</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="benchmark">benchmark</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>redis-benchmark [-h ] [-p ] [-c ] [-n &lt;requests]&gt; [-k ] 
</code></pre>
<ul>
<li>范例1</li>
</ul>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-benchmark 
</code></pre>
<p>说明：50个连接，10000次请求对应的性能</p>
<ul>
<li>范例2</li>
</ul>
<pre><code>redis-benchmark -c 100 -n 5000 
</code></pre>
<p>说明：100个连接，5000次请求对应的性能</p>
<h2 id="benchmark-2"><strong>benchmark</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/benchmark.png" alt="图片" loading="lazy"></figure>
<h2 id="monitor">monitor</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>monitor 
</code></pre>
<p>打印服务器调试信息</p>
<h2 id="slowlog">slowlog</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>slowlog [operator] 
</code></pre>
<ul>
<li>get ：获取慢查询日志</li>
<li>len ：获取慢查询日志条目数</li>
<li>reset ：重置慢查询日志</li>
<li>相关配置</li>
</ul>
<pre><code>slowlog-log-slower-than 1000 #设置慢查询的时间下线，单位：微妙 
slowlog-max-len 100 #设置慢查询命令对应的日志显示长度，单位：命令数
</code></pre>
<h1 id="总结-5">总结</h1>
<p>企业级解决方案</p>
<ul>
<li>缓存预热</li>
<li>缓存雪崩</li>
<li>缓存击穿</li>
<li>缓存穿透</li>
<li>性能指标监控
<ul>
<li>工具</li>
<li>命令</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线程]]></title>
        <id>https://epitomm.github.io/post/xian-cheng/</id>
        <link href="https://epitomm.github.io/post/xian-cheng/">
        </link>
        <updated>2020-03-29T03:08:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="p-stylecolorred1-线程抽象p"><p style="color:red">1. 线程抽象</p></h1>
<p>一个线程是一个单一的执行序列，它表示了一个单独被调度的任务.</p>
<ul>
<li><strong>单一的执行序列</strong>. 每个线程执行一个指令序列——赋值，条件，循环，过程, 等等</li>
<li><strong>单独被调度的任务</strong>. 操作系统可以在任意时刻，运行，暂停或者继续一个线程。</li>
<li><strong>运行，挂起和继续执行的线程</strong></li>
</ul>
<p>线程提供了一个有无限个处理机的幻象。OS 如何实现这样的幻象呢？它必须执行每个进程的指令使得每个线程都有进展，但实际的硬件只有有限个数的处理机，甚至只有 1 个</p>
<p>为了将任意数量的线程映射到有限个处理机上，OS 包含一个调度器(scheduler)能够在运行和就绪的线程之间来回切换。但是线程的切换对线程来说是透明的，只是某些时刻处理机的执行变得比较慢而已。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%90%8C%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.3</strong>: 一个线程 3 种可能的执行方式 ，对于程序员来说是无差的.</p>
<p>上图说明了一个程序员角度的一个简单程序有三种不同的执行方式，这取决于调度器。从线程的角度，除了执行的速度不一样，这些是没差的。确实，线程并不知道有其他线程在执行。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E4%BA%A4%E9%94%99%E6%89%A7%E8%A1%8C.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.4</strong>: 3 个线程在运行时许多种可能的交错执行的方式.</p>
<p>上图展示了 3 个线程的交替执行。他们的这种速度是不可控的，每次执行可能都不一样。</p>
<p><strong>例子</strong>:内核中断处理程序是一个线程?</p>
<p><strong>回答： 不，一个中断处理程序不是一个线程</strong>. 一个内核中断处理程序和线程有一些相似性: 它是一个指令的序列， 从开头执行到结尾。然而，一个中断处理程序<strong>不是独立可调度的</strong>: 它被一个硬件I/O 事件所触发执行,  而不是内核中线程调度器来决定什么时候执行. 一旦开始，中断处理程序运行到结束，除非被另外一个优先级更高的中断抢占.</p>
<h1 id="p-stylecolorred2-简化的线程-apip"><p style="color:red">2. 简化的线程 API</p></h1>
<table>
<thead>
<tr>
<th style="text-align:left">void thread_create  (thread, func,arg)</th>
<th style="text-align:left">创建一个新线程, 把信息存入 thread. 和调用的线程并发执行，线程执行函数 func，其参数为 arg.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">void thread_yield()</td>
<td style="text-align:left">调用的线程自愿放弃处理机让其他线程来运行。调度器也可以继续运行调用的线程.</td>
</tr>
<tr>
<td style="text-align:left">int thread_join  (thread)</td>
<td style="text-align:left">等待 thread 结束如果 thread 还没有结束的话; 然后返回由 thread 通过 thread_exit 传递来的参数. 注意， 对每个线程，thread_join 只能被调用一次.</td>
</tr>
<tr>
<td style="text-align:left">void thread_exit(ret)</td>
<td style="text-align:left">完成当前的线程. 将 ret 的值存在当前线程的数据结构中。如果另一个线程已经用 thread_join 等待该线程, 则继续执行那个等待的线程.</td>
</tr>
</tbody>
</table>
<p><strong>图 4.5</strong>:使用线程简化的 API</p>
<p>图 4.5 展示了使用线程的简单的API. 这个简化的API 是基于POSIX 标准的pthreads API, 但是它忽略了某些POSIX 选项和错误处理(为了简化). 绝大多数其他线程包也类似，如果你理解如何用这个 API 编程的话，你会发现对于绝大多数标准的线程 API 来说，其代码很容易编写.</p>
<p>我们看见 UNIX 进程抽象中有类似的概念. thread_create 类似于UNIX 进程 fork 和 exec, 而 thread_join 类似于 UNIX 进程wait. UNIX fork 创建了一个新的进程和原来调用 fork 的进程并发的执行;UNIX exec 导致进程运行一个指定的程序。UNIX wait 运行调用的进程暂停执行直到新的进程完成为止。</p>
<h2 id="1-多线程的hello-world">1. 多线程的Hello World!</h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E5%A4%9A%E7%BA%BF%E7%A8%8Bhelloworld%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.png" alt="图片" loading="lazy"></figure>
<p><strong>图 4.6</strong>: 用简单线程API 来打印”Hello”十次的多线程编程的例子。也展示了一种可能的输出。</p>
<p>上图是一个多线程的程序，用了简单的线程 API 来打印 hello 十次。也展示了一个可能的输出结果。Main 函数用 thread_create 创建了 10 个子线程。有趣的参数是第二个和第三个。第二个参数 go 是一个函数指针——新创建的检测应该开始执行的代码位置。第三个参数 i 传递给 go 函数。因此，thread_create 初始化第i 个线程的状态使得它准备调用函数 go，参数是 i。</p>
<p>当调度者运行第 i 个线程，线程运行函数go，参数为 i，打印 hello from 线程 i。 线程接着返回值 i+100 通过调用 thread_exit. 这个调用将特定的值保存到 trhead_t 的对象里，使得 thread_join 能够找到它。</p>
<p>Main 函数用thread_join 来等待每个它创建的线程。当每个线程完成的时候，main 的代码会的读取完成线程的退出值并打印。</p>
<p><strong>例子</strong>：为什么来自线程 2 的“线程 returned”的消息<strong>一定是</strong>在来自线程 5 的线程 returned 的消息打印之前先打印？</p>
<p>回答：虽然每个创建的线程完成的顺序是不确定的，但是主线程是按照创建的顺序按顺序检查的。</p>
<p><strong>例子</strong>：当线程 5 打印 hello 的时候未退出的线程的最少数是多少？最多数是多少？</p>
<p><strong>回答</strong>：最少是 2，最多是 11</p>
<h2 id="2-创建线程thread_create和线程等待thread_join在并行计算中的应用">2. 创建线程(thread_create)和线程等待(thread_join)在并行计算中的应用</h2>
<p>尽管线程接口很简单，但非常强大。例如用”<strong>fork-join 并行”</strong>（<strong>fork-join 并行</strong>即 thread_create 和 thread_join 一起使用来实现并行化计算）, 一个线程可以创建子线程来执行工作(“fork”, 或者 thread_create), 它可以等待他们的结果(“join”).</p>
<pre><code>// 为了传递两个参数，我们需要一个结构来保存它们.
typedef struct bzeroparams {
   unsigned char *buffer; int length;
};
#define NTHREADS 10
void go (struct bzeroparams *p) {
   memset(p-&gt;buffer, 0, p-&gt;length);
}
//用多线程对一个块进行清零.
void blockzero (unsigned char *p, int length) {
  int i;
  thread_t threads[NTHREADS];
  struct bzeroparams params[NTHREADS];
  // 为了简化，假设长度可以被NTHREADS 整除. assert((length   NTHREADS) == 0);
  for (i = 0; i &lt; NTHREADS; i++) {
      params[i].buffer = p + i * length/NTHREADS; params[i].length = length/NTHREADS; thread_create_p(&amp;(threads[i]), &amp;go, &amp;params[i]);
  }
  for (i = 0; i &lt; NTHREADS; i++) {
      thread_join(threads[i]);
    }
}
</code></pre>
<p><strong>图 4.7</strong>: 使用多线程并行地对一个内存连续区域清零的程序.<br>
<strong>例子：并行的块清零</strong>.在操作系统中一个应用 fork-join 并行的简单例子是对一段连续内存块清零的过程. 每当一个进程结束的时候，为了阻止无意的数据泄露, 操作系统必须把分配给这个进程中的内存清零。否则，一个新的进程可能会被重新分配给这个内存, 使得这个进程可以读取潜在的敏感的数据。例如，一个操作系统的远程登录程序可能暂时存储一个用户的密码在内存中，但是下一个使用同一内存区间的进程可能会是一个被一个恶意用户调用的扫描内存的程序.</p>
<p>对于一个大的进程，并行地清零的函数是合理的。在现代计算机上，对 1GB 的内存清零需要大约 50 毫秒; 相比之下，创建和启动一个新的线程只需要几十微秒.</p>
<p>图 4.7 展示了一个使用fork-join 并行清零的代码。多线程的 blockzero 创建了一系列线程并给每个分配了一段不相交的内存区间; 当所有线程都完成它们的工作的时候整个区间都被清零. 操作系统可以创建一系列低优先级的线程来运行 blockzero. 之后，当内存被需要的时候，内核可以调用 thread_join. 如果那个时候已经完全清零，则join 会立即返回；否则它需要等待直到这块内存可以被安全使用.</p>
<h1 id="p-stylecolorred3-线程的数据结构p"><p style="color:red">3. 线程的数据结构</p></h1>
<p>为了理解操作系统如何实现线程的抽象，我们必须定义两种状态，一个是每个线程的状态(the Per-Thread State)， 另一个是多个线程的共享状态(the Shared State)。然后我们才能给描述一个线程的生命周期——提供上述抽象，操作系统是如何能够创建，开始，暂停和删除线程的。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.8</strong>: 一个多线程的进程或者操作系统的内核既有每个线程的状态也有共享状态. 线程控制块（TCB）存储了每个线程的状态: 线程当前的计算状态(例如，被保存的处理机的寄存器和一个指向(内核)栈的指针)和需要管理该线程的元数据(例如，线程的 ID，调度优先级，拥有者). 共享的状态包括程序的代码，全局静态变量和堆.</p>
<p>一个多线程的进程或者操作系统内核都有每个线程的状态和共享状态。线程控制块保存着每个线程的状态: 线程计算当前的状态(例如，保存的处理机的寄存器和(内核)栈指针)和需要管理这个线程的元数据(例如，线程的 ID， 调度的优先级，拥有者)。共享状态包括：程序的代码，全局变量和堆。</p>
<ul>
<li><strong>每个线程的状态(Per-Thread State)和线程控制块(TCB)</strong></li>
</ul>
<p>操作系统需要一个数据结构来表示一个线程的状态；线程就好比是这个数据结构下的一个具体的对象。这个数据结构被称为线程控制块(线程控制块, TCB)。对于每个操作系统创建的线程，它就创建一个TCB。</p>
<p>线程控制块记录两种类型的每个线程的信息：</p>
<ol>
<li>这个线程当前的计算状态：栈和处理器中寄存器的值</li>
<li>用于管理该线程的元数据</li>
</ol>
<ul>
<li><strong>共享状态</strong></li>
</ul>
<p>有一些状态是属于同一应用进程里的不同线程之间共享的状态，或者是操作系统内核内的线程之间共享的状态。特别的，程序代码是同一进程中所有线程共享的，尽管每个线程可能执行代码的不同位置。除此以外，静态分配的  全局变量和动态分配的堆变量也是同一进程的所有线程所共享的。</p>
<p><strong>警告</strong>：这是逻辑上的区分状态（Per-Thread State 和 Shared State），而操作系统往往不强制这种区分，换句话说，一个线程可以去访问同一进程内的其他线程的每个线程的状态，例如访问其他线程的用户栈。<strong>这是被允许的</strong>。那么为了避免不要的错误，编写一个多线程的程序的时候必须要清楚哪些变量是线程之间共享的，哪些是私有的。以防一个线程会破坏其他线程。</p>
<h1 id="p-stylecolorred4-线程的生命周期p"><p style="color:red">4. 线程的生命周期</p></h1>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.9: 一个线程在它的生命周期中的状态.</strong></p>
<p>上图展示了一个线程的生命周期。</p>
<ul>
<li><strong>新建</strong>：线程创建会把一个线程设为新建状态，分配和初始化每个线程的的数据结构。一旦这些完成，thread_ creation 代码会把该线程放到就绪队列中（隐含的意思是设置为READY 状态）。</li>
<li><strong>就绪</strong>：一个线程是就绪态就是指它可以运行但当前还没有运行。它的 TCB 被放在就绪队列上，它的寄存器的值被保存在它的 TCB 中。在任意时刻，调度器可以让一个线程从就绪态到运行态，只需要把它保存在 TCB 中的寄存器的值恢复到处理机的寄存器上。</li>
<li><strong>运行</strong>：一个线程是运行态就是指它正在一个处理机上运行。此时，它的寄存器的值还在处理机的寄存器上，而不是TCB 中。一个运行态的线程可以按下面两种方式切换到就绪态：
<ul>
<li>
<p>调度器抢占一个运行的线程，然后将它放到就绪态，通过（1）保存线程的寄存器值到它的 TCB 中；并且（2）将处理机切换去执行就绪队列中某线程</p>
</li>
<li>
<p>一个运行态的线程可以自愿地放弃(relinquish)处理机然后从运行态到就绪态，通过调用 yield(例如，线程库中的 thread_yield)</p>
</li>
</ul>
</li>
</ul>
<p>注：一个线程可以从就绪态到运行态，再从运行态到就绪态，这样多次切换。</p>
<ul>
<li><strong>等待</strong>：一个线程在等待态是指它在等待某个事件。调度器能够将一个线程从就绪态移动到运行态，一个在等待态的线程却不能切换到运行态，它必须要等待某个其他的线程将它从等待态移动到就绪态。</li>
<li><strong>完成</strong>：一个线程在完成态就意味着它用于不会再运行了。系统能够释放部分或者它的全部状态，但它仍然要保留线程残留的一些信息，并把线程的 TCB 放到一个完成队列上。例如，thread_exit 调用会让一个线程将它的退出值通过 thread_join 传递给它的父亲线程。当一个线程的状态再没任何用处的时候（例如，当它的退出值已经被 thread_join 读取了），系统就可以删除和取回该线程的状态。</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E4%B8%8D%E5%90%8C%E7%8A%B6%E6%80%81%E4%B8%8B%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BD%8D%E7%BD%AE.png" alt="图片" loading="lazy"></figure>
<p><strong>图 4.10: 在不同状态下线程的每个线程状态的位置.</strong></p>
<p>理解这些状态的一种方式就是考虑一个线程的 TCB 和寄存器值存放的位置，如上图所示。当所有线程在就绪态，它们的 TCB 被放在就绪队列，它们的寄存器的值的拷贝也放在 TCB 中。所有在运行态的线程，它们的 TCB 被放在运行队列上，它们的寄存器值是在硬件寄存器上。所有在等待态的线程它们的 TCB 是放在不同的同步变量的等待队列上。</p>
<hr>
<p><strong>idle 线 程</strong></p>
<p>如果一个系统有 k 个处理机,  绝大多数操作系统确保正好有 k 个执行态的线程,  通过在每个处理机上维护一个低优先级的 <strong>idle 线程</strong>以保证当该处理机没有什么事情可做的时候，仍然有线程在执行.</p>
<p>在旧机器上，idle 线程会在一个紧凑循环中什么也不做. 而今天，idle 线程仍然在一个loop 中 spin, 但是为了省电，在每次迭代中，它把处理机进入一个低耗电的睡眠模式。在睡眠模式中，处理机暂停执行指令直到出现一个硬件中断。然后，处理机醒来并按照通常的方式来处理中断—保存当前正在执行的线程(idle 线程)的状态并执行处理程序. 在运行了处理程序之后，一个等待此 I/O 事件的线程现在可以是就绪态. 如果是这样的话，调度器接下来就执行这个进入就绪态的线程；否则 idle 线程继续执行，让处理机再次去睡觉.</p>
<hr>
<p><strong>例子</strong>：对于线程 Hello 程序，在一个单处理机上，主线程进入就绪态的最少次数是多少？最多次数又是多少？</p>
<p><strong>回答</strong>：当主线程被创建时，它必须进入就绪态；否则它永远不会被调度。在一个单处理机上，它必须放弃处理机为了让它的线程运行。在主线程被重新调度之前，子线程们接下来可以完成运行。一旦孩子们完成，主线程可以完成运行。<strong>因此最小的次数是 2</strong>.</p>
<p><strong>最大的次数则是接近于无穷大</strong>。一个运行的线程可以被抢占然后被重新调度若干次，而不影响执行的正确性。</p>
<h1 id="p-stylecolorred5-实现内核线程p"><p style="color:red">5. 实现内核线程</p></h1>
<p>我们介绍内核线程的实现。这是所有线程实现中最基础的，也是最简单的。</p>
<h2 id="p-stylecolorreda-创建内核线程代码不要求但后面介绍的基本步骤需要掌握p"><p style="color:red">a. 创建内核线程（代码不要求，但后面介绍的基本步骤需要掌握）</p></h2>
<pre><code>// func 是一个指向线程要运行的过程的指针.
// arg 是传递给这个过程的参数.
void thread_create(thread_t *thread, void (*func)(int), int arg) {
  // Allocate TCB and stack TCB *tcb = new TCB();
  thread -&gt;tcb = tcb;
  tcb-&gt;stack_size = INITIAL_STACK_SIZE;
  tcb-&gt;stack = new Stack(INITIAL_STACK_SIZE);
  // 初始化寄存器使得当线程继续执行的时候，它从 stub 开始执行。
  //栈从分配的区域的顶端开始，然后向下增长. tcb-&gt;sp = tcb-&gt;stack + INITIAL_STACK_SIZE; tcb-&gt;pc = stub;
  // 通过把 stub 的参数压栈来创建一个栈帧
  *(tcb-&gt;sp) = arg; tcb-&gt;sp--;
  *(tcb-&gt;sp) = func; tcb-&gt;sp--;
  // 创建另一个栈帧使得 thread_switch 正确工作. 这个 routine 在本章后面解释. thread_dummySwitchFrame(tcb);
  tcb-&gt;state = READY;
  readyList.add(tcb); // 把 TCB 放在就绪队列
}
void stub(void (*func)(int), int arg) {
  (*func)(arg); // 执行函数 func()
  thread_exit(0); // 如果 func()不调用 exit,在这里调用 exit.
}


</code></pre>
<p><strong>图 4.13</strong>创建线程的伪代码。对栈的初始化和传参给初始函数是和机器相关的。在 intel x86 架构中，栈从搞地址开始然后向下增长，而参数被传递到栈上。在其他系统，栈能够向上增长，参数是通过寄存器传递。图 4.14 提供了thread_dummySwitchFrame 的伪代码<br>
图 4.13 展示了创建一个新线程的伪代码。thread_create 的目标是执行一个异步的过程调用给 func，其参数为 arg。当线程运行时，它执行 func(arg)【与父进程并发执行】</p>
<p><strong>创建一个线程有 3 个步骤</strong></p>
<ol>
<li><strong>分配每个线程的状态</strong>. 第一步是为线程的每个线程的状态分配空间：TCB 和栈。正如我们所提到的，TCB 是操作系统用于管理线程的数据结构。</li>
<li><strong>初始化每个线程的状态</strong>. 为了初始化TCB，需要初始化各个寄存器的值。当该线程被调度时，我们想要我们想要它运行 func(arg)。然而，是先从一个 dummy 函数, stub, 运行，stub 接着调用func。我们需要这个步骤是因为 func 是返回而不是调用 thread_exit。没有这个 stub 的话，func 会返回栈顶的一个随机的位置。，有了 stub，函数 func 返回到stub，然后再由 stub 调用 thread_exit 来完成线程。在伪代码中，我们给 stub 压入两个参数进栈：func 和 arg。当线程开始运行，stub 的代码就会访问它的代码就行一个普通的procedure。</li>
<li><strong>将TCB 放到就绪队列</strong>. 创建一个线程的最后一步就是将它的状态设置为就绪态，然后把新的 TCB 放到就绪队列， 使得该线程能够被调度。</li>
</ol>
<h2 id="p-stylecolorred-b-一个自愿的内核线程切换代码不要求但线程上下文切换的基本步骤需要掌握即保存旧线程的寄存器的值到tcb-中把新线程的tcb-中寄存器的值加载到cpu-的寄存器中p"><p style="color:red"> b. 一个自愿的内核线程切换（代码不要求，但线程上下文切换的基本步骤需要掌握，即：保存旧线程的寄存器的值到TCB 中，把新线程的TCB 中寄存器的值加载到CPU 的寄存器中</p></h2>
<p>图 4.14 展示了在Intel x86 硬件架构下，thread_yiled 的简单实现的伪代码.一个线程调用 thread_yield 自愿地放弃处理机给另一个线程用. 调用的线程的寄存器被拷贝到它的 TCB 和栈中，便于当调度器再次选择它的时候，可以继续运行.</p>
<pre><code>//我们以一个旧线程进入，而以新线程返回.
//以新线程的寄存器和栈返回.
void thread_switch(oldThreadTCB, newThread TCB) { 
    pushad; //把通用寄存器的值压入旧的栈中. 
    oldThreadTCB-&gt;sp = esp; //保存旧线程的栈指针. 
    esp = newThreadTCB-&gt;sp; // 切 换 到 新 的 栈 . 
    popad; // 从新的栈弹出寄存器的值.
    return;
}
void thread_yield() {
  TCB *chosenTCB, *finishedTCB;
  // 在切换的中间过程中阻止有中断暂停. disableInterrupts();
  // 从 就 绪 队 列 中 选 择 另 一 个 TCB. chosenTCB = readyList.getNext 线程(); 
  if (chosenTCB == NULL) {
    // 没有什么可以运行的，回去运行原始的线程.
  } else {
    // 将运行的线程移动到就绪队列. runningThread-&gt;state = ready; readyList.add(runningThread);
    thread_switch(runningThread, chosenTCB); // 切换到新的线程. runningThread -&gt;state = running;
  }
  //删除完成队列上的任意线程.
  while ((finishedTCB = finishedList-&gt;getNextThread()) != NULL) {
    delete finishedTCB-&gt;stack;
    delete finishedTCB;
  }
  enableInterrupts();
}
//thread_create 必须在它的栈顶放一个 dummy frame:
// 返回的 PC 和给 pushad 的空间来存储寄存器的备份.
// 这样的话，当某人切换到一个新创建的线程, thread_switch 的最后两行能正确工作.
void thread_dummySwitchFrame(new 线程) {
  *(tcb-&gt;sp) = stub; //返回到 stub 的开头. tcb-&gt;sp--;
  tcb-&gt;sp -= SizeOfPopad;
}
</code></pre>
<p><strong>图 4.14</strong>: 在 Intel x86 架构上 thread_switch 和 thread_yield 的伪代码。注意， thread_yield 是一个空操作如果没有其他线程可以运行。否则，它保存旧线程的状态并恢复新线程的状态。当旧线程被重新调度，它从thread_switch 返回到正在运行的线程.</p>
<hr>
<p>thread_yield 的伪代码首先关闭中断来阻止线程系统试图在同一时间做两个上下文切换. 伪代码接着把下一个线程拉出就绪队列(如果有的话)，然后切换到它. thread_switch 代码也许看上去有点不易理解, 由于它是在旧线程的上下文中被调用，而完成的时候是在新线程的上下文. 为了完成切换，thread_switch 把寄存器的状态保存到栈上，然后把栈指针保存到 TCB 中。接着它切换到新的线程的栈，从新线程的栈来恢复新线程的状态，然后返回到存储在新栈中的程序计数器的位置. 一个比较扭曲的地方是返回的位置可能不是 thread_yield!  返回到了新线程之前被暂停的地方.</p>
<hr>
<p><strong>一个 0-线程的内核</strong></p>
<p>我们不仅可以有一个单线程的内核或者一个多线程的内核，还有可能有一个没有线程的内核——0 线程的内核。实际上，这也是常见的。因为几乎内核中所有事情都是事件驱动的，例如响应一个中断，处理机异常或者系统调用。</p>
<p>在一个简单的操作系统中，就没有必要创建内核线程或者内核线程控制块来追踪正在进行的计算。而是，当发生一个中断，陷阱或者异常，栈指针就设置为指向中断栈的栈底，指令指针设置为处理程序的地址。接着，处理程序开始执行，要不就立即返回到用户级的进程要不就暂停用户级的进程，然后返回到其他用户级进程。</p>
<hr>
<h1 id="p-stylecolorred6-实现多线程的进程p"><p style="color:red">6. 实现多线程的进程</p></h1>
<p>所有广泛被应用的操作系统既支持内核线程也支持多线程进程。编程语言，例如 Java，和标准库接口例如 POSIX 用操作系统的这种支持来为编程者提供线程的抽象。</p>
<ul>
<li><strong>用内核线程实现多线程的进程</strong></li>
</ul>
<p>支持多线程进程的最简单的方式是使用内核线程的实现。当一个用户级线程访问线程库要做同样的事情，它用系统调用来请求内核做同样的操作。</p>
<p>如图 4.12 所示，一个进程的线程有：</p>
<ul>
<li>一个用户级的栈用于执行用户代码</li>
<li>一个内核中断栈：当该线程做系统调用时，或者引发了一次处理机异常，或者被中断</li>
<li>一个内核TCB：用于保存和恢复每个线程的状态</li>
</ul>
<p>为了创建一个线程，<strong>用户线程库</strong>分配一个用户级的栈给新的线程，然后做一个系统调用进入内核。内核分配一个TCB 和内核栈，设置线程的状态使其用用户级栈从被请求的过程的开始处开始执行。内核需要在<strong>进程控制块</strong>（<strong>PCB</strong>） 中保存一个指向该TCB 的指针；如果进程退出，内核必须终止在这个进程内的任意线程。在创建了线程后，内核把新的线程放到就绪队列上，就像其他线程一样可以被调度，然后返回一个唯一的标识符给用户程序，以便于以后想要指定这个新创建的线程的时候使用（例如，for join）。线程的 join, yield,和 exit 用同样的方式实现：<strong>通过系统调用进入内核来执行所请求的函数</strong>。</p>
<h1 id="p-stylecolorred7-实现用户级线程没有内核支持p"><p style="color:red">7. 实现用户级线程（没有内核支持）</p></h1>
<p>也可以实现一个完全在用户级的线程（作为库函数），不需要任何操作系统的支持。早期线程库函数采用这种纯用户级方法的原因是：因为极少有操作系统支持多线程的进程。在 JAVA 虚拟机中，也被称为绿线程。</p>
<p>基本思想比较简单。线程库函数在进程中初始化线程的所有数据结构：TCB，就绪队列，完成队列，等待队列，这些全部在进程的用户地址空间。对线程库函数的调用就是普通的过程调用。</p>
<p>在操作系统内核看来，一个用户级多线程的应用程序就是一个普通的单线程进程。绿线程的限制是操作系统<strong>内核不知道用户级就绪队列</strong>。如果应用程序的某个线程执行一个系统调用需要等待 I/O，内核不知道还有别的用户级线程可以运行。就会<strong>把整个进程都阻塞</strong>。类似的，在一个多处理机上，内核也不能让一个进程的多个线程在不同的处理机上运行。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[进程]]></title>
        <id>https://epitomm.github.io/post/jin-cheng/</id>
        <link href="https://epitomm.github.io/post/jin-cheng/">
        </link>
        <updated>2020-03-29T02:28:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="p-stylecolorred1-为什么引入进程p"><p style="color:red">1. 为什么引入进程？</p></h1>
<p>操作系统需要一种统一的方法监视、管理、控制处理器中不同程序的动态执行过程，“进程”的概念被引入！</p>
<h1 id="p-stylecolorred2-进程的定义p"><p style="color:red">2. 进程的定义</p></h1>
<p>进程没有严格的定义，但可以通过不同的角度去描述：计算机中正在运行的程序的一个实例（Instance。它包含（内存中的）代码段，数据段，堆，栈（用户栈和内核栈）；和当前的执行上下文（PC，SP 和其他寄存器），操作系统通过维护数据结构——进程控制块（PCB）来管理每个进程。</p>
<p><strong>进程控制块（Process Control Block——PCB</strong>：PCB 是是操作系统用来管理进程的数据结构，是进程存在的唯一标识。每当操作系统创建一个进程，就是由操作系统为该进程设置一个 PCB；进程执行完成时，由系统收回其 PCB， 该进程便消亡了。PCB 的内容包括：</p>
<ul>
<li>进程的状态（就绪，执行，等待，完成）</li>
<li>进程的 ID</li>
<li>进程的名字</li>
<li>进程的执行上下文（PC，SP，ELFAGS，其他寄存器）</li>
<li>调度需要的信息（优先级，调度参数，使用的 CPU 时间，进程开始的时间…）</li>
<li>内存管理的信息（基址和界限…）</li>
<li>I/O 状态信息（打开的文件，占用的 I/O 设备…）</li>
</ul>
<h1 id="p-stylecolorred3-内核线程和用户进程放到一起p"><p style="color:red">3. 内核线程和用户进程放到一起</p></h1>
<p>下面两个图展示了包含用户进程（上图是单线程进程，下图是多线程进程）和内核线程的内存空间信息。</p>
<ul>
<li>所有<strong>内核线程</strong>都<strong>共享</strong>内核的代码段（Code），全局变量(Globals)，堆(Heap)，和自己<strong>专门</strong>的 TCB 和内核栈。</li>
<li><strong>单线程的用户进程</strong>在用户空间有自己的代码段，数据段，堆，栈，在内核空间有内核用于管理该进程使用的 PCB和内核栈。</li>
<li>多线程的用户进程在用户空间有自己的代码段，数据段，堆和多个线程。每个线程有自己的用户栈，和内核空间的内核栈以及内核用于管理该线程的TCB。</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B-%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.11</strong>:一个多线程的内核：有 3 个内核线程和两个单线程的用户级进程. 每个内核线程 有它自己的 TCB 和它自己的栈. 每个用户进程有一个用户级的栈用于执行用户的代码和一个内核中断栈用于执行系统调用和中断.</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%86%85%E6%A0%B8.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.12</strong>: 一个多线程的内核：有 3 个内核线程和两个用户级的进程, 每个进程有 2 个线程. 每个用户级线程有一个用户级栈和一个内核中的中断栈用于执行系统调用和中断.</p>
<h1 id="p-stylecolorred4-进程的状态及其变迁p"><p style="color:red">4. 进程的状态及其变迁</p></h1>
<h2 id="a-三状态变迁图">a)  三状态变迁图</h2>
<p><strong>运行中的</strong>进程至少具有以下三种基本状态（如下图所示）：</p>
<ol>
<li><strong>就绪状态</strong>– 在某时刻，进程已获得除处理机以外的所有资源，一旦分到了处理机就可以立即执行</li>
<li><strong>运行状态</strong>– 进程已经获得必要资源，并占有处理机运行</li>
<li><strong>等待状态</strong>（也叫<strong>阻塞状态</strong>） – 正在执行的进程，由于发生某事件而暂时无法执行下去</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%B8%89%E7%8A%B6%E6%80%81.png" alt="图片" loading="lazy"></figure>
<p>例如，下图展示了 3 个进程的状态的变迁。其中调度程序是操作系统内核中用于从就绪队列中选择下一个占用CPU 执行的进程的调度程序。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%BA%8F%E5%88%97%E5%9B%BE%E4%B8%BE%E4%BE%8B-%E4%B8%89%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<h2 id="b-五状态变迁图">b)  五状态变迁图</h2>
<p>其状态变迁图如下图所示，比 3 状态图多了两个状态：新建和退出。</p>
<ul>
<li><strong>新建状态</strong>– 至少建立PCB，但进程相关的其他内容可能未调入主存</li>
<li><strong>退出状态</strong>– 进程已经终止，但资源等待父进程或系统回收</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%BA%94%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<p><strong>触发进程状态变迁的事件</strong>描述如下：</p>
<ul>
<li><strong>创建</strong>→<strong>就绪</strong>：(1)系统初始化，(2)用户请求创建一个新进程，(3)进程执行了创建进程的系统调用</li>
<li><strong>就绪</strong>→<strong>执行</strong>：内核的调度程序(scheduler)选择了一个就绪的进程，让它占用处理机执行</li>
<li><strong>运行</strong>→<strong>等待</strong>: 需要等待某个事件发生才可以继续执行，例如 I/O 请求或者某个共享数据被锁住不能访问</li>
<li><strong>运行</strong>→<strong>就绪</strong>（被<strong>抢占</strong>）：高优先级的进程进入就绪态，进程的时间片用完</li>
<li><strong>等待</strong>→<strong>就绪</strong>(被<strong>唤醒</strong>)：等待的事件发生，例如 I/O 请求完成，共享数据可以访问</li>
<li><strong>运行</strong>→<strong>结束</strong>：可能是正常退出（调用 exit 系统调用），可能是出错（异常，由操作系统强制终止）</li>
</ul>
<h2 id="c-七状态变迁图">c.) 七状态变迁图</h2>
<p>当内存不够的时候，执行状态的进程，就绪状态的进程和等待状态的进程都有可能因为优先级较低而被从内存移出放到外存，如果是执行态和就绪态的进程被移出到外存，则被称为<strong>就绪挂起</strong>；如果是等待态的进程被移出到外存，则被称为<strong>等待挂起</strong>。</p>
<ul>
<li><strong>等待挂起</strong>：进程在外存等待某事件的出现</li>
<li><strong>就绪挂起</strong>：进程在外存，但只要进入内存就可以运行新加入的<strong>状态变迁</strong>有两类：挂起和激活。</li>
<li><strong>挂起：把一个进程从内存移到外存</strong>
<ul>
<li><strong>等待</strong>→<strong>等待挂起</strong>：没有进程处于就绪状态或者就绪进程要求更多的内存</li>
<li><strong>就绪</strong>→<strong>就绪挂起</strong>：当有高优先级等待的进程和低优先级的就绪进程</li>
<li><strong>运行</strong>→<strong>就绪挂起</strong>：当有高优先级等待挂起进程因为等待的事件发生了而进入就绪挂起</li>
<li><strong>等待挂起</strong>→<strong>就绪挂起</strong>：当有等待挂起的进程所等待的事件发生了</li>
</ul>
</li>
<li><strong>激活：把一个进程从外存移到内存</strong>
<ul>
<li><strong>就绪挂起</strong>→<strong>就绪</strong>：没有就绪进程或挂起就绪进程优先级高于就绪进程</li>
<li><strong>等待挂起</strong>→<strong>等待</strong>：当一个进程释放足够内存，并有高优先级等待挂起进程</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%B8%83%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<h1 id="p-stylecolorred5-进程状态的队列p"><p style="color:red">5. 进程状态的队列</p></h1>
<p>进程控制块根据不同状态被放到不同的队列中，如下图所示</p>
<ul>
<li>就绪队列：状态为就绪的PCB 队列，该队列可以是链表也可以是索引，还可以多个队列</li>
<li>执行队列：状态为执行的PCB 队列</li>
<li>等待队列：状态为等待的PCB 队列，不同的等待事件对应不同的等待队列</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E9%98%9F%E5%88%97.jpg" alt="图片" loading="lazy"></figure>
<h1 id="p-stylecolorred6-进程状态切换的实现p"><p style="color:red">6. 进程状态切换的实现</p></h1>
<p>我们用下图来说明两个进程之间的切换过程。</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E5%88%87%E6%8D%A2.png" alt="图片" loading="lazy"></figure>
<p>如上图所示，有两个并发执行的进程，P0 和 P1.首先是 P0 执行，当出现一个中断或系统调用，硬件开始执行相应的处理程序，假设该处理程序调用了 scheduler（调度程序），该调度程序决定让进程 P1 执行，于是需要切换进程的上下文。具体地，(1)先将进程 P0 的进程上下文（PC，SP 和其他寄存器信息）保存到 PCB0，(2)如果是时钟中断，将PCB0 加入就绪队列中等待下一次被 scheduler 调度；如果是一次 I/O 系统调用，则将 PCB0 放入相应的等待队列中， (3)把进程 P1 的 PCB1 从就绪队列中移除，放进执行队列中，(4)将进程上下文从 PCB1 中恢复到寄存器中，此时 PC 指向了进程 P1 要执行的指令，SP 指向了进程 P1 的执行栈，于是 P1 开始执行。当再次出现时钟中断或者系统调用，再用同样的方式保存 P1 的状态到 PCB1 中。不再赘述。</p>
<h1 id="p-stylecolorred7-windows-的进程管理p"><p style="color:red">7. Windows 的进程管理</p></h1>
<p>进程管理之一就是增加一个系统调用，用于创建一个进程。这个理论上很简单但实际实现却比较复杂。在Windows 中，有一个程序，称为CreateProcess，它的简化形式如下</p>
<pre><code>Boolean CreateProcess(char *prog, char *args);
</code></pre>
<p>我们称创建进程的进程为<strong>父亲</strong>，而被创建的进程被称为<strong>孩子</strong>。</p>
<p>CreateProcess 需要执行哪些步骤呢？我们之前已有介绍，内核需要</p>
<ul>
<li>创建并初始化内核中的 PCB</li>
<li>创建和初始化一个新的地址空间</li>
<li>加载程序prog 进入地址空间</li>
<li>将参数 args 拷贝到地址空间的内存中</li>
<li>初始化硬件上下文来从第一条指令开始执行</li>
<li>通知调度程序有新的进程准备运行了<br>
不幸的是，实际的实现要复杂的多，CreateProcess 有十个参数需要设置，如下图所示。<br>
<img src="https://epitomm.github.io/post-images/CreateProcess.png" alt="**Figure 3.3**: 一个如何用 Windows 的系统调用 CreateProcess 的例子. 前两个参数指定程序和它的参数；剩下的关心进程的运行环境." loading="lazy"><br>
Figure 3.3: 一个如何用 Windows 的系统调用 CreateProcess 的例子. 前两个参数指定程序和它的参数；剩下的关心进程的运行环境.</li>
</ul>
<h1 id="p-stylecolorred-8-unix-的进程管理p"><p style="color:red"> 8. UNIX 的进程管理</p></h1>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>创建和管理进程的 API</strong></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">fork()</td>
<td style="text-align:left">创建一个子进程作为当前进程的一个克隆。fork 调用有两个  返回，一个是返回到父进程，另一个返回到子进程.</td>
</tr>
<tr>
<td style="text-align:left">exec(prog, args)</td>
<td style="text-align:left">在当前进程中运行应用程序 prog.</td>
</tr>
<tr>
<td style="text-align:left">exit()</td>
<td style="text-align:left">告诉内核当前的进程完成了，它的数据结构需要被垃圾回收.</td>
</tr>
<tr>
<td style="text-align:left">wait(processID)</td>
<td style="text-align:left">暂停一直到该子进程结束.</td>
</tr>
<tr>
<td style="text-align:left">signal(processID, type)</td>
<td style="text-align:left">发送一个特定类型的中断给其他一个进程.</td>
</tr>
</tbody>
</table>
<p><strong>Figure 3.7</strong>: UNIX 中管理和创建进程的 API.</p>
<p>UNIX 用一种不同的方法来创建进程，这种实现是在理论上复杂，但实现上却比较简单。UNIX 把 CreateProcess 分割成两个阶段，分别称为 fork 和 exec，如下图所示</p>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/fork-exec.jpg" alt="图片" loading="lazy"></figure>
<p><strong>Figure 3.4</strong>: UNIX 的系统调用 fork 和 exec 的操作. UNIX 的 fork 对父进程做了一个拷贝; UNIX 的 exec 将子进程改变成新运行的程序.</p>
<p><strong>UNIX 的 fork</strong>创建一个和父进程完全一致的拷贝，只有一项例外（我们需要某种方法来区分父进程和孩子）。一旦上下文设置好，子进程就调用 UNIX 的 exec 程序。exec 加载新的可执行镜像进入内存并开始执行。看上去先拷贝父进程，然后又用一个新的可执行镜像覆盖看上去有些没必要。实际上 fork 和 exec 来创建新进程的实现确是非常快速的，其中所使用的技术我们会在后面介绍。</p>
<p>在这个设计中, UNIX 的 fork 不接受参数，并返回一个整数。UNIX 的 exec 接受两个参数(要运行的程序的名字和传递给该程序的参数的数组). 这里是 CreateProcess 需要 10 个参数. 部分是因为 UNIX 的 fork 和 exec 的简洁性， 这个接口从 70 年代初期被设计出来到现在几乎没有改变.</p>
<p><strong>UNIX 的 fork</strong>程序包含以下步骤：</p>
<ul>
<li>创建和初始化内核中的 PCB</li>
<li>创建一个新的地址空间</li>
<li>初始化地址空间，将父进程的地址空间完全拷贝过来</li>
<li>继承父进程的执行上下文</li>
<li>通知调度程序有新的进程可以运行</li>
</ul>
<p>比较诡异的一点就是 fork 这个系统调用返回会返回两次：一个是返回给父亲进程，一个是返回给子进程。对于父进程，UNIX 返回子进程的 ID，对于子进程，返回 0 来表示成功。显然，当你克隆了你自己，你需要有某种方式来分辨谁是克隆者，谁是你本身。UNIX 就通过 fork 这个系统调用的返回值来区分这两个进程。Fork 的 sample code 如下图所示</p>
<pre><code>int child_pid = fork();
if (child_pid == 0) { //我是子进程.
  printf(&quot;I am process #   d\n&quot;, getpid()); return 0;
} else { //我是父进程.
  printf(&quot;I am the parent of process #   d\n&quot;, child_pid); return 0;
}
</code></pre>
<p>可能的输出有两种：<br>
<strong>I am the parent of process 495 I am process 495</strong></p>
<p>另一种概率小但仍可能的输出是:</p>
<p><strong>I am process 456</strong></p>
<p><strong>I am the parent of process 456</strong></p>
<p><strong>Figure 3.5</strong>: fork 一个进程的 UNIX 代码, 和运行这个代码的可能的输出。。getpid 是一个系统调用，用来获取当前进程的 ID.</p>
<p>如果我们运行图 3.5 的程序会发生什么？UNIX fork 返回两次，一次是从子进程返回，结果是 0，一次从父进程返回， 结果是子进程的 ID。然而，我们不知道是父进程还是子进程先运行。父进程已经在运行了，看上去它更可能先打印输出。然而，一个时钟中断(timer interrupt)可能在父进程fork 了进程后出现，因此会出现进程切换。或者，我们在多核系统上运行，父进程和子进程是同时运行。无论哪种情况子进程都可能在父进程之前输出。</p>
<p><strong>UNIX 的exec 和wait</strong></p>
<p>UNIX 的系统调用 exec 完成需要运行一个新成效的步骤。一旦子进程从 UNIX fork 返回并设置了新进程的执行环节后，子进程调用 UNIX exec. 在我们下一节讨论UNIX 管道的时候，我们会描述更多这个如何工作的.</p>
<p>Exec 包含如下步骤：</p>
<ul>
<li>加载程序prog 到当前的地址空间</li>
<li>拷贝参数 args 到地址空间中</li>
<li>初始化硬件上下文来从开头开始执行  到此为止，exec 就创建了一个新的进程</li>
</ul>
<p>另一方面，父进程常常需要暂停直到子进程完成运行为止，例如下一步骤是依赖于上一步骤的输出。所以 UNIX 还有一个系统调用，很自然地被叫做wait，它会暂停父进程知道子进程完成或者崩掉或者终止。由于父进程可能创建了许多的子进程，wait 需要设定子进程的 ID 作为参数，来确定要等待的子进程。然而，这个对wait 的调用在 UNIX 中是可选的。</p>
<h1 id="p-stylecolorred9-案例实现一个简单的-shellp"><p style="color:red">9. 案例：实现一个简单的 Shell</p></h1>
<p>图 3.7 列出的UNIX 系统调用已经足以构建一个灵活和强大的命令行 shell，该 shell 完全在用户级运行，不需要特殊权限.</p>
<pre><code>main() {
  char *prog = NULL; char **args = NULL;
  // 一次读取输入的一行，并解析每一行为程序名字和程序参数
  while (readAndParseCmdLine(&amp;prog, &amp;args)) {
    // 创建一个子进程来运行命令. int child_pid = fork();
    if (child_pid == 0) {
      //我是子进程，用父进程的输入来运行程序exec(prog, args);
      // 这里不会到达。。
      } else {
        // 我是父进程，等待子进程完成. wait(child_pid);
        return 0;
    }
  }
}
</code></pre>
<p><strong>Figure 3.8</strong>: 一个简单的 UNIX shell 的代码.<br>
图 3.8 展示了一个shell 的基本操作的代码。这个 shell 从输入读取一个命令行, 然后它 fork 一个进程来执行指令.父进程(shell)在读取下一个要执行的命令行之前必须等待子进程完成。</p>
]]></content>
    </entry>
</feed>