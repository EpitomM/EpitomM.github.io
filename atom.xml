<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://epitomm.github.io</id>
    <title>SSM</title>
    <updated>2020-04-04T10:59:51.428Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://epitomm.github.io"/>
    <link rel="self" href="https://epitomm.github.io/atom.xml"/>
    <subtitle>热心善良的老学姐</subtitle>
    <logo>https://epitomm.github.io/images/avatar.png</logo>
    <icon>https://epitomm.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, SSM</rights>
    <entry>
        <title type="html"><![CDATA[42道计算机网络面试高频题+答案，面试官喜欢的答案都在这里！]]></title>
        <id>https://epitomm.github.io/post/42-dao-ji-suan-ji-wang-luo-mian-shi-gao-pin-ti-da-an-mian-shi-guan-xi-huan-de-da-an-du-zai-zhe-li/</id>
        <link href="https://epitomm.github.io/post/42-dao-ji-suan-ji-wang-luo-mian-shi-gao-pin-ti-da-an-mian-shi-guan-xi-huan-de-da-an-du-zai-zhe-li/">
        </link>
        <updated>2020-04-03T04:48:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-谈下你对五层网络协议体系结构的理解">1、谈下你对五层网络协议体系结构的理解（*）</h1>
<p>学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。</p>
<figure data-type="image" tabindex="1"><img src="https://uploader.shimo.im/f/7hz3woCT4osuGDlM.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="1-应用层">1. 应用层</h2>
<figure data-type="image" tabindex="2"><img src="https://uploader.shimo.im/f/VgEj6OsBq3M4NeVo.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>应用层（application-layer）的任务是<strong>通过应用进程间的交互来完成特定网络应用</strong>。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。我们把应用层交互的数据单元称为报文。</p>
<h2 id="2-运输层">2. 运输层</h2>
<figure data-type="image" tabindex="3"><img src="https://uploader.shimo.im/f/vK8fB6Z7AYwmj7pZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>运输层（transport layer）的主要任务就是负责<strong>向两台主机进程之间的通信提供通用的数据传输服务</strong>。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。</p>
<figure data-type="image" tabindex="4"><img src="https://uploader.shimo.im/f/6lbS0Lrsgp4A08VN.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。</p>
<h2 id="3-网络层">3. 网络层</h2>
<figure data-type="image" tabindex="5"><img src="https://uploader.shimo.im/f/Zhp7yuBDGiAfWeXE.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是<strong>选择合适的网间路由和交换结点， 确保数据及时传送</strong>。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP / IP 体系结构中，由于网络层使用 IP 协议，因此<strong>分组</strong>也叫 <strong>IP 数据报</strong>，简称数据报。</p>
<h2 id="4-数据链路层">4. 数据链路层</h2>
<figure data-type="image" tabindex="6"><img src="https://uploader.shimo.im/f/xYbKq3tQOuQDgd28.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>数据链路层（data link layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，<strong>数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧</strong>。每一帧包括数据和必要的控制信息（如：同步信息，地址信息，差错控制等）。</p>
<figure data-type="image" tabindex="7"><img src="https://uploader.shimo.im/f/dBp0roAfwA0pkbOv.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://uploader.shimo.im/f/HyQygpuEJPwv7E1L.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://uploader.shimo.im/f/OXtDKDdN8Rkqt0O7.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出<strong>数据部分</strong>，上交给网络层。控制信息还使接收端能够检测到所收到的帧中<strong>有无差错</strong>。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用<strong>可靠性传输协议</strong>来纠正出现的差错。这种方法会使链路层的协议复杂些。</p>
<h2 id="5-物理层">5. 物理层</h2>
<figure data-type="image" tabindex="10"><img src="https://uploader.shimo.im/f/5W4Y12Sb37oiQxav.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在物理层上所传送的数据单位是<strong>比特</strong>。物理层（physical layer）的作用是实现相邻计算机节点之间<strong>比特流的透明传送</strong>，尽可能<strong>屏蔽掉具体传输介质和物理设备的差异</strong>。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。</p>
<h1 id="2-简单说下每一层对应的网络协议有哪些">2、简单说下每一层对应的网络协议有哪些？（**）</h1>
<blockquote>
<p>简单记住两三个常见的就行。</p>
</blockquote>
<p>计算机五层网络体系中涉及的协议非常多，下面就常用的做了列举：</p>
<figure data-type="image" tabindex="11"><img src="https://uploader.shimo.im/f/KEPmaUdZoIkiZWZS.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="3-arp-协议的工作原理">3、ARP 协议的工作原理？（*）</h1>
<figure data-type="image" tabindex="12"><img src="https://uploader.shimo.im/f/Imrbk2qiUVUV8c5K.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="mac-地址">MAC 地址</h2>
<figure data-type="image" tabindex="13"><img src="https://uploader.shimo.im/f/7hAVdUAX3KgOQISG.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://uploader.shimo.im/f/it41YFgMMpkXBCES.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>MAC 地址有时也被称为<strong>物理地址</strong>，但这不意味着 MAC 属于网络体系结构中的物理层，MAC 地址属于<strong>数据链路层</strong>。</p>
</blockquote>
<h2 id="ip-地址">IP 地址</h2>
<figure data-type="image" tabindex="15"><img src="https://uploader.shimo.im/f/fQTQYZC4YxIRcPuj.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://uploader.shimo.im/f/pUpJ0mXvAIkRKYb5.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="https://uploader.shimo.im/f/3UMQHY27Dno3U2Z0.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="https://uploader.shimo.im/f/14nXPBBhg9s7ViKb.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="https://uploader.shimo.im/f/MmcffwXZYTMTQYyN.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="arp-协议">ARP 协议</h2>
<figure data-type="image" tabindex="20"><img src="https://uploader.shimo.im/f/FJA5dMHkRC8QXQBQ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="21"><img src="https://uploader.shimo.im/f/mZ9TWqnTfQgqff8m.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="https://uploader.shimo.im/f/o2CuEUAoXKQrBgtv.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="23"><img src="https://uploader.shimo.im/f/yF69YY3Gh2wFp0k2.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://uploader.shimo.im/f/irwCT9nLdQ0WDlUr.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="25"><img src="https://uploader.shimo.im/f/CD4J1MjqhZYJM9Ro.png!thumbnail" alt="图片" loading="lazy"></figure>
<blockquote>
<p>ARP 只能在一段链路或一个网络上使用，不能跨网络使用。</p>
</blockquote>
<p><strong>网络层</strong>的 ARP 协议完成了 <strong>IP 地址与物理地址的映射</strong>。首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址：如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。</p>
<p>此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。</p>
<h1 id="4-谈下你对-ip-地址分类的理解">4、谈下你对 IP 地址分类的理解？</h1>
<p>IP 地址是指互联网协议地址，是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP 地址编址方案将 IP 地址空间划分为 A、B、C、D、E 五类，其中 A、B、C 是基本类，D、E 类作为多播和保留使用，为特殊地址。</p>
<figure data-type="image" tabindex="26"><img src="https://uploader.shimo.im/f/6TvJJC0SKC8N3fRi.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>每个 IP 地址包括两个标识码（ID），即网络 ID 和主机 ID。同一个物理网络上的所有主机都使用同一个网络 ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机 ID 与其对应。A~E 类地址的特点如下：</p>
<p>A 类地址：以 0 开头，第一个字节范围：0~127；</p>
<p>B 类地址：以 10 开头，第一个字节范围：128~191；</p>
<p>C 类地址：以 110 开头，第一个字节范围：192~223；</p>
<p>D 类地址：以 1110 开头，第一个字节范围为 224~239；</p>
<p>E 类地址：以 1111 开头，保留地址</p>
<figure data-type="image" tabindex="27"><img src="https://uploader.shimo.im/f/H8ZWz6fsJMkBBNBs.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="28"><img src="https://uploader.shimo.im/f/6O9LBeVjsNA3cjL1.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="29"><img src="https://uploader.shimo.im/f/lrFOgqmsEG806jNp.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="30"><img src="https://uploader.shimo.im/f/2IG540gBRwkMNP9e.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="31"><img src="https://uploader.shimo.im/f/G9oD9evG81EmL1QH.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="5-tcp-的主要特点是什么">5、TCP 的主要特点是什么？（*）</h1>
<ol>
<li>
<p>TCP 是<strong>面向连接</strong>的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；</p>
</li>
<li>
<p>每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是点对点的（<strong>一对一</strong>）；</p>
</li>
<li>
<p>TCP 提供<strong>可靠</strong>交付的服务。通过 TCP 连接传送的数据，无差错、不丢失、不重复、并且按序到达；</p>
</li>
<li>
<p>TCP 提供<strong>全双工</strong>通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；</p>
</li>
<li>
<p>面向<strong>字节流</strong>。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。</p>
</li>
</ol>
<h1 id="6-udp-的主要特点是什么">6、UDP 的主要特点是什么？</h1>
<ol>
<li>
<p>UDP 是<strong>无连接</strong>的；</p>
</li>
<li>
<p>UDP 使用尽最大努力交付，即<strong>不</strong>保证<strong>可靠</strong>交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；</p>
</li>
<li>
<p>UDP 是<strong>面向报文</strong>的；</p>
</li>
<li>
<p>UDP <strong>没有拥塞控制</strong>，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；</p>
</li>
<li>
<p>UDP 支持<strong>一对一、一对多、多对一和多对多</strong>的交互通信；</p>
</li>
<li>
<p>UDP 的<strong>首部开销小</strong>，只有 8 个字节，比 TCP 的 20 个字节的首部要短。</p>
</li>
</ol>
<h1 id="7-tcp-和-udp-的区别">7、TCP 和 UDP 的区别？（*）</h1>
<figure data-type="image" tabindex="32"><img src="https://uploader.shimo.im/f/cGEBZNflD9EjWCqz.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。</p>
<p>UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如：QQ 语音、 QQ 视频 、直播等等。</p>
<figure data-type="image" tabindex="33"><img src="https://uploader.shimo.im/f/mdhPaxpzb5oIJMW2.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="34"><img src="https://uploader.shimo.im/f/7u9g88OLoW4CdqQ7.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="35"><img src="https://uploader.shimo.im/f/fsJkcJYSPRs8C34V.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="36"><img src="https://uploader.shimo.im/f/fH5S3LGWfi0oHUxM.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="37"><img src="https://uploader.shimo.im/f/7Uwcb5rUdBsTs5Us.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="8-tcp-和-udp-分别对应的常见应用层协议有哪些">8、TCP 和 UDP 分别对应的常见应用层协议有哪些？</h1>
<ul>
<li>
<ol>
<li>TCP 对应的应用层协议</li>
</ol>
</li>
</ul>
<p>FTP：定义了文件传输协议，使用 21 端口。常说某某计算机开了 FTP 服务便是启动了文件传输服务。下载文件，上传主页，都要用到 FTP 服务。</p>
<p>Telnet：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于 DOS 模式下的通信服务。如以前的 BBS 是-纯字符界面的，支持 BBS 的服务器将 23 端口打开，对外提供服务。</p>
<p>SMTP：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么 SMTP 端口设置这个栏，服务器开放的是 25 号端口。</p>
<p>POP3：它是和 SMTP 对应，POP3 用于接收邮件。通常情况下，POP3 协议所用的是 110 端口。也是说，只要你有相应的使用 POP3 协议的程序（例如 Fo-xmail 或 Outlook），就可以不以 Web 方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163 邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。</p>
<p>HTTP：从 Web 服务器传输超文本到本地浏览器的传送协议。</p>
<ul>
<li>
<ol start="2">
<li>UDP 对应的应用层协议</li>
</ol>
</li>
</ul>
<p>DNS：用于域名解析服务，将域名地址转换为 IP 地址。DNS 用的是 53 号端口。</p>
<p>SNMP：简单网络管理协议，使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。</p>
<p>TFTP(Trival File Transfer Protocal)：简单文件传输协议，该协议在熟知端口 69 上使用 UDP 服务。</p>
<h1 id="9-详细说下-tcp-三次握手的过程">9、详细说下 TCP 三次握手的过程？（*）</h1>
<ul>
<li>
<ol>
<li>三次握手</li>
</ol>
</li>
</ul>
<p>TCP 建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 TCP 报文段。</p>
<figure data-type="image" tabindex="38"><img src="https://uploader.shimo.im/f/sVrpuVA01g4E8YtW.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>最初客户端和服务端都处于 CLOSED(关闭) 状态。本例中 A（Client） 主动打开连接，B（Server） 被动打开连接。</p>
<p>一开始，B 的 TCP 服务器进程首先创建传输控制块TCB，准备接受客户端进程的连接请求。然后服务端进程就处于 LISTEN(监听) 状态，等待客户端的连接请求。如有，立即作出响应。</p>
<p>第一次握手：A 的 TCP 客户端进程也是首先创建传输控制块 TCB。然后，在打算建立 TCP 连接时，向 B 发出连接请求报文段，这时首部中的同步位 SYN=1，同时选择一个初始序号 seq = x。TCP 规定，SYN 报文段（即 SYN = 1 的报文段）不能携带数据，但要消耗掉一个序号。这时，TCP 客户进程进入 SYN-SENT（同步已发送）状态。</p>
<p>第二次握手：B 收到连接请求报文后，如果同意建立连接，则向 A 发送确认。在确认报文段中应把 SYN 位和 ACK 位都置 1，确认号是 ack = x + 1，同时也为自己选择一个初始序号 seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时 TCP 服务端进程进入 SYN-RCVD（同步收到）状态。</p>
<p>第三次握手：TCP 客户进程收到 B 的确认后，还要向 B 给出确认。确认报文段的 ACK 置 1，确认号 ack = y +  1，而自己的序号 seq = x + 1。这时 ACK 报文段可以携带数据。但如果不携带数据则不消耗序号，这种情况下，下一个数据报文段的序号仍是 seq = x + 1。这时，TCP 连接已经建立，A 进入 ESTABLISHED（已建立连接）状态。</p>
<h1 id="10-为什么两次握手不可以呢">10、为什么两次握手不可以呢？（*）</h1>
<figure data-type="image" tabindex="39"><img src="https://uploader.shimo.im/f/FgFJfk6FgJQdTJko.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>为了防止已经失效的连接请求报文段突然又传送到了 B，因而产生错误。比如下面这种情况：A 发出的第一个连接请求报文段并没有丢失，而是在网路结点长时间滞留了，以致于延误到连接释放以后的某个时间段才到达 B。本来这是一个早已失效的报文段。但是 B 收到此失效的链接请求报文段后，就误认为 A 又发出一次新的连接请求。于是就向 A 发出确认报文段，同意建立连接。</p>
<p>对于上面这种情况，如果不进行第三次握手，B 发出确认后就认为新的运输连接已经建立了，并一直等待 A 发来数据。B 的许多资源就这样白白浪费了。</p>
<p>如果采用了三次握手，由于 A 实际上并没有发出建立连接请求，所以不会理睬 B 的确认，也不会向 B 发送数据。B 由于收不到确认，就知道 A 并没有要求建立连接。</p>
<h1 id="11-为什么不需要四次握手">11、为什么不需要四次握手？（*）</h1>
<p>有人可能会说 A 发出第三次握手的信息后在没有接收到 B 的请求就已经进入了连接状态，那如果 A 的这个确认包丢失或者滞留了怎么办？</p>
<p>我们需要明白一点，完全可靠的通信协议是不存在的。在经过三次握手之后，客户端和服务端已经可以确认之前的通信状况，都收到了确认信息。所以即便再增加握手次数也不能保证后面的通信完全可靠，所以是没有必要的。</p>
<h1 id="12-server-端收到-client-端的-syn-后为什么还要传回-syn">12、Server 端收到 Client 端的 SYN 后，为什么还要传回 SYN？</h1>
<p>接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。</p>
<p>SYN 是 TCP / IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符，在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误]）消息响应。这样在客户机和服务器之间才能建立起可靠的 TCP 连接，数据才可以在客户机和服务器之间传递。</p>
<h1 id="13-传了-syn为什么还要传-ack">13、传了 SYN，为什么还要传 ACK？</h1>
<p>双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。</p>
<h1 id="14-详细说下-tcp-四次挥手的过程">14、详细说下 TCP 四次挥手的过程？（*）</h1>
<p>据传输结束后，通信的双方都可以释放连接。现在 A 和 B 都处于 ESTABLISHED 状态。</p>
<figure data-type="image" tabindex="40"><img src="https://uploader.shimo.im/f/fJStbiea6HoBykQF.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>第一次挥手：A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP 连接。A 把连接释放报文段首部的终止控制位 FIN 置 1，其序号 seq = u（等于前面已传送过的数据的最后一个字节的序号加 1），这时 A 进入 FIN-WAIT-1（终止等待1）状态，等待 B 的确认。请注意：TCP 规定，FIN 报文段即使不携带数据，也将消耗掉一个序号。</p>
<p>第二次挥手：B 收到连接释放报文段后立即发出确认，确认号是 ack = u + 1，而这个报文段自己的序号是 v（等于 B 前面已经传送过的数据的最后一个字节的序号加1），然后 B 就进入 CLOSE-WAIT（关闭等待）状态。TCP 服务端进程这时应通知高层应用进程，因而从 A 到 B 这个方向的连接就释放了，这时的 TCP 连接处于半关闭（half-close）状态，即 A 已经没有数据要发送了，但 B 若发送数据，A 仍要接收。也就是说，从 B 到 A 这个方向的连接并未关闭，这个状态可能会持续一段时间。A 收到来自 B 的确认后，就进入 FIN-WAIT-2(终止等待2)状态，等待 B 发出的连接释放报文段。</p>
<p>第三次挥手：若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。这时 B 发出的连接释放报文段必须使 FIN = 1。假定 B 的序号为 w（在半关闭状态，B 可能又发送了一些数据）。B 还必须重复上次已发送过的确认号 ack = u + 1。这时 B 就进入 LAST-ACK(最后确认)状态，等待 A 的确认。</p>
<p>第四次挥手：A 在收到 B 的连接释放报文后，必须对此发出确认。在确认报文段中把 ACK 置 1，确认号 ack = w + 1，而自己的序号 seq = u + 1（前面发送的 FIN 报文段要消耗一个序号）。然后进入 TIME-WAIT(时间等待) 状态。请注意，现在 TCP 连接还没有释放掉。必须经过时间等待计时器设置的时间 2MSL（MSL：最长报文段寿命）后，A 才能进入到 CLOSED 状态，然后撤销传输控制块，结束这次 TCP 连接。当然如果 B 一收到 A 的确认就进入 CLOSED 状态，然后撤销传输控制块。所以在释放连接时，B 结束 TCP 连接的时间要早于 A。</p>
<h1 id="15-为什么-time-wait-状态必须等待-2msl-的时间呢">15、为什么 TIME-WAIT 状态必须等待 2MSL 的时间呢？（*）</h1>
<figure data-type="image" tabindex="41"><img src="https://uploader.shimo.im/f/IZd7Slvq5VQpgRyq.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li>
<p>为了保证 A 发送的最后一个 ACK 报文段能够到达 B。这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 B 收不到对已发送的 FIN + ACK 报文段的确认。B 会超时重传这个 FIN+ACK 报文段，而 A 就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN+ACK 报文段。接着 A 重传一次确认，重新启动 2MSL 计时器。最后，A 和 B 都正常进入到 CLOSED 状态。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段，这样，B 就无法按照正常步骤进入 CLOSED 状态。</p>
</li>
<li>
<p>防止已失效的连接请求报文段出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。</p>
</li>
</ol>
<h1 id="16-为什么第二次跟第三次不能合并-第二次和第三次之间的等待是什么">16、为什么第二次跟第三次不能合并, 第二次和第三次之间的等待是什么?</h1>
<p>当服务器执行第二次挥手之后, 此时证明客户端不会再向服务端请求任何数据, 但是服务端可能还正在给客户端发送数据（可能是客户端上一次请求的资源还没有发送完毕），所以此时服务端会等待把之前未传输完的数据传输完毕之后再发送关闭请求。</p>
<h1 id="17-保活计时器的作用">17、保活计时器的作用？</h1>
<p>除时间等待计时器外，TCP 还有一个保活计时器（keepalive  timer）。设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。</p>
<p>服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔  75 秒钟发送一次。若连续发送 10个 探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。</p>
<h1 id="18-tcp-协议是如何保证可靠传输的">18、TCP 协议是如何保证可靠传输的？（*）</h1>
<ol>
<li>
<p><strong>数据包校验</strong>：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据；</p>
</li>
<li>
<p><strong>对失序数据包重排序</strong>：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层；</p>
</li>
<li>
<p><strong>丢弃重复数据</strong>：对于重复数据，能够丢弃重复数据；</p>
</li>
<li>
<p><strong>应答机制</strong>：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；</p>
</li>
<li>
<p><strong>超时重发</strong>：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；</p>
</li>
<li>
<p><strong>流量控制</strong>：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。</p>
</li>
</ol>
<h1 id="19-谈谈你对停止等待协议的理解">19、谈谈你对停止等待协议的理解？</h1>
<figure data-type="image" tabindex="42"><img src="https://uploader.shimo.im/f/ilbrX9885DshiTgj.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="43"><img src="https://uploader.shimo.im/f/I2PqsOrJ0BczTYUl.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认迟到、确认丢失和确认迟到。</p>
<figure data-type="image" tabindex="44"><img src="https://uploader.shimo.im/f/GwbkBys0LIYRMJgU.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="20-谈谈你对-arq-协议的理解">20、谈谈你对 ARQ 协议的理解？</h1>
<ul>
<li>自动重传请求 ARQ 协议</li>
</ul>
<p>停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。</p>
<ul>
<li>连续 ARQ 协议</li>
</ul>
<p>连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。</p>
<h1 id="21-谈谈你对滑动窗口的了解">21、谈谈你对滑动窗口的了解？（*）</h1>
<p>TCP 利用滑动窗口实现流量控制的机制。滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。</p>
<p>TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。</p>
<figure data-type="image" tabindex="45"><img src="https://uploader.shimo.im/f/HVPjgKO3S2Qq75tF.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="46"><img src="https://uploader.shimo.im/f/JRAM7qssAgUQ5Fnq.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="47"><img src="https://uploader.shimo.im/f/wblaPkbu32k96yVU.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="48"><img src="https://uploader.shimo.im/f/4MN4C6h3K30y3RjS.png!thumbnail" alt="图片" loading="lazy"></figure>
<h1 id="22-谈下你对流量控制的理解">22、谈下你对流量控制的理解？（*）</h1>
<p>TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</p>
<h1 id="23-谈下你对-tcp-拥塞控制的理解使用了哪些算法">23、谈下你对 TCP 拥塞控制的理解？使用了哪些算法？</h1>
<figure data-type="image" tabindex="49"><img src="https://uploader.shimo.im/f/Cxp9wJCABu8ya4XR.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="50"><img src="https://uploader.shimo.im/f/e1KHhdkCmu0JrJdy.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="51"><img src="https://uploader.shimo.im/f/A1Mt383YnYwRuMhl.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>拥塞控制和流量控制不同，前者是一个全局性的过程，而后者指点对点通信量的控制。在某段时间，若<strong>对网络中某一资源的需求超过了该资源所能提供的可用部分</strong>，网络的性能就要变坏。这种情况就叫<strong>拥塞</strong>。</p>
<p>拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致于过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。</p>
<p>为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。</p>
<p>TCP 的拥塞控制采用了四种算法，即：慢开始、拥塞避免、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如：主动队列管理 AQM），以减少网络拥塞的发生。</p>
<h2 id="慢开始">慢开始：</h2>
<figure data-type="image" tabindex="52"><img src="https://uploader.shimo.im/f/DwBr0f7gJWoRju09.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。<strong>cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍</strong>。</p>
<h2 id="拥塞避免">拥塞避免：</h2>
<figure data-type="image" tabindex="53"><img src="https://uploader.shimo.im/f/mnjZbVjUW7YioSgE.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="54"><img src="https://uploader.shimo.im/f/ZzBMLCrBW7AWgnTc.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="55"><img src="https://uploader.shimo.im/f/DhyXyH4VI3o4atqY.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="56"><img src="https://uploader.shimo.im/f/VSWKrfeo84Q3BEAg.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把<strong>发送方的 cwnd 加 1</strong>。</p>
<figure data-type="image" tabindex="57"><img src="https://uploader.shimo.im/f/a3mLciCHy54Vf9xL.png!thumbnail" alt="图片" loading="lazy"></figure>
<h2 id="快重传与快恢复">快重传与快恢复：</h2>
<figure data-type="image" tabindex="58"><img src="https://uploader.shimo.im/f/5JXdessxcTMMsAoG.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="59"><img src="https://uploader.shimo.im/f/lfhgzFCGEiQ7ZJNZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="60"><img src="https://uploader.shimo.im/f/YUstziH9Z0YCkxoZ.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="61"><img src="https://uploader.shimo.im/f/9Ej3t6jYGPA7arPd.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>在 TCP/IP 中，快速重传和快恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。</p>
<p>有时，个别报文段会在网络中丢失，但实际上网络并未发生拥塞，这将导致发送方超时重传，并误认为网络发生了拥塞；发送方把拥塞窗口 cwnd 又设置为最小值 1，并错误地启动慢开始算法，因而降低了传输效率。采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。</p>
<p>所谓快重传，就是使发送方尽快进行重传，而不是等超时重传计时器超时再重传。</p>
<p>要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认；</p>
<p>即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。</p>
<p>发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传计时器超时再重传。</p>
<h1 id="24-什么是粘包">24、什么是粘包？</h1>
<p>在进行 Java NIO 学习时，可能会发现：如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况。</p>
<ol>
<li>
<p>TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界；</p>
</li>
<li>
<p>从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。</p>
</li>
</ol>
<p>基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。</p>
<p>接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。</p>
<h1 id="25-tcp-黏包是怎么产生的">25、TCP 黏包是怎么产生的？</h1>
<ul>
<li><strong>发送方产生粘包</strong></li>
</ul>
<p>采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。</p>
<ul>
<li><strong>接收方产生粘包</strong></li>
</ul>
<p>接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度）</p>
<p>​</p>
<h1 id="26-怎么解决拆包和粘包">26、怎么解决拆包和粘包？</h1>
<p>分包机制一般有两个通用的解决方法：</p>
<ol>
<li>
<p>特殊字符控制；</p>
</li>
<li>
<p>在包头首都添加数据包的长度。</p>
</li>
</ol>
<p>如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。</p>
<p>tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。</p>
<h1 id="27-你对-http-状态码有了解吗">27、你对 HTTP 状态码有了解吗？</h1>
<figure data-type="image" tabindex="62"><img src="https://uploader.shimo.im/f/g5uWYFy1vK00cvhl.png!thumbnail" alt="图片" loading="lazy"></figure>
<ul>
<li><strong>1XX 信息</strong></li>
</ul>
<ol>
<li>100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。</li>
</ol>
<ul>
<li><strong>2XX 成功</strong></li>
</ul>
<ol>
<li>
<p>200 OK</p>
</li>
<li>
<p>204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。</p>
</li>
<li>
<p>206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。</p>
</li>
</ol>
<ul>
<li><strong>3XX 重定向</strong></li>
</ul>
<ol>
<li>
<p>301 Moved Permanently ：永久性重定向；</p>
</li>
<li>
<p>302 Found ：临时性重定向；</p>
</li>
<li>
<p>303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。</p>
</li>
<li>
<p>304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。</p>
</li>
<li>
<p>307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。</p>
</li>
</ol>
<ul>
<li><strong>4XX 客户端错误</strong></li>
</ul>
<ol>
<li>
<p>400 Bad Request ：请求报文中存在语法错误。</p>
</li>
<li>
<p>401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。</p>
</li>
<li>
<p>403 Forbidden ：请求被拒绝。</p>
</li>
<li>
<p>404 Not Found</p>
</li>
</ol>
<ul>
<li><strong>5XX 服务器错误</strong></li>
</ul>
<ol>
<li>
<p>500 Internal Server Error ：服务器正在执行请求时发生错误；</p>
</li>
<li>
<p>503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。</p>
</li>
</ol>
<h1 id="28-http-状态码-301-和-302-代表的是什么有什么区别">28、HTTP 状态码 301 和 302 代表的是什么？有什么区别？</h1>
<p>301，302 都是 HTTP 状态的编码，都代表着某个 URL 发生了转移。</p>
<ul>
<li>**区别： **</li>
</ul>
<p>301 redirect: 301 代表永久性转移（Permanently Moved）</p>
<p>302 redirect: 302 代表暂时性转移（Temporarily Moved）</p>
<h1 id="29-forward-和-redirect-的区别">29、forward 和 redirect 的区别？</h1>
<p>Forward 和 Redirect 代表了两种请求转发方式：直接转发和间接转发。</p>
<p>直接转发方式（Forward）：客户端和浏览器只发出<strong>一次请求</strong>，Servlet、HTML、JSP 或其它信息资源，由第二个信息资源响应该请求，在请求对象 request 中，保存的对象对于每个信息资源是共享的。</p>
<p>间接转发方式（Redirect）：实际是<strong>两次 HTTP 请求</strong>，服务器端在响应第一次请求的时候，让浏览器再向另外一个 URL 发出请求，从而达到转发的目的。</p>
<ul>
<li>举个通俗的例子：</li>
</ul>
<p>直接转发就相当于：“A 找 B 借钱，B 说没有，B 去找 C 借，借到借不到都会把消息传递给 A”；</p>
<p>间接转发就相当于：&quot;A 找 B 借钱，B 说没有，让 A 去找 C 借&quot;。</p>
<h1 id="30-http-方法有哪些">30、HTTP 方法有哪些？</h1>
<p>客户端发送的 请求报文 第一行为请求行，包含了方法字段。</p>
<ol>
<li>
<p>GET：获取资源，当前网络中绝大部分使用的都是 GET；</p>
</li>
<li>
<p>HEAD：获取报文首部，和 GET 方法类似，但是不返回报文实体主体部分；</p>
</li>
<li>
<p>POST：传输实体主体</p>
</li>
<li>
<p>PUT：上传文件，由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。</p>
</li>
<li>
<p>PATCH：对资源进行部分修改。PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。</p>
</li>
<li>
<p>OPTIONS：查询指定的 URL 支持的方法；</p>
</li>
<li>
<p>CONNECT：要求在与代理服务器通信时建立隧道。使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。</p>
</li>
<li>
<p>TRACE：追踪路径。服务器会将通信路径返回给客户端。发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。</p>
</li>
</ol>
<h1 id="31-说下-get-和-post-的区别">31、说下 GET 和 POST 的区别？（**）</h1>
<p>GET 和 POST 本质都是 HTTP 请求，只不过对它们的作用做了界定和适配，并且让他们适应各自的场景。</p>
<p>本质区别：GET 只是一次 HTTP请求，POST 先发请求头再发请求体，实际上是两次请求。</p>
<ol>
<li>
<p>从功能上讲，GET 一般用来从服务器上获取资源，POST 一般用来更新服务器上的资源；</p>
</li>
<li>
<p>从 REST 服务角度上说，GET 是幂等的，即读取同一个资源，总是得到相同的数据，而 POST 不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET 不会改变服务器上的资源，而 POST 会对服务器资源进行改变；</p>
</li>
<li>
<p>从请求参数形式上看，GET 请求的数据会附在 URL 之后，即将请求数据放置在 HTTP 报文的 请求头 中，以 ? 分割 URL 和传输数据，参数之间以 &amp; 相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用 BASE64 加密，得出如：%E4%BD%A0%E5%A5%BD，其中 ％XX 中的 XX 为该符号以 16 进制表示的 ASCII)；而 POST 请求会把提交的数据则放置在是 HTTP 请求报文的 请求体 中；</p>
</li>
<li>
<p>就安全性而言，POST 的安全性要比 GET 的安全性高，因为 GET 请求提交的数据将明文出现在 URL 上，而且 POST 请求参数则被包装到请求体中，相对更安全；</p>
</li>
<li>
<p>从请求的大小看，GET 请求的长度受限于浏览器或服务器对 URL 长度的限制，允许发送的数据量比较小，而 POST 请求则是没有大小限制的。</p>
</li>
</ol>
<h1 id="32-在浏览器中输入-url-地址到显示主页的过程">32、在浏览器中输入 URL 地址到显示主页的过程？（*）</h1>
<ol>
<li>
<p>DNS 解析：浏览器查询 DNS，获取域名对应的 IP 地址：具体过程包括浏览器搜索自身的 DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服务器进行查询等。对于向本地 DNS 服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；</p>
</li>
<li>
<p>TCP 连接：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手；</p>
</li>
<li>
<p>发送 HTTP 请求：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求；</p>
</li>
<li>
<p>服务器处理请求并返回 HTTP 报文：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；</p>
</li>
<li>
<p>浏览器解析渲染页面：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。</p>
</li>
<li>
<p>连接结束。</p>
</li>
</ol>
<h1 id="33-dns-的解析过程">33、DNS 的解析过程？（**）</h1>
<figure data-type="image" tabindex="63"><img src="https://uploader.shimo.im/f/jm7dKHGyA543S9Xk.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="64"><img src="https://uploader.shimo.im/f/LypWsW5YTq0QVvld.png!thumbnail" alt="图片" loading="lazy"></figure>
<ol>
<li>
<p><strong>主机向本地域名服务器</strong>的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。</p>
</li>
<li>
<p><strong>本地域名服务器向根域名服务器</strong>的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，本地域名服务器得到了所要解析的 IP 地址或报错，然后把这个结果返回给发起查询的主机。</p>
</li>
</ol>
<h1 id="34-谈谈你对域名缓存的了解">34、谈谈你对域名缓存的了解？</h1>
<figure data-type="image" tabindex="65"><img src="https://uploader.shimo.im/f/xfZfIy82Vsc3MhHx.png!thumbnail" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="66"><img src="https://uploader.shimo.im/f/QPRdQphNRlkh30Na.png!thumbnail" alt="图片" loading="lazy"></figure>
<p>为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在<strong>域名服务器</strong>中广泛使用了<strong>高速缓存</strong>，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。</p>
<p>由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置<strong>计时器</strong>并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。</p>
<p>不仅在本地域名服务器中需要高速缓存，在<strong>主机</strong>中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，而且主机必须从缓存中删除无效的项。由于域名改动并不频繁，大多数网点不需花精力就能维护数据库的一致性。</p>
<h1 id="35-谈下你对-http-长连接和短连接的理解分别应用于哪些场景">35、谈下你对 HTTP 长连接和短连接的理解？分别应用于哪些场景？</h1>
<p>在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如：JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。</p>
<p>而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：</p>
<p>Connection:keep-alive</p>
<p>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。</p>
<p>Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如：Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。</p>
<h1 id="36-谈下-http-10-和-11-12-的主要变化">36、谈下 HTTP 1.0 和 1.1、1.2 的主要变化？</h1>
<ul>
<li><strong>HTTP1.1 的主要变化：</strong></li>
</ul>
<ol>
<li>
<p>HTTP1.0 经过多年发展，在 1.1 提出了改进。首先是提出了长连接，HTTP 可以在一次 TCP 连接中不断发送请求。</p>
</li>
<li>
<p>然后 HTTP1.1 支持只发送 header 而不发送 body。原因是先用 header 判断能否成功，再发数据，节约带宽，事实上，post 请求默认就是这样做的。</p>
</li>
<li>
<p>HTTP1.1 的 host 字段。由于虚拟主机可以支持多个域名，所以一般将域名解析后得到 host。</p>
</li>
</ol>
<ul>
<li><strong>HTTP2.0 的主要变化：</strong></li>
</ul>
<ol>
<li>
<p>HTTP2.0 支持多路复用，同一个连接可以并发处理多个请求，方法是把 HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组，而不需要一个个 HTTP请求顺序到达；</p>
</li>
<li>
<p>HTTP2.0 支持服务端推送，就是服务端在 HTTP 请求到达后，除了返回数据之外，还推送了额外的内容给客户端；</p>
</li>
<li>
<p>HTTP2.0 压缩了请求头，同时基本单位是二进制帧流，这样的数据占用空间更少；</p>
</li>
<li>
<p>HTTP2.0 适用于 HTTPS 场景，因为其在 HTTP和 TCP 中间加了一层 SSL 层。</p>
</li>
</ol>
<h1 id="37-https-的工作过程">37、HTTPS 的工作过程？（**）</h1>
<ol>
<li>
<p>客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了；</p>
</li>
<li>
<p>服务器从中选出一套加密算法和 hash 算法以及自己的身份信息（地址等）以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构；</p>
</li>
<li>
<p>客户端收到网站的证书之后要做下面的事情：</p>
</li>
</ol>
<ul>
<li>3.1 验证证书的合法性；</li>
</ul>
<p>3.2 果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密；</p>
<ul>
<li>3.3 用约定好的 hash 算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器。</li>
</ul>
<ol start="4">
<li>服务器接收到客户端传送来的信息，要做下面的事情：</li>
</ol>
<ul>
<li>4.1 用私钥解析出密码，用密码解析握手消息，验证 hash 值是否和浏览器发来的一致；</li>
<li>4.2 使用密钥加密消息；</li>
</ul>
<ol start="5">
<li>如果计算法 hash 值一致，握手成功。</li>
</ol>
<h1 id="38-http-和-https-的区别"><strong>38、HTTP 和 HTTPS 的区别？</strong></h1>
<ol>
<li>
<p>开销：HTTPS 协议需要到 CA 申请证书，一般免费证书很少，需要交费；</p>
</li>
<li>
<p>资源消耗：HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 ssl 加密传输协议，需要消耗更多的 CPU 和内存资源；</p>
</li>
<li>
<p>端口不同：HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是  80，后者是 443；</p>
</li>
<li>
<p>安全性：HTTP 的连接很简单，是无状态的；HTTPS 协议是由 TSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。</p>
</li>
</ol>
<h1 id="39-https-的优缺点"><strong>39、HTTPS 的优缺点？</strong></h1>
<ul>
<li><strong>优点：</strong></li>
</ul>
<ol>
<li>
<p>使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</p>
</li>
<li>
<p>HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性；</p>
</li>
<li>
<p>HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</p>
</li>
</ol>
<ul>
<li><strong>缺点：</strong></li>
</ul>
<ol>
<li>
<p>HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近 50%，增加 10% 到 20% 的耗电；</p>
</li>
<li>
<p>HTTPS 连接缓存不如 HTTP 高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；</p>
</li>
<li>
<p>SSL 证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用；</p>
</li>
<li>
<p>SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗；</p>
</li>
<li>
<p>HTTPS 协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。</p>
</li>
</ol>
<h1 id="40-什么是数字签名"><strong>40、什么是数字签名？</strong></h1>
<p>为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。</p>
<h1 id="41-什么是数字证书"><strong>41、什么是数字证书？</strong></h1>
<p>对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。</p>
<h1 id="42-什么是对称加密和非对称加密"><strong>42、什么是对称加密和非对称加密？</strong></h1>
<p>对称密钥加密是指<strong>加密和解密使用同一个密钥</strong>的方式，这种方式存在的最大问题就是密钥发送问题，即如何<strong>安全地将密钥发给对方</strong>。</p>
<p>非对称加密指使用一对非对称密钥，即：公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的<strong>公钥</strong>进行<strong>加密</strong>处理，对方接收到加密信息后，使用自己的<strong>私钥</strong>进行<strong>解密</strong>。</p>
<p>由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性。但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。</p>
<p>附：计网思维导图<br>
<img src="https://epitomm.github.io/post-images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.png" alt="图片" loading="lazy"></p>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://mp.weixin.qq.com/s/Gy4ElItSvBoeQnN4YbMPGQ">https://mp.weixin.qq.com/s/Gy4ElItSvBoeQnN4YbMPGQ</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题 —— 由浅入深全面解析 Threadlocal]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-threadlocal/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-threadlocal/">
        </link>
        <updated>2020-04-01T16:09:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-threadlocal-介绍">一、ThreadLocal 介绍</h1>
<h2 id="11-官方介绍">1.1 官方介绍</h2>
<pre><code>/**
 * This class provides thread-local variables.  These variables differ from
 * their normal counterparts in that each thread that accesses one (via its
 * {@code get} or {@code set} method) has its own, independently initialized
 * copy of the variable.  {@code ThreadLocal} instances are typically private
 * static fields in classes that wish to associate state with a thread (e.g.,
 * a user ID or Transaction ID).
 *
 * &lt;p&gt;For example, the class below generates unique identifiers local to each
 * thread.
 * A thread's id is assigned the first time it invokes {@code ThreadId.get()}
 * and remains unchanged on subsequent calls.
 * &lt;pre&gt;
 * import java.util.concurrent.atomic.AtomicInteger;
 *
 * public class ThreadId {
 *     // Atomic integer containing the next thread ID to be assigned
 *     private static final AtomicInteger nextId = new AtomicInteger(0);
 *
 *     // Thread local variable containing each thread's ID
 *     private static final ThreadLocal&amp;lt;Integer&amp;gt; threadId =
 *         new ThreadLocal&amp;lt;Integer&amp;gt;() {
 *             &amp;#64;Override protected Integer initialValue() {
 *                 return nextId.getAndIncrement();
 *         }
 *     };
 *
 *     // Returns the current thread's unique ID, assigning it if necessary
 *     public static int get() {
 *         return threadId.get();
 *     }
 * }
 * &lt;/pre&gt;
 * &lt;p&gt;Each thread holds an implicit reference to its copy of a thread-local
 * variable as long as the thread is alive and the {@code ThreadLocal}
 * instance is accessible; after a thread goes away, all of its copies of
 * thread-local instances are subject to garbage collection (unless other
 * references to these copies exist).
 *
 * @author  Josh Bloch and Doug Lea
 * @since   1.2
 */
</code></pre>
<p>从 Java 官方文档中的描述：ThreadLocal类用来提供<strong>线程内部的局部变量</strong>。这种变量在多线程环境下访问（通过get和set方法访问）时能保证各个线程的变量相对独立于其他线程内的变量。ThreadLocal实例通常来说都是private static类型的，用于关联线程和线程上下文。<br>
我们可以得知ThreadLocal的作用是：提供线程内的局部变量，不同的线程之间不会相互干扰，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或组件之间一些公共变量传递的复杂度。</p>
<p>总结：</p>
<ol>
<li>
<p>线程并发：在多并发的场景下</p>
</li>
<li>
<p>传递数据：我们可以通过 ThreadLocal 在同一线程，不同组件中传递公共变量</p>
</li>
<li>
<p>线程隔离：每个线程的变量都是独立的，不会互相影响。</p>
</li>
</ol>
<h2 id="12-基本使用">1.2 基本使用</h2>
<h3 id="121-常用方法">1.2.1 常用方法</h3>
<p>在使用之前，我们先来认识几个 ThreadLoal 的常用方法</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>方法声明</strong></th>
<th style="text-align:left"><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ThreadLocal()</td>
<td style="text-align:left">创建 ThreadLocal 对象</td>
</tr>
<tr>
<td style="text-align:left">public void set(T value)</td>
<td style="text-align:left">设置当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public T get()</td>
<td style="text-align:left">获取当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public void remove()</td>
<td style="text-align:left">移除当前线程绑定的局部变量</td>
</tr>
</tbody>
</table>
<h3 id="122-使用案列">1.2.2 使用案列</h3>
<pre><code>package com.ssm.threadlocal;
/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 */
public class MyDemo01 {
    private String content;
    private String getContent(){
        return content;
    }
    private void setContent(String content){
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo01 demo = new MyDemo01();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                System.out.println(&quot; ---------------- &quot;);
                System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>运行结果：部分线程取出的数据 与 它存入的数据不一样</p>
<pre><code> ---------------- 
 ---------------- 
线程2---&gt;线程3的数据
 ---------------- 
线程1---&gt;线程4的数据
 ---------------- 
线程4---&gt;线程4的数据
线程0---&gt;线程2的数据
 ---------------- 
线程3---&gt;线程4的数据
</code></pre>
<p>从结果可以看出多个线程在访问同一个变量的时候出现的异常，线程间的数据没有隔离。下面我们来看下采用 ThreadLocal 的方式来解决这个问题的例子。</p>
<pre><code>package com.ssm.threadlocal;

/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 *
 *      ThreadLocal:
 *          1.set()：将变量绑定到当前线程中；
 *          2.get()：获取当前线程绑定的变量
 */
public class MyDemo01 {
    ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();
    private String getContent(){
        return threadLocal.get();
    }
    private void setContent(String content){
        // 变量绑定到当前线程中
        threadLocal.set(content);
    }

    public static void main(String[] args) {
        MyDemo01 demo = new MyDemo01();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                System.out.println(&quot; ---------------- &quot;);
                System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code> ---------------- 
 ---------------- 
线程3---&gt;线程3的数据
 ---------------- 
线程2---&gt;线程2的数据
 ---------------- 
 ---------------- 
线程4---&gt;线程4的数据
线程0---&gt;线程0的数据
线程1---&gt;线程1的数据
</code></pre>
<p>从结果来看，这样很好的解决了多线程之间数据隔离的问题，十分方便。</p>
<h2 id="13-threadlocal-与-synchronized-关键字">1.3 ThreadLocal 与 synchronized 关键字</h2>
<h3 id="131-synchronized-同步方式">1.3.1 synchronized 同步方式</h3>
<p>这里可能有的朋友会觉得在上述例子中我们完全可以通过加锁来实现这个功能。我们首先来看一下用synchronized代码块实现的效果：</p>
<pre><code>package com.ssm.threadlocal;

/**
 * 需求：线程隔离
 *  在多线程并发的场景下，每个线程中的变量都是互相独立
 *      线程 A：设置(变量1)    获取(变量1)
 *      线程 B：设置(变量2)    获取(变量2)
 */
public class MyDemo02 {
    private String content;
    private String getContent(){
        return content;
    }
    private void setContent(String content){
        this.content = content;
    }

    public static void main(String[] args) {
        MyDemo02 demo = new MyDemo02();
        for (int i = 0; i &lt; 5; i++) {
            Thread thread = new Thread(()-&gt;{
                /*
                    每个线程：存一个变量，过一会 取出这个变量
                 */
                synchronized (MyDemo02.class){
                    demo.setContent(Thread.currentThread().getName() + &quot;的数据&quot;);
                    System.out.println(&quot; ---------------- &quot;);
                    System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demo.getContent());
                }

            });
            thread.setName(&quot;线程&quot; + i);
            thread.start();
        }
    }
}
</code></pre>
<p>从结果可以发现，加锁确实可以解决这个问题，但是在这里我们强调的是<strong>线程数据隔离</strong>的问题，并不是<strong>多线程共享数据的</strong>问题，在这个案例中使用synchronized关键字是不合适的。</p>
<h3 id="132-threadlocal-与-synchronized-关键字的区别">1.3.2 ThreadLocal 与 synchronized 关键字的区别</h3>
<p>虽然ThreadLocal模式与synchronized关键字都用于处理多线程并发访问变量的问题，不过两者处理问题的角度和思路不同。</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">synchronized</th>
<th style="text-align:left">ThreadLocal</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">原理</td>
<td style="text-align:left">同步机制采用 “<strong>以时间换空间</strong>” 的方式，只提供了一分变量，让不用的线程派对访问</td>
<td style="text-align:left">ThreadLocal 采用 “<strong>以空间换时间</strong>” 的方式，为每一个线程都提供了一份变量的副本，从而实现同时访问互不干扰</td>
</tr>
<tr>
<td style="text-align:left">侧重点</td>
<td style="text-align:left">多个线程之间访问资源的同步</td>
<td style="text-align:left">多线程中让每个线程之间的数据相互隔离</td>
</tr>
</tbody>
</table>
<p>总结：在刚刚的案例中，虽然使用Thr eadLocal和synchronized都能解决问题，但是使用ThreadLocal更为合适，因为这样可以使程序拥有更高的并发性。</p>
<h1 id="二-运用场景_事务案例">二、 运用场景_事务案例</h1>
<p>​通过以上的介绍，我们已经基本了解ThreadLocal的特点。但是它具体是运用在什么场景中呢？ 接下来让我们看一个案例： 事务操作。</p>
<h2 id="21-转账案例">2.1 转账案例</h2>
<h3 id="211-场景构建">2.1.1 场景构建</h3>
<p>​这里我们先构建一个简单的转账场景： 有一个数据表account，里面有两个用户Jack和Rose，用户Jack  给用户Rose 转账。</p>
<p>案例的实现主要用mysql数据库，JDBC 和 C3P0 框架。以下是详细代码 ：</p>
<p>（1） 项目结构<br>
<img src="https://epitomm.github.io/post-images/001.png" alt="图片" loading="lazy"><br>
（2） 数据准备</p>
<pre><code class="language-sql">-- 使用数据库
use test;
-- 创建一张账户表
create table account(
	id int primary key auto_increment,
	name varchar(20),
	money double
);
-- 初始化数据
insert into account values(null, 'Jack', 1000);
insert into account values(null, 'Rose', 0);
</code></pre>
<p>（3） C3P0配置文件和工具类</p>
<pre><code class="language-xml">&lt;c3p0-config&gt;
  &lt;!-- 使用默认的配置读取连接池对象 --&gt;
  &lt;default-config&gt;
  	&lt;!--  连接参数 --&gt;
    &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt;
    &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt;
    &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt;
    &lt;property name=&quot;password&quot;&gt;1234&lt;/property&gt;
    
    &lt;!-- 连接池参数 --&gt;
    &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt;
    &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt;
    &lt;property name=&quot;checkoutTimeout&quot;&gt;3000&lt;/property&gt;
  &lt;/default-config&gt;

&lt;/c3p0-config&gt;
</code></pre>
<p>（4） 工具类 ： JdbcUtils</p>
<pre><code class="language-java">package com.itheima.transfer.utils;

import com.mchange.v2.c3p0.ComboPooledDataSource;
import java.sql.Connection;
import java.sql.SQLException;

public class JdbcUtils {
    // c3p0 数据库连接池对象属性
    private static final ComboPooledDataSource ds = new ComboPooledDataSource();
    // 获取连接
    public static Connection getConnection() throws SQLException {
        return ds.getConnection();
    }
    //释放资源
    public static void release(AutoCloseable... ios){
        for (AutoCloseable io : ios) {
            if(io != null){
                try {
                    io.close();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }
    
    
    public static void commitAndClose(Connection conn) {
        try {
            if(conn != null){
                //提交事务
                conn.commit();
                //释放连接
                conn.close();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void rollbackAndClose(Connection conn) {
        try {
            if(conn != null){
                //回滚事务
                conn.rollback();
                //释放连接
                conn.close();
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>（5） dao层代码 ： AccountDao</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(String outUser, int money) throws SQLException {
        String sql = &quot;update account set money = money - ? where name = ?&quot;;

        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();

        JdbcUtils.release(pstm,conn);
    }

    public void in(String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;

        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();

        JdbcUtils.release(pstm,conn);
    }
}
</code></pre>
<p>（6） service层代码 ： AccountService</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import java.sql.SQLException;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        try {
            // 转出
            ad.out(outUser, money);
            // 转入
            ad.in(inUser, money);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>（7） web层代码 ： AccountWeb</p>
<pre><code class="language-java">package com.itheima.transfer.web;

import com.itheima.transfer.service.AccountService;

public class AccountWeb {

    public static void main(String[] args) {
        // 模拟数据 : Jack 给 Rose 转账 100
        String outUser = &quot;Jack&quot;;
        String inUser = &quot;Rose&quot;;
        int money = 100;

        AccountService as = new AccountService();
        boolean result = as.transfer(outUser, inUser, money);

        if (result == false) {
            System.out.println(&quot;转账失败!&quot;);
        } else {
            System.out.println(&quot;转账成功!&quot;);
        }
    }
}
</code></pre>
<h3 id="212-引入事务">2.1.2 引入事务</h3>
<p>​案例中的转账涉及两个DML操作： 一个转出，一个转入。这些操作是需要具备原子性的，不可分割。不然就有可能出现数据修改异常情况。</p>
<pre><code class="language-java">public class AccountService {
    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        try {
            // 转出
            ad.out(outUser, money);
            // 模拟转账过程中的异常
            int i = 1/0;
            // 转入
            ad.in(inUser, money);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>所以这里就需要操作事务，来保证转出和转入操作具备原子性，要么同时成功，要么同时失败。<br>
（1） JDBC中关于事务的操作的api</p>
<table>
<thead>
<tr>
<th>Connection接口的方法</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>void  setAutoCommit(false)</td>
<td>禁用事务自动提交（改为手动）</td>
</tr>
<tr>
<td>void  commit();</td>
<td>提交事务</td>
</tr>
<tr>
<td>void rollback();</td>
<td>回滚事务</td>
</tr>
</tbody>
</table>
<p>（2） <strong>开启事务的注意点</strong>:</p>
<ul>
<li>
<p>为了保证所有的操作在一个事务中,案例中使用的连接必须是同一个:  service层开启事务的connection需要跟dao层访问数据库的connection保持一致</p>
</li>
<li>
<p>线程并发情况下, 每个线程只能操作各自的 connection</p>
</li>
</ul>
<h2 id="22-常规解决方案">2.2  常规解决方案</h2>
<h3 id="221-常规方案的实现">2.2.1 常规方案的实现</h3>
<p>基于上面给出的前提， 大家通常想到的解决方案是 ：</p>
<ul>
<li>传参: 从service层将connection对象向dao层传递</li>
<li>加锁</li>
</ul>
<p>以下是代码实现修改的部分：</p>
<p>（1 ) AccountService 类</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();
        //线程并发情况下,为了保证每个线程使用各自的connection,故加锁
        synchronized (AccountService.class) {

            Connection conn = null;
            try {
                conn = JdbcUtils.getConnection();
                //开启事务
                conn.setAutoCommit(false);
                // 转出
                ad.out(conn, outUser, money);
                // 模拟转账过程中的异常
//            int i = 1/0;
                // 转入
                ad.in(conn, inUser, money);
                //事务提交
                JdbcUtils.commitAndClose(conn);
            } catch (Exception e) {
                e.printStackTrace();
                //事务回滚
                JdbcUtils.rollbackAndClose(conn);
                return false;
            }
            return true;
        }
    }
}
</code></pre>
<p>（2) AccountDao 类 （这里需要注意的是： connection不能在dao层释放，要在service层，不然在dao层释放，service层就无法使用了）</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(Connection conn, String outUser, int money) throws SQLException{
        String sql = &quot;update account set money = money - ? where name = ?&quot;;
        //注释从连接池获取连接的代码,使用从service中传递过来的connection
//        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();
        //连接不能在这里释放,service层中还需要使用
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }

    public void in(Connection conn, String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;
//        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }
}
</code></pre>
<h3 id="222-常规方案的弊端">2.2.2 常规方案的弊端</h3>
<p>上述方式我们看到的确按要求解决了问题，但是仔细观察，会发现这样实现的弊端：</p>
<ol>
<li>
<p>直接从service层传递connection到dao层, 造成代码耦合度提高</p>
</li>
<li>
<p>加锁会造成线程失去并发性，程序性能降低</p>
</li>
</ol>
<h2 id="23-threadlocal解决方案">2.3 ThreadLocal解决方案</h2>
<h3 id="231-threadlocal方案的实现">2.3.1 ThreadLocal方案的实现</h3>
<p>像这种需要在项目中进行<strong>数据传递</strong>和<strong>线程隔离</strong>的场景，我们不妨用ThreadLocal来解决：</p>
<p>（1） 工具类的修改： 加入ThreadLocal</p>
<pre><code class="language-java">package com.itheima.transfer.utils;

import com.mchange.v2.c3p0.ComboPooledDataSource;
import java.sql.Connection;
import java.sql.SQLException;

public class JdbcUtils {
    //ThreadLocal对象 : 将connection绑定在当前线程中
    private static final ThreadLocal&lt;Connection&gt; tl = new ThreadLocal();

    // c3p0 数据库连接池对象属性
    private static final ComboPooledDataSource ds = new ComboPooledDataSource();

    // 获取连接
    public static Connection getConnection() throws SQLException {
        //取出当前线程绑定的connection对象
        Connection conn = tl.get();
        if (conn == null) {
            //如果没有，则从连接池中取出
            conn = ds.getConnection();
            //再将connection对象绑定到当前线程中
            tl.set(conn);
        }
        return conn;
    }

    //释放资源
    public static void release(AutoCloseable... ios) {
        for (AutoCloseable io : ios) {
            if (io != null) {
                try {
                    io.close();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public static void commitAndClose() {
        try {
            Connection conn = getConnection();
            //提交事务
            conn.commit();
            //解除绑定
            tl.remove();
            //释放连接
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }

    public static void rollbackAndClose() {
        try {
            Connection conn = getConnection();
            //回滚事务
            conn.rollback();
            //解除绑定
            tl.remove();
            //释放连接
            conn.close();
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>（2） AccountService类的修改：不需要传递connection对象</p>
<pre><code class="language-java">package com.itheima.transfer.service;

import com.itheima.transfer.dao.AccountDao;
import com.itheima.transfer.utils.JdbcUtils;
import java.sql.Connection;

public class AccountService {

    public boolean transfer(String outUser, String inUser, int money) {
        AccountDao ad = new AccountDao();

        try {
            Connection conn = JdbcUtils.getConnection();
            //开启事务
            conn.setAutoCommit(false);
            // 转出 ： 这里不需要传参了 ！
            ad.out(outUser, money);
            // 模拟转账过程中的异常
//            int i = 1 / 0;
            // 转入
            ad.in(inUser, money);
            //事务提交
            JdbcUtils.commitAndClose();
        } catch (Exception e) {
            e.printStackTrace();
            //事务回滚
           JdbcUtils.rollbackAndClose();
            return false;
        }
        return true;
    }
}
</code></pre>
<p>（3） AccountDao类的修改：照常使用</p>
<pre><code class="language-java">package com.itheima.transfer.dao;

import com.itheima.transfer.utils.JdbcUtils;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;

public class AccountDao {

    public void out(String outUser, int money) throws SQLException {
        String sql = &quot;update account set money = money - ? where name = ?&quot;;
        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,outUser);
        pstm.executeUpdate();
        //照常使用
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }

    public void in(String inUser, int money) throws SQLException {
        String sql = &quot;update account set money = money + ? where name = ?&quot;;
        Connection conn = JdbcUtils.getConnection();
        PreparedStatement pstm = conn.prepareStatement(sql);
        pstm.setInt(1,money);
        pstm.setString(2,inUser);
        pstm.executeUpdate();
//        JdbcUtils.release(pstm,conn);
        JdbcUtils.release(pstm);
    }
}
</code></pre>
<h3 id="232-threadlocal方案的好处">2.3.2 ThreadLocal方案的好处</h3>
<p>从上述的案例中我们可以看到， 在一些特定场景下，ThreadLocal方案有两个突出的优势：</p>
<ol>
<li>
<p>传递数据 ： 保存每个线程绑定的数据，在需要的地方可以直接获取, 避免参数直接传递带来的代码耦合问题</p>
</li>
<li>
<p>线程隔离 ： 各线程之间的数据相互隔离却又具备并发性，避免同步方式带来的性能损失</p>
</li>
</ol>
<h1 id="三-threadlocal的内部结构">三、ThreadLocal的内部结构</h1>
<p>通过以上的学习，我们对ThreadLocal的作用有了一定的认识。现在我们一起来看一下ThreadLocal的内部结构，探究它能够实现线程数据隔离的原理。</p>
<h2 id="31常见的误解">3.1常见的误解</h2>
<p>通常，如果我们不去看源代码的话，我猜 ThreadLocal 是这样子设计的：每个ThreadLocal 类都创建一个 Map，然后用线程作为Map的key，要存储的局部变量作为Map的value，这样就能达到各个线程的局部变量隔离的效果。这是最简单的设计方法，JDK最早期的ThreadLocal就是这样设计的。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E6%97%A9%E6%9C%9FThreadLocal.png" alt="图片" loading="lazy"></figure>
<h2 id="32-现在的设计">3.2 现在的设计</h2>
<p>但是，JDK后面优化了设计方案，JDK8 中 ThreadLocal的设计是：每个Thread维护一个ThreadLocalMap 哈希表，这个哈希表的key是ThreadLocal实例本身，value才是真正要存储的值object。</p>
<p>（1）每个Thread线程内部都有一个Map（ThreadLocalMap）</p>
<p>（2）Map里面存储ThreadLocal对象（key）和线程的变量副本（value）</p>
<p>（3）Thread内部的Map是由ThreadLocal维护的，由ThreadLocal负责向map获取和设置线程的变量值。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/JDK8ThreadLocal.png" alt="图片" loading="lazy"></figure>
<h2 id="33-jdk8的设计方案两个好处">3.3 JDK8的设计方案两个好处</h2>
<ol>
<li>每个Map存储的Entry数量变少</li>
</ol>
<p>[在早期版本内，Map 的 Entry 数量由 Thread 决定；而 JDK8 中，Map 的 Entry 数量由 ThreadLocal 决定，一般情况下 ThreadLocal 数量是比 Thread 少的]</p>
<ol start="2">
<li>当Thread销毁的时候，ThreadLocalMap也会随之销毁，减少内存的使用</li>
</ol>
<p>[早期版本内，ThreadLocalMap 由 ThreadLocal 维护；而 JDK8 中，ThreadLocalMap 由 Thread 维护，当 Thread 销毁，ThreadLocalMap 也会销毁]</p>
<h1 id="四-threadlocal-的和核心方法源码">四、ThreadLocal 的和核心方法源码</h1>
<p>基于ThreadLocal的内部结构，我们继续分析它的核心方法源码，更深入的了解其操作原理。</p>
<p>除了构造方法之外，ThreadLocal对外暴露的方法有以下4个：</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法声明</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">protected T initialValue()</td>
<td style="text-align:left">返回当前线程局部变量的初始值</td>
</tr>
<tr>
<td style="text-align:left">public void set(T value)</td>
<td style="text-align:left">设置当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public T get()</td>
<td style="text-align:left">获取当前线程绑定的局部变量</td>
</tr>
<tr>
<td style="text-align:left">public void remove()</td>
<td style="text-align:left">移除当前线程绑定的局部变量</td>
</tr>
</tbody>
</table>
<p>以下是这4个方法的详细源码分析（为了保证思路清晰，ThreadLocalMap部分暂时不展开，下一个知识点详解）</p>
<h2 id="41-set方法">4.1 set方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 设置当前线程对应的 ThreadLocal 的值
 * @param value 将要保存在当前线程对应的ThreadLocal的值
 */
public void set(T value) {
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取当前线程对象中维护的 ThreadLocalMap 对象
    ThreadLocalMap map = getMap(t);
    // 判断 map 是否存在
    if (map != null)
        // 存在则调用 map.set 设置此实体 Entry
        map.set(this, value);
    else
        // 1）当前线程 Thread 不存在 ThreadLocalMap 对象
        // 2）则调用 createMap 进行 ThreadLocalMap 对象的初始化
        // 3）并将 t（当前线程）和value（t对应的值）作为第一个 entry 存放至 ThreadLocalMap 中
        createMap(t, value);
}
/**
 * 获取当前线程 Thread 对应维护的 ThreadLocalMap
 *
 * @param  t the current thread 当前线程
 * @return the map 对应维护的 ThreadLocalMap
 */

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

/**
 * 创建当前线程 Thread 对应维护的 ThreadLocalMap
 *
 * @param t the current thread 当前线程
 * @param firstValue value for the initial entry of the map 存放到 map 中第一个 entry 值 
 */
void createMap(Thread t, T firstValue) {
    // 这里的 this 是调用此方法的threadLocal
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线，并根据当前线程获取一个Map</p>
<p>B.如果获取的Map不为空，则将参数设置到Map中（当前ThreadLocal的引用作为key）</p>
<p>C.如果Map为空，则给该线程创建Map，并设置初始值</p>
<h2 id="42-get方法">4.2 get方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 返回当前线程中保存 ThreadLocal 的值
 * 当前线程没有此 ThreadLocal 变量
 * 则它会通过调用 {@link #initialValue} 方法进行初始化
 *
 * @return 返回当前线程对应此 ThreadLocal 的值
 */
public T get() {
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取当前线程中维护的 ThreadLocalMap 对象
    ThreadLocal.ThreadLocalMap map = getMap(t);
    // 如果此 map 存在
    if (map != null) {
        // 以当前的 ThreadLocal 为 key，调用 getEntry 获取对应的存储实体 e
        ThreadLocal.ThreadLocalMap.Entry e = map.getEntry(this);
        // 对 e 进行判空
        if (e != null) {
            @SuppressWarnings(&quot;unchecked&quot;)
            // 获取存储实体 e 对应的 value 值，即为我们想要的当前线程对应此 ThreadLocal 的值
            T result = (T)e.value;
            return result;
        }
    }
    /*
        初始化：有两种情况执行当前代码
        第一种情况：map 不存在，表示此线程没有维护的 ThreadLocalMap 对象
        第二种情况：map 存在，但是没有与当前 ThreadLocal 关联的 Entry
     */
    return setInitialValue();
}
/**
 * 初始化
 *
 * @return the initial value
 */
private T setInitialValue() {
    // 调用 initialValue 获取初始化的值
    // 此方法可以被子类重写，如果不重写默认返回 null
    T value = initialValue();
    // 获取当前线程对象
    Thread t = Thread.currentThread();
    // 获取此线程对象中维护的 ThreadLocalMap 对象
    ThreadLocal.ThreadLocalMap map = getMap(t);
    // 判断 map 是否存在
    if (map != null)
        // 存在则调用 map.set 设置此实体 entry
        map.set(this, value);
    else
        // 1)当前线程 Thread 不存在 ThreadLocalMap 对象
        // 2)则调用 createMap 进行 ThreadLocalMap 对象的初始化
        // 3)并将 t(当前线程)和 value(t对应的值)作为第一个 entry 存放至 ThreadLocalMap 中
        createMap(t, value);
    // 返回设置的值 value
    return value;
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线程，根据当前线程获取一个Map</p>
<p>B.如果获取的Map不为空，则在Map中以ThreadLoca的引用作为key来在Map中获取对应的Entrye，否则转到D</p>
<p>C.如果e不为null，则返回e.value，否则转到D</p>
<p>D.Map为空或者e为空，则通过initiaValue函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map</p>
<p>总结：<strong>先获取当前线程的ThreadLocalMap变量，如果存在则返回值，不存在则创建并返回初始值</strong>。</p>
<h2 id="43-remove方法">4.3 remove方法</h2>
<p>（1）源码和对应的中文注释</p>
<pre><code>/**
 * 删除当前线程中保存的 ThreadLocal 对应的实体 entry
 */
public void remove() {
    // 获取当前线程对象中维护的 ThreadLocalMap
    ThreadLocal.ThreadLocalMap m = getMap(Thread.currentThread());
    // 如果此 map 存在
    if (m != null)
        // 存在则调用 map.remove
        // 以当前 ThreadLocal 为 key 删除对应的实体 entry
        m.remove(this);
}
</code></pre>
<p>（2）代码执行流程<br>
A.首先获取当前线程，并根据当前线程获取一个Map</p>
<p>B.如果获取的Map不为空，则移除当前ThreadLocal对象对应的entry</p>
<h2 id="44-initialvalue方法">4.4 initialValue方法</h2>
<pre><code>/**
 * 返回当前线程对应的ThreadLocal的初始值
 * 
 * 此方法的第一次调用发生在，当线程通过get方法访问此线程的ThreadLocal值时
 * 除非线程先调用了set方法，在这种情况下，initialvalue 才不会被这个线程调用。
 * 通常情况下，每个线程最多调用一次这个方法。
 * &lt;p&gt;这个方法仅仅简单的返回nu11{@code nu11}；
 * 如果程序员想ThreadLocal线程局部变量有一个除nu11以外的初始值，
 * 必须通过子类继承{@code ThreadLocal}的方式去重写此方法
 * 通常，可以通过匿名内部类的方式实现
 * 
 * @return 当前 ThreadLocal 的初始值
 */
protected T initialValue() {
    return null;
}
</code></pre>
<p>此方法的作用是返回该线程局部变量的初始值。<br>
（1）这个方法是一个延迟调用方法，从面的代码我们得知，在set方法还未调用而先调用了get方法时才执行，并且仅执行1次。</p>
<p>（2）这个方法缺省实现直接返回一个null。</p>
<p>（3）如果想要一个除null之外的初始值，可以重写此方法。（备注：该方法是一个protected的方法，显然是为了让子类覆盖而设计的）</p>
<h1 id="五-threadlocalmap源码分析">五、ThreadLocalMap源码分析</h1>
<p>在分析ThreadLocal方法的时候，我们了解到ThreadLocal的操作实际上是围绕ThreadLocalMap展开的。</p>
<p>ThreadLocalMap的源码相对比较复杂，我们从以下三个方面进行讨论。</p>
<h2 id="51基本结构">5.1基本结构</h2>
<p>ThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部的Entry也是独立实现。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/ThreadLocal%E7%9A%84UML.png" alt="图片" loading="lazy"></figure>
<p>（1）成员变量</p>
<pre><code>/**
 * 初始容量 - 必须是 2 的整次幂
 */
private static final int INITIAL_CAPACITY = 16;

/**
 * 存放数据的 table，Entry类的定义在下面分析
 * 同样，数组长度必须是 2 的整次幂。
 */
private ThreadLocal.ThreadLocalMap.Entry[] table;

/**
 * 数组里面 entrys 的个数，可以用于判断 table 当前使用量是否超过阈值
 */
private int size = 0;

/**
 * 进行扩容的阈值，表使用量大于它的时候进行扩容。
 */
private int threshold; // Default to 0
</code></pre>
<p>跟HashMap类似，INITIAL_CAPACITY代表这个Map的初始容量；table是一个Entry类型的数组，用于存储数据；size代表表中的存储数目；threshold 代表需要扩容时对应 size的阈值。<br>
（2）存储结构-Entry</p>
<pre><code>/**
 * Entry 继承 WeakReference，并且用 ThreadLocal 作为 key
 * 如果 key 为 null(entry.get() == null)，意味着 key 不再被引用，
 * 因此这时候 entry 也可以从 table 中清除
 */
static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal&lt;?&gt; k, Object v) {
        super(k);
        value = v;
    }
}
</code></pre>
<p>在ThreadLocalMap中，也是用Entry来保存K-V结构数据的。不过Entry中的key只能是ThreadLocal对象，这点在构造方法中已经限定死了。<br>
另外，Entry继承WeakReference，也就是key（ThreadLocal）是弱引用，其目的是将ThreadLocal对象的生命周期和线程生命周期解绑。</p>
<h2 id="52弱引用和内存泄漏">5.2弱引用和内存泄漏</h2>
<p>有些程序员在使用ThreadLocal的过程中会发现有内存泄漏的情况发生，就猜测这个内存泄漏跟Entry中使用了弱引用的key有关系。这个理解其实是不对的。</p>
<p>我们先来回顾这个问题中涉及的几个名词概念，再来分析问题。</p>
<h3 id="1内存泄漏相关概念">（1）内存泄漏相关概念</h3>
<ul>
<li>Memory overflow：内存溢出，没有足够的内存提供申请者使用。</li>
<li>Memory leak：内存泄漏是指程序中<strong>己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费</strong>，导致程序运行速度减慢甚至系统溃等严重后果。内存泄漏的堆积终将导致内存溢出。</li>
</ul>
<h3 id="2弱引用相关概念">（2）弱引用相关概念</h3>
<p>Java中的引用有4种类型：强、软、弱、虚。当前这个问题主要涉及到强引用和弱引用：</p>
<p><strong>强引用</strong>（&quot;Strong”Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾回收器就不会回收这种对象。</p>
<p><strong>弱引用</strong>（WeakReference），垃圾回收器一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。</p>
<h3 id="3如果key使用强引用">（3）如果key使用强引用</h3>
<p>假设ThreadLocalMap中的key使用了强引用，那么会出现内存泄漏吗？</p>
<p>此时ThreadLocal的内存图（实线表示强引用）如下：</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/key%E5%BC%BA%E5%BC%95%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<p>1.假设在业务代码中使用完ThreadLocal，threadLocal Ref被回收了。</p>
<p>2.但是因为threadLocalMap的Entry强引用了threadLocal，造成threadLocal无法被回收。</p>
<p>3.在没有手动删除这个Entry以及CurrentThread依然运行的前提下，始终有强引用链 threadRef-&gt;currentThread-&gt;threadLocalMap-&gt;entry，Entry就不会被回收（Entry中包括了ThreadLocal实例和value），导致Entry内存泄漏。</p>
<p>也就是说，ThreadLocalMap中的key使用了强引用，是无法完全避免内存泄漏的。</p>
<h3 id="4如果key使用弱引用">（4）如果key使用弱引用</h3>
<p>那么ThreadLocalMap中的key使用了弱引用，会出现内存泄漏吗？此时ThreadLocal的内存图（实线表示强引用，虚线表示弱引用）如下：</p>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/key%E5%BC%B1%E5%BC%95%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<p>同样假设在业务代码中使用完ThreadLocal，threadLocal Ref被回收了。</p>
<p>由于ThreadLocalMap只持有ThreadLocal的弱引用，没有任何强引用指向threadlocal实例，所以threadlocal就可以顺利被gc回收，此时Entry中的key=null。</p>
<p>但是在没有手动删除这个Entry以及CurrentThread依然运行的前提下，也存在有强引用链 threadRef -&gt;currentThread-&gt;threadLocalMap-&gt;entry-&gt;value，value不会被回收，而这块value永远不会被访问到了，导致value内存泄漏。</p>
<p>也就是说，ThreadLocalMap中的key使用了弱引用，也有可能内存泄漏。</p>
<h3 id="5出现内存泄漏的真实原因">（5）出现内存泄漏的真实原因</h3>
<p>比较以上两种情况，我们就会发现，内存泄漏的发生跟ThreadLocalMap中的key是否使用弱引用是没有关系的。那么内存泄漏的的真正原因是什么呢？</p>
<p>细心的同学会发现，在以上两种内存泄漏的情况中，都有两个前提：</p>
<p>1.没有手动删除这个Entry</p>
<p>2.CurrentThread依然运行</p>
<p>第一点很好理解，只要在使用完ThreadLocal，调用其remove方法删除对应的Entry，就能避免内存泄漏。第二点稍微复杂一点，由于ThreadLocalMap是Thread的一个属性，被当前线程所引用，所以它的生命周期跟Thread一样长。那么在使用完ThreadLocal的使用，如果当前Thread也随之执行结束，ThreadLocalMap自然也会被gc回收，从根源上避免了内存泄漏。</p>
<p>综上，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏。</p>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/ThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9C%9F%E6%AD%A3%E5%8E%9F%E5%9B%A0.png" alt="图片" loading="lazy"></figure>
<h3 id="6为什么使用弱引用">（6）为什么使用弱引用</h3>
<p>根据刚才的分析，我们知道了：无论使用ThreadLocalMap中的key使用哪种类型引用都无法完全避免内存泄漏，跟使用弱引用没有关系。要避免内存泄漏有两种方式：</p>
<p>1.使用完ThreadLocal，调用其remove方法删除对应的Entry</p>
<p>2.使用完ThreadLocal，当前Thread也随之运行结束</p>
<p>相对第一种方式，第二种方式显然更不好控制，特别是使用线程池的时候，线程结束是不会销毁的。</p>
<p>也就是说，只要记得在使用完ThreadLocal及时的调用remove，无论key是强引用还是弱引用都不会有问题。</p>
<p><strong>那么为什么key要用弱引用呢？</strong></p>
<p>事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为nul（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为nul的。</p>
<p>这就意味着使用完ThreadLocal，CurrentThread依然运行的前提下，就算忘记调用remove方法，弱引用比强引用可以多一层保障：弱引用的ThreadLocal会被回收，对应的value在下一次ThreadLocalMap调用set，get，remove中的任一方法的时候会被清除，从而避免内存泄漏。</p>
<h2 id="43hash冲突的解决">4.3hash冲突的解决</h2>
<p>hash冲突的解决是Map中的一个重要内容。我们以hash冲突的解决为线索，来研究一下ThreadLocalMap的核心源码。</p>
<h3 id="1首先从threadlocal的set方法入手">（1）首先从ThreadLocal的set(）方法入手</h3>
<pre><code>public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<p>这个方法我们刚才分析过，其作用是设置当前线程绑定的局部变量：<br>
A.首先获取当前线程，并根据当前线程获取一个Map</p>
<p>B.如果获取的Map不为空，则将参数设置到Map中（当前ThreadLocal的引用作为key）</p>
<p>（这里调用了ThreadLocalMap的set方法）</p>
<p>C.如果Map为空，则给该线程创建Map，并设置初始值</p>
<p>（这里调用了ThreadLocalMap的构造方法）</p>
<h3 id="2构造方法threadlocalmapthreadlocal-firstkeyobject-firstvalue">（2）构造方法ThreadLocalMap（ThreadLocal-？&gt;firstKey，Object firstValue）</h3>
<pre><code>/**
 * @param firstKey 本地 ThreadLocal 实例(this)
 * @param firstValue 要保存的线程本地变量
 */
ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) {
    // 初始化 table
    table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY];
    // 计算索引（重点代码）
    int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);
    // 设置值
    table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue);
    size = 1;
    // 设置阈值
    setThreshold(INITIAL_CAPACITY);
}
</code></pre>
<p>构造函数首先创建一个长度为16的Entry数组，然后计算出firstKey对应的索引，然后存储到table中，并设置size和threshold。<br>
重点分析：int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);</p>
<p>a.关于firstkey.threadLocalHashcode：</p>
<pre><code>private final int threadLocalHashCode = nextHashCode();
private static int nextHashCode() {
    return nextHashCode.getAndAdd(HASH_INCREMENT);
}
// AtomicInteger 是一个提供原子操作的 Integer类，通过线程安全的方式操作加减，适合高并发情况下的使用
private static AtomicInteger nextHashCode =
    new AtomicInteger();
// 特殊的 hash 值
private static final int HASH_INCREMENT = 0x61c88647;
</code></pre>
<p>这里定义了一个Atomiclnteger类型，每次获取当前值并加上HASH_INCREMENT，HASH_INCREMENT=0x61c88647，这个值跟斐波那契数列（黄金分割数）有关，其主要目的就是为了让哈希码能均匀的分布在2的n次方的数组里，也就是Entry]table中，这样做可以尽量避免hash冲突。<br>
b.关于&amp;（INITIAL_CAPACITY-1）</p>
<p>计算hash的时候里面采用了hashCode&amp;（size-1）的算法，这相当于取模运算hashCode%size的一个更高效的实现。正是因为这种算法，我们要求size必须是2的整次幂，这也能保证保证在索引不越界的前提下，使得hash发生冲突的次数减小。</p>
<h3 id="3threadlocalmap中的set方法">（3）ThreadLocalMap中的set方法</h3>
<pre><code>private void set(ThreadLocal&lt;?&gt; key, Object value) {

    // We don't use a fast path as with get() because it is at
    // least as common to use set() to create new entries as
    // it is to replace existing ones, in which case, a fast
    // path would fail more often than not.

    ThreadLocal.ThreadLocalMap.Entry[] tab = table;
    int len = tab.length;
    // 计算索引（重点代码）
    int i = key.threadLocalHashCode &amp; (len-1);

    /**
     * 使用线性探测法查找元素（重点代码）
     */
    for (ThreadLocal.ThreadLocalMap.Entry e = tab[i];
         e != null;
         e = tab[i = nextIndex(i, len)]) {
        ThreadLocal&lt;?&gt; k = e.get();
        // ThreadLocal 对应的 key 存在，直接覆盖之前的值
        if (k == key) {
            e.value = value;
            return;
        }

        // key 为 null，但是值不为 null，说明之前的 ThreadLocal 对象已经被回收了
        // 当前数组中的 Entry 是一个陈旧（stale）的元素
        if (k == null) {
            // 用新元素替换旧元素，这个方法进行了不少的垃圾清理动作，防止内存泄漏
            replaceStaleEntry(key, value, i);
            return;
        }
    }
    //ThreadLocal对应的key不存在并且没有找到陈旧的元素，则在空元素的位置创建一个新的Entry。
    tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value);
    int sz = ++size;
    /**
     * cleanSomeslots用于清除那些e.get（）==nu11的元素，
     * 这种数据key关联的对象已经被回收，所以这个Entry（table[index]）可以被置nu11。
     * 如果没有清除任何entry，并且当前使用量达到了负载因子所定义（长度的2/3），那么进行
     * rehash（执行一次全表的扫描清理工作）
     */
    if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
        rehash();
}
// 获取环形数组的下一个索引
private static int nextIndex(int i, int len) {
    return ((i + 1 &lt; len) ? i + 1 : 0);
}
</code></pre>
<p>代码执行流程：<br>
A.首先还是根据key计算出索引i，然后查找位置上的Entry，B.若是Entry已经存在并且key等于传入的key，那么这时候直接给这个Entry赋新的value值C.若是Entry存在，但是key为null，则调用replaceStaleEntry来更换这个key为空的Entry，D.不断循环检测，直到遇到为null的地方，这时候要是还没在循环过程中return，那么就在这个null的位置新建一个Entry，并且插入，同时size增加1。</p>
<p>最后调用cleanSomeSlots，清理key为null的Entry，最后返回是否清理了Entry，接下来再判断sz是否&gt;=thresgold达到了rehash的条件，达到的话就会调用rehash函数执行一次全表的扫描清理。</p>
<p>重点分析：ThreadLocalMap使用线性探测法来解决哈希冲突的。</p>
<p>该方法一次探测下一个地址，直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出。</p>
<p>举个例子，假设当前table长度为16，也就是说如果计算出来key的hash值为14，如果table[14]上已经有值，并且其key与当前key不一致，那么就发生了hash冲突，这个时候将1401得到15，取table[15]进行判断，这个时候如果还是冲突会回到0，取table[0]，以此类推，直到可以插入。</p>
<p><strong>重点分析</strong>：ThreadLocalMap使用线性探测法来解决哈希冲突的。</p>
<p>该方法一次探测下一个地址，直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出。</p>
<p>举个例子，假设当前table长度为16，也就是说如果计算出来key的hash值为14，如果table[14]上已经有值，并且其key与当前key不一致，那么就发生了hash冲突，这个时候将14加1得到15，取table[15]进行判断，这个时候如果还是冲突会回到0，取table[0].以此类推，直到可以插入。</p>
<p>按照上面的描述，可以把Entry table看成一个环形数组。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Java 并发]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/">
        </link>
        <updated>2020-03-31T14:58:28.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java 并发的东西比较多，今天先总结一部分。</p>
</blockquote>
<h1 id="1什么是线程和进程">1.什么是线程和进程？</h1>
<ul>
<li>进程是 OS 资源分配的基本单位。进程拥有独立的虚拟地址空间。</li>
<li>线程是 CPU 调度的基本单位。线程共享进程的堆、方法区资源，但每个线程有自己的程序计数器、虚拟机栈、本地方法栈。</li>
</ul>
<h1 id="2并发和并行的区别">2.并发和并行的区别？</h1>
<ul>
<li>并发：统一时间段内，多个任务都在执行。</li>
<li>并行：同一时间内，多个任务同时执行。</li>
</ul>
<h1 id="3为什么要使用多线程">3.为什么要使用多线程？</h1>
<p>先从总体上来说：</p>
<ul>
<li>从计算机底层来说：线程可以比作是轻量级的进程，是程序执行的最小单位，<strong>线程间的切换和调度的成本远远小于进程</strong>另外，多核CPU时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。</li>
<li>从当代互联网发展趋势来说：现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。</li>
</ul>
<p>再深入到计算机底层来探讨：</p>
<ul>
<li>单核时代：在单核时代多线程主要是为了提高CPU和IO设备的综合利用率。举个例子：当只有一个线程的时候会导致CPU计算时，IO设备空闲；进行IO操作时，CPU空闲。我们可以简单地说这两者的利用率目前都是50%左右。但是当有两个线程的时候就不一样了，当一个线程执行CPU计算时，另外一个线程可以进行IO操作，这样两个的利用率就可以在理想情况下达到100%了。</li>
<li>多核时代：多核时代多线程主要是为了<strong>提高CPU利用率</strong>。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU只会一个CPU核心被利用到，而创建多个线程就可以让多个CPU核心被利用到，这样就提高了CPU的利用率。</li>
</ul>
<h1 id="4创建线程的方式">4.创建线程的方式</h1>
<ul>
<li>实现 Runnable 接口</li>
</ul>
<pre><code>// 1. 实现 Runnable 接口
class MyRunnable implements Runnbale{
  // 2. 实现 run 方法
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  // 3. 使用自定义 runnable 对象创建线程
  MyRunnable runnable = new MyRunnable();
  Thread thread = new Thread(runnable);
  // 4. start() 启动线程
  thread.start();
}
</code></pre>
<ul>
<li>实现 Callable 接口</li>
</ul>
<p>与 Runnable 相比，Callable 可以有返回值，返回值由 FutureTask 进行封装。</p>
<pre><code>// 1. 实现 Callable 接口，并声明泛型
class MyCallable implements Callable&lt;Integer&gt;{
  // 2. 重写 call 方法
  public Integer call(){
    return 123;
  }
}
</code></pre>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException{
  MyCallable callable = new MyCallable();
  // 3. 使用 FutureTask 封装 call 方法的返回值
  FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(callable);
  Thread thread = new Thread(ft);
  thread.start();
  System.out.println(ft.get());
}
</code></pre>
<ul>
<li>继承 Thread 类</li>
</ul>
<pre><code>class MyThread extends Thread{
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  MyThread thread = new MyThread();
  thread.start();
}
</code></pre>
<h2 id="继承-vs-实现接口">继承 vs 实现接口</h2>
<p>实现接口更好一些，因为：</p>
<ul>
<li>Java 不支持多重继承，因此继承了 Thread 类就无法集成其它类，但是可以实现多个接口。</li>
<li>适合多个线程进行资源共享（Runnable 类可以作为多个 Thread 构造方法的参数）</li>
<li>线程池内只能放入 Runnable 或 Callable 接口的实现类，不能放入继承 Thread 对象的类。</li>
</ul>
<h1 id="5runnable-接口和-callable-接口的区别">5.Runnable 接口和 Callable 接口的区别</h1>
<ul>
<li>Runnable 接口重写的是 run 方法，Callable 接口重写的是 call 方法</li>
<li>run 方法执行后不能有返回值，call 方法执行后可以有返回值。</li>
<li>call()方法可以抛出异常，run()方法不可以</li>
<li>运行Callable任务可以拿到一个Future对象，表示异步计算的结果 。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</li>
</ul>
<h1 id="6start-方法和-run-方法的区别">6.start() 方法和 run() 方法的区别</h1>
<p>new 一个 Thread，线程进入了新建状态</p>
<ul>
<li>start() 方法可以启动一个线程，将线程由新建状态切换到就绪态。</li>
<li>run() 方法不会启动一个线程，只会把它当做一个普通方法去执行。</li>
</ul>
<h1 id="7sleep-方法和-wait-方法有什么区别">7.sleep 方法和 wait 方法有什么区别？</h1>
<ul>
<li>wait() 是 Object 类的方法，而 sleep() 是 Thread 的静态方法。</li>
<li>sleep 和 wait 方法都可以用来放弃 CPU 一定时间，<strong>暂停线程的执行</strong>。</li>
<li><strong>是否释放锁</strong>：两者最主要的区别在于：sleep 方法不会释放锁，而 wait 方法会释放锁。</li>
<li><strong>用途</strong>：wait 通常用于线程间交互 / 通信，sleep 通常被用于暂停执行。</li>
<li><strong>是否会自动苏醒</strong>：wait 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。</li>
</ul>
<h1 id="8reentrantlock-和-synchronized-的比较">8.ReentrantLock 和 synchronized 的比较</h1>
<ul>
<li>锁的实现</li>
</ul>
<p>synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。</p>
<ul>
<li>性能</li>
</ul>
<p>新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 和 ReentrantLock 大致相同。</p>
<ul>
<li>等待可中断</li>
</ul>
<p>当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。</p>
<p>ReentrantLock 可中断，而 synchronized 不行。</p>
<ul>
<li>公平锁</li>
</ul>
<p>公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。</p>
<p>synchronized 是不公平锁，而 ReentrantLock 默认情况下也是非公平的，但是可以在构造函数中设置公平还是不公平锁。</p>
<ul>
<li>锁绑定多个条件</li>
</ul>
<p>一个 ReentrantLock 可以同时绑定多个 Conditino 对象</p>
<ul>
<li>使用选择</li>
</ul>
<p>除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一 种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。</p>
<h1 id="9cyclicbarrier和countdownlatch的区别">9.CyclicBarrier和CountDownLatch的区别</h1>
<h2 id="countdownlatch">CountDownLatch</h2>
<p>用来控制一个线程等待多个线程。</p>
<p>维护了一个计数器 cnt，<strong>每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒</strong>。</p>
<h2 id="cyclicbarrier">CyclicBarrier</h2>
<p>用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。</p>
<p>和 CountdownLatch 相似，都是通过维护计数器来实现的。<strong>线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行</strong>。</p>
<p>CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做<strong>循环屏障</strong>。</p>
<p>CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。</p>
<h1 id="10semaphore有什么作用">10.Semaphore有什么作用</h1>
<p>Semaphore就是一个信号量，它的作用是<strong>限制某段代码块的并发数</strong>。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。</p>
<h1 id="11volatile关键字的作用">11.volatile关键字的作用</h1>
<ul>
<li>保证了可见性，不能保证原子性</li>
</ul>
<p>立刻将缓存中的值写到内存；线程通过嗅探总线上传播过来的数据监测自己的缓存是否过期了，如果过期了，就把缓存内的值设置为失效，如果要修改时，就去主存读取新值。</p>
<ul>
<li>禁止指令重排</li>
</ul>
<h1 id="12使用-blockingqueue-生产者消费者问题">12.使用 BlockingQueue 生产者消费者问题</h1>
<pre><code>public class ProductConsumer{
  private static BlockingQueue&lt;String&gt; queue = new BlockingQueue&lt;&gt;();
  private static class Producer extends Thread{
    @Override
    public void run(){
      try{
        queue.put(&quot;product&quot;);
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;produce...&quot;);
    }
  }
  private static class Consumer extends Thread{
    @Override
    public void run(){
      try{
        String product = queue.take();
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;consume...&quot;)
    }
  }
  public static void main(String[] args) {
  for (int i = 0; i &lt; 2; i++) {
    Producer producer = new Producer();
    producer.start();
  }
  for (int i = 0; i &lt; 5; i++) {
    Consumer consumer = new Consumer();
    consumer.start();
  }
  for (int i = 0; i &lt; 3; i++) {
    Producer producer = new Producer();
    producer.start();
  } 
}
</code></pre>
<p>运行结果：</p>
<pre><code>produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. 
</code></pre>
<h1 id="13一个线程如果出现了运行时异常会怎么样">13.一个线程如果出现了运行时异常会怎么样</h1>
<p>如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：<strong>如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放</strong></p>
<h1 id="14threadlocal有什么用">14.ThreadLocal有什么用</h1>
<p>线程局部变量，<strong>以空间换时间</strong>，每个线程内都有一个，把数据进行隔离，解决多线程之间共享数据的安全问题。</p>
<h1 id="15wait方法和notifynotifyall方法在放弃对象监视器时有什么区别">15.wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别</h1>
<p>wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：<strong>wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器</strong>。</p>
<h1 id="16为什么要使用线程池">16.为什么要使用线程池</h1>
<p>来一个请求创建一个线程，执行结束再销毁线程，资源耗费太大，使用线程池达到对<strong>线程的复用</strong>。使用线程池还可以灵活地控制并发的数目。</p>
<h1 id="17怎么检测一个线程是否持有对象监视器">17.怎么检测一个线程是否持有对象监视器</h1>
<p>我也是在网上看到一道多线程面试题才知道有方法可以判断某个线程是否持有对象监视器：Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着&quot;某条线程&quot;指的是当前线程。</p>
<h1 id="18concurrenthashmap的并发度是什么">18.ConcurrentHashMap的并发度是什么</h1>
<p>ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？</p>
<h1 id="19futuretask是什么">19.FutureTask是什么</h1>
<p>在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。</p>
<pre><code>public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 
public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 
</code></pre>
<p>FutureTask 可用<strong>于异步获取执行结果</strong>或<strong>取消执行任务的场景</strong>。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。</p>
<h1 id="20aqs">20.AQS</h1>
<ol>
<li>概念</li>
</ol>
<ul>
<li>AbstractQueuedSynchronizer</li>
<li>同步发生器</li>
<li>构建 LOCK</li>
<li>JUC：java.util.current</li>
</ul>
<ol start="2">
<li>基本思想</li>
</ol>
<ul>
<li>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</li>
<li>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。</li>
</ul>
<p>CLH同步队列</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/CLH%E5%90%8C%E6%AD%A5%E9%98%9F%E5%88%97.png" alt="图片" loading="lazy"></figure>
<p>AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。</p>
<pre><code>private volatile int state;//共享变量，使用volatile修饰保证线程可见性
</code></pre>
<p>状态信息通过 protected 类型的getState，setState，compareAndSetState进行操作</p>
<pre><code>//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
</code></pre>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md</a><br>
<a href="https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg">https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg</a><br>
<a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/AQS.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/AQS.md</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[记一个面试题 —— Redis 一启动挂了怎么办]]></title>
        <id>https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-redis-yi-qi-dong-gua-liao-zen-me-ban/</id>
        <link href="https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-redis-yi-qi-dong-gua-liao-zen-me-ban/">
        </link>
        <updated>2020-03-30T08:43:04.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>面试官：Redis 一启动就挂了怎么办？<br>
答：添加 Redis 集群</p>
</blockquote>
<h1 id="集群简介">集群简介</h1>
<h2 id="现状问题">现状问题</h2>
<h3 id="业务发展过程中遇到的峰值瓶颈">业务发展过程中遇到的峰值瓶颈</h3>
<ul>
<li>redis提供的服务OPS可以达到10万/秒，当前业务OPS已经达到20万/秒</li>
<li>内存单机容量达到256G，当前业务需求内存容量1T</li>
<li>使用集群的方式可以快速解决上述问题</li>
</ul>
<h2 id="集群架构">集群架构</h2>
<ul>
<li>集群就是使用网络将若干台计算机联通起来，并提供统一的管理方式，使其对外呈现单机的服务效果</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<h2 id="集群作用">集群作用</h2>
<ul>
<li>分散单台服务器的访问压力，实现负载均衡</li>
<li>分散单台服务器的存储压力，实现可扩展性</li>
<li>降低单台服务器宕机带来的业务灾难</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E4%BD%9C%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<h1 id="redis集群结构设计">Redis集群结构设计</h1>
<h2 id="数据存储设计"><strong>数据存储设计</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>一个 key 放在 Redis 存储空间：单机方案。<br>
一个 key 对应多个存储空间，变成多台计算机了，应该怎样存储呢？</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A82.png" alt="图片" loading="lazy"></figure>
<ul>
<li>通过算法设计，计算出key应该保存的位置</li>
<li>将所有的存储空间计划切割成16384份，每台主机保存一部分
<ul>
<li>每份代表的是一个存储空间，不是一个key的保存空间</li>
</ul>
</li>
<li>将key按照计算出的结果放到对应的存储空间</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A83.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在有三个存储空间，突然又增加了一个存储空间。把原来的三个 Redis 存储空间都进行优化，每个存储空间拿出一部分给新的存储空间</p>
</blockquote>
<ul>
<li>增强可扩展性</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A85.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>旧的存储空间给新的存储空间 的 这一小块空间（也就是前面标记的37）叫做槽，用来放数据的空间区域。所谓的增加、删除 Redis 存储空间就是：改变槽所存储的位置不同。<br>
槽更换位置后，如何知道它被换到哪里了呢？<br>
内部通讯设计</p>
</blockquote>
<h2 id="集群内部通讯设计"><strong>集群内部通讯设计</strong></h2>
<ul>
<li>各个数据库相互通信，保存各个库中槽的编号数据</li>
<li>一次命中，直接返回</li>
<li>一次未命中，告知具体位置</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在有 A、B、C 三个机器互联，三个机器存储好了以后，会进行互联，互联的目的：谁那有什么样的东西一清二楚。每一台计算机都有一个账本，存储各个计算机里对应的存储空间的槽是几到几。</p>
</blockquote>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A12.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在来了一台计算机，发出一个 key 要访问 Redis，key 通过两个算法计算后得到 key 对应的存储槽在哪里，假定它访问的就是 A，一次命中，直接返回。假设它没有命中，会根据这个 key 对应的槽位置在 A 的小本子里面找，发现这个东西在 B 里面，于是就让这个 key 去 B 里面找，不是 A 去 B 里面找，而是这个连接请求客户端直接去 B 里面找。</p>
</blockquote>
<p>key 加密就是为了确定存储位置，保证最多两次命中</p>
<h2 id="总结">总结</h2>
<p>集群内存存储结构设计：</p>
<p>1.槽用来区分数据存储空间</p>
<p>2.key 加密后确定存储的位置</p>
<p>3.一次命中或两次命中就可以找到数据</p>
<h1 id="cluster集群结构搭建">cluster集群结构搭建</h1>
<h2 id="搭建方式">搭建方式</h2>
<ul>
<li>原生安装（单条命令）
<ul>
<li>配置服务器（3主3从）</li>
<li>建立通信（Meet）</li>
<li>分槽（Slot）</li>
<li>搭建主从（master-slave）</li>
</ul>
</li>
<li>工具安装（批处理）</li>
</ul>
<h2 id="cluster节点操作命令">Cluster节点操作命令</h2>
<ul>
<li>查看集群节点信息</li>
</ul>
<pre><code>cluster nodes 
</code></pre>
<ul>
<li>进入一个从节点 redis，切换其主节点</li>
</ul>
<pre><code>cluster replicate &lt;master-id&gt; 
</code></pre>
<ul>
<li>发现一个新节点，新增主节点</li>
</ul>
<pre><code>cluster meet ip:port 
</code></pre>
<ul>
<li>忽略一个没有solt的节点</li>
</ul>
<pre><code>cluster forget &lt;id&gt; 
</code></pre>
<ul>
<li>手动故障转移</li>
</ul>
<pre><code>cluster failover
</code></pre>
<h2 id="redis-trib命令">redis-trib命令</h2>
<ul>
<li>添加节点</li>
</ul>
<pre><code>redis-trib.rb add-node 
</code></pre>
<ul>
<li>删除节点</li>
</ul>
<pre><code>redis-trib.rb del-node 
</code></pre>
<ul>
<li>重新分片</li>
</ul>
<pre><code>redis-trib.rb reshard
</code></pre>
<h2 id="cluster配置">Cluster配置</h2>
<ul>
<li>添加节点</li>
</ul>
<pre><code>cluster-enabled yes|no 
</code></pre>
<ul>
<li>cluster配置文件名，该文件属于自动生成，仅用于快速查找文件并查询文件内容</li>
</ul>
<pre><code>cluster-config-file &lt;filename&gt; 
</code></pre>
<ul>
<li>节点服务响应超时时间，用于判定该节点是否下线或切换为从节点</li>
</ul>
<pre><code>cluster-node-timeout &lt;milliseconds&gt; 
</code></pre>
<ul>
<li>master连接的slave最小数量</li>
</ul>
<pre><code> cluster-migration-barrier &lt;count&gt;
</code></pre>
<ol>
<li>修改 redis.conf 配置文件</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# vim redis-6379.conf 
port 6379
daemonize no
#logfile &quot;6379.log&quot;
dir &quot;/root/redis-5.0.7/data&quot;
dbfilename &quot;dump-6379.rdb&quot;
rdbcompression yes
rdbchecksum yes
appendonly yes
appendfsync everysec
appendfilename &quot;appendonly-6379.aof&quot;
bind 127.0.0.1
databases 16

cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 10000
</code></pre>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6380/g&quot; redis-6379.conf &gt; redis-6380.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6381/g&quot; redis-6379.conf &gt; redis-6381.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6382/g&quot; redis-6379.conf &gt; redis-6382.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6383/g&quot; redis-6379.conf &gt; redis-6383.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6384/g&quot; redis-6379.conf &gt; redis-6384.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6385/g&quot; redis-6379.conf &gt; redis-6385.conf 
</code></pre>
<ol>
<li>启动 redis 客户端</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6379.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6380.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6381.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6382.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6383.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6384.conf 
</code></pre>
<ol>
<li>每个 reids 服务都以 cluster 节点呈现</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# ps -ef | grep redis-
root      9015  8373  0 18:44 pts/1    00:00:00 redis-server 127.0.0.1:6379 [cluster]
root      9019  8430  0 18:44 pts/5    00:00:00 redis-server 127.0.0.1:6380 [cluster]
root      9023  8411  0 18:45 pts/4    00:00:00 redis-server 127.0.0.1:6381 [cluster]
root      9028  8469  0 18:45 pts/6    00:00:00 redis-server 127.0.0.1:6382 [cluster]
root      9033  8488  0 18:45 pts/7    00:00:00 redis-server 127.0.0.1:6383 [cluster]
root      9037  8507  0 18:46 pts/8    00:00:00 redis-server 127.0.0.1:6384 [cluster]
root      9045  8545  0 18:46 pts/10   00:00:00 grep --color=auto redis-
</code></pre>
<ol>
<li>把这些  cluster 节点 连接在一起</li>
</ol>
<p>redis5.0之前的版本需要部署 ruby 和 gem：<a href="https://blog.51cto.com/wujianwei/2460638">部署ruby环境遇到的坑</a></p>
<p>redis5.0以上的版本可以使用redis-cli命令</p>
<p><a href="https://juejin.im/post/5d16206b518825597909b5f9">https://juejin.im/post/5d16206b518825597909b5f9</a></p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z redis-5.0.7]# src/redis-cli --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 --cluster-replicas 1
// --cluster-replicas 1：一个 master 连接一个 slave；2：一个 master 连接两个 slave
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="图片" loading="lazy"></figure>
<p>输入 yes 重写配置文件后：</p>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C2.png" alt="图片" loading="lazy"></figure>
<h2 id="解析-master-和-slave-日志信息">解析 master 和 slave 日志信息</h2>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4master%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master：6379 日志</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4slave%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave：6382 日志</p>
<h2 id="设置与获取数据">设置与获取数据</h2>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli
127.0.0.1:6379&gt; set name itheima   // 把 name 对应的 key 进行转化后，对应的槽在 6380，不能在 6379 set
(error) MOVED 5798 127.0.0.1:6380 
127.0 .0.1:6379&gt; set lll sss      //  lll 对应的 key 进行转化后，对应的槽在 6379，所以此处 set 成功
OK

[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli -c   // -c 专门用来操作 cluster 集群的
127.0.0.1:6379&gt; set name itheima
-&gt; Redirected to slot [5798] located at 127.0.0.1:6380  // 重定向到 5798 这个槽，这个槽在 6380 下
OK
127.0.0.1:6380&gt; get name
&quot;itheima&quot;
[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli -c -p 6382
127.0.0.1:6382&gt; get name
-&gt; Redirected to slot [5798] located at 127.0.0.1:6380
&quot;itheima&quot;
127.0.0.1:6380&gt; 
</code></pre>
<h2 id="主从下线与主从切换">主从下线与主从切换</h2>
<h3 id="slave6382-下线">slave:6382 下线</h3>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/slave%E4%B8%8B%E7%BA%BF%E4%B8%BB%E8%8A%82%E7%82%B9%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6381（slave:6382 的 master） 日志打印</p>
<figure data-type="image" tabindex="14"><img src="https://epitomm.github.io/post-images/slave%E4%B8%8B%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6379 日志打印</p>
<h3 id="slave6382-重新上线">slave:6382 重新上线</h3>
<figure data-type="image" tabindex="15"><img src="https://epitomm.github.io/post-images/slave%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6381（slave:6382 的 master） 日志打印<br>
<img src="https://epitomm.github.io/post-images/%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E7%9A%84master%E5%8F%98%E6%88%90slave%E4%BA%86.png" alt="图片" loading="lazy"></p>
<p>master:6379 日志打印</p>
<h3 id="master6379-下线">master:6379 下线</h3>
<figure data-type="image" tabindex="16"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BFslave%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave:6383（master:6379 的 slave）日志打印</p>
<p>查看 cluster 信息：</p>
<figure data-type="image" tabindex="17"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BFcluster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave:6383 自己当 master</p>
<h3 id="master6379-重新上线">master:6379 重新上线</h3>
<figure data-type="image" tabindex="18"><img src="https://epitomm.github.io/post-images/master%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p><strong>master:6383</strong>（slave:6379 的 master） 日志信息</p>
<figure data-type="image" tabindex="19"><img src="https://epitomm.github.io/post-images/%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E7%9A%84master%E5%8F%98%E6%88%90slave%E4%BA%86.png" alt="图片" loading="lazy"></figure>
<p>再次上线的 6379 变成 slave 了</p>
<h1 id="总结-2">总结</h1>
<p><strong>集群</strong></p>
<ul>
<li>集群简介</li>
<li>集群结构</li>
<li>cluster集群结构搭建</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试常问之缓存预热、缓存雪崩、缓存击穿、缓存穿透]]></title>
        <id>https://epitomm.github.io/post/mian-shi-chang-wen-zhi-huan-cun-chuan-tou-huan-cun-xue-beng/</id>
        <link href="https://epitomm.github.io/post/mian-shi-chang-wen-zhi-huan-cun-chuan-tou-huan-cun-xue-beng/">
        </link>
        <updated>2020-03-30T01:33:36.000Z</updated>
        <content type="html"><![CDATA[<h1 id="缓存预热">缓存预热</h1>
<h2 id="宕机">“宕机”</h2>
<p>服务器<strong>启动后迅速宕机</strong></p>
<h2 id="问题排查">问题排查</h2>
<ol>
<li>
<p>请求数量较高</p>
</li>
<li>
<p>主从之间数据吞吐量较大（不停地加载数据），数据同步操作频度较高</p>
</li>
</ol>
<blockquote>
<p>数据库读的频度高：服务器一启动，缓存中没有数据，自然就会给服务器带来压力，这时候如果请求比较多的话，redis 服务器就会宕机。</p>
</blockquote>
<h2 id="解决方案">解决方案</h2>
<p>前置准备工作：</p>
<ol>
<li>日常例行统计数据访问记录，统计访问频度较高的热点数据</li>
<li>利用LRU数据删除策略，构建数据留存队列
<ul>
<li>例如：storm与kafka配合</li>
</ul>
</li>
</ol>
<p>准备工作：</p>
<ol start="3">
<li>将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据</li>
<li>利用分布式多服务器同时进行数据读取，提速数据加载过程</li>
</ol>
<p>实施：</p>
<ol>
<li>使用脚本程序固定触发数据预热过程</li>
<li>如果条件允许，使用了CDN（内容分发网络），效果会更好</li>
</ol>
<h2 id="总结">总结</h2>
<p>缓存预热就是系统启动前，<strong>提前将相关的缓存数据直接加载到缓存系统</strong>。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p>
<h1 id="缓存雪崩">缓存雪崩</h1>
<h2 id="数据库服务器崩溃1">数据库服务器崩溃（1）</h2>
<ol>
<li>系统平稳运行过程中，忽然数据库连接量激增</li>
<li>应用服务器无法及时处理请求</li>
<li>大量408，500错误页面出现</li>
<li>客户反复刷新页面获取数据</li>
<li>数据库崩溃</li>
<li>应用服务器崩溃</li>
<li>重启应用服务器无效</li>
<li>Redis服务器崩溃</li>
<li>Redis集群崩溃</li>
<li>重启数据库后再次被瞬间流量放倒</li>
</ol>
<h2 id="问题排查-2">问题排查</h2>
<ol>
<li>在一个<span style="color:red">较短</span>的时间内，缓存中较多的<span style="color:red">key集中过期 </span></li>
<li>此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据</li>
<li>数据库同时接收到大量的请求无法及时处理</li>
<li>Redis大量请求被积压，开始出现超时现象</li>
<li>数据库流量激增，数据库崩溃</li>
<li>重启后仍然面对缓存中无数据可用</li>
<li>Redis服务器资源被严重占用，Redis服务器崩溃</li>
<li>Redis集群呈现崩塌，集群瓦解</li>
<li>应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃</li>
<li>应用服务器，redis，数据库全部重启，效果不理想</li>
</ol>
<h2 id="问题分析">问题分析</h2>
<ul>
<li>短时间范围内</li>
<li>大量key集中过期</li>
</ul>
<h2 id="解决方案道">解决方案（道）</h2>
<ol>
<li>更多的页面静态化处理</li>
<li>构建多级缓存架构</li>
</ol>
<ul>
<li>Nginx缓存+redis缓存+ehcache缓存</li>
</ul>
<ol start="3">
<li>检测Mysql严重耗时业务进行优化</li>
</ol>
<ul>
<li>对数据库的瓶颈排查：例如超时查询、耗时较高事务等</li>
</ul>
<ol start="4">
<li>灾难预警机制</li>
</ol>
<ul>
<li>监控redis服务器性能指标
<ul>
<li>CPU占用、CPU使用率</li>
<li>内存容量</li>
<li>查询平均响应时间</li>
<li>线程数</li>
</ul>
</li>
</ul>
<ol start="5">
<li>限流、降级</li>
</ol>
<ul>
<li>短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问</li>
</ul>
<h2 id="解决方案术">解决方案（术）</h2>
<ol>
<li>LRU与LFU切换</li>
<li>数据有效期策略调整</li>
</ol>
<ul>
<li>根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟</li>
<li>过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量</li>
</ul>
<ol start="3">
<li>超热数据使用永久key</li>
<li>定期维护（自动+人工）</li>
</ol>
<ul>
<li>对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时</li>
</ul>
<ol start="5">
<li>加锁</li>
</ol>
<ul>
<li>慎用！</li>
</ul>
<h2 id="总结-2">总结</h2>
<p>缓存雪崩就是<strong>瞬间过期数据量太大</strong>，导致对数据库服务器造成压力。如能够有<strong>效避免过期时间集中</strong>，可以有效解决雪崩现象的出现 （约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>大量 key 集中过期，更多向 mysql 发起请求</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-2.png" alt="图片" loading="lazy"></figure>
<h1 id="缓存击穿">缓存击穿</h1>
<h2 id="数据库服务器崩溃2">数据库服务器崩溃（2）</h2>
<ol>
<li>系统平稳运行过程中</li>
<li>数据库连接量瞬间激增</li>
<li>Redis服务器无大量key过期</li>
<li>Redis内存平稳，无波动</li>
<li>Redis服务器CPU正常</li>
<li>数据库崩溃</li>
</ol>
<h2 id="问题排查-3">问题排查</h2>
<ol>
<li>Redis中**某个key过期，该key访问量巨大 **</li>
<li>多个数据请求从服务器直接压到Redis后，均未命中</li>
<li>Redis在短时间内发起了大量对数据库中同一数据的访问</li>
</ol>
<h2 id="问题分析-2">问题分析</h2>
<ul>
<li>单个key高热数据</li>
<li>key过期</li>
</ul>
<h2 id="解决方案术-2">解决方案（术）</h2>
<ol>
<li>预先设定</li>
</ol>
<ul>
<li>以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长</li>
<li>注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势</li>
</ul>
<ol start="2">
<li>现场调整</li>
</ol>
<ul>
<li>监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key</li>
</ul>
<ol start="3">
<li>后台刷新数据</li>
</ol>
<ul>
<li>启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</li>
</ul>
<ol start="4">
<li>二级缓存</li>
</ol>
<ul>
<li>设置不同的失效时间，保障不会被同时淘汰就行</li>
</ul>
<ol start="5">
<li>加锁</li>
</ol>
<ul>
<li>分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</li>
</ul>
<h2 id="总结-3">总结</h2>
<p>缓存击穿就是<strong>单个高热数据过期的瞬间，数据访问量较大</strong>，未命中redis后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过期监控难度较高，配合雪崩处理策略即可。</p>
<h1 id="缓存穿透">缓存穿透</h1>
<h2 id="数据库服务器崩溃3">数据库服务器崩溃（3）</h2>
<ol>
<li>系统平稳运行过程中</li>
<li>应用服务器流量随时间增量较大</li>
<li>Redis服务器命中率随时间逐步降低</li>
<li>Redis内存平稳，内存无压力</li>
<li>Redis服务器CPU占用激增</li>
<li>数据库服务器压力激增</li>
<li>数据库崩溃</li>
</ol>
<h2 id="问题排查-4">问题排查</h2>
<ol>
<li>Redis中大面积出现未命中</li>
<li>出现非正常URL访问</li>
</ol>
<h2 id="问题分析-3">问题分析</h2>
<ul>
<li>获取的数据在数据库中也不存在，数据库查询未得到对应数据</li>
<li>Redis获取到null数据未进行持久化，直接返回</li>
<li>下次此类数据到达重复上述过程</li>
<li>出现黑客攻击服务器</li>
</ul>
<p><strong>解决方案（术）</strong></p>
<ol>
<li>缓存null</li>
</ol>
<ul>
<li>对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟</li>
</ul>
<ol start="2">
<li>白名单策略</li>
</ol>
<ul>
<li>提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时，放行，加载异常数据时直接拦截（效率偏低）</li>
<li>使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略）</li>
</ul>
<ol start="3">
<li>实施监控</li>
</ol>
<ul>
<li>实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比
<ul>
<li>非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象</li>
<li>活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象</li>
</ul>
</li>
<li>根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）</li>
</ul>
<ol start="4">
<li>key加密</li>
</ol>
<ul>
<li>问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验</li>
<li>例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问</li>
</ul>
<h2 id="总结-4">总结</h2>
<p>缓存击穿<strong>访问了不存在的数据</strong>，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。</p>
<p>无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。</p>
<h1 id="性能指标监控">性能指标监控</h1>
<h2 id="监控指标">监控指标</h2>
<ul>
<li>性能指标：Performance</li>
<li>内存指标：Memory</li>
<li>基本活动指标：Basic activity</li>
<li>持久性指标：Persistence</li>
<li>错误指标：Error</li>
</ul>
<h3 id="性能指标performance">性能指标：Performance</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">latency</td>
<td style="text-align:left">Redis响应一个请求的时间</td>
</tr>
<tr>
<td style="text-align:left">instantaneous_ops_per_sec</td>
<td style="text-align:left">平均每秒处理总数</td>
</tr>
<tr>
<td style="text-align:left">hit rate(calculate)</td>
<td style="text-align:left">缓存命中率（计算出来的）</td>
</tr>
</tbody>
</table>
<h3 id="内存指标memory">内存指标：Memory</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">used_memory</td>
<td style="text-align:left">已使用内存</td>
</tr>
<tr>
<td style="text-align:left">mem_fragmentation_ratio</td>
<td style="text-align:left">内存碎片化</td>
</tr>
<tr>
<td style="text-align:left">evicted_keys</td>
<td style="text-align:left">由于最大内存限制被移除的 key 的数量</td>
</tr>
<tr>
<td style="text-align:left">blocked_clients</td>
<td style="text-align:left">由于 BLPOP、BRPOP、or BRPOPLPUSH 而备受阻塞的客户端</td>
</tr>
</tbody>
</table>
<h3 id="基本活动指标basic-activity">基本活动指标：Basic activity</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">connected_clients</td>
<td style="text-align:left">客户端连接数</td>
</tr>
<tr>
<td style="text-align:left">connected_slaves</td>
<td style="text-align:left">Slave 数量</td>
</tr>
<tr>
<td style="text-align:left">master_last_io_seconds_ago</td>
<td style="text-align:left">最近一次主从交互之后的秒数</td>
</tr>
<tr>
<td style="text-align:left">keyspace</td>
<td style="text-align:left">数据库中的 key 值总数</td>
</tr>
</tbody>
</table>
<h3 id="持久性指标persistence">持久性指标：Persistence</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">rdb_last_save_time</td>
<td style="text-align:left">最后一次持久化保存到磁盘的时间戳</td>
</tr>
<tr>
<td style="text-align:left">rdb_changes_since_last_save</td>
<td style="text-align:left">自最后一次持久化依赖数据库的更改数</td>
</tr>
</tbody>
</table>
<h3 id="错误指标error">错误指标：Error</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">rejected_connections</td>
<td style="text-align:left">由于达到 maxclient 限制而被拒绝的连接数</td>
</tr>
<tr>
<td style="text-align:left">keyspace_misses</td>
<td style="text-align:left">key 值查找失败（没有命中）次数</td>
</tr>
<tr>
<td style="text-align:left">master_link_down_since_seconds</td>
<td style="text-align:left">主从断开的持续时间（以秒为单位）</td>
</tr>
</tbody>
</table>
<h2 id="监控方式">监控方式</h2>
<ul>
<li>工具
<ul>
<li>Cloud Insight Redis</li>
<li>Prometheus</li>
<li>Redis-stat</li>
<li>Redis-faina</li>
<li>RedisLive</li>
<li>zabbix</li>
</ul>
</li>
<li>命令
<ul>
<li>benchmark</li>
<li>redis cli
<ul>
<li>monitor</li>
<li>showlog</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="benchmark">benchmark</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>redis-benchmark [-h ] [-p ] [-c ] [-n &lt;requests]&gt; [-k ] 
</code></pre>
<ul>
<li>范例1</li>
</ul>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-benchmark 
</code></pre>
<p>说明：50个连接，10000次请求对应的性能</p>
<ul>
<li>范例2</li>
</ul>
<pre><code>redis-benchmark -c 100 -n 5000 
</code></pre>
<p>说明：100个连接，5000次请求对应的性能</p>
<h2 id="benchmark-2"><strong>benchmark</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/benchmark.png" alt="图片" loading="lazy"></figure>
<h2 id="monitor">monitor</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>monitor 
</code></pre>
<p>打印服务器调试信息</p>
<h2 id="slowlog">slowlog</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>slowlog [operator] 
</code></pre>
<ul>
<li>get ：获取慢查询日志</li>
<li>len ：获取慢查询日志条目数</li>
<li>reset ：重置慢查询日志</li>
<li>相关配置</li>
</ul>
<pre><code>slowlog-log-slower-than 1000 #设置慢查询的时间下线，单位：微妙 
slowlog-max-len 100 #设置慢查询命令对应的日志显示长度，单位：命令数
</code></pre>
<h1 id="总结-5">总结</h1>
<p>企业级解决方案</p>
<ul>
<li>缓存预热</li>
<li>缓存雪崩</li>
<li>缓存击穿</li>
<li>缓存穿透</li>
<li>性能指标监控
<ul>
<li>工具</li>
<li>命令</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线程]]></title>
        <id>https://epitomm.github.io/post/xian-cheng/</id>
        <link href="https://epitomm.github.io/post/xian-cheng/">
        </link>
        <updated>2020-03-29T03:08:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="p-stylecolorred1-线程抽象p"><p style="color:red">1. 线程抽象</p></h1>
<p>一个线程是一个单一的执行序列，它表示了一个单独被调度的任务.</p>
<ul>
<li><strong>单一的执行序列</strong>. 每个线程执行一个指令序列——赋值，条件，循环，过程, 等等</li>
<li><strong>单独被调度的任务</strong>. 操作系统可以在任意时刻，运行，暂停或者继续一个线程。</li>
<li><strong>运行，挂起和继续执行的线程</strong></li>
</ul>
<p>线程提供了一个有无限个处理机的幻象。OS 如何实现这样的幻象呢？它必须执行每个进程的指令使得每个线程都有进展，但实际的硬件只有有限个数的处理机，甚至只有 1 个</p>
<p>为了将任意数量的线程映射到有限个处理机上，OS 包含一个调度器(scheduler)能够在运行和就绪的线程之间来回切换。但是线程的切换对线程来说是透明的，只是某些时刻处理机的执行变得比较慢而已。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%90%8C%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.3</strong>: 一个线程 3 种可能的执行方式 ，对于程序员来说是无差的.</p>
<p>上图说明了一个程序员角度的一个简单程序有三种不同的执行方式，这取决于调度器。从线程的角度，除了执行的速度不一样，这些是没差的。确实，线程并不知道有其他线程在执行。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E4%BA%A4%E9%94%99%E6%89%A7%E8%A1%8C.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.4</strong>: 3 个线程在运行时许多种可能的交错执行的方式.</p>
<p>上图展示了 3 个线程的交替执行。他们的这种速度是不可控的，每次执行可能都不一样。</p>
<p><strong>例子</strong>:内核中断处理程序是一个线程?</p>
<p><strong>回答： 不，一个中断处理程序不是一个线程</strong>. 一个内核中断处理程序和线程有一些相似性: 它是一个指令的序列， 从开头执行到结尾。然而，一个中断处理程序<strong>不是独立可调度的</strong>: 它被一个硬件I/O 事件所触发执行,  而不是内核中线程调度器来决定什么时候执行. 一旦开始，中断处理程序运行到结束，除非被另外一个优先级更高的中断抢占.</p>
<h1 id="p-stylecolorred2-简化的线程-apip"><p style="color:red">2. 简化的线程 API</p></h1>
<table>
<thead>
<tr>
<th style="text-align:left">void thread_create  (thread, func,arg)</th>
<th style="text-align:left">创建一个新线程, 把信息存入 thread. 和调用的线程并发执行，线程执行函数 func，其参数为 arg.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">void thread_yield()</td>
<td style="text-align:left">调用的线程自愿放弃处理机让其他线程来运行。调度器也可以继续运行调用的线程.</td>
</tr>
<tr>
<td style="text-align:left">int thread_join  (thread)</td>
<td style="text-align:left">等待 thread 结束如果 thread 还没有结束的话; 然后返回由 thread 通过 thread_exit 传递来的参数. 注意， 对每个线程，thread_join 只能被调用一次.</td>
</tr>
<tr>
<td style="text-align:left">void thread_exit(ret)</td>
<td style="text-align:left">完成当前的线程. 将 ret 的值存在当前线程的数据结构中。如果另一个线程已经用 thread_join 等待该线程, 则继续执行那个等待的线程.</td>
</tr>
</tbody>
</table>
<p><strong>图 4.5</strong>:使用线程简化的 API</p>
<p>图 4.5 展示了使用线程的简单的API. 这个简化的API 是基于POSIX 标准的pthreads API, 但是它忽略了某些POSIX 选项和错误处理(为了简化). 绝大多数其他线程包也类似，如果你理解如何用这个 API 编程的话，你会发现对于绝大多数标准的线程 API 来说，其代码很容易编写.</p>
<p>我们看见 UNIX 进程抽象中有类似的概念. thread_create 类似于UNIX 进程 fork 和 exec, 而 thread_join 类似于 UNIX 进程wait. UNIX fork 创建了一个新的进程和原来调用 fork 的进程并发的执行;UNIX exec 导致进程运行一个指定的程序。UNIX wait 运行调用的进程暂停执行直到新的进程完成为止。</p>
<h2 id="1-多线程的hello-world">1. 多线程的Hello World!</h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E5%A4%9A%E7%BA%BF%E7%A8%8Bhelloworld%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.png" alt="图片" loading="lazy"></figure>
<p><strong>图 4.6</strong>: 用简单线程API 来打印”Hello”十次的多线程编程的例子。也展示了一种可能的输出。</p>
<p>上图是一个多线程的程序，用了简单的线程 API 来打印 hello 十次。也展示了一个可能的输出结果。Main 函数用 thread_create 创建了 10 个子线程。有趣的参数是第二个和第三个。第二个参数 go 是一个函数指针——新创建的检测应该开始执行的代码位置。第三个参数 i 传递给 go 函数。因此，thread_create 初始化第i 个线程的状态使得它准备调用函数 go，参数是 i。</p>
<p>当调度者运行第 i 个线程，线程运行函数go，参数为 i，打印 hello from 线程 i。 线程接着返回值 i+100 通过调用 thread_exit. 这个调用将特定的值保存到 trhead_t 的对象里，使得 thread_join 能够找到它。</p>
<p>Main 函数用thread_join 来等待每个它创建的线程。当每个线程完成的时候，main 的代码会的读取完成线程的退出值并打印。</p>
<p><strong>例子</strong>：为什么来自线程 2 的“线程 returned”的消息<strong>一定是</strong>在来自线程 5 的线程 returned 的消息打印之前先打印？</p>
<p>回答：虽然每个创建的线程完成的顺序是不确定的，但是主线程是按照创建的顺序按顺序检查的。</p>
<p><strong>例子</strong>：当线程 5 打印 hello 的时候未退出的线程的最少数是多少？最多数是多少？</p>
<p><strong>回答</strong>：最少是 2，最多是 11</p>
<h2 id="2-创建线程thread_create和线程等待thread_join在并行计算中的应用">2. 创建线程(thread_create)和线程等待(thread_join)在并行计算中的应用</h2>
<p>尽管线程接口很简单，但非常强大。例如用”<strong>fork-join 并行”</strong>（<strong>fork-join 并行</strong>即 thread_create 和 thread_join 一起使用来实现并行化计算）, 一个线程可以创建子线程来执行工作(“fork”, 或者 thread_create), 它可以等待他们的结果(“join”).</p>
<pre><code>// 为了传递两个参数，我们需要一个结构来保存它们.
typedef struct bzeroparams {
   unsigned char *buffer; int length;
};
#define NTHREADS 10
void go (struct bzeroparams *p) {
   memset(p-&gt;buffer, 0, p-&gt;length);
}
//用多线程对一个块进行清零.
void blockzero (unsigned char *p, int length) {
  int i;
  thread_t threads[NTHREADS];
  struct bzeroparams params[NTHREADS];
  // 为了简化，假设长度可以被NTHREADS 整除. assert((length   NTHREADS) == 0);
  for (i = 0; i &lt; NTHREADS; i++) {
      params[i].buffer = p + i * length/NTHREADS; params[i].length = length/NTHREADS; thread_create_p(&amp;(threads[i]), &amp;go, &amp;params[i]);
  }
  for (i = 0; i &lt; NTHREADS; i++) {
      thread_join(threads[i]);
    }
}
</code></pre>
<p><strong>图 4.7</strong>: 使用多线程并行地对一个内存连续区域清零的程序.<br>
<strong>例子：并行的块清零</strong>.在操作系统中一个应用 fork-join 并行的简单例子是对一段连续内存块清零的过程. 每当一个进程结束的时候，为了阻止无意的数据泄露, 操作系统必须把分配给这个进程中的内存清零。否则，一个新的进程可能会被重新分配给这个内存, 使得这个进程可以读取潜在的敏感的数据。例如，一个操作系统的远程登录程序可能暂时存储一个用户的密码在内存中，但是下一个使用同一内存区间的进程可能会是一个被一个恶意用户调用的扫描内存的程序.</p>
<p>对于一个大的进程，并行地清零的函数是合理的。在现代计算机上，对 1GB 的内存清零需要大约 50 毫秒; 相比之下，创建和启动一个新的线程只需要几十微秒.</p>
<p>图 4.7 展示了一个使用fork-join 并行清零的代码。多线程的 blockzero 创建了一系列线程并给每个分配了一段不相交的内存区间; 当所有线程都完成它们的工作的时候整个区间都被清零. 操作系统可以创建一系列低优先级的线程来运行 blockzero. 之后，当内存被需要的时候，内核可以调用 thread_join. 如果那个时候已经完全清零，则join 会立即返回；否则它需要等待直到这块内存可以被安全使用.</p>
<h1 id="p-stylecolorred3-线程的数据结构p"><p style="color:red">3. 线程的数据结构</p></h1>
<p>为了理解操作系统如何实现线程的抽象，我们必须定义两种状态，一个是每个线程的状态(the Per-Thread State)， 另一个是多个线程的共享状态(the Shared State)。然后我们才能给描述一个线程的生命周期——提供上述抽象，操作系统是如何能够创建，开始，暂停和删除线程的。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.8</strong>: 一个多线程的进程或者操作系统的内核既有每个线程的状态也有共享状态. 线程控制块（TCB）存储了每个线程的状态: 线程当前的计算状态(例如，被保存的处理机的寄存器和一个指向(内核)栈的指针)和需要管理该线程的元数据(例如，线程的 ID，调度优先级，拥有者). 共享的状态包括程序的代码，全局静态变量和堆.</p>
<p>一个多线程的进程或者操作系统内核都有每个线程的状态和共享状态。线程控制块保存着每个线程的状态: 线程计算当前的状态(例如，保存的处理机的寄存器和(内核)栈指针)和需要管理这个线程的元数据(例如，线程的 ID， 调度的优先级，拥有者)。共享状态包括：程序的代码，全局变量和堆。</p>
<ul>
<li><strong>每个线程的状态(Per-Thread State)和线程控制块(TCB)</strong></li>
</ul>
<p>操作系统需要一个数据结构来表示一个线程的状态；线程就好比是这个数据结构下的一个具体的对象。这个数据结构被称为线程控制块(线程控制块, TCB)。对于每个操作系统创建的线程，它就创建一个TCB。</p>
<p>线程控制块记录两种类型的每个线程的信息：</p>
<ol>
<li>这个线程当前的计算状态：栈和处理器中寄存器的值</li>
<li>用于管理该线程的元数据</li>
</ol>
<ul>
<li><strong>共享状态</strong></li>
</ul>
<p>有一些状态是属于同一应用进程里的不同线程之间共享的状态，或者是操作系统内核内的线程之间共享的状态。特别的，程序代码是同一进程中所有线程共享的，尽管每个线程可能执行代码的不同位置。除此以外，静态分配的  全局变量和动态分配的堆变量也是同一进程的所有线程所共享的。</p>
<p><strong>警告</strong>：这是逻辑上的区分状态（Per-Thread State 和 Shared State），而操作系统往往不强制这种区分，换句话说，一个线程可以去访问同一进程内的其他线程的每个线程的状态，例如访问其他线程的用户栈。<strong>这是被允许的</strong>。那么为了避免不要的错误，编写一个多线程的程序的时候必须要清楚哪些变量是线程之间共享的，哪些是私有的。以防一个线程会破坏其他线程。</p>
<h1 id="p-stylecolorred4-线程的生命周期p"><p style="color:red">4. 线程的生命周期</p></h1>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.9: 一个线程在它的生命周期中的状态.</strong></p>
<p>上图展示了一个线程的生命周期。</p>
<ul>
<li><strong>新建</strong>：线程创建会把一个线程设为新建状态，分配和初始化每个线程的的数据结构。一旦这些完成，thread_ creation 代码会把该线程放到就绪队列中（隐含的意思是设置为READY 状态）。</li>
<li><strong>就绪</strong>：一个线程是就绪态就是指它可以运行但当前还没有运行。它的 TCB 被放在就绪队列上，它的寄存器的值被保存在它的 TCB 中。在任意时刻，调度器可以让一个线程从就绪态到运行态，只需要把它保存在 TCB 中的寄存器的值恢复到处理机的寄存器上。</li>
<li><strong>运行</strong>：一个线程是运行态就是指它正在一个处理机上运行。此时，它的寄存器的值还在处理机的寄存器上，而不是TCB 中。一个运行态的线程可以按下面两种方式切换到就绪态：
<ul>
<li>
<p>调度器抢占一个运行的线程，然后将它放到就绪态，通过（1）保存线程的寄存器值到它的 TCB 中；并且（2）将处理机切换去执行就绪队列中某线程</p>
</li>
<li>
<p>一个运行态的线程可以自愿地放弃(relinquish)处理机然后从运行态到就绪态，通过调用 yield(例如，线程库中的 thread_yield)</p>
</li>
</ul>
</li>
</ul>
<p>注：一个线程可以从就绪态到运行态，再从运行态到就绪态，这样多次切换。</p>
<ul>
<li><strong>等待</strong>：一个线程在等待态是指它在等待某个事件。调度器能够将一个线程从就绪态移动到运行态，一个在等待态的线程却不能切换到运行态，它必须要等待某个其他的线程将它从等待态移动到就绪态。</li>
<li><strong>完成</strong>：一个线程在完成态就意味着它用于不会再运行了。系统能够释放部分或者它的全部状态，但它仍然要保留线程残留的一些信息，并把线程的 TCB 放到一个完成队列上。例如，thread_exit 调用会让一个线程将它的退出值通过 thread_join 传递给它的父亲线程。当一个线程的状态再没任何用处的时候（例如，当它的退出值已经被 thread_join 读取了），系统就可以删除和取回该线程的状态。</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E4%B8%8D%E5%90%8C%E7%8A%B6%E6%80%81%E4%B8%8B%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BD%8D%E7%BD%AE.png" alt="图片" loading="lazy"></figure>
<p><strong>图 4.10: 在不同状态下线程的每个线程状态的位置.</strong></p>
<p>理解这些状态的一种方式就是考虑一个线程的 TCB 和寄存器值存放的位置，如上图所示。当所有线程在就绪态，它们的 TCB 被放在就绪队列，它们的寄存器的值的拷贝也放在 TCB 中。所有在运行态的线程，它们的 TCB 被放在运行队列上，它们的寄存器值是在硬件寄存器上。所有在等待态的线程它们的 TCB 是放在不同的同步变量的等待队列上。</p>
<hr>
<p><strong>idle 线 程</strong></p>
<p>如果一个系统有 k 个处理机,  绝大多数操作系统确保正好有 k 个执行态的线程,  通过在每个处理机上维护一个低优先级的 <strong>idle 线程</strong>以保证当该处理机没有什么事情可做的时候，仍然有线程在执行.</p>
<p>在旧机器上，idle 线程会在一个紧凑循环中什么也不做. 而今天，idle 线程仍然在一个loop 中 spin, 但是为了省电，在每次迭代中，它把处理机进入一个低耗电的睡眠模式。在睡眠模式中，处理机暂停执行指令直到出现一个硬件中断。然后，处理机醒来并按照通常的方式来处理中断—保存当前正在执行的线程(idle 线程)的状态并执行处理程序. 在运行了处理程序之后，一个等待此 I/O 事件的线程现在可以是就绪态. 如果是这样的话，调度器接下来就执行这个进入就绪态的线程；否则 idle 线程继续执行，让处理机再次去睡觉.</p>
<hr>
<p><strong>例子</strong>：对于线程 Hello 程序，在一个单处理机上，主线程进入就绪态的最少次数是多少？最多次数又是多少？</p>
<p><strong>回答</strong>：当主线程被创建时，它必须进入就绪态；否则它永远不会被调度。在一个单处理机上，它必须放弃处理机为了让它的线程运行。在主线程被重新调度之前，子线程们接下来可以完成运行。一旦孩子们完成，主线程可以完成运行。<strong>因此最小的次数是 2</strong>.</p>
<p><strong>最大的次数则是接近于无穷大</strong>。一个运行的线程可以被抢占然后被重新调度若干次，而不影响执行的正确性。</p>
<h1 id="p-stylecolorred5-实现内核线程p"><p style="color:red">5. 实现内核线程</p></h1>
<p>我们介绍内核线程的实现。这是所有线程实现中最基础的，也是最简单的。</p>
<h2 id="p-stylecolorreda-创建内核线程代码不要求但后面介绍的基本步骤需要掌握p"><p style="color:red">a. 创建内核线程（代码不要求，但后面介绍的基本步骤需要掌握）</p></h2>
<pre><code>// func 是一个指向线程要运行的过程的指针.
// arg 是传递给这个过程的参数.
void thread_create(thread_t *thread, void (*func)(int), int arg) {
  // Allocate TCB and stack TCB *tcb = new TCB();
  thread -&gt;tcb = tcb;
  tcb-&gt;stack_size = INITIAL_STACK_SIZE;
  tcb-&gt;stack = new Stack(INITIAL_STACK_SIZE);
  // 初始化寄存器使得当线程继续执行的时候，它从 stub 开始执行。
  //栈从分配的区域的顶端开始，然后向下增长. tcb-&gt;sp = tcb-&gt;stack + INITIAL_STACK_SIZE; tcb-&gt;pc = stub;
  // 通过把 stub 的参数压栈来创建一个栈帧
  *(tcb-&gt;sp) = arg; tcb-&gt;sp--;
  *(tcb-&gt;sp) = func; tcb-&gt;sp--;
  // 创建另一个栈帧使得 thread_switch 正确工作. 这个 routine 在本章后面解释. thread_dummySwitchFrame(tcb);
  tcb-&gt;state = READY;
  readyList.add(tcb); // 把 TCB 放在就绪队列
}
void stub(void (*func)(int), int arg) {
  (*func)(arg); // 执行函数 func()
  thread_exit(0); // 如果 func()不调用 exit,在这里调用 exit.
}


</code></pre>
<p><strong>图 4.13</strong>创建线程的伪代码。对栈的初始化和传参给初始函数是和机器相关的。在 intel x86 架构中，栈从搞地址开始然后向下增长，而参数被传递到栈上。在其他系统，栈能够向上增长，参数是通过寄存器传递。图 4.14 提供了thread_dummySwitchFrame 的伪代码<br>
图 4.13 展示了创建一个新线程的伪代码。thread_create 的目标是执行一个异步的过程调用给 func，其参数为 arg。当线程运行时，它执行 func(arg)【与父进程并发执行】</p>
<p><strong>创建一个线程有 3 个步骤</strong></p>
<ol>
<li><strong>分配每个线程的状态</strong>. 第一步是为线程的每个线程的状态分配空间：TCB 和栈。正如我们所提到的，TCB 是操作系统用于管理线程的数据结构。</li>
<li><strong>初始化每个线程的状态</strong>. 为了初始化TCB，需要初始化各个寄存器的值。当该线程被调度时，我们想要我们想要它运行 func(arg)。然而，是先从一个 dummy 函数, stub, 运行，stub 接着调用func。我们需要这个步骤是因为 func 是返回而不是调用 thread_exit。没有这个 stub 的话，func 会返回栈顶的一个随机的位置。，有了 stub，函数 func 返回到stub，然后再由 stub 调用 thread_exit 来完成线程。在伪代码中，我们给 stub 压入两个参数进栈：func 和 arg。当线程开始运行，stub 的代码就会访问它的代码就行一个普通的procedure。</li>
<li><strong>将TCB 放到就绪队列</strong>. 创建一个线程的最后一步就是将它的状态设置为就绪态，然后把新的 TCB 放到就绪队列， 使得该线程能够被调度。</li>
</ol>
<h2 id="p-stylecolorred-b-一个自愿的内核线程切换代码不要求但线程上下文切换的基本步骤需要掌握即保存旧线程的寄存器的值到tcb-中把新线程的tcb-中寄存器的值加载到cpu-的寄存器中p"><p style="color:red"> b. 一个自愿的内核线程切换（代码不要求，但线程上下文切换的基本步骤需要掌握，即：保存旧线程的寄存器的值到TCB 中，把新线程的TCB 中寄存器的值加载到CPU 的寄存器中</p></h2>
<p>图 4.14 展示了在Intel x86 硬件架构下，thread_yiled 的简单实现的伪代码.一个线程调用 thread_yield 自愿地放弃处理机给另一个线程用. 调用的线程的寄存器被拷贝到它的 TCB 和栈中，便于当调度器再次选择它的时候，可以继续运行.</p>
<pre><code>//我们以一个旧线程进入，而以新线程返回.
//以新线程的寄存器和栈返回.
void thread_switch(oldThreadTCB, newThread TCB) { 
    pushad; //把通用寄存器的值压入旧的栈中. 
    oldThreadTCB-&gt;sp = esp; //保存旧线程的栈指针. 
    esp = newThreadTCB-&gt;sp; // 切 换 到 新 的 栈 . 
    popad; // 从新的栈弹出寄存器的值.
    return;
}
void thread_yield() {
  TCB *chosenTCB, *finishedTCB;
  // 在切换的中间过程中阻止有中断暂停. disableInterrupts();
  // 从 就 绪 队 列 中 选 择 另 一 个 TCB. chosenTCB = readyList.getNext 线程(); 
  if (chosenTCB == NULL) {
    // 没有什么可以运行的，回去运行原始的线程.
  } else {
    // 将运行的线程移动到就绪队列. runningThread-&gt;state = ready; readyList.add(runningThread);
    thread_switch(runningThread, chosenTCB); // 切换到新的线程. runningThread -&gt;state = running;
  }
  //删除完成队列上的任意线程.
  while ((finishedTCB = finishedList-&gt;getNextThread()) != NULL) {
    delete finishedTCB-&gt;stack;
    delete finishedTCB;
  }
  enableInterrupts();
}
//thread_create 必须在它的栈顶放一个 dummy frame:
// 返回的 PC 和给 pushad 的空间来存储寄存器的备份.
// 这样的话，当某人切换到一个新创建的线程, thread_switch 的最后两行能正确工作.
void thread_dummySwitchFrame(new 线程) {
  *(tcb-&gt;sp) = stub; //返回到 stub 的开头. tcb-&gt;sp--;
  tcb-&gt;sp -= SizeOfPopad;
}
</code></pre>
<p><strong>图 4.14</strong>: 在 Intel x86 架构上 thread_switch 和 thread_yield 的伪代码。注意， thread_yield 是一个空操作如果没有其他线程可以运行。否则，它保存旧线程的状态并恢复新线程的状态。当旧线程被重新调度，它从thread_switch 返回到正在运行的线程.</p>
<hr>
<p>thread_yield 的伪代码首先关闭中断来阻止线程系统试图在同一时间做两个上下文切换. 伪代码接着把下一个线程拉出就绪队列(如果有的话)，然后切换到它. thread_switch 代码也许看上去有点不易理解, 由于它是在旧线程的上下文中被调用，而完成的时候是在新线程的上下文. 为了完成切换，thread_switch 把寄存器的状态保存到栈上，然后把栈指针保存到 TCB 中。接着它切换到新的线程的栈，从新线程的栈来恢复新线程的状态，然后返回到存储在新栈中的程序计数器的位置. 一个比较扭曲的地方是返回的位置可能不是 thread_yield!  返回到了新线程之前被暂停的地方.</p>
<hr>
<p><strong>一个 0-线程的内核</strong></p>
<p>我们不仅可以有一个单线程的内核或者一个多线程的内核，还有可能有一个没有线程的内核——0 线程的内核。实际上，这也是常见的。因为几乎内核中所有事情都是事件驱动的，例如响应一个中断，处理机异常或者系统调用。</p>
<p>在一个简单的操作系统中，就没有必要创建内核线程或者内核线程控制块来追踪正在进行的计算。而是，当发生一个中断，陷阱或者异常，栈指针就设置为指向中断栈的栈底，指令指针设置为处理程序的地址。接着，处理程序开始执行，要不就立即返回到用户级的进程要不就暂停用户级的进程，然后返回到其他用户级进程。</p>
<hr>
<h1 id="p-stylecolorred6-实现多线程的进程p"><p style="color:red">6. 实现多线程的进程</p></h1>
<p>所有广泛被应用的操作系统既支持内核线程也支持多线程进程。编程语言，例如 Java，和标准库接口例如 POSIX 用操作系统的这种支持来为编程者提供线程的抽象。</p>
<ul>
<li><strong>用内核线程实现多线程的进程</strong></li>
</ul>
<p>支持多线程进程的最简单的方式是使用内核线程的实现。当一个用户级线程访问线程库要做同样的事情，它用系统调用来请求内核做同样的操作。</p>
<p>如图 4.12 所示，一个进程的线程有：</p>
<ul>
<li>一个用户级的栈用于执行用户代码</li>
<li>一个内核中断栈：当该线程做系统调用时，或者引发了一次处理机异常，或者被中断</li>
<li>一个内核TCB：用于保存和恢复每个线程的状态</li>
</ul>
<p>为了创建一个线程，<strong>用户线程库</strong>分配一个用户级的栈给新的线程，然后做一个系统调用进入内核。内核分配一个TCB 和内核栈，设置线程的状态使其用用户级栈从被请求的过程的开始处开始执行。内核需要在<strong>进程控制块</strong>（<strong>PCB</strong>） 中保存一个指向该TCB 的指针；如果进程退出，内核必须终止在这个进程内的任意线程。在创建了线程后，内核把新的线程放到就绪队列上，就像其他线程一样可以被调度，然后返回一个唯一的标识符给用户程序，以便于以后想要指定这个新创建的线程的时候使用（例如，for join）。线程的 join, yield,和 exit 用同样的方式实现：<strong>通过系统调用进入内核来执行所请求的函数</strong>。</p>
<h1 id="p-stylecolorred7-实现用户级线程没有内核支持p"><p style="color:red">7. 实现用户级线程（没有内核支持）</p></h1>
<p>也可以实现一个完全在用户级的线程（作为库函数），不需要任何操作系统的支持。早期线程库函数采用这种纯用户级方法的原因是：因为极少有操作系统支持多线程的进程。在 JAVA 虚拟机中，也被称为绿线程。</p>
<p>基本思想比较简单。线程库函数在进程中初始化线程的所有数据结构：TCB，就绪队列，完成队列，等待队列，这些全部在进程的用户地址空间。对线程库函数的调用就是普通的过程调用。</p>
<p>在操作系统内核看来，一个用户级多线程的应用程序就是一个普通的单线程进程。绿线程的限制是操作系统<strong>内核不知道用户级就绪队列</strong>。如果应用程序的某个线程执行一个系统调用需要等待 I/O，内核不知道还有别的用户级线程可以运行。就会<strong>把整个进程都阻塞</strong>。类似的，在一个多处理机上，内核也不能让一个进程的多个线程在不同的处理机上运行。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[进程]]></title>
        <id>https://epitomm.github.io/post/jin-cheng/</id>
        <link href="https://epitomm.github.io/post/jin-cheng/">
        </link>
        <updated>2020-03-29T02:28:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="p-stylecolorred1-为什么引入进程p"><p style="color:red">1. 为什么引入进程？</p></h1>
<p>操作系统需要一种统一的方法监视、管理、控制处理器中不同程序的动态执行过程，“进程”的概念被引入！</p>
<h1 id="p-stylecolorred2-进程的定义p"><p style="color:red">2. 进程的定义</p></h1>
<p>进程没有严格的定义，但可以通过不同的角度去描述：计算机中正在运行的程序的一个实例（Instance。它包含（内存中的）代码段，数据段，堆，栈（用户栈和内核栈）；和当前的执行上下文（PC，SP 和其他寄存器），操作系统通过维护数据结构——进程控制块（PCB）来管理每个进程。</p>
<p><strong>进程控制块（Process Control Block——PCB</strong>：PCB 是是操作系统用来管理进程的数据结构，是进程存在的唯一标识。每当操作系统创建一个进程，就是由操作系统为该进程设置一个 PCB；进程执行完成时，由系统收回其 PCB， 该进程便消亡了。PCB 的内容包括：</p>
<ul>
<li>进程的状态（就绪，执行，等待，完成）</li>
<li>进程的 ID</li>
<li>进程的名字</li>
<li>进程的执行上下文（PC，SP，ELFAGS，其他寄存器）</li>
<li>调度需要的信息（优先级，调度参数，使用的 CPU 时间，进程开始的时间…）</li>
<li>内存管理的信息（基址和界限…）</li>
<li>I/O 状态信息（打开的文件，占用的 I/O 设备…）</li>
</ul>
<h1 id="p-stylecolorred3-内核线程和用户进程放到一起p"><p style="color:red">3. 内核线程和用户进程放到一起</p></h1>
<p>下面两个图展示了包含用户进程（上图是单线程进程，下图是多线程进程）和内核线程的内存空间信息。</p>
<ul>
<li>所有<strong>内核线程</strong>都<strong>共享</strong>内核的代码段（Code），全局变量(Globals)，堆(Heap)，和自己<strong>专门</strong>的 TCB 和内核栈。</li>
<li><strong>单线程的用户进程</strong>在用户空间有自己的代码段，数据段，堆，栈，在内核空间有内核用于管理该进程使用的 PCB和内核栈。</li>
<li>多线程的用户进程在用户空间有自己的代码段，数据段，堆和多个线程。每个线程有自己的用户栈，和内核空间的内核栈以及内核用于管理该线程的TCB。</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B-%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.11</strong>:一个多线程的内核：有 3 个内核线程和两个单线程的用户级进程. 每个内核线程 有它自己的 TCB 和它自己的栈. 每个用户进程有一个用户级的栈用于执行用户的代码和一个内核中断栈用于执行系统调用和中断.</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%86%85%E6%A0%B8.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.12</strong>: 一个多线程的内核：有 3 个内核线程和两个用户级的进程, 每个进程有 2 个线程. 每个用户级线程有一个用户级栈和一个内核中的中断栈用于执行系统调用和中断.</p>
<h1 id="p-stylecolorred4-进程的状态及其变迁p"><p style="color:red">4. 进程的状态及其变迁</p></h1>
<h2 id="a-三状态变迁图">a)  三状态变迁图</h2>
<p><strong>运行中的</strong>进程至少具有以下三种基本状态（如下图所示）：</p>
<ol>
<li><strong>就绪状态</strong>– 在某时刻，进程已获得除处理机以外的所有资源，一旦分到了处理机就可以立即执行</li>
<li><strong>运行状态</strong>– 进程已经获得必要资源，并占有处理机运行</li>
<li><strong>等待状态</strong>（也叫<strong>阻塞状态</strong>） – 正在执行的进程，由于发生某事件而暂时无法执行下去</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%B8%89%E7%8A%B6%E6%80%81.png" alt="图片" loading="lazy"></figure>
<p>例如，下图展示了 3 个进程的状态的变迁。其中调度程序是操作系统内核中用于从就绪队列中选择下一个占用CPU 执行的进程的调度程序。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%BA%8F%E5%88%97%E5%9B%BE%E4%B8%BE%E4%BE%8B-%E4%B8%89%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<h2 id="b-五状态变迁图">b)  五状态变迁图</h2>
<p>其状态变迁图如下图所示，比 3 状态图多了两个状态：新建和退出。</p>
<ul>
<li><strong>新建状态</strong>– 至少建立PCB，但进程相关的其他内容可能未调入主存</li>
<li><strong>退出状态</strong>– 进程已经终止，但资源等待父进程或系统回收</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%BA%94%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<p><strong>触发进程状态变迁的事件</strong>描述如下：</p>
<ul>
<li><strong>创建</strong>→<strong>就绪</strong>：(1)系统初始化，(2)用户请求创建一个新进程，(3)进程执行了创建进程的系统调用</li>
<li><strong>就绪</strong>→<strong>执行</strong>：内核的调度程序(scheduler)选择了一个就绪的进程，让它占用处理机执行</li>
<li><strong>运行</strong>→<strong>等待</strong>: 需要等待某个事件发生才可以继续执行，例如 I/O 请求或者某个共享数据被锁住不能访问</li>
<li><strong>运行</strong>→<strong>就绪</strong>（被<strong>抢占</strong>）：高优先级的进程进入就绪态，进程的时间片用完</li>
<li><strong>等待</strong>→<strong>就绪</strong>(被<strong>唤醒</strong>)：等待的事件发生，例如 I/O 请求完成，共享数据可以访问</li>
<li><strong>运行</strong>→<strong>结束</strong>：可能是正常退出（调用 exit 系统调用），可能是出错（异常，由操作系统强制终止）</li>
</ul>
<h2 id="c-七状态变迁图">c.) 七状态变迁图</h2>
<p>当内存不够的时候，执行状态的进程，就绪状态的进程和等待状态的进程都有可能因为优先级较低而被从内存移出放到外存，如果是执行态和就绪态的进程被移出到外存，则被称为<strong>就绪挂起</strong>；如果是等待态的进程被移出到外存，则被称为<strong>等待挂起</strong>。</p>
<ul>
<li><strong>等待挂起</strong>：进程在外存等待某事件的出现</li>
<li><strong>就绪挂起</strong>：进程在外存，但只要进入内存就可以运行新加入的<strong>状态变迁</strong>有两类：挂起和激活。</li>
<li><strong>挂起：把一个进程从内存移到外存</strong>
<ul>
<li><strong>等待</strong>→<strong>等待挂起</strong>：没有进程处于就绪状态或者就绪进程要求更多的内存</li>
<li><strong>就绪</strong>→<strong>就绪挂起</strong>：当有高优先级等待的进程和低优先级的就绪进程</li>
<li><strong>运行</strong>→<strong>就绪挂起</strong>：当有高优先级等待挂起进程因为等待的事件发生了而进入就绪挂起</li>
<li><strong>等待挂起</strong>→<strong>就绪挂起</strong>：当有等待挂起的进程所等待的事件发生了</li>
</ul>
</li>
<li><strong>激活：把一个进程从外存移到内存</strong>
<ul>
<li><strong>就绪挂起</strong>→<strong>就绪</strong>：没有就绪进程或挂起就绪进程优先级高于就绪进程</li>
<li><strong>等待挂起</strong>→<strong>等待</strong>：当一个进程释放足够内存，并有高优先级等待挂起进程</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%B8%83%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<h1 id="p-stylecolorred5-进程状态的队列p"><p style="color:red">5. 进程状态的队列</p></h1>
<p>进程控制块根据不同状态被放到不同的队列中，如下图所示</p>
<ul>
<li>就绪队列：状态为就绪的PCB 队列，该队列可以是链表也可以是索引，还可以多个队列</li>
<li>执行队列：状态为执行的PCB 队列</li>
<li>等待队列：状态为等待的PCB 队列，不同的等待事件对应不同的等待队列</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E9%98%9F%E5%88%97.jpg" alt="图片" loading="lazy"></figure>
<h1 id="p-stylecolorred6-进程状态切换的实现p"><p style="color:red">6. 进程状态切换的实现</p></h1>
<p>我们用下图来说明两个进程之间的切换过程。</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E5%88%87%E6%8D%A2.png" alt="图片" loading="lazy"></figure>
<p>如上图所示，有两个并发执行的进程，P0 和 P1.首先是 P0 执行，当出现一个中断或系统调用，硬件开始执行相应的处理程序，假设该处理程序调用了 scheduler（调度程序），该调度程序决定让进程 P1 执行，于是需要切换进程的上下文。具体地，(1)先将进程 P0 的进程上下文（PC，SP 和其他寄存器信息）保存到 PCB0，(2)如果是时钟中断，将PCB0 加入就绪队列中等待下一次被 scheduler 调度；如果是一次 I/O 系统调用，则将 PCB0 放入相应的等待队列中， (3)把进程 P1 的 PCB1 从就绪队列中移除，放进执行队列中，(4)将进程上下文从 PCB1 中恢复到寄存器中，此时 PC 指向了进程 P1 要执行的指令，SP 指向了进程 P1 的执行栈，于是 P1 开始执行。当再次出现时钟中断或者系统调用，再用同样的方式保存 P1 的状态到 PCB1 中。不再赘述。</p>
<h1 id="p-stylecolorred7-windows-的进程管理p"><p style="color:red">7. Windows 的进程管理</p></h1>
<p>进程管理之一就是增加一个系统调用，用于创建一个进程。这个理论上很简单但实际实现却比较复杂。在Windows 中，有一个程序，称为CreateProcess，它的简化形式如下</p>
<pre><code>Boolean CreateProcess(char *prog, char *args);
</code></pre>
<p>我们称创建进程的进程为<strong>父亲</strong>，而被创建的进程被称为<strong>孩子</strong>。</p>
<p>CreateProcess 需要执行哪些步骤呢？我们之前已有介绍，内核需要</p>
<ul>
<li>创建并初始化内核中的 PCB</li>
<li>创建和初始化一个新的地址空间</li>
<li>加载程序prog 进入地址空间</li>
<li>将参数 args 拷贝到地址空间的内存中</li>
<li>初始化硬件上下文来从第一条指令开始执行</li>
<li>通知调度程序有新的进程准备运行了<br>
不幸的是，实际的实现要复杂的多，CreateProcess 有十个参数需要设置，如下图所示。<br>
<img src="https://epitomm.github.io/post-images/CreateProcess.png" alt="**Figure 3.3**: 一个如何用 Windows 的系统调用 CreateProcess 的例子. 前两个参数指定程序和它的参数；剩下的关心进程的运行环境." loading="lazy"><br>
Figure 3.3: 一个如何用 Windows 的系统调用 CreateProcess 的例子. 前两个参数指定程序和它的参数；剩下的关心进程的运行环境.</li>
</ul>
<h1 id="p-stylecolorred-8-unix-的进程管理p"><p style="color:red"> 8. UNIX 的进程管理</p></h1>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>创建和管理进程的 API</strong></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">fork()</td>
<td style="text-align:left">创建一个子进程作为当前进程的一个克隆。fork 调用有两个  返回，一个是返回到父进程，另一个返回到子进程.</td>
</tr>
<tr>
<td style="text-align:left">exec(prog, args)</td>
<td style="text-align:left">在当前进程中运行应用程序 prog.</td>
</tr>
<tr>
<td style="text-align:left">exit()</td>
<td style="text-align:left">告诉内核当前的进程完成了，它的数据结构需要被垃圾回收.</td>
</tr>
<tr>
<td style="text-align:left">wait(processID)</td>
<td style="text-align:left">暂停一直到该子进程结束.</td>
</tr>
<tr>
<td style="text-align:left">signal(processID, type)</td>
<td style="text-align:left">发送一个特定类型的中断给其他一个进程.</td>
</tr>
</tbody>
</table>
<p><strong>Figure 3.7</strong>: UNIX 中管理和创建进程的 API.</p>
<p>UNIX 用一种不同的方法来创建进程，这种实现是在理论上复杂，但实现上却比较简单。UNIX 把 CreateProcess 分割成两个阶段，分别称为 fork 和 exec，如下图所示</p>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/fork-exec.jpg" alt="图片" loading="lazy"></figure>
<p><strong>Figure 3.4</strong>: UNIX 的系统调用 fork 和 exec 的操作. UNIX 的 fork 对父进程做了一个拷贝; UNIX 的 exec 将子进程改变成新运行的程序.</p>
<p><strong>UNIX 的 fork</strong>创建一个和父进程完全一致的拷贝，只有一项例外（我们需要某种方法来区分父进程和孩子）。一旦上下文设置好，子进程就调用 UNIX 的 exec 程序。exec 加载新的可执行镜像进入内存并开始执行。看上去先拷贝父进程，然后又用一个新的可执行镜像覆盖看上去有些没必要。实际上 fork 和 exec 来创建新进程的实现确是非常快速的，其中所使用的技术我们会在后面介绍。</p>
<p>在这个设计中, UNIX 的 fork 不接受参数，并返回一个整数。UNIX 的 exec 接受两个参数(要运行的程序的名字和传递给该程序的参数的数组). 这里是 CreateProcess 需要 10 个参数. 部分是因为 UNIX 的 fork 和 exec 的简洁性， 这个接口从 70 年代初期被设计出来到现在几乎没有改变.</p>
<p><strong>UNIX 的 fork</strong>程序包含以下步骤：</p>
<ul>
<li>创建和初始化内核中的 PCB</li>
<li>创建一个新的地址空间</li>
<li>初始化地址空间，将父进程的地址空间完全拷贝过来</li>
<li>继承父进程的执行上下文</li>
<li>通知调度程序有新的进程可以运行</li>
</ul>
<p>比较诡异的一点就是 fork 这个系统调用返回会返回两次：一个是返回给父亲进程，一个是返回给子进程。对于父进程，UNIX 返回子进程的 ID，对于子进程，返回 0 来表示成功。显然，当你克隆了你自己，你需要有某种方式来分辨谁是克隆者，谁是你本身。UNIX 就通过 fork 这个系统调用的返回值来区分这两个进程。Fork 的 sample code 如下图所示</p>
<pre><code>int child_pid = fork();
if (child_pid == 0) { //我是子进程.
  printf(&quot;I am process #   d\n&quot;, getpid()); return 0;
} else { //我是父进程.
  printf(&quot;I am the parent of process #   d\n&quot;, child_pid); return 0;
}
</code></pre>
<p>可能的输出有两种：<br>
<strong>I am the parent of process 495 I am process 495</strong></p>
<p>另一种概率小但仍可能的输出是:</p>
<p><strong>I am process 456</strong></p>
<p><strong>I am the parent of process 456</strong></p>
<p><strong>Figure 3.5</strong>: fork 一个进程的 UNIX 代码, 和运行这个代码的可能的输出。。getpid 是一个系统调用，用来获取当前进程的 ID.</p>
<p>如果我们运行图 3.5 的程序会发生什么？UNIX fork 返回两次，一次是从子进程返回，结果是 0，一次从父进程返回， 结果是子进程的 ID。然而，我们不知道是父进程还是子进程先运行。父进程已经在运行了，看上去它更可能先打印输出。然而，一个时钟中断(timer interrupt)可能在父进程fork 了进程后出现，因此会出现进程切换。或者，我们在多核系统上运行，父进程和子进程是同时运行。无论哪种情况子进程都可能在父进程之前输出。</p>
<p><strong>UNIX 的exec 和wait</strong></p>
<p>UNIX 的系统调用 exec 完成需要运行一个新成效的步骤。一旦子进程从 UNIX fork 返回并设置了新进程的执行环节后，子进程调用 UNIX exec. 在我们下一节讨论UNIX 管道的时候，我们会描述更多这个如何工作的.</p>
<p>Exec 包含如下步骤：</p>
<ul>
<li>加载程序prog 到当前的地址空间</li>
<li>拷贝参数 args 到地址空间中</li>
<li>初始化硬件上下文来从开头开始执行  到此为止，exec 就创建了一个新的进程</li>
</ul>
<p>另一方面，父进程常常需要暂停直到子进程完成运行为止，例如下一步骤是依赖于上一步骤的输出。所以 UNIX 还有一个系统调用，很自然地被叫做wait，它会暂停父进程知道子进程完成或者崩掉或者终止。由于父进程可能创建了许多的子进程，wait 需要设定子进程的 ID 作为参数，来确定要等待的子进程。然而，这个对wait 的调用在 UNIX 中是可选的。</p>
<h1 id="p-stylecolorred9-案例实现一个简单的-shellp"><p style="color:red">9. 案例：实现一个简单的 Shell</p></h1>
<p>图 3.7 列出的UNIX 系统调用已经足以构建一个灵活和强大的命令行 shell，该 shell 完全在用户级运行，不需要特殊权限.</p>
<pre><code>main() {
  char *prog = NULL; char **args = NULL;
  // 一次读取输入的一行，并解析每一行为程序名字和程序参数
  while (readAndParseCmdLine(&amp;prog, &amp;args)) {
    // 创建一个子进程来运行命令. int child_pid = fork();
    if (child_pid == 0) {
      //我是子进程，用父进程的输入来运行程序exec(prog, args);
      // 这里不会到达。。
      } else {
        // 我是父进程，等待子进程完成. wait(child_pid);
        return 0;
    }
  }
}
</code></pre>
<p><strong>Figure 3.8</strong>: 一个简单的 UNIX shell 的代码.<br>
图 3.8 展示了一个shell 的基本操作的代码。这个 shell 从输入读取一个命令行, 然后它 fork 一个进程来执行指令.父进程(shell)在读取下一个要执行的命令行之前必须等待子进程完成。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— MySQL 数据库]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-mysql-shu-ju-ku/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-mysql-shu-ju-ku/">
        </link>
        <updated>2020-03-27T07:15:29.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1存储引擎">1.存储引擎</h1>
<ul>
<li>MySQL 默认的存储引擎是 InnoDB</li>
</ul>
<h2 id="myisam-和-innodb-的区别">MyISAM 和 InnoDB 的区别</h2>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">MyISAM</th>
<th style="text-align:left">InnoDB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>是否支持行级锁</strong></td>
<td style="text-align:left">只有<strong>表级锁</strong></td>
<td style="text-align:left">支持<strong>行级锁和表级锁</strong>，默认为行级锁</td>
</tr>
<tr>
<td style="text-align:left">查询性能</td>
<td style="text-align:left">强调的是性能，每次查询具有原子性，执行速度快</td>
<td style="text-align:left">使用了聚簇索引、或需要访问的数据可以放入内存的应用下速度快</td>
</tr>
<tr>
<td style="text-align:left"><strong>是否支持事务</strong></td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持</td>
</tr>
<tr>
<td style="text-align:left"><strong>是否支持崩溃后的安全恢复</strong></td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持。事务、回滚、崩溃修复能力和事务安全型表</td>
</tr>
<tr>
<td style="text-align:left">是否支持外键</td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持</td>
</tr>
<tr>
<td style="text-align:left">是否支持 MVCC</td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持。应对高并发事务，MVCC比单纯的加锁更高效。MVCC只在READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作；MVCC 可以使用乐观锁和悲观锁来实现。</td>
</tr>
<tr>
<td style="text-align:left">其他功能</td>
<td style="text-align:left">全文索引、压缩、空间函数</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<h1 id="2索引">2.索引</h1>
<h2 id="1-聚簇索引与非聚簇索引">(1) 聚簇索引与非聚簇索引</h2>
<ul>
<li>MyISAM：B+ 树叶子节点的 data 域存放的是<strong>数据记录的地址</strong>。在索引检索的时候，首先按照 B+ 树搜索算法搜索索引，如果指定的 key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为 “<strong>非聚簇索引</strong>”。</li>
<li>InnoDB：其数据本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按照 B+ 树组织的一个索引结构。B+ 树叶子节点的 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 <strong>InnoDB 表数据文件本身就是主索引</strong>。这被称为“<strong>聚簇索引</strong>”（或“聚集索引”）。而其余的索引都作为辅助索引，<strong>辅助索引的 data 域存储相应记录主键的值</strong>而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。</li>
</ul>
<h2 id="2-hash-索引与-b-数索引">(2) Hash 索引与 B+ 数索引</h2>
<h3 id="hash-索引">Hash 索引</h3>
<ul>
<li>Hash 索引仅仅能满足 &quot;=&quot;、“IN” 的等值查询，不能使用范围查询。</li>
<li>Hash 索引不能利用组合索引的部分索引键查询。</li>
<li>Hash 索引遇到大量 Hash 值相等的情况后性能不一定就会比 B+ 树高。</li>
</ul>
<h3 id="b-树索引">B+ 树索引</h3>
<p>B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，<strong>在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题</strong>。</p>
<h1 id="3什么是事务">3.什么是事务？</h1>
<p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>
<h1 id="4事务的四大特征">4.事务的四大特征</h1>
<ul>
<li>原子性（Atomicity）：事务被视为不可分割的最小单元。事务的所有操作要么全部成功提交，要么全部失败回滚。</li>
<li>一致性（Consistency）：数据库在事务执行前后保持一致性状态，多个事务对同一个数据读取的结果是相同的。</li>
<li>隔离性（Isolation）：一个事务所做的修改在最终提交以前，对其他事务是不可见的。</li>
<li>持久性（Durability）：一旦事务提交，则其所做的修改将永远保存在数据库中。即使系统发生崩溃，事务执行的结果页不能丢失。</li>
</ul>
<hr>
<ul>
<li>只有满足一致性，事务的执行结果才是正确的。</li>
<li>在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要满足原子性，就一定能满足一致性。</li>
<li>在并发的情况下，多个失误并行执行，事务不仅要满足原子性，还要满足隔离性，才能满足一致性。</li>
<li>事务满足持久化是为了能应对数据库崩溃的情况。</li>
</ul>
<p><strong>AUTOCOMMIT</strong></p>
<p>MySQL 默认采用自动提交模式。也就是说，如果不显式使用 START TRASACTION 语句来开启一个事务，那么每个查询都会被当作一个事务自动提交。</p>
<h1 id="5并发事务带来哪些问题">5.并发事务带来哪些问题？</h1>
<h2 id="1-丢失修改">(1) 丢失修改</h2>
<p>T1 和 T2 两个事务都对一个数据进行修改， T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E4%B8%A2%E5%A4%B1%E4%BF%AE%E6%94%B9.png" alt="图片" loading="lazy"></figure>
<h2 id="2-读脏数据">(2) 读脏数据</h2>
<p>T1 修改一个数据，T2 随后读取这个数据，如果 T1 撤销了这次修改，那么 T2 读取到的数据是脏数据。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E8%84%8F%E8%AF%BB.png" alt="图片" loading="lazy"></figure>
<h2 id="3-不可重复读">(3) 不可重复读</h2>
<p>T2 读取一个数据，T1 对这个数据进行了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png" alt="图片" loading="lazy"></figure>
<h2 id="4-幻影读">(4) 幻影读</h2>
<p>T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围内的数据，此时读取的结果和第一次读取的结果不同。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E5%B9%BB%E8%AF%BB.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>不可重复读和幻读的区别：<br>
不可重复读的重点是修改，比如多次读取一条记录发现其中的某些列的值被修改；幻读的重点在于新增或者删除，比如多次读取同一范围发现记录增多或减少了。</p>
</blockquote>
<hr>
<p>产生并发不一致问题主要原因是破坏了事务的隔离性，解决方法时通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。</p>
<h1 id="6事务的隔离级别有哪些">6.事务的隔离级别有哪些？</h1>
<h2 id="1-读未提交read-uncommitted">(1) 读未提交（READ UNCOMMITTED）</h2>
<p>事务中的修改，即使没有提交，对其他事务也是可见的。</p>
<h2 id="2-读已提交read-committed">(2) 读已提交（READ COMMITTED）</h2>
<p>一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。</p>
<h2 id="3-可重复读repeatable-read">(3) 可重复读（REPEATABLE READ）</h2>
<p>一个事务在第一次读取过某条记录后，即使其他事务修改了该记录的值并且提交，该<strong>事物之后再读该条记录时，读到的仍是第一次读到的值</strong>。而不是每次都读到不同的数据，这就是可重复读。</p>
<h2 id="4-可串行化serializable">(4) 可串行化（SERIALIZABLE）</h2>
<p>强制事务串行执行。</p>
<p>需要加锁实现，而其它隔离级别通常不需要。</p>
<table>
<thead>
<tr>
<th style="text-align:left">隔离级别</th>
<th style="text-align:left">脏读</th>
<th style="text-align:left">不可重复读</th>
<th style="text-align:left">幻影读</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读未提交</td>
<td style="text-align:left">√</td>
<td style="text-align:left">√</td>
<td style="text-align:left">√</td>
</tr>
<tr>
<td style="text-align:left">读已提交</td>
<td style="text-align:left">×</td>
<td style="text-align:left">√</td>
<td style="text-align:left">√</td>
</tr>
<tr>
<td style="text-align:left">可重复读</td>
<td style="text-align:left">×</td>
<td style="text-align:left">×</td>
<td style="text-align:left">√</td>
</tr>
<tr>
<td style="text-align:left">可串行化</td>
<td style="text-align:left">×</td>
<td style="text-align:left">×</td>
<td style="text-align:left">×</td>
</tr>
</tbody>
</table>
<p>MySQL InnoDB 存储引擎默认的隔离级别是<strong>可重复读</strong>。InnoDB 存储引擎在可重读事务隔离级别下使用的是 Next-Key Lock 算法，因此可以避免幻读的产生。</p>
<h1 id="7-锁机制与-innodb-锁算法">7. 锁机制与 InnoDB 锁算法</h1>
<p>MyISAM 和 InnoDB 存储引擎使用的锁</p>
<ul>
<li>MyISAM 使用表级锁</li>
<li>InnoDB 支持行级锁和表级锁，默认使用表级锁</li>
</ul>
<p>行级锁和表级锁的对比：</p>
<ul>
<li>表级锁：MySQL 中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源耗费也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发率最低，MyISAM 和 InnoDB 引擎都支持表级锁。</li>
<li>行级锁：MySQL 中锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</li>
</ul>
<p>InnoDB 存储引擎的锁的算法有三种：</p>
<ul>
<li>Record Lock：单个行记录上的锁</li>
<li>Gap Lock：间隙锁，锁定一个范围，不包括记录本身。GAP锁的⽬的，是为了防⽌同⼀事务的两次当前读，出现幻读的情况。</li>
<li>Next-key Lock：Record + Gap 锁定一个范围，包含记录本身。对于⾏的查询，都是采⽤该⽅ 法，主要⽬的是解决幻读的问题。</li>
</ul>
<p>相关知识点：</p>
<p>1.innodb对于行的查询使用next-key lock</p>
<p>2.Next-locking keying为了解决Phantom Problem幻读问题</p>
<p>3.当查询的索引含有唯一属性时，将next-key lock降级为record key</p>
<p>4.Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生5.有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock）A.将事务隔离级别设置为RCB.将参数innodb_locks_unsafe_for_binlog设置为1</p>
<h1 id="8介绍一下两段锁协议">8.介绍一下两段锁协议</h1>
<ul>
<li>阶段一：<strong>加锁阶段</strong>。在这阶段，事务可以申请获得任何数据项上的任何类型的锁，但是不能释放任何锁。</li>
<li>阶段二：<strong>解锁阶段</strong>。在这阶段，事务可以释放任何数据项上的任何类型的琐，但是不能再申请任何锁。</li>
</ul>
<blockquote>
<p>注意：两段锁协议可能会导致死锁。<br>
<img src="https://epitomm.github.io/post-images/%E4%B8%A4%E6%AE%B5%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84%E6%AD%BB%E9%94%81.png" alt="图片" loading="lazy"></p>
</blockquote>
<h1 id="9介绍一下多版本并发控制mvcc">9.介绍一下多版本并发控制（MVCC）</h1>
<p>多版本并发控制（MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现读已提交和可重复读这两种隔离级别。而读未提交总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。</p>
<p>对于使用 InnoDB 存储引擎的表来说，它的聚簇索引记录中都包三个隐藏列：</p>
<table>
<thead>
<tr>
<th style="text-align:center"><strong>列名</strong></th>
<th style="text-align:center"><strong>是否必须</strong></th>
<th style="text-align:center"><strong>占用空间</strong></th>
<th style="text-align:center"><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">row_id</td>
<td style="text-align:center">否</td>
<td style="text-align:center">6字节</td>
<td style="text-align:center">行ID，唯一标识一条记录</td>
</tr>
<tr>
<td style="text-align:center">transaction_id</td>
<td style="text-align:center">是</td>
<td style="text-align:center">6字节</td>
<td style="text-align:center">事务ID</td>
</tr>
<tr>
<td style="text-align:center">roll_pointer</td>
<td style="text-align:center">是</td>
<td style="text-align:center">7字节</td>
<td style="text-align:center">回滚指针</td>
</tr>
</tbody>
</table>
<ul>
<li>trx_id：每次对某条记录进行改动时，都会把对应的 <strong>事务 id</strong> 赋值给 trx_id 列。</li>
<li>roll_pointer：每次对某条记录进行改动时，这个隐藏列都会存一个指针，可以通过这个指针找到该记录修改前的信息（<strong>回滚指针</strong>）。</li>
</ul>
<h2 id="readview">ReadView</h2>
<p>对于使用READ UNCOMMITTED隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用 SERIALIZABLE隔离级别的事务来说，使用加锁的方式来访问记录。对于使用READ COMMITTED 和 REPEATABLE READ 隔离级别的事务来说，就需要用到我们上边所说的版本链了，核心问题就是：<strong>需要判断一下版本链中的哪个版本是当前事务可见的</strong>。</p>
<p>ReadView 中主要包含4个比较重要的内容：</p>
<ol>
<li>m_ids：表示在生成 ReadView 时当前系统中<strong>活跃的（未提交的）读写事务的事务id列表</strong>。</li>
<li>min_trx_id：表示在生成 ReadView 时当前系统中<strong>活跃的读写事务中最小的事务id</strong>，也就是m_ids 中的最小值。</li>
<li>max_trx_id：表示生成 ReadView 时系统中应该<strong>分配给下一个事务的 id值</strong>。</li>
<li>creator_trx_id：表示<strong>生成该 ReadView 的事务的事务id</strong>。</li>
</ol>
<blockquote>
<p>注意max_trx_id并不是m_ids中的最大值，事务id是递增分配的。比方说现在有id为1，2，3这三个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，m_ids就包括1和2，min_trx_id的值就是1，max_trx_id的值就是4。</p>
</blockquote>
<h2 id="read-commited-实现方式">READ COMMITED 实现方式</h2>
<p><strong>每次读取数据前都生成一个ReadView</strong></p>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E8%AF%BB%E5%B7%B2%E6%8F%90%E4%BA%A4MVCC.png" alt="图片" loading="lazy"></figure>
<h2 id="repeatable-read-实现方式">REPEATABLE READ 实现方式</h2>
<p><strong>在第一次读取数据时生成一个ReadView，第二次读取数据时使用第一次生成的 ReadView。</strong></p>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BBMVCC.png" alt="图片" loading="lazy"></figure>
<h2 id="mvcc总结">MVCC总结</h2>
<p>MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 READ COMMITTD、 REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程。可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ 这两个隔离级别的一个很大不同就是：<strong>生成ReadView 的时机不同</strong>，READ COMMITTD 在每一次进行普通 SELECT 操作前都会</p>
<p>生成一个 ReadView，而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。</p>
<h1 id="10next-key-locks">10.Next-Key Locks</h1>
<p>Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。</p>
<p>MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。</p>
<h2 id="record-locks">Record Locks</h2>
<p>锁定一个记录上的索引，而不是记录本身。</p>
<p>如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。</p>
<h2 id="gap-locks">Gap Locks</h2>
<p>锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。</p>
<pre><code>SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
</code></pre>
<h2 id="next-key-locks">Next-Key Locks</h2>
<p>它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间，例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：</p>
<pre><code>(-∞, 10]
(10, 11]
(11, 13]
(13, 20]
(20, +∞)
</code></pre>
<h1 id="11大表优化">11.大表优化</h1>
<p>当 MySQL 单表记录数过大时，数据库的 CRUD 性能会明显下降，一些常见的优化措施如下：</p>
<h2 id="限定数据的范围">限定数据的范围</h2>
<p>务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询历史订单的时候，我们可以控制在一个月的范围内；</p>
<h2 id="读写分离">读/写分离</h2>
<p>经典的数据库拆分方案，主库负责写，从库负责读；</p>
<h2 id="垂直分区">垂直分区</h2>
<p>根据数据库里面数据表的相关性进行拆分。例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。</p>
<p>简单来说垂直拆分是指数据表<strong>列的拆分</strong>，把一张列比较多的表拆分为多张表。如下图所示，这样来说大家应该就更容易理解了。</p>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E5%9E%82%E7%9B%B4%E5%88%86%E5%8C%BA.png" alt="图片" loading="lazy"></figure>
<ul>
<li>垂直拆分的优点：可以使得列数据变小，在查询时减少读取的 Block 数，减少 I/O 次数。此外，垂直分区可以简化表的结构，易于维护。</li>
<li>垂直拆分的缺点：主键会出现冗余，需要管理冗余列，并会引起 join 操作，可以通过在应用层进行 join 来解决。此外，垂直分区会让食物变得更加复杂。</li>
</ul>
<h2 id="水平分区">水平分区</h2>
<p>保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。水平拆分可以支撑非常大的数据量。</p>
<p>水平拆分是指数据表<strong>行的拆分</strong>，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E6%B0%B4%E5%B9%B3%E5%88%86%E5%8C%BA.png" alt="图片" loading="lazy"></figure>
<p>水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库。</p>
<p>水平拆分能够支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。</p>
<p>下面补充一下数据库分片的两种常见方案：</p>
<ul>
<li>客户端代理：分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。当当网的Sharding-JDBC、阿里的TDDL是两种比较常用的实现。</li>
<li>中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。我们现在谈的Mycat、360的Atlas、网易的DDB等等都是这种架构的实现。</li>
</ul>
<p>详细内容可以参考：MySQL大表优化方案：<a href="https://segmentfault.com/a/1190000006158186">https://segmentfault.com/a/1190000006158186</a></p>
<h1 id="12分库分表之后id-主键如何处理">12.分库分表之后，id 主键如何处理？</h1>
<p>因为要分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要一个全剧唯一的 id 来支持。</p>
<p>生成全局 id 有一下这几种方式：</p>
<ul>
<li><strong>UUID</strong>：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标识，比如文件的名字。</li>
<li><strong>数据库自增 id</strong>：两台数据库分别设置不同步长，生成不重复 ID 的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。</li>
<li><strong>利用 redis 生成 id</strong>：性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。</li>
<li>......</li>
</ul>
<h1 id="13查询语句不同元素where-join-limit-group-by-having等的先后执行顺序">13.查询语句不同元素（where、join、limit、group by、having等）的先后执行顺序？</h1>
<p>查询中使用到的关键字主要包含六个，并且它们的书写顺序依次为：</p>
<p>select —— from —— where —— group by —— having  —— order by</p>
<p>其中 select 和 from 是必须的，其他关键词是可选的，这六个关键词的执行顺序与 sql 语句的书写顺序并不是一样的，而是按照下面的顺序来执行。</p>
<ul>
<li>from：需要从哪个数据库表检索数据</li>
<li>where：过滤表中的数据条件</li>
<li>group by：如何将上面过滤出的数据进行分组</li>
<li>having：对上面已经分组的数据进行过滤的条件</li>
<li>select：查看结果集中的哪个列，或者列的计算结果</li>
<li>order by：按照什么顺序来查看返回的数据</li>
</ul>
<p>from 后面的表关联，是自右向左解析，而 where 条件的解析顺序是自下向上的。</p>
<p>也就是说，在写 SQL 的时候，尽量把数据量小的表放在最右边来进行关联（用小表去匹配大表），而把筛选出销量数据的条件尽量放在 where 语句的最左边（用小表去匹配大表）。</p>
<h1 id="14关系型数据库与非关系型数据库">14.关系型数据库与非关系型数据库</h1>
<p>(1) 关系型数据库</p>
<ul>
<li>使用 SQL 语句方便的在一个表以及多个表之间做非常<strong>复杂的数据查询</strong>。</li>
<li>支持事务，对于<strong>安全性能很高</strong>的数据访问要求得以实现。</li>
</ul>
<p>(2) 非关系型数据库</p>
<ul>
<li>NoSQL 基于键值对，不需要经过 SQL 层的解析，<strong>性能高</strong>。</li>
<li>给予减会对，数据之间没有耦合性，<strong>容易水平扩展</strong>。</li>
</ul>
<h1 id="15b-树的数据结构">15.B+ 树的数据结构？</h1>
<p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。</p>
<p>B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。</p>
<p>在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。</p>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/B+%E6%A0%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<h1 id="16为什么使用-b-树索引而不用红黑树">16.为什么使用 B+ 树索引，而不用红黑树？</h1>
<p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：</p>
<p>（一）更少的查找次数</p>
<p>平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。</p>
<p>红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。</p>
<p>（二）利用磁盘预读特性</p>
<p>为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。</p>
<p>操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。</p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s/IZpRNTKs3EHiXO-vYphk1w">为什么MySQL的索引要使用B+树而不是其它树形结构?比如B树？</a><br>
因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变（有些资料也称为扇出）<br>
指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；</p>
</blockquote>
<h1 id="17mysql-读写分离-主从复制">17.MySQL 读写分离、主从复制</h1>
<h2 id="读写分离-2">读写分离</h2>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB.png" alt="图片" loading="lazy"></figure>
<p>MySQL 读写分离基本原理是让 <strong>master 数据库处理写操作，slave 数据库处理读操作</strong>。master 将写操作的变更同步到各个 slave 节点。</p>
<h2 id="主从复制原理">主从复制原理</h2>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt="图片" loading="lazy"></figure>
<ul>
<li>master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；</li>
<li>slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件</li>
<li>同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。</li>
</ul>
<p>参考链接：</p>
<p><a href="https://cyc2018.github.io/CS-Notes/#/notes/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86">https://cyc2018.github.io/CS-Notes/#/notes/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86</a></p>
<p><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/MySQL.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/MySQL.md</a></p>
<blockquote>
<p>MyBatis如何防止SQL注入的？<br>
mybatis的#{}和<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;#&#039; at position 21: …以及order by注入问题
#̲{}：相当于JDBC中的Pre…'>{}的区别以及order by注入问题
#{}：相当于JDBC中的PreparedStatement
</span>{}：是输出变量的值<br>
简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— JVM]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-jvm/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-jvm/">
        </link>
        <updated>2020-03-25T11:36:10.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-比较-jvm-jre-jdk">1. 比较 JVM 、JRE、JDK</h1>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/jre-jvm-jdk.png" alt="图片" loading="lazy"></figure>
<ul>
<li>JVM：Java Virtual Machine：Java 虚拟机</li>
<li>JRE：Java Runtime Environment：Java 运行环境（JVM + 基础类库）</li>
<li>JDK：JVM + 基础类库 + 编译工具（java、javac、javap）</li>
</ul>
<h1 id="2-介绍下-java-内存区域-结构运行时数据区">2. 介绍下 Java 内存区域 / 结构（运行时数据区）</h1>
<h2 id="线程私有的">线程私有的：</h2>
<h3 id="程序计数器">程序计数器</h3>
<ul>
<li>作用：记录正在执行的虚拟机<strong>字节码指令的地址</strong>（如果正在执行的是本地方法则为空）</li>
<li>唯一一个<strong>不会 OutOfMemory</strong> 的内存区域</li>
</ul>
<h3 id="虚拟机栈线程栈">虚拟机栈（线程栈）</h3>
<ul>
<li>组成：<strong>栈帧</strong>（每个方法有一个栈帧）
<ul>
<li>局部变量表</li>
<li>操作数栈</li>
<li>动态链接</li>
<li>出口信息</li>
</ul>
</li>
</ul>
<blockquote>
<p>ps：几个小问题</p>
</blockquote>
<ul>
<li><strong>垃圾回收是否涉及栈内存？</strong>
<ul>
<li>栈内存放的是栈帧，每一次方法调用结束后（或抛出异常后）栈帧都会自动弹出栈，所以不需要垃圾回收来管理栈内存。</li>
</ul>
</li>
<li><strong>栈内存分配越大越好吗</strong>？
<ul>
<li>不，物理内存的大小是一定的，每个线程都有一个栈，如果栈内存过大，会让线程数变少。</li>
</ul>
</li>
<li><strong>方法内的局部变量是否线程安全</strong>？
<ul>
<li>如果方法内局部变量没有逃逸出方法，线程安全</li>
<li>如果方法内局部变量逃逸出方法的作用范围，
<ul>
<li>基本数据类型存在<strong>栈帧</strong>内，其他线程无法访问，线程安全。</li>
<li>引用数据类型存在于<strong>堆</strong>内，如果逃逸出方法（方法参数、返回值），其他线程拿到对象的引用，就可以通过引用找到堆内存中的对象进行修改，线程不安全。</li>
</ul>
</li>
</ul>
</li>
<li><strong>栈内存溢出：</strong>
<ul>
<li>栈帧过多：递归调用中没有设置正确的结束条件。</li>
<li>栈帧过大</li>
</ul>
</li>
</ul>
<h3 id="本地方法栈">本地方法栈</h3>
<ul>
<li>JVM 在调用本地方法（native 修饰的方法）时，需要为本地方法提供的内存空间。</li>
</ul>
<h2 id="线程共有的">线程共有的</h2>
<h3 id="堆">堆</h3>
<ul>
<li>通过 <strong>new</strong> 关键字创建出来的对象存放在堆内存中。</li>
<li>有<strong>垃圾回收</strong>机制。</li>
</ul>
<h3 id="方法区方法区内有常量池">方法区（方法区内有常量池）</h3>
<p>存储类结构相关的信息：成员变量、成员方法和构造器方法的代码部分、包括一些特殊方法。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E6%96%B9%E6%B3%95%E5%8C%BA1.6.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>HotSpot 1.6 虚拟机内存结构：<br>
方法区是一个概念，用一个<strong>永久代</strong>作为方法区的实现。永久代包括：Class 类信息、类加载器、运行时常量池。StringTable 存在于运行时常量池中。<br>
方法区与永久代：方法区是一种<strong>概念</strong>，永久代是 HotSpot 虚拟机对虚拟机规范中方法区的一种<strong>实现</strong>。</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E6%96%B9%E6%B3%95%E5%8C%BA.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>HotSpot 1.8 虚拟机内存结构：<br>
方法区还是一个概念上的东西，方法区的实现使用<strong>元空间</strong>。元空间内包含了：Class 类信息、类加载器、常量池，不过他已经不再占用堆内存了（不是由 JVM 管理它的内存结构），移出到本地内存（<strong>操作系统内存</strong>）中。本地内存中还会放一些其他进程，有一块是元空间。StringTable 串被移动到了堆中。</p>
</blockquote>
<h1 id="3-介绍下-java-内存模型">3. 介绍下 Java 内存模型</h1>
<ul>
<li>JMM：Java Memory Mmodel</li>
<li>Java 内存模型定义了一套在<strong>多线程</strong>读写共享数据时，对数据的可见性、有序性和原子性的保障。</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/jmm.png" alt="图片" loading="lazy"></figure>
<h1 id="4-如何判断对象是否死亡">4. 如何判断对象是否死亡？</h1>
<h2 id="引用计数法">引用计数法</h2>
<p>为每个对象添加一个<strong>引用计数器</strong>，每当有一个引用指向这个对象，就把引用计数器的值 +1，当引用失效，计数器值 -1，直到引用计数器的值为 0，表示不再有引用指向这个对象，就可判定这个对象已死亡。</p>
<p>因为无法解决对象间<strong>循环引用</strong>的问题，所以主流的 Java 虚拟机中没有采用这种方法来管理内存。</p>
<h2 id="可达性分析法">可达性分析法</h2>
<p>以 GC Root 为起点向下搜索，搜索过的路径称为引用链，当一个对象到 GC Root 没有任何引用链相连时，则证明这个对象是不可用的。</p>
<h3 id="哪些对象可以作为-gc-root">哪些对象可以作为 GC Root？</h3>
<ul>
<li>虚拟机栈中局部变量引用的对象</li>
<li>本地方法栈中 JNI 中引用的对象</li>
<li>方法区静态属性引用的对象</li>
<li>方法区中的常量引用的对象</li>
</ul>
<h1 id="5-介绍一下-强引用-软引用-弱引用-虚引用">5. 介绍一下 强引用、软引用、弱引用、虚引用</h1>
<h2 id="强引用">强引用</h2>
<p>只要一个对象还有<strong>强引用</strong>指向它，它就不会被回收。</p>
<p>使用 **new **一个对象的方式来创建强引用。</p>
<pre><code>Object obj = new Object();
</code></pre>
<h2 id="软引用">软引用</h2>
<p>仅有软引用指向该对象时，在<strong>垃圾回收后，内存仍不足</strong>就会再次触发垃圾回收，回收<strong>软引用对象</strong>。可配合引用队列回收软引用本身。</p>
<p>使用<code>SoftReference</code> 类来创建软引用。</p>
<pre><code>Object obj = new Object();
SoftReference&lt;Ojbect&gt; sf = new SoftReference&lt;Object&gt;(obj);
obj = null; // 使对象只被软引用关联
</code></pre>
<h2 id="弱引用">弱引用</h2>
<p>当仅有弱引用指向该对象时，在<strong>垃圾回收</strong>时，无论内存是否充足，都会回收弱引用对象。可配合引用队列回收软引用本身。</p>
<p>使用 <code>WeakReference</code>类来创建弱引用。</p>
<pre><code>Object obj = new Object();
WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);
obj = null;
</code></pre>
<h2 id="虚引用">虚引用</h2>
<p>一个对象是否有虚引用的存在，不会对其生存时间造成影响，也<strong>无法通过虚引用得到一个对象</strong>。</p>
<p>为一个对象设置虚引用的唯一目的就是能<strong>在这个对象被回收时收到一个系统通知</strong>。</p>
<p>使用 <strong>PhantomReference</strong> 来创建虚引用。</p>
<pre><code>Object obj = new Object();
PhantomReference &lt;Object&gt; wf = new PhantomReference &lt;Object&gt;(obj, null);
obj = null;
</code></pre>
<h1 id="6-垃圾收集有哪些算法各自的特点">6. 垃圾收集有哪些算法？各自的特点？</h1>
<h2 id="标记清除算法">标记清除算法</h2>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4.png" alt="图片" loading="lazy"></figure>
<p>过程：</p>
<ul>
<li><strong>标记</strong>：从 GC Root 开始向下找，如果某个对象没有经过任意一条引用链，则把这个对象标记为垃圾对象</li>
<li><strong>清除</strong>：清除标记为垃圾的对象，并不是把内存中每个字节都清零，只是把这段内存的起始、结束地址放入一个空闲地址列表，下次分配内存时从空闲地址列表选择一块空闲内存进行分配。</li>
</ul>
<p>特点：</p>
<ul>
<li>速度快</li>
<li>易造成内碎片</li>
</ul>
<h2 id="标记整理算法">标记整理算法</h2>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E6%A0%87%E8%AE%B0%E6%95%B4%E7%90%86.png" alt="图片" loading="lazy"></figure>
<p>过程：</p>
<ul>
<li><strong>标记</strong>：由 GC Root 向下找，经过的路径称为引用链，如果某个对象没有经过任何一条引用链，将其标记为垃圾对象。</li>
<li><strong>整理</strong>：清理垃圾的过程中，将非垃圾对象依次向前移动，使内存更加紧凑。</li>
</ul>
<p>特点：</p>
<ul>
<li>涉及到大量对象的移动，<strong>速度慢</strong>。对象在整理的过程中，如果有其他引用指向这个对象，需要更改这些引用。</li>
<li>没有内碎片</li>
</ul>
<h2 id="复制算法">复制算法</h2>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E5%A4%8D%E5%88%B61.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E5%A4%8D%E5%88%B62.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E5%A4%8D%E5%88%B63.png" alt="图片" loading="lazy"></figure>
<p>过程：</p>
<ul>
<li>标记：将不经过引用链的对象标记垃圾对象。</li>
<li>复制：将非垃圾对象从 FROM 区域复制到 TO 区域，在复制的过程中完成了整理，FROM 区域存在的都是垃圾对象，全部清除，交换 FROM 区域和 TO 区域。</li>
</ul>
<p>特点：</p>
<ul>
<li>不会有内碎片</li>
<li>需要占用双倍空间</li>
</ul>
<h2 id="分代收集算法">分代收集算法</h2>
<p>将堆划分为新生代和老年代</p>
<ul>
<li>新生代使用：复制算法</li>
<li>老年代使用：标记-清除 算法 或 标记-整理 算法</li>
</ul>
<h1 id="7-hotspot-为什么要分为新生代和老年代">7. HotSpot 为什么要分为新生代和老年代？</h1>
<p>HotSpot 根据对象存活周期的不同将内存划分为新生代和老年代，<strong>新生代</strong>在垃圾回收后，只有少部分对象会被保留，所以采用<strong>复制算法</strong>；而<strong>老年代则</strong>有大部分对象被保留，使用<strong>标记-清除</strong> 或 <strong>标记-整理</strong> 算法。</p>
<h1 id="8-方法区的回收">8. 方法区的回收</h1>
<p>主要是对常量池的回收和类的回收。</p>
<p>类的回收需要满足三个条件：</p>
<ul>
<li>该类的所有实例已经被回收，此时堆中不存在该类的任何实例。</li>
<li>该类的类加载器已经被回收。</li>
<li>该类的类对象没有在任何地方被引用，且通过反射也无法获得该类方法。</li>
</ul>
<h1 id="9-hotspot-gc-的触发条件">9. HotSpot GC 的触发条件</h1>
<h2 id="minor-gc">Minor GC</h2>
<p>新生代中的 Eden 区域内存不足时触发 Minor GC。</p>
<blockquote>
<p>Minor GC 会回收新生代，因为新生代对象存活时间较短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快</p>
</blockquote>
<h2 id="full-gc">Full GC</h2>
<ul>
<li>调用 System.gc() 建议虚拟机执行 Full GC</li>
<li>老年代空间不足（大对象或长期存活的对象进入老年代导致老年代空间不足）时触发 Full GC</li>
<li>空间分配担保失败</li>
<li>JDK1.7 及以前的永久代空间不足</li>
<li>Concurrent Mode Failure<br>
执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。</li>
</ul>
<blockquote>
<p>Full GC 回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。</p>
</blockquote>
<h1 id="10-什么情况下新生代对象会晋升到老年代">10. 什么情况下新生代对象会晋升到老年代？</h1>
<ul>
<li>晋升年龄达到阈值的对象，会晋升到老年代。</li>
<li>大对象直接进入老年代：避免在 Eden 和 Survior 之间来回进行大量复制。</li>
<li>Minor GC 后，如果对象太大无法进入 Suirior 区，则直接进入老年代。</li>
<li>如果在 Survior 区中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄对象就可以直接进入老年代，无须等年龄达到晋升阈值。</li>
</ul>
<h1 id="11-常见的垃圾收集器有哪些">11. 常见的垃圾收集器有哪些？</h1>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="图片" loading="lazy"></figure>
<p>以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。</p>
<ul>
<li>单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程。</li>
<li>串行与并行：串行指的是垃圾收集器工作的时候必须停止用户线程；并行指的是垃圾收集器和用户线程同时工作。除了 CMS 和 G1之外，其他垃圾收集器都是以串行的方式执行的。</li>
</ul>
<h2 id="serial串行单线程收集器">Serial（串行单线程）收集器</h2>
<ul>
<li><strong>串行</strong>方式执行</li>
<li><strong>单线程</strong>收集器，只使用一个线程进行垃圾手机工作</li>
<li><strong>简单高效</strong>，单个 CPU 没有进程切换的开销。</li>
</ul>
<p>它是 Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大。它收集一两百兆垃圾的停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿时间是可以接受的。</p>
<h2 id="parnew串行多线程-收集器">ParNew（串行多线程） 收集器</h2>
<ul>
<li><strong>串行</strong></li>
<li><strong>多线程</strong>垃圾收集器</li>
</ul>
<p>它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。</p>
<h2 id="parallel-scavenge串行多线程吞吐量-收集器">Parallel Scavenge（串行多线程吞吐量） 收集器</h2>
<ul>
<li><strong>多线程</strong>垃圾收集器</li>
<li><strong>吞吐量优先</strong>。吞吐量：CPU 用于运行用户程序的时间与总时间的比值。</li>
</ul>
<p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。</p>
<p><strong>缩短停顿时间是以牺牲吞吐量和新生代空间来换取的</strong>：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。</p>
<p>可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。</p>
<h2 id="serial-old串行单线程老年代-收集器">Serial Old（串行单线程老年代） 收集器</h2>
<p>是 Serial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途：</p>
<ul>
<li>在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。</li>
<li>作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。</li>
</ul>
<h2 id="parallel-old多线程吞吐量老年代-收集器">Parallel Old（多线程吞吐量老年代） 收集器</h2>
<p>是 Parallel Scavenge 收集器的老年代版本。</p>
<p>在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。</p>
<h2 id="cms-收集器">CMS 收集器</h2>
<p>CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。</p>
<p>分为以下四个流程：</p>
<ul>
<li>初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。</li>
<li>并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。</li>
<li>重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。</li>
<li>并发清除：不需要停顿。</li>
</ul>
<p>在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。</p>
<p>具有以下缺点：</p>
<ul>
<li>吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。</li>
<li>无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。</li>
<li>标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。</li>
</ul>
<h2 id="g1-收集器">G1 收集器</h2>
<p>G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。 HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。</p>
<p>堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。</p>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/heap.png" alt="图片" loading="lazy"></figure>
<p>G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/G1.png" alt="图片" loading="lazy"></figure>
<p>通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。</p>
<p>每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用</p>
<p>Remembered Set，在做可达性分析的时候就可以避免全堆扫描</p>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/G1_2.png" alt="图片" loading="lazy"></figure>
<p>如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：</p>
<ul>
<li>初始标记</li>
<li>并发标记</li>
<li>最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。</li>
<li>筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</li>
</ul>
<p>具备如下特点：</p>
<ul>
<li>空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复 制”算法实现的，这意味着运行期间不会产生内存空间碎片。</li>
<li>可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒</li>
</ul>
<h1 id="12-类加载的过程">12. 类加载的过程</h1>
<p>包含了加载、验证、准备、解析和初始化这 5 个阶段。</p>
<p><strong>1. 加载</strong></p>
<p>加载是类加载的一个阶段，注意不要混淆。</p>
<p>加载过程完成以下三件事：</p>
<ul>
<li>通过类的完全限定名称获取定义该类的二进制字节流。</li>
<li>将该字节流表示的静态存储结构转换为方法区的运行时存储结构。</li>
<li>在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。</li>
</ul>
<p>其中二进制字节流可以从以下方式中获取：</p>
<ul>
<li>从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。</li>
<li>从网络中获取，最典型的应用是 Applet。</li>
<li>运行时计算生成，例如动态代理技术，在 java.lang.reflflect.Proxy 使用 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。</li>
<li>由其他文件生成，例如由 JSP 文件生成对应的 Class 类。</li>
</ul>
<p><strong>2. 验证</strong></p>
<p>确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p>
<p><strong>3. 准备</strong></p>
<p>类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。</p>
<p>实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中。应该注意到，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。</p>
<p>初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。</p>
<pre><code>public static int value = 123; 
</code></pre>
<p>如果类变量是常量，那么它将初始化为表达式所定义的值而不是 0。例如下面的常量 value 被初始化为 123 而不是 0。</p>
<pre><code>public static final int value = 123; 
</code></pre>
<p><strong>4. 解析</strong><br>
将常量池的符号引用替换为直接引用的过程。</p>
<p>其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。</p>
<p><strong>5. 初始化</strong></p>
<p>初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段是虚拟机执行类构造器 <clinit>() 方法的过程。在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。</p>
<p><clinit>() 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码：</p>
<pre><code>public class Test { 
    static { 
        i = 0; // 给变量赋值可以正常编译通过 
        System.out.print(i); // 这句编译器会提示“非法向前引用” 
    }
    static int i = 1; 
} 
</code></pre>
<p>由于父类的 <clinit>() 方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。例如以下代码：</p>
<pre><code>static class Parent { 
    public static int A = 1; 
    static { 
        A = 2; 
    } 
}
static class Sub extends Parent { 
    public static int B = A; 
}
public static void main(String[] args) { 
    System.out.println(Sub.B); // 2 
} 
</code></pre>
<p>接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 <clinit>() 方法。但接口与类不同的是，执行接口的 <clinit>() 方法不需要先执行父接口的 <clinit>() 方法。只有当父接口中定义的变量使<br>
用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 <clinit>() 方法。</p>
<p>虚拟机会保证一个类的 <clinit>() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 <clinit>() 方法，其它线程都会阻塞等待，直到活动线程执行 <clinit>() 方法完毕。如果在一 个类的 <clinit>() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。</p>
<h1 id="13-类初始化时机">13. 类初始化时机</h1>
<p><strong>1. 主动引用</strong></p>
<p>虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：</p>
<ul>
<li>遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 fifinal 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。</li>
<li>使用 java.lang.reflflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。</li>
<li>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；</li>
<li>当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；</li>
</ul>
<p><strong>2. 被动引用</strong></p>
<p>以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引 用。被动引用的常见例子包括：</p>
<ul>
<li>通过子类引用父类的静态字段，不会导致子类初始化。</li>
</ul>
<pre><code>System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 
</code></pre>
<p>通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。</p>
<pre><code>SuperClass[] sca = new SuperClass[10]; 
</code></pre>
<p>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</p>
<pre><code>System.out.println(ConstClass.HELLOWORLD);
</code></pre>
<h1 id="14-java-虚拟机中有哪些类加载器">14. Java 虚拟机中有哪些类加载器？</h1>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>名称</strong></th>
<th style="text-align:left"><strong>加载哪的类</strong></th>
<th style="text-align:center"><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Bootstrap ClassLoader（启动类加载器）</td>
<td style="text-align:left">JAVA_HOME/jre/lib</td>
<td style="text-align:center">无法直接访问</td>
</tr>
<tr>
<td style="text-align:left">Extension ClassLoader（扩展类加载器）</td>
<td style="text-align:left">JAVA_HOME/jre/lib/ext</td>
<td style="text-align:center">上级为 Bootstrap，显示为 null</td>
</tr>
<tr>
<td style="text-align:left">Application ClassLoader（应用程序类加载器）</td>
<td style="text-align:left">classpath</td>
<td style="text-align:center">上级为 Extension</td>
</tr>
<tr>
<td style="text-align:left">自定义类加载器</td>
<td style="text-align:left">自定义</td>
<td style="text-align:center">上级为 Application</td>
</tr>
</tbody>
</table>
<h1 id="15-什么是双亲委派模型">15. 什么是双亲委派模型？</h1>
<p>如果一个类加载器收到了类加载请求，它首先不会自己去尝试加载这个类，而是把类加载的请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都会传送到顶层的启动类加载器中，只有当父类无法处理这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。</p>
<h1 id="16-使用双亲委派模型有什么好处">16. 使用双亲委派模型有什么好处？</h1>
<p>双亲委派模型保证了 Java 程序的稳定运行，可以<strong>避免类的重复加载</strong>（JVM 区分类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也<strong>保证了 Java 的核心 API 不被篡改</strong>。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。</p>
<h1 id="17-内存分配策略">17. 内存分配策略</h1>
<h2 id="对象优先在-eden-分配">对象优先在 Eden 分配</h2>
<p>大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不足时，触发 Minor GC。</p>
<h2 id="大对象直接进入老年代">大对象直接进入老年代</h2>
<p>大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。<br>
经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。<br>
-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。</p>
<h2 id="长期存活的对象进入老年代">长期存活的对象进入老年代</h2>
<p>为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。<br>
-XX:MaxTenuringThreshold 用来定义年龄的阈值。</p>
<h2 id="动态对象年龄不判定">动态对象年龄不判定</h2>
<p>虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到MaxTenuringThreshold 中要求的年龄。</p>
<h2 id="空间分配担保">空间分配担保</h2>
<p>在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。<br>
如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。</p>
<h1 id="18-说一下-java-对象的创建过程">18. 说一下 Java 对象的创建过程</h1>
<p><img src="https://epitomm.github.io/post-images/java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B.png" alt="图片" loading="lazy"><br>
① <strong>类加载检查</strong>：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。<br>
② <strong>分配内存</strong>：在类加载检查通过后，接下来虚拟机将为新生代对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。</p>
<blockquote>
<p>内存分配的两种方式：选择哪种空间分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由 GC 收集器的算法是 “标记-清除”，还是“标记-整理”/ &quot;复制&quot;。<br>
<img src="https://epitomm.github.io/post-images/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.png" alt="图片" loading="lazy"><br>
内存分配并发问题：在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：</p>
<ul>
<li>CAS+失败重试：CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突重试就失败，直到成功为止。虚拟机采用 CAS 配上失败重试的方式来保证更新操作的原子性。</li>
<li>TLAB：为每个线程预先在 Eden 区分配一块内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配。</li>
</ul>
</blockquote>
<p>③ <strong>初始化零值</strong>：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。<br>
④ <strong>设置对象头</strong>：初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。<br>
⑤ <strong>执行 init 方法</strong>：在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚开始，&lt; init &gt;方法还没有执行，所有的字段都还为零。所以一般来说，执行new指令之后会接着执行&lt; init &gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Java 集合]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-ji-he/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-ji-he/">
        </link>
        <updated>2020-03-24T11:57:19.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-说一说-list-set-map-三者的区别">1. 说一说 List、Set、Map 三者的区别</h1>
<ul>
<li><code>List</code> 是存储<strong>有序</strong>的集合</li>
<li><code>Set</code> 集合元素<strong>不可重复</strong></li>
<li><code>Map</code> 是存储<strong>键值对</strong>的集合</li>
</ul>
<h1 id="2-arraylist-与-linkedlist-的区别">2. ArrayList 与 LinkedList 的区别</h1>
<ol>
<li>底层存储数据结构：</li>
</ol>
<ul>
<li><code>ArrayList</code> 初始容量时 10，底层是<strong>Object 数组</strong>，所以具有数组的特性，可<strong>随机访问</strong>，并且实现了<code>RandomAccess</code> 接口标识支持随机访问。</li>
<li><code>LinkedList</code> 底层是<strong>双向链表</strong>，所以具有链表的特性，<strong>增删速度快</strong>，但每个节点都有维护前后两个指针，占用<strong>存储空间较大</strong>。</li>
</ul>
<ol start="2">
<li>增删查效率：</li>
</ol>
<ul>
<li><code>ArrayList</code> 如果添加到<strong>末尾</strong>，时间复杂度<strong>O(1)</strong>；如果添加<strong>中间</strong>到指定 i 位置，需要把 i ~ n 位置的元素统一向后移动，时间复杂度 <strong>O(n-i)</strong>。如果<strong>按下标查找</strong>，时间复杂度<strong>O(1)</strong>。</li>
<li><code>LinkedList</code> 如果添加<strong>末尾</strong>，时间复杂度 <strong>O(1)</strong>，如果插入到<strong>中间</strong>第 i 个位置，需要先查找到到 i 个位置的元素，查找效率 <strong>O(n)</strong>，然后执行添加操作，修改指针指向，复杂度<strong>O(1)</strong>。如果<strong>按下标查找</strong>，需要判断下标是否大于当前 <code>size/2</code> ，如果大于则从末尾向中间查找；否则从头向中间查找，时间复杂度<strong>O(n)</strong>。</li>
</ul>
<h1 id="3-arraylist-扩容机制">3. ArrayList 扩容机制</h1>
<pre><code>private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);
    if (newCapacity - minCapacity &lt; 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
</code></pre>
<blockquote>
<p>上述代码基于 JDK1.8</p>
</blockquote>
<h1 id="4-arraylist-和-vector-的区别">4. ArrayList 和 Vector 的区别</h1>
<p>线程安全</p>
<ul>
<li><code>ArrayList</code> 线程不安全</li>
<li><code>Vector</code> 方法都使用 <code>synchronized</code> 修饰，所以线程安全，同时效率也低。正因为 <code>Vector</code> 效率低，所以一般不会使用，如果想实现同步，可以使用 <code>Collections.synchronizedList(new ArrayList&lt;&gt;());</code></li>
</ul>
<p>扩容机制：</p>
<ul>
<li><code>ArrayList</code> 扩容后的容量为原来的 1.5 倍</li>
<li><code>Vector</code> 扩容后的容量 是原来的 2 倍</li>
</ul>
<h1 id="5-hashmap-和-hashtable的区别">5. HashMap 和 Hashtable的区别</h1>
<p>线程安全：</p>
<ul>
<li><code>HashMap</code> 线程不安全</li>
<li><code>Hashtable</code> 的方法使用 <code>synchronized</code> 修饰，所以线程安全，也是正因为用 <code>synchronized</code> 修饰，所以效率较低。</li>
</ul>
<p>初始大小扩容机制：</p>
<ul>
<li><code>HashMap</code> 的默认初始容量为 16（2 &lt;&lt; 4）；如果指定了初始容量，会把它扩充为 2 的幂次。扩容后容量为原来的 2n</li>
<li><code>Hashtable</code> 默认初始容量时 11，如果指定初始容量，使用初始容量。扩容后容量为原来的 2n+1</li>
</ul>
<p>是否允许 null 键值</p>
<ul>
<li><code>HashMap</code> 允许 null 键值</li>
<li><code>Hashtable</code> 不允许 null 键值</li>
</ul>
<h1 id="6-hashmap-的-put-方法的具体流程">6. HashMap 的 put 方法的具体流程</h1>
<pre><code>public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/put.png" alt="图片" loading="lazy"></figure>
<ol>
<li>如果散列表为 null，<code>resize()</code> 初始化散列表</li>
<li>没有发生碰撞，直接添加元素到散列表中</li>
<li>如果发生碰撞，判断时红黑树还是链表，然后调用相应的插入方法</li>
<li>HashMap 的 resize() 扩容方法</li>
</ol>
<h1 id="7-hashmap-的-resize-扩容方法">7. HashMap 的 resize() 扩容方法</h1>
<p>如果当前容量 &gt; 阈值（容量 * 装填因子），则扩容</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/resize.png" alt="图片" loading="lazy"></figure>
<h1 id="8-hashmap-容量为什么是-2-的幂次">8. HashMap 容量为什么是 2 的幂次</h1>
<p>减少 <code>hash</code> 冲突，因为要用 <code>hash &amp; (n-1)</code> 确定元素存在数组中的下标位置，如果 n 是 2 的幂（1000），那么 n-1 得到的结果就全为 1 （10000 - 1 = 1111），这样 <code>(n-1) &amp; hash</code> 的值就是 hash。如果 n-1 中有某位为 0，那么 0 与任何数 &amp; 结果都为0，增加了hash 冲突的概率。</p>
<h1 id="9-hashmap-17-18-对比">9. HashMap 1.7 1.8 对比</h1>
<ul>
<li>JDK1.7</li>
</ul>
<p>数据结构：数组+链表</p>
<p>JDK1.7 hash 方法：9 次扰动（4 次位运算，5 次异或运算）</p>
<pre><code>static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).
    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);
    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);
}
</code></pre>
<ul>
<li>JDK 1.8</li>
</ul>
<p>数据结构：数组 + 链表 + 红黑树</p>
<p>JDK 1.8 hash 方法：2 次扰动（1 次位运算，1 次异或运算）</p>
<pre><code>static final int hash(Object key) {
    int h;
    // key.hashCode()：返回散列值也就是hashcode
    // ^ ：按位异或
    // &gt;&gt;&gt;:⽆符号右移，忽略符号位，空位都以0补⻬
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
}
</code></pre>
<p>贴一张比较详细的图：<br>
<img src="https://epitomm.github.io/post-images/hashmap.png" alt="图片" loading="lazy"></p>
<p>图片来源；<a href="https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485685&amp;idx=2&amp;sn=b393e444487c88e8c204821faddff370&amp;chksm=ebd749f4dca0c0e257e15c656f4504f224456495ad78e8aeb9ea370214ebd4b5c455b15e6045&amp;token=1948873548&amp;lang=zh_CN#rd">https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485685&amp;idx=2&amp;sn=b393e444487c88e8c204821faddff370&amp;chksm=ebd749f4dca0c0e257e15c656f4504f224456495ad78e8aeb9ea370214ebd4b5c455b15e6045&amp;token=1948873548&amp;lang=zh_CN#rd</a></p>
<h1 id="10-hashmap-是怎么解决哈希冲突的">10. HashMap 是怎么解决哈希冲突的</h1>
<p>什么是哈希冲突：两个不同的输入值，根据同一散列函数，计算出相同的散列值。</p>
<ul>
<li>使用<strong>拉链法</strong>来链接具有相同 hash 值的数据</li>
<li>使用<strong>两次扰动函数</strong>（hash 函数）来降低哈希冲突的概率，使得<strong>数据分布更均匀</strong></li>
<li>引入<strong>红黑树</strong>降低查找的时间复杂度</li>
</ul>
<h1 id="11-hashmap-17-18多线程操作导致死循环问题">11. HashMap 1.7 1.8多线程操作导致死循环问题</h1>
<p>参考链接：<a href="https://coolshell.cn/articles/9606.html">https://coolshell.cn/articles/9606.html</a></p>
<h1 id="12-hashmap-的-key-值要是为类对象则该类需要满足什么条件">12. HashMap 的 key 值要是为类对象则该类需要满⾜什么条件？</h1>
<p><strong>重写 hashCode() 和 equals() 方法。</strong></p>
<p><code>Hashmap</code> 中放入相同的 <code>key</code>，会覆盖 <code>value</code> 值，而不是重新添加一个 <code>key-value</code> 对，这就要求我们判断 <code>key</code> 是否相同。</p>
<p>以下为 <code>HashMap</code> 的 <code>final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)</code> 方法：</p>
<pre><code>if (p.hash == hash &amp;&amp;
    ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
</code></pre>
<p>从源码得知判断分为三个步骤：①判断 <code>key</code> 的 <code>hash</code> 值是否相同，这就要求我们重写 <code>hashCode()</code> 方法；② 通过 <code>==</code> 判断 <code>key</code> 对象引用是否相等；③ 使用 <code>equals()</code> 判断对象是否相等，这就要求我们重写 <code>equals()</code> 方法。</p>
<h1 id="13-concurrenthashmap-的底层实现方式">13. ConcurrentHashMap 的底层实现方式</h1>
<p>JDK1.7</p>
<ul>
<li>数据结构：分段数组（<code>Segment</code> 继承了 <code>ReentrantLock</code>，每个段都有一个锁） + 链表（<code>HashEntry</code>）</li>
<li>线程安全：对整个桶数组进行了分割分段，每把锁只锁住一<strong>段</strong>，多线程访问其他段的数据时不会产生冲突。</li>
</ul>
<p>JDK1.8</p>
<ul>
<li>数据结构：数组 + 链表 + 红黑树</li>
<li>线程安全：部分锁定 + CAS。<code>synchronized</code> 只锁定<strong>当前链表或红黑二叉树的首节点</strong>，这样只要 hash 不冲突，就不会产生并发。</li>
</ul>
<h1 id="14-concurrenthashmap-和-hashtable-的区别">14. ConcurrentHashMap 和 Hashtable 的区别</h1>
<p><code>Hashtable</code> 数据结构：数组 + 链表</p>
<p><code>Hashtable</code> 实现线程安全：会锁住整个数组，某个线程在进行 put 操作时，其他线程只能阻塞。</p>
<h1 id="15-如何选用集合">15. 如何选用集合</h1>
<ul>
<li>如果存储键值对，选 <code>Map</code> 接口下的集合
<ul>
<li>如果需要排序，选择 <code>TreeMap</code></li>
<li>如果不需要排序，优先选择 <code>HashMap</code></li>
<li>如果需要线程安全，选择 <code>ConcurrentHashMap</code></li>
</ul>
</li>
<li>只需要存放元素值时，选择 <code>Collection</code> 接口下的集合
<ul>
<li>如果需要顺序放取，选择 <code>ArrayList</code></li>
<li>如果需要频繁增删，选择 <code>LinkedList</code></li>
<li>如果需要元素不重复且排序，选择 <code>TreeSet</code></li>
<li>如果需要元素不重复但无需排序，优先选择 <code>HashSet</code></li>
</ul>
</li>
</ul>
<p>参考链接：</p>
<p><a href="https://github.com/ZhongFuCheng3y/3y">https://github.com/ZhongFuCheng3y/3y</a></p>
<p><a href="https://github.com/Snailclimb/JavaGuide">https://github.com/Snailclimb/JavaGuide</a></p>
]]></content>
    </entry>
</feed>