<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://epitomm.github.io</id>
    <title>SSM</title>
    <updated>2020-04-01T02:18:53.344Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://epitomm.github.io"/>
    <link rel="self" href="https://epitomm.github.io/atom.xml"/>
    <subtitle>热心善良的老学姐</subtitle>
    <logo>https://epitomm.github.io/images/avatar.png</logo>
    <icon>https://epitomm.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, SSM</rights>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Java 并发]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-bing-fa/">
        </link>
        <updated>2020-03-31T14:58:28.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Java 并发的东西比较多，今天先总结一部分。</p>
</blockquote>
<h1 id="1什么是线程和进程">1.什么是线程和进程？</h1>
<ul>
<li>进程是 OS 资源分配的基本单位。进程拥有独立的虚拟地址空间。</li>
<li>线程是 CPU 调度的基本单位。线程共享进程的堆、方法区资源，但每个线程有自己的程序计数器、虚拟机栈、本地方法栈。</li>
</ul>
<h1 id="2并发和并行的区别">2.并发和并行的区别？</h1>
<ul>
<li>并发：统一时间段内，多个任务都在执行。</li>
<li>并行：同一时间内，多个任务同时执行。</li>
</ul>
<h1 id="3为什么要使用多线程">3.为什么要使用多线程？</h1>
<p>先从总体上来说：</p>
<ul>
<li>从计算机底层来说：线程可以比作是轻量级的进程，是程序执行的最小单位，<strong>线程间的切换和调度的成本远远小于进程</strong>另外，多核CPU时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。</li>
<li>从当代互联网发展趋势来说：现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。</li>
</ul>
<p>再深入到计算机底层来探讨：</p>
<ul>
<li>单核时代：在单核时代多线程主要是为了提高CPU和IO设备的综合利用率。举个例子：当只有一个线程的时候会导致CPU计算时，IO设备空闲；进行IO操作时，CPU空闲。我们可以简单地说这两者的利用率目前都是50%左右。但是当有两个线程的时候就不一样了，当一个线程执行CPU计算时，另外一个线程可以进行IO操作，这样两个的利用率就可以在理想情况下达到100%了。</li>
<li>多核时代：多核时代多线程主要是为了<strong>提高CPU利用率</strong>。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU只会一个CPU核心被利用到，而创建多个线程就可以让多个CPU核心被利用到，这样就提高了CPU的利用率。</li>
</ul>
<h1 id="4创建线程的方式">4.创建线程的方式</h1>
<ul>
<li>实现 Runnable 接口</li>
</ul>
<pre><code>// 1. 实现 Runnable 接口
class MyRunnable implements Runnbale{
  // 2. 实现 run 方法
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  // 3. 使用自定义 runnable 对象创建线程
  MyRunnable runnable = new MyRunnable();
  Thread thread = new Thread(runnable);
  // 4. start() 启动线程
  thread.start();
}
</code></pre>
<ul>
<li>实现 Callable 接口</li>
</ul>
<p>与 Runnable 相比，Callable 可以有返回值，返回值由 FutureTask 进行封装。</p>
<pre><code>// 1. 实现 Callable 接口，并声明泛型
class MyCallable implements Callable&lt;Integer&gt;{
  // 2. 重写 call 方法
  public Integer call(){
    return 123;
  }
}
</code></pre>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException{
  MyCallable callable = new MyCallable();
  // 3. 使用 FutureTask 封装 call 方法的返回值
  FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(callable);
  Thread thread = new Thread(ft);
  thread.start();
  System.out.println(ft.get());
}
</code></pre>
<ul>
<li>继承 Thread 类</li>
</ul>
<pre><code>class MyThread extends Thread{
  public void run(){
    // ...
  }
}
</code></pre>
<pre><code>public static void main(String[] args){
  MyThread thread = new MyThread();
  thread.start();
}
</code></pre>
<h2 id="继承-vs-实现接口">继承 vs 实现接口</h2>
<p>实现接口更好一些，因为：</p>
<ul>
<li>Java 不支持多重继承，因此继承了 Thread 类就无法集成其它类，但是可以实现多个接口。</li>
<li>适合多个线程进行资源共享（Runnable 类可以作为多个 Thread 构造方法的参数）</li>
<li>线程池内只能放入 Runnable 或 Callable 接口的实现类，不能放入继承 Thread 对象的类。</li>
</ul>
<h1 id="5runnable-接口和-callable-接口的区别">5.Runnable 接口和 Callable 接口的区别</h1>
<ul>
<li>Runnable 接口重写的是 run 方法，Callable 接口重写的是 call 方法</li>
<li>run 方法执行后不能有返回值，call 方法执行后可以有返回值。</li>
<li>call()方法可以抛出异常，run()方法不可以</li>
<li>运行Callable任务可以拿到一个Future对象，表示异步计算的结果 。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</li>
</ul>
<h1 id="6start-方法和-run-方法的区别">6.start() 方法和 run() 方法的区别</h1>
<p>new 一个 Thread，线程进入了新建状态</p>
<ul>
<li>start() 方法可以启动一个线程，将线程由新建状态切换到就绪态。</li>
<li>run() 方法不会启动一个线程，只会把它当做一个普通方法去执行。</li>
</ul>
<h1 id="7sleep-方法和-wait-方法有什么区别">7.sleep 方法和 wait 方法有什么区别？</h1>
<ul>
<li>wait() 是 Object 类的方法，而 sleep() 是 Thread 的静态方法。</li>
<li>sleep 和 wait 方法都可以用来放弃 CPU 一定时间，<strong>暂停线程的执行</strong>。</li>
<li><strong>是否释放锁</strong>：两者最主要的区别在于：sleep 方法不会释放锁，而 wait 方法会释放锁。</li>
<li><strong>用途</strong>：wait 通常用于线程间交互 / 通信，sleep 通常被用于暂停执行。</li>
<li><strong>是否会自动苏醒</strong>：wait 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。</li>
</ul>
<h1 id="8reentrantlock-和-synchronized-的比较">8.ReentrantLock 和 synchronized 的比较</h1>
<ul>
<li>锁的实现</li>
</ul>
<p>synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。</p>
<ul>
<li>性能</li>
</ul>
<p>新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 和 ReentrantLock 大致相同。</p>
<ul>
<li>等待可中断</li>
</ul>
<p>当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。</p>
<p>ReentrantLock 可中断，而 synchronized 不行。</p>
<ul>
<li>公平锁</li>
</ul>
<p>公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。</p>
<p>synchronized 是不公平锁，而 ReentrantLock 默认情况下也是非公平的，但是可以在构造函数中设置公平还是不公平锁。</p>
<ul>
<li>锁绑定多个条件</li>
</ul>
<p>一个 ReentrantLock 可以同时绑定多个 Conditino 对象</p>
<ul>
<li>使用选择</li>
</ul>
<p>除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一 种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。</p>
<h1 id="9cyclicbarrier和countdownlatch的区别">9.CyclicBarrier和CountDownLatch的区别</h1>
<h2 id="countdownlatch">CountDownLatch</h2>
<p>用来控制一个线程等待多个线程。</p>
<p>维护了一个计数器 cnt，<strong>每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒</strong>。</p>
<h2 id="cyclicbarrier">CyclicBarrier</h2>
<p>用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。</p>
<p>和 CountdownLatch 相似，都是通过维护计数器来实现的。<strong>线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行</strong>。</p>
<p>CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做<strong>循环屏障</strong>。</p>
<p>CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。</p>
<h1 id="10semaphore有什么作用">10.Semaphore有什么作用</h1>
<p>Semaphore就是一个信号量，它的作用是<strong>限制某段代码块的并发数</strong>。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。</p>
<h1 id="11volatile关键字的作用">11.volatile关键字的作用</h1>
<ul>
<li>保证了可见性，不能保证原子性</li>
</ul>
<p>立刻将缓存中的值写到内存；线程通过嗅探总线上传播过来的数据监测自己的缓存是否过期了，如果过期了，就把缓存内的值设置为失效，如果要修改时，就去主存读取新值。</p>
<ul>
<li>禁止指令重排</li>
</ul>
<h1 id="12使用-blockingqueue-生产者消费者问题">12.使用 BlockingQueue 生产者消费者问题</h1>
<pre><code>public class ProductConsumer{
  private static BlockingQueue&lt;String&gt; queue = new BlockingQueue&lt;&gt;();
  private static class Producer extends Thread{
    @Override
    public void run(){
      try{
        queue.put(&quot;product&quot;);
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;produce...&quot;);
    }
  }
  private static class Consumer extends Thread{
    @Override
    public void run(){
      try{
        String product = queue.take();
      }catch(InterruptedException e){
        e.printStackTrace();
      }
      System.out.print(&quot;consume...&quot;)
    }
  }
  public static void main(String[] args) {
  for (int i = 0; i &lt; 2; i++) {
    Producer producer = new Producer();
    producer.start();
  }
  for (int i = 0; i &lt; 5; i++) {
    Consumer consumer = new Consumer();
    consumer.start();
  }
  for (int i = 0; i &lt; 3; i++) {
    Producer producer = new Producer();
    producer.start();
  } 
}
</code></pre>
<p>运行结果：</p>
<pre><code>produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. 
</code></pre>
<h1 id="13一个线程如果出现了运行时异常会怎么样">13.一个线程如果出现了运行时异常会怎么样</h1>
<p>如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：<strong>如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放</strong></p>
<h1 id="14threadlocal有什么用">14.ThreadLocal有什么用</h1>
<p>线程局部变量，<strong>以空间换时间</strong>，每个线程内都有一个，把数据进行隔离，解决多线程之间共享数据的安全问题。</p>
<h1 id="15wait方法和notifynotifyall方法在放弃对象监视器时有什么区别">15.wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别</h1>
<p>wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：<strong>wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器</strong>。</p>
<h1 id="16为什么要使用线程池">16.为什么要使用线程池</h1>
<p>来一个请求创建一个线程，执行结束再销毁线程，资源耗费太大，使用线程池达到对<strong>线程的复用</strong>。使用线程池还可以灵活地控制并发的数目。</p>
<h1 id="17怎么检测一个线程是否持有对象监视器">17.怎么检测一个线程是否持有对象监视器</h1>
<p>我也是在网上看到一道多线程面试题才知道有方法可以判断某个线程是否持有对象监视器：Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着&quot;某条线程&quot;指的是当前线程。</p>
<h1 id="18concurrenthashmap的并发度是什么">18.ConcurrentHashMap的并发度是什么</h1>
<p>ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？</p>
<h1 id="19futuretask是什么">19.FutureTask是什么</h1>
<p>在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。</p>
<pre><code>public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 
public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 
</code></pre>
<p>FutureTask 可用<strong>于异步获取执行结果</strong>或<strong>取消执行任务的场景</strong>。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。</p>
<h1 id="20aqs">20.AQS</h1>
<ol>
<li>概念</li>
</ol>
<ul>
<li>AbstractQueuedSynchronizer</li>
<li>同步发生器</li>
<li>构建 LOCK</li>
<li>JUC：java.util.current</li>
</ul>
<ol start="2">
<li>基本思想</li>
</ol>
<ul>
<li>通过内置对象 FIFO 同步队列来完成线程争夺资源的管理工作。</li>
<li>AQS实际上以双向队列的形式连接所有的Entry，比方说ReentrantLock，所有等待的线程都被放在一个Entry中并连成双向队列，前面一个线程使用ReentrantLock好了，则双向队列实际上的第一个Entry开始运行。</li>
<li>AQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。</li>
</ul>
<ol start="3">
<li>CLH同步队列</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/CLH%E5%90%8C%E6%AD%A5%E9%98%9F%E5%88%97.png" alt="图片" loading="lazy"></figure>
<h1 id="参考链接">参考链接</h1>
<p><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/JavaConcurrencyBasicsCommonInterviewQuestionsSummary.md</a></p>
<p><a href="https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg">https://mp.weixin.qq.com/s/SCugxnAV1_f3sq-UhFD7wg</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[记一个面试题 —— Redis 一启动挂了怎么办]]></title>
        <id>https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-redis-yi-qi-dong-gua-liao-zen-me-ban/</id>
        <link href="https://epitomm.github.io/post/ji-yi-ge-mian-shi-ti-redis-yi-qi-dong-gua-liao-zen-me-ban/">
        </link>
        <updated>2020-03-30T08:43:04.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>面试官：Redis 一启动就挂了怎么办？<br>
答：添加 Redis 集群</p>
</blockquote>
<h1 id="集群简介">集群简介</h1>
<h2 id="现状问题">现状问题</h2>
<h3 id="业务发展过程中遇到的峰值瓶颈">业务发展过程中遇到的峰值瓶颈</h3>
<ul>
<li>redis提供的服务OPS可以达到10万/秒，当前业务OPS已经达到20万/秒</li>
<li>内存单机容量达到256G，当前业务需求内存容量1T</li>
<li>使用集群的方式可以快速解决上述问题</li>
</ul>
<h2 id="集群架构">集群架构</h2>
<ul>
<li>集群就是使用网络将若干台计算机联通起来，并提供统一的管理方式，使其对外呈现单机的服务效果</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<h2 id="集群作用">集群作用</h2>
<ul>
<li>分散单台服务器的访问压力，实现负载均衡</li>
<li>分散单台服务器的存储压力，实现可扩展性</li>
<li>降低单台服务器宕机带来的业务灾难</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E4%BD%9C%E7%94%A8.png" alt="图片" loading="lazy"></figure>
<h1 id="redis集群结构设计">Redis集群结构设计</h1>
<h2 id="数据存储设计"><strong>数据存储设计</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>一个 key 放在 Redis 存储空间：单机方案。<br>
一个 key 对应多个存储空间，变成多台计算机了，应该怎样存储呢？</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A82.png" alt="图片" loading="lazy"></figure>
<ul>
<li>通过算法设计，计算出key应该保存的位置</li>
<li>将所有的存储空间计划切割成16384份，每台主机保存一部分
<ul>
<li>每份代表的是一个存储空间，不是一个key的保存空间</li>
</ul>
</li>
<li>将key按照计算出的结果放到对应的存储空间</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A83.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在有三个存储空间，突然又增加了一个存储空间。把原来的三个 Redis 存储空间都进行优化，每个存储空间拿出一部分给新的存储空间</p>
</blockquote>
<ul>
<li>增强可扩展性</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/Redis%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A85.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>旧的存储空间给新的存储空间 的 这一小块空间（也就是前面标记的37）叫做槽，用来放数据的空间区域。所谓的增加、删除 Redis 存储空间就是：改变槽所存储的位置不同。<br>
槽更换位置后，如何知道它被换到哪里了呢？<br>
内部通讯设计</p>
</blockquote>
<h2 id="集群内部通讯设计"><strong>集群内部通讯设计</strong></h2>
<ul>
<li>各个数据库相互通信，保存各个库中槽的编号数据</li>
<li>一次命中，直接返回</li>
<li>一次未命中，告知具体位置</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在有 A、B、C 三个机器互联，三个机器存储好了以后，会进行互联，互联的目的：谁那有什么样的东西一清二楚。每一台计算机都有一个账本，存储各个计算机里对应的存储空间的槽是几到几。</p>
</blockquote>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/Redis%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E9%80%9A%E8%AE%AF%E8%AE%BE%E8%AE%A12.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>假定现在来了一台计算机，发出一个 key 要访问 Redis，key 通过两个算法计算后得到 key 对应的存储槽在哪里，假定它访问的就是 A，一次命中，直接返回。假设它没有命中，会根据这个 key 对应的槽位置在 A 的小本子里面找，发现这个东西在 B 里面，于是就让这个 key 去 B 里面找，不是 A 去 B 里面找，而是这个连接请求客户端直接去 B 里面找。</p>
</blockquote>
<p>key 加密就是为了确定存储位置，保证最多两次命中</p>
<h2 id="总结">总结</h2>
<p>集群内存存储结构设计：</p>
<p>1.槽用来区分数据存储空间</p>
<p>2.key 加密后确定存储的位置</p>
<p>3.一次命中或两次命中就可以找到数据</p>
<h1 id="cluster集群结构搭建">cluster集群结构搭建</h1>
<h2 id="搭建方式">搭建方式</h2>
<ul>
<li>原生安装（单条命令）
<ul>
<li>配置服务器（3主3从）</li>
<li>建立通信（Meet）</li>
<li>分槽（Slot）</li>
<li>搭建主从（master-slave）</li>
</ul>
</li>
<li>工具安装（批处理）</li>
</ul>
<h2 id="cluster节点操作命令">Cluster节点操作命令</h2>
<ul>
<li>查看集群节点信息</li>
</ul>
<pre><code>cluster nodes 
</code></pre>
<ul>
<li>进入一个从节点 redis，切换其主节点</li>
</ul>
<pre><code>cluster replicate &lt;master-id&gt; 
</code></pre>
<ul>
<li>发现一个新节点，新增主节点</li>
</ul>
<pre><code>cluster meet ip:port 
</code></pre>
<ul>
<li>忽略一个没有solt的节点</li>
</ul>
<pre><code>cluster forget &lt;id&gt; 
</code></pre>
<ul>
<li>手动故障转移</li>
</ul>
<pre><code>cluster failover
</code></pre>
<h2 id="redis-trib命令">redis-trib命令</h2>
<ul>
<li>添加节点</li>
</ul>
<pre><code>redis-trib.rb add-node 
</code></pre>
<ul>
<li>删除节点</li>
</ul>
<pre><code>redis-trib.rb del-node 
</code></pre>
<ul>
<li>重新分片</li>
</ul>
<pre><code>redis-trib.rb reshard
</code></pre>
<h2 id="cluster配置">Cluster配置</h2>
<ul>
<li>添加节点</li>
</ul>
<pre><code>cluster-enabled yes|no 
</code></pre>
<ul>
<li>cluster配置文件名，该文件属于自动生成，仅用于快速查找文件并查询文件内容</li>
</ul>
<pre><code>cluster-config-file &lt;filename&gt; 
</code></pre>
<ul>
<li>节点服务响应超时时间，用于判定该节点是否下线或切换为从节点</li>
</ul>
<pre><code>cluster-node-timeout &lt;milliseconds&gt; 
</code></pre>
<ul>
<li>master连接的slave最小数量</li>
</ul>
<pre><code> cluster-migration-barrier &lt;count&gt;
</code></pre>
<ol>
<li>修改 redis.conf 配置文件</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# vim redis-6379.conf 
port 6379
daemonize no
#logfile &quot;6379.log&quot;
dir &quot;/root/redis-5.0.7/data&quot;
dbfilename &quot;dump-6379.rdb&quot;
rdbcompression yes
rdbchecksum yes
appendonly yes
appendfsync everysec
appendfilename &quot;appendonly-6379.aof&quot;
bind 127.0.0.1
databases 16

cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 10000
</code></pre>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6380/g&quot; redis-6379.conf &gt; redis-6380.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6381/g&quot; redis-6379.conf &gt; redis-6381.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6382/g&quot; redis-6379.conf &gt; redis-6382.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6383/g&quot; redis-6379.conf &gt; redis-6383.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6384/g&quot; redis-6379.conf &gt; redis-6384.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# sed &quot;s/6379/6385/g&quot; redis-6379.conf &gt; redis-6385.conf 
</code></pre>
<ol>
<li>启动 redis 客户端</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6379.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6380.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6381.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6382.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6383.conf 
[root@iZ2ze4u2bufi0915gyi843Z conf]# redis-server redis-6384.conf 
</code></pre>
<ol>
<li>每个 reids 服务都以 cluster 节点呈现</li>
</ol>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z conf]# ps -ef | grep redis-
root      9015  8373  0 18:44 pts/1    00:00:00 redis-server 127.0.0.1:6379 [cluster]
root      9019  8430  0 18:44 pts/5    00:00:00 redis-server 127.0.0.1:6380 [cluster]
root      9023  8411  0 18:45 pts/4    00:00:00 redis-server 127.0.0.1:6381 [cluster]
root      9028  8469  0 18:45 pts/6    00:00:00 redis-server 127.0.0.1:6382 [cluster]
root      9033  8488  0 18:45 pts/7    00:00:00 redis-server 127.0.0.1:6383 [cluster]
root      9037  8507  0 18:46 pts/8    00:00:00 redis-server 127.0.0.1:6384 [cluster]
root      9045  8545  0 18:46 pts/10   00:00:00 grep --color=auto redis-
</code></pre>
<ol>
<li>把这些  cluster 节点 连接在一起</li>
</ol>
<p>redis5.0之前的版本需要部署 ruby 和 gem：<a href="https://blog.51cto.com/wujianwei/2460638">部署ruby环境遇到的坑</a></p>
<p>redis5.0以上的版本可以使用redis-cli命令</p>
<p><a href="https://juejin.im/post/5d16206b518825597909b5f9">https://juejin.im/post/5d16206b518825597909b5f9</a></p>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z redis-5.0.7]# src/redis-cli --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 --cluster-replicas 1
// --cluster-replicas 1：一个 master 连接一个 slave；2：一个 master 连接两个 slave
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="图片" loading="lazy"></figure>
<p>输入 yes 重写配置文件后：</p>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C2.png" alt="图片" loading="lazy"></figure>
<h2 id="解析-master-和-slave-日志信息">解析 master 和 slave 日志信息</h2>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4master%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master：6379 日志</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/%E9%9B%86%E7%BE%A4slave%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave：6382 日志</p>
<h2 id="设置与获取数据">设置与获取数据</h2>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli
127.0.0.1:6379&gt; set name itheima   // 把 name 对应的 key 进行转化后，对应的槽在 6380，不能在 6379 set
(error) MOVED 5798 127.0.0.1:6380 
127.0 .0.1:6379&gt; set lll sss      //  lll 对应的 key 进行转化后，对应的槽在 6379，所以此处 set 成功
OK

[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli -c   // -c 专门用来操作 cluster 集群的
127.0.0.1:6379&gt; set name itheima
-&gt; Redirected to slot [5798] located at 127.0.0.1:6380  // 重定向到 5798 这个槽，这个槽在 6380 下
OK
127.0.0.1:6380&gt; get name
&quot;itheima&quot;
[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-cli -c -p 6382
127.0.0.1:6382&gt; get name
-&gt; Redirected to slot [5798] located at 127.0.0.1:6380
&quot;itheima&quot;
127.0.0.1:6380&gt; 
</code></pre>
<h2 id="主从下线与主从切换">主从下线与主从切换</h2>
<h3 id="slave6382-下线">slave:6382 下线</h3>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/slave%E4%B8%8B%E7%BA%BF%E4%B8%BB%E8%8A%82%E7%82%B9%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6381（slave:6382 的 master） 日志打印</p>
<figure data-type="image" tabindex="14"><img src="https://epitomm.github.io/post-images/slave%E4%B8%8B%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6379 日志打印</p>
<h3 id="slave6382-重新上线">slave:6382 重新上线</h3>
<figure data-type="image" tabindex="15"><img src="https://epitomm.github.io/post-images/slave%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>master:6381（slave:6382 的 master） 日志打印<br>
<img src="https://epitomm.github.io/post-images/%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E7%9A%84master%E5%8F%98%E6%88%90slave%E4%BA%86.png" alt="图片" loading="lazy"></p>
<p>master:6379 日志打印</p>
<h3 id="master6379-下线">master:6379 下线</h3>
<figure data-type="image" tabindex="16"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BFslave%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave:6383（master:6379 的 slave）日志打印</p>
<p>查看 cluster 信息：</p>
<figure data-type="image" tabindex="17"><img src="https://epitomm.github.io/post-images/master%E4%B8%8B%E7%BA%BFcluster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p>slave:6383 自己当 master</p>
<h3 id="master6379-重新上线">master:6379 重新上线</h3>
<figure data-type="image" tabindex="18"><img src="https://epitomm.github.io/post-images/master%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BFmaster%E6%97%A5%E5%BF%97.png" alt="图片" loading="lazy"></figure>
<p><strong>master:6383</strong>（slave:6379 的 master） 日志信息</p>
<figure data-type="image" tabindex="19"><img src="https://epitomm.github.io/post-images/%E9%87%8D%E6%96%B0%E4%B8%8A%E7%BA%BF%E7%9A%84master%E5%8F%98%E6%88%90slave%E4%BA%86.png" alt="图片" loading="lazy"></figure>
<p>再次上线的 6379 变成 slave 了</p>
<h1 id="总结-2">总结</h1>
<p><strong>集群</strong></p>
<ul>
<li>集群简介</li>
<li>集群结构</li>
<li>cluster集群结构搭建</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试常问之缓存预热、缓存雪崩、缓存击穿、缓存穿透]]></title>
        <id>https://epitomm.github.io/post/mian-shi-chang-wen-zhi-huan-cun-chuan-tou-huan-cun-xue-beng/</id>
        <link href="https://epitomm.github.io/post/mian-shi-chang-wen-zhi-huan-cun-chuan-tou-huan-cun-xue-beng/">
        </link>
        <updated>2020-03-30T01:33:36.000Z</updated>
        <content type="html"><![CDATA[<h1 id="缓存预热">缓存预热</h1>
<h2 id="宕机">“宕机”</h2>
<p>服务器<strong>启动后迅速宕机</strong></p>
<h2 id="问题排查">问题排查</h2>
<ol>
<li>
<p>请求数量较高</p>
</li>
<li>
<p>主从之间数据吞吐量较大（不停地加载数据），数据同步操作频度较高</p>
</li>
</ol>
<blockquote>
<p>数据库读的频度高：服务器一启动，缓存中没有数据，自然就会给服务器带来压力，这时候如果请求比较多的话，redis 服务器就会宕机。</p>
</blockquote>
<h2 id="解决方案">解决方案</h2>
<p>前置准备工作：</p>
<ol>
<li>日常例行统计数据访问记录，统计访问频度较高的热点数据</li>
<li>利用LRU数据删除策略，构建数据留存队列
<ul>
<li>例如：storm与kafka配合</li>
</ul>
</li>
</ol>
<p>准备工作：</p>
<ol start="3">
<li>将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据</li>
<li>利用分布式多服务器同时进行数据读取，提速数据加载过程</li>
</ol>
<p>实施：</p>
<ol>
<li>使用脚本程序固定触发数据预热过程</li>
<li>如果条件允许，使用了CDN（内容分发网络），效果会更好</li>
</ol>
<h2 id="总结">总结</h2>
<p>缓存预热就是系统启动前，<strong>提前将相关的缓存数据直接加载到缓存系统</strong>。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p>
<h1 id="缓存雪崩">缓存雪崩</h1>
<h2 id="数据库服务器崩溃1">数据库服务器崩溃（1）</h2>
<ol>
<li>系统平稳运行过程中，忽然数据库连接量激增</li>
<li>应用服务器无法及时处理请求</li>
<li>大量408，500错误页面出现</li>
<li>客户反复刷新页面获取数据</li>
<li>数据库崩溃</li>
<li>应用服务器崩溃</li>
<li>重启应用服务器无效</li>
<li>Redis服务器崩溃</li>
<li>Redis集群崩溃</li>
<li>重启数据库后再次被瞬间流量放倒</li>
</ol>
<h2 id="问题排查-2">问题排查</h2>
<ol>
<li>在一个<span style="color:red">较短</span>的时间内，缓存中较多的<span style="color:red">key集中过期 </span></li>
<li>此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据</li>
<li>数据库同时接收到大量的请求无法及时处理</li>
<li>Redis大量请求被积压，开始出现超时现象</li>
<li>数据库流量激增，数据库崩溃</li>
<li>重启后仍然面对缓存中无数据可用</li>
<li>Redis服务器资源被严重占用，Redis服务器崩溃</li>
<li>Redis集群呈现崩塌，集群瓦解</li>
<li>应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃</li>
<li>应用服务器，redis，数据库全部重启，效果不理想</li>
</ol>
<h2 id="问题分析">问题分析</h2>
<ul>
<li>短时间范围内</li>
<li>大量key集中过期</li>
</ul>
<h2 id="解决方案道">解决方案（道）</h2>
<ol>
<li>更多的页面静态化处理</li>
<li>构建多级缓存架构</li>
</ol>
<ul>
<li>Nginx缓存+redis缓存+ehcache缓存</li>
</ul>
<ol start="3">
<li>检测Mysql严重耗时业务进行优化</li>
</ol>
<ul>
<li>对数据库的瓶颈排查：例如超时查询、耗时较高事务等</li>
</ul>
<ol start="4">
<li>灾难预警机制</li>
</ol>
<ul>
<li>监控redis服务器性能指标
<ul>
<li>CPU占用、CPU使用率</li>
<li>内存容量</li>
<li>查询平均响应时间</li>
<li>线程数</li>
</ul>
</li>
</ul>
<ol start="5">
<li>限流、降级</li>
</ol>
<ul>
<li>短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问</li>
</ul>
<h2 id="解决方案术">解决方案（术）</h2>
<ol>
<li>LRU与LFU切换</li>
<li>数据有效期策略调整</li>
</ol>
<ul>
<li>根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟</li>
<li>过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量</li>
</ul>
<ol start="3">
<li>超热数据使用永久key</li>
<li>定期维护（自动+人工）</li>
</ol>
<ul>
<li>对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时</li>
</ul>
<ol start="5">
<li>加锁</li>
</ol>
<ul>
<li>慎用！</li>
</ul>
<h2 id="总结-2">总结</h2>
<p>缓存雪崩就是<strong>瞬间过期数据量太大</strong>，导致对数据库服务器造成压力。如能够有<strong>效避免过期时间集中</strong>，可以有效解决雪崩现象的出现 （约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-1.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>大量 key 集中过期，更多向 mysql 发起请求</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9-2.png" alt="图片" loading="lazy"></figure>
<h1 id="缓存击穿">缓存击穿</h1>
<h2 id="数据库服务器崩溃2">数据库服务器崩溃（2）</h2>
<ol>
<li>系统平稳运行过程中</li>
<li>数据库连接量瞬间激增</li>
<li>Redis服务器无大量key过期</li>
<li>Redis内存平稳，无波动</li>
<li>Redis服务器CPU正常</li>
<li>数据库崩溃</li>
</ol>
<h2 id="问题排查-3">问题排查</h2>
<ol>
<li>Redis中**某个key过期，该key访问量巨大 **</li>
<li>多个数据请求从服务器直接压到Redis后，均未命中</li>
<li>Redis在短时间内发起了大量对数据库中同一数据的访问</li>
</ol>
<h2 id="问题分析-2">问题分析</h2>
<ul>
<li>单个key高热数据</li>
<li>key过期</li>
</ul>
<h2 id="解决方案术-2">解决方案（术）</h2>
<ol>
<li>预先设定</li>
</ol>
<ul>
<li>以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长</li>
<li>注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势</li>
</ul>
<ol start="2">
<li>现场调整</li>
</ol>
<ul>
<li>监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key</li>
</ul>
<ol start="3">
<li>后台刷新数据</li>
</ol>
<ul>
<li>启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</li>
</ul>
<ol start="4">
<li>二级缓存</li>
</ol>
<ul>
<li>设置不同的失效时间，保障不会被同时淘汰就行</li>
</ul>
<ol start="5">
<li>加锁</li>
</ol>
<ul>
<li>分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</li>
</ul>
<h2 id="总结-3">总结</h2>
<p>缓存击穿就是<strong>单个高热数据过期的瞬间，数据访问量较大</strong>，未命中redis后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过期监控难度较高，配合雪崩处理策略即可。</p>
<h1 id="缓存穿透">缓存穿透</h1>
<h2 id="数据库服务器崩溃3">数据库服务器崩溃（3）</h2>
<ol>
<li>系统平稳运行过程中</li>
<li>应用服务器流量随时间增量较大</li>
<li>Redis服务器命中率随时间逐步降低</li>
<li>Redis内存平稳，内存无压力</li>
<li>Redis服务器CPU占用激增</li>
<li>数据库服务器压力激增</li>
<li>数据库崩溃</li>
</ol>
<h2 id="问题排查-4">问题排查</h2>
<ol>
<li>Redis中大面积出现未命中</li>
<li>出现非正常URL访问</li>
</ol>
<h2 id="问题分析-3">问题分析</h2>
<ul>
<li>获取的数据在数据库中也不存在，数据库查询未得到对应数据</li>
<li>Redis获取到null数据未进行持久化，直接返回</li>
<li>下次此类数据到达重复上述过程</li>
<li>出现黑客攻击服务器</li>
</ul>
<p><strong>解决方案（术）</strong></p>
<ol>
<li>缓存null</li>
</ol>
<ul>
<li>对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟</li>
</ul>
<ol start="2">
<li>白名单策略</li>
</ol>
<ul>
<li>提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时，放行，加载异常数据时直接拦截（效率偏低）</li>
<li>使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略）</li>
</ul>
<ol start="3">
<li>实施监控</li>
</ol>
<ul>
<li>实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比
<ul>
<li>非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象</li>
<li>活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象</li>
</ul>
</li>
<li>根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）</li>
</ul>
<ol start="4">
<li>key加密</li>
</ol>
<ul>
<li>问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验</li>
<li>例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问</li>
</ul>
<h2 id="总结-4">总结</h2>
<p>缓存击穿<strong>访问了不存在的数据</strong>，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。</p>
<p>无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。</p>
<h1 id="性能指标监控">性能指标监控</h1>
<h2 id="监控指标">监控指标</h2>
<ul>
<li>性能指标：Performance</li>
<li>内存指标：Memory</li>
<li>基本活动指标：Basic activity</li>
<li>持久性指标：Persistence</li>
<li>错误指标：Error</li>
</ul>
<h3 id="性能指标performance">性能指标：Performance</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">latency</td>
<td style="text-align:left">Redis响应一个请求的时间</td>
</tr>
<tr>
<td style="text-align:left">instantaneous_ops_per_sec</td>
<td style="text-align:left">平均每秒处理总数</td>
</tr>
<tr>
<td style="text-align:left">hit rate(calculate)</td>
<td style="text-align:left">缓存命中率（计算出来的）</td>
</tr>
</tbody>
</table>
<h3 id="内存指标memory">内存指标：Memory</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">used_memory</td>
<td style="text-align:left">已使用内存</td>
</tr>
<tr>
<td style="text-align:left">mem_fragmentation_ratio</td>
<td style="text-align:left">内存碎片化</td>
</tr>
<tr>
<td style="text-align:left">evicted_keys</td>
<td style="text-align:left">由于最大内存限制被移除的 key 的数量</td>
</tr>
<tr>
<td style="text-align:left">blocked_clients</td>
<td style="text-align:left">由于 BLPOP、BRPOP、or BRPOPLPUSH 而备受阻塞的客户端</td>
</tr>
</tbody>
</table>
<h3 id="基本活动指标basic-activity">基本活动指标：Basic activity</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">connected_clients</td>
<td style="text-align:left">客户端连接数</td>
</tr>
<tr>
<td style="text-align:left">connected_slaves</td>
<td style="text-align:left">Slave 数量</td>
</tr>
<tr>
<td style="text-align:left">master_last_io_seconds_ago</td>
<td style="text-align:left">最近一次主从交互之后的秒数</td>
</tr>
<tr>
<td style="text-align:left">keyspace</td>
<td style="text-align:left">数据库中的 key 值总数</td>
</tr>
</tbody>
</table>
<h3 id="持久性指标persistence">持久性指标：Persistence</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">rdb_last_save_time</td>
<td style="text-align:left">最后一次持久化保存到磁盘的时间戳</td>
</tr>
<tr>
<td style="text-align:left">rdb_changes_since_last_save</td>
<td style="text-align:left">自最后一次持久化依赖数据库的更改数</td>
</tr>
</tbody>
</table>
<h3 id="错误指标error">错误指标：Error</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Name</strong></th>
<th style="text-align:left"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">rejected_connections</td>
<td style="text-align:left">由于达到 maxclient 限制而被拒绝的连接数</td>
</tr>
<tr>
<td style="text-align:left">keyspace_misses</td>
<td style="text-align:left">key 值查找失败（没有命中）次数</td>
</tr>
<tr>
<td style="text-align:left">master_link_down_since_seconds</td>
<td style="text-align:left">主从断开的持续时间（以秒为单位）</td>
</tr>
</tbody>
</table>
<h2 id="监控方式">监控方式</h2>
<ul>
<li>工具
<ul>
<li>Cloud Insight Redis</li>
<li>Prometheus</li>
<li>Redis-stat</li>
<li>Redis-faina</li>
<li>RedisLive</li>
<li>zabbix</li>
</ul>
</li>
<li>命令
<ul>
<li>benchmark</li>
<li>redis cli
<ul>
<li>monitor</li>
<li>showlog</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="benchmark">benchmark</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>redis-benchmark [-h ] [-p ] [-c ] [-n &lt;requests]&gt; [-k ] 
</code></pre>
<ul>
<li>范例1</li>
</ul>
<pre><code>[root@iZ2ze4u2bufi0915gyi843Z ~]# redis-benchmark 
</code></pre>
<p>说明：50个连接，10000次请求对应的性能</p>
<ul>
<li>范例2</li>
</ul>
<pre><code>redis-benchmark -c 100 -n 5000 
</code></pre>
<p>说明：100个连接，5000次请求对应的性能</p>
<h2 id="benchmark-2"><strong>benchmark</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/benchmark.png" alt="图片" loading="lazy"></figure>
<h2 id="monitor">monitor</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>monitor 
</code></pre>
<p>打印服务器调试信息</p>
<h2 id="slowlog">slowlog</h2>
<ul>
<li>命令</li>
</ul>
<pre><code>slowlog [operator] 
</code></pre>
<ul>
<li>get ：获取慢查询日志</li>
<li>len ：获取慢查询日志条目数</li>
<li>reset ：重置慢查询日志</li>
<li>相关配置</li>
</ul>
<pre><code>slowlog-log-slower-than 1000 #设置慢查询的时间下线，单位：微妙 
slowlog-max-len 100 #设置慢查询命令对应的日志显示长度，单位：命令数
</code></pre>
<h1 id="总结-5">总结</h1>
<p>企业级解决方案</p>
<ul>
<li>缓存预热</li>
<li>缓存雪崩</li>
<li>缓存击穿</li>
<li>缓存穿透</li>
<li>性能指标监控
<ul>
<li>工具</li>
<li>命令</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线程]]></title>
        <id>https://epitomm.github.io/post/xian-cheng/</id>
        <link href="https://epitomm.github.io/post/xian-cheng/">
        </link>
        <updated>2020-03-29T03:08:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="p-stylecolorred1-线程抽象p"><p style="color:red">1. 线程抽象</p></h1>
<p>一个线程是一个单一的执行序列，它表示了一个单独被调度的任务.</p>
<ul>
<li><strong>单一的执行序列</strong>. 每个线程执行一个指令序列——赋值，条件，循环，过程, 等等</li>
<li><strong>单独被调度的任务</strong>. 操作系统可以在任意时刻，运行，暂停或者继续一个线程。</li>
<li><strong>运行，挂起和继续执行的线程</strong></li>
</ul>
<p>线程提供了一个有无限个处理机的幻象。OS 如何实现这样的幻象呢？它必须执行每个进程的指令使得每个线程都有进展，但实际的硬件只有有限个数的处理机，甚至只有 1 个</p>
<p>为了将任意数量的线程映射到有限个处理机上，OS 包含一个调度器(scheduler)能够在运行和就绪的线程之间来回切换。但是线程的切换对线程来说是透明的，只是某些时刻处理机的执行变得比较慢而已。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%90%8C%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.3</strong>: 一个线程 3 种可能的执行方式 ，对于程序员来说是无差的.</p>
<p>上图说明了一个程序员角度的一个简单程序有三种不同的执行方式，这取决于调度器。从线程的角度，除了执行的速度不一样，这些是没差的。确实，线程并不知道有其他线程在执行。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E4%BA%A4%E9%94%99%E6%89%A7%E8%A1%8C.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.4</strong>: 3 个线程在运行时许多种可能的交错执行的方式.</p>
<p>上图展示了 3 个线程的交替执行。他们的这种速度是不可控的，每次执行可能都不一样。</p>
<p><strong>例子</strong>:内核中断处理程序是一个线程?</p>
<p><strong>回答： 不，一个中断处理程序不是一个线程</strong>. 一个内核中断处理程序和线程有一些相似性: 它是一个指令的序列， 从开头执行到结尾。然而，一个中断处理程序<strong>不是独立可调度的</strong>: 它被一个硬件I/O 事件所触发执行,  而不是内核中线程调度器来决定什么时候执行. 一旦开始，中断处理程序运行到结束，除非被另外一个优先级更高的中断抢占.</p>
<h1 id="p-stylecolorred2-简化的线程-apip"><p style="color:red">2. 简化的线程 API</p></h1>
<table>
<thead>
<tr>
<th style="text-align:left">void thread_create  (thread, func,arg)</th>
<th style="text-align:left">创建一个新线程, 把信息存入 thread. 和调用的线程并发执行，线程执行函数 func，其参数为 arg.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">void thread_yield()</td>
<td style="text-align:left">调用的线程自愿放弃处理机让其他线程来运行。调度器也可以继续运行调用的线程.</td>
</tr>
<tr>
<td style="text-align:left">int thread_join  (thread)</td>
<td style="text-align:left">等待 thread 结束如果 thread 还没有结束的话; 然后返回由 thread 通过 thread_exit 传递来的参数. 注意， 对每个线程，thread_join 只能被调用一次.</td>
</tr>
<tr>
<td style="text-align:left">void thread_exit(ret)</td>
<td style="text-align:left">完成当前的线程. 将 ret 的值存在当前线程的数据结构中。如果另一个线程已经用 thread_join 等待该线程, 则继续执行那个等待的线程.</td>
</tr>
</tbody>
</table>
<p><strong>图 4.5</strong>:使用线程简化的 API</p>
<p>图 4.5 展示了使用线程的简单的API. 这个简化的API 是基于POSIX 标准的pthreads API, 但是它忽略了某些POSIX 选项和错误处理(为了简化). 绝大多数其他线程包也类似，如果你理解如何用这个 API 编程的话，你会发现对于绝大多数标准的线程 API 来说，其代码很容易编写.</p>
<p>我们看见 UNIX 进程抽象中有类似的概念. thread_create 类似于UNIX 进程 fork 和 exec, 而 thread_join 类似于 UNIX 进程wait. UNIX fork 创建了一个新的进程和原来调用 fork 的进程并发的执行;UNIX exec 导致进程运行一个指定的程序。UNIX wait 运行调用的进程暂停执行直到新的进程完成为止。</p>
<h2 id="1-多线程的hello-world">1. 多线程的Hello World!</h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E5%A4%9A%E7%BA%BF%E7%A8%8Bhelloworld%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.png" alt="图片" loading="lazy"></figure>
<p><strong>图 4.6</strong>: 用简单线程API 来打印”Hello”十次的多线程编程的例子。也展示了一种可能的输出。</p>
<p>上图是一个多线程的程序，用了简单的线程 API 来打印 hello 十次。也展示了一个可能的输出结果。Main 函数用 thread_create 创建了 10 个子线程。有趣的参数是第二个和第三个。第二个参数 go 是一个函数指针——新创建的检测应该开始执行的代码位置。第三个参数 i 传递给 go 函数。因此，thread_create 初始化第i 个线程的状态使得它准备调用函数 go，参数是 i。</p>
<p>当调度者运行第 i 个线程，线程运行函数go，参数为 i，打印 hello from 线程 i。 线程接着返回值 i+100 通过调用 thread_exit. 这个调用将特定的值保存到 trhead_t 的对象里，使得 thread_join 能够找到它。</p>
<p>Main 函数用thread_join 来等待每个它创建的线程。当每个线程完成的时候，main 的代码会的读取完成线程的退出值并打印。</p>
<p><strong>例子</strong>：为什么来自线程 2 的“线程 returned”的消息<strong>一定是</strong>在来自线程 5 的线程 returned 的消息打印之前先打印？</p>
<p>回答：虽然每个创建的线程完成的顺序是不确定的，但是主线程是按照创建的顺序按顺序检查的。</p>
<p><strong>例子</strong>：当线程 5 打印 hello 的时候未退出的线程的最少数是多少？最多数是多少？</p>
<p><strong>回答</strong>：最少是 2，最多是 11</p>
<h2 id="2-创建线程thread_create和线程等待thread_join在并行计算中的应用">2. 创建线程(thread_create)和线程等待(thread_join)在并行计算中的应用</h2>
<p>尽管线程接口很简单，但非常强大。例如用”<strong>fork-join 并行”</strong>（<strong>fork-join 并行</strong>即 thread_create 和 thread_join 一起使用来实现并行化计算）, 一个线程可以创建子线程来执行工作(“fork”, 或者 thread_create), 它可以等待他们的结果(“join”).</p>
<pre><code>// 为了传递两个参数，我们需要一个结构来保存它们.
typedef struct bzeroparams {
   unsigned char *buffer; int length;
};
#define NTHREADS 10
void go (struct bzeroparams *p) {
   memset(p-&gt;buffer, 0, p-&gt;length);
}
//用多线程对一个块进行清零.
void blockzero (unsigned char *p, int length) {
  int i;
  thread_t threads[NTHREADS];
  struct bzeroparams params[NTHREADS];
  // 为了简化，假设长度可以被NTHREADS 整除. assert((length   NTHREADS) == 0);
  for (i = 0; i &lt; NTHREADS; i++) {
      params[i].buffer = p + i * length/NTHREADS; params[i].length = length/NTHREADS; thread_create_p(&amp;(threads[i]), &amp;go, &amp;params[i]);
  }
  for (i = 0; i &lt; NTHREADS; i++) {
      thread_join(threads[i]);
    }
}
</code></pre>
<p><strong>图 4.7</strong>: 使用多线程并行地对一个内存连续区域清零的程序.<br>
<strong>例子：并行的块清零</strong>.在操作系统中一个应用 fork-join 并行的简单例子是对一段连续内存块清零的过程. 每当一个进程结束的时候，为了阻止无意的数据泄露, 操作系统必须把分配给这个进程中的内存清零。否则，一个新的进程可能会被重新分配给这个内存, 使得这个进程可以读取潜在的敏感的数据。例如，一个操作系统的远程登录程序可能暂时存储一个用户的密码在内存中，但是下一个使用同一内存区间的进程可能会是一个被一个恶意用户调用的扫描内存的程序.</p>
<p>对于一个大的进程，并行地清零的函数是合理的。在现代计算机上，对 1GB 的内存清零需要大约 50 毫秒; 相比之下，创建和启动一个新的线程只需要几十微秒.</p>
<p>图 4.7 展示了一个使用fork-join 并行清零的代码。多线程的 blockzero 创建了一系列线程并给每个分配了一段不相交的内存区间; 当所有线程都完成它们的工作的时候整个区间都被清零. 操作系统可以创建一系列低优先级的线程来运行 blockzero. 之后，当内存被需要的时候，内核可以调用 thread_join. 如果那个时候已经完全清零，则join 会立即返回；否则它需要等待直到这块内存可以被安全使用.</p>
<h1 id="p-stylecolorred3-线程的数据结构p"><p style="color:red">3. 线程的数据结构</p></h1>
<p>为了理解操作系统如何实现线程的抽象，我们必须定义两种状态，一个是每个线程的状态(the Per-Thread State)， 另一个是多个线程的共享状态(the Shared State)。然后我们才能给描述一个线程的生命周期——提供上述抽象，操作系统是如何能够创建，开始，暂停和删除线程的。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.8</strong>: 一个多线程的进程或者操作系统的内核既有每个线程的状态也有共享状态. 线程控制块（TCB）存储了每个线程的状态: 线程当前的计算状态(例如，被保存的处理机的寄存器和一个指向(内核)栈的指针)和需要管理该线程的元数据(例如，线程的 ID，调度优先级，拥有者). 共享的状态包括程序的代码，全局静态变量和堆.</p>
<p>一个多线程的进程或者操作系统内核都有每个线程的状态和共享状态。线程控制块保存着每个线程的状态: 线程计算当前的状态(例如，保存的处理机的寄存器和(内核)栈指针)和需要管理这个线程的元数据(例如，线程的 ID， 调度的优先级，拥有者)。共享状态包括：程序的代码，全局变量和堆。</p>
<ul>
<li><strong>每个线程的状态(Per-Thread State)和线程控制块(TCB)</strong></li>
</ul>
<p>操作系统需要一个数据结构来表示一个线程的状态；线程就好比是这个数据结构下的一个具体的对象。这个数据结构被称为线程控制块(线程控制块, TCB)。对于每个操作系统创建的线程，它就创建一个TCB。</p>
<p>线程控制块记录两种类型的每个线程的信息：</p>
<ol>
<li>这个线程当前的计算状态：栈和处理器中寄存器的值</li>
<li>用于管理该线程的元数据</li>
</ol>
<ul>
<li><strong>共享状态</strong></li>
</ul>
<p>有一些状态是属于同一应用进程里的不同线程之间共享的状态，或者是操作系统内核内的线程之间共享的状态。特别的，程序代码是同一进程中所有线程共享的，尽管每个线程可能执行代码的不同位置。除此以外，静态分配的  全局变量和动态分配的堆变量也是同一进程的所有线程所共享的。</p>
<p><strong>警告</strong>：这是逻辑上的区分状态（Per-Thread State 和 Shared State），而操作系统往往不强制这种区分，换句话说，一个线程可以去访问同一进程内的其他线程的每个线程的状态，例如访问其他线程的用户栈。<strong>这是被允许的</strong>。那么为了避免不要的错误，编写一个多线程的程序的时候必须要清楚哪些变量是线程之间共享的，哪些是私有的。以防一个线程会破坏其他线程。</p>
<h1 id="p-stylecolorred4-线程的生命周期p"><p style="color:red">4. 线程的生命周期</p></h1>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.9: 一个线程在它的生命周期中的状态.</strong></p>
<p>上图展示了一个线程的生命周期。</p>
<ul>
<li><strong>新建</strong>：线程创建会把一个线程设为新建状态，分配和初始化每个线程的的数据结构。一旦这些完成，thread_ creation 代码会把该线程放到就绪队列中（隐含的意思是设置为READY 状态）。</li>
<li><strong>就绪</strong>：一个线程是就绪态就是指它可以运行但当前还没有运行。它的 TCB 被放在就绪队列上，它的寄存器的值被保存在它的 TCB 中。在任意时刻，调度器可以让一个线程从就绪态到运行态，只需要把它保存在 TCB 中的寄存器的值恢复到处理机的寄存器上。</li>
<li><strong>运行</strong>：一个线程是运行态就是指它正在一个处理机上运行。此时，它的寄存器的值还在处理机的寄存器上，而不是TCB 中。一个运行态的线程可以按下面两种方式切换到就绪态：
<ul>
<li>
<p>调度器抢占一个运行的线程，然后将它放到就绪态，通过（1）保存线程的寄存器值到它的 TCB 中；并且（2）将处理机切换去执行就绪队列中某线程</p>
</li>
<li>
<p>一个运行态的线程可以自愿地放弃(relinquish)处理机然后从运行态到就绪态，通过调用 yield(例如，线程库中的 thread_yield)</p>
</li>
</ul>
</li>
</ul>
<p>注：一个线程可以从就绪态到运行态，再从运行态到就绪态，这样多次切换。</p>
<ul>
<li><strong>等待</strong>：一个线程在等待态是指它在等待某个事件。调度器能够将一个线程从就绪态移动到运行态，一个在等待态的线程却不能切换到运行态，它必须要等待某个其他的线程将它从等待态移动到就绪态。</li>
<li><strong>完成</strong>：一个线程在完成态就意味着它用于不会再运行了。系统能够释放部分或者它的全部状态，但它仍然要保留线程残留的一些信息，并把线程的 TCB 放到一个完成队列上。例如，thread_exit 调用会让一个线程将它的退出值通过 thread_join 传递给它的父亲线程。当一个线程的状态再没任何用处的时候（例如，当它的退出值已经被 thread_join 读取了），系统就可以删除和取回该线程的状态。</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E4%B8%8D%E5%90%8C%E7%8A%B6%E6%80%81%E4%B8%8B%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BD%8D%E7%BD%AE.png" alt="图片" loading="lazy"></figure>
<p><strong>图 4.10: 在不同状态下线程的每个线程状态的位置.</strong></p>
<p>理解这些状态的一种方式就是考虑一个线程的 TCB 和寄存器值存放的位置，如上图所示。当所有线程在就绪态，它们的 TCB 被放在就绪队列，它们的寄存器的值的拷贝也放在 TCB 中。所有在运行态的线程，它们的 TCB 被放在运行队列上，它们的寄存器值是在硬件寄存器上。所有在等待态的线程它们的 TCB 是放在不同的同步变量的等待队列上。</p>
<hr>
<p><strong>idle 线 程</strong></p>
<p>如果一个系统有 k 个处理机,  绝大多数操作系统确保正好有 k 个执行态的线程,  通过在每个处理机上维护一个低优先级的 <strong>idle 线程</strong>以保证当该处理机没有什么事情可做的时候，仍然有线程在执行.</p>
<p>在旧机器上，idle 线程会在一个紧凑循环中什么也不做. 而今天，idle 线程仍然在一个loop 中 spin, 但是为了省电，在每次迭代中，它把处理机进入一个低耗电的睡眠模式。在睡眠模式中，处理机暂停执行指令直到出现一个硬件中断。然后，处理机醒来并按照通常的方式来处理中断—保存当前正在执行的线程(idle 线程)的状态并执行处理程序. 在运行了处理程序之后，一个等待此 I/O 事件的线程现在可以是就绪态. 如果是这样的话，调度器接下来就执行这个进入就绪态的线程；否则 idle 线程继续执行，让处理机再次去睡觉.</p>
<hr>
<p><strong>例子</strong>：对于线程 Hello 程序，在一个单处理机上，主线程进入就绪态的最少次数是多少？最多次数又是多少？</p>
<p><strong>回答</strong>：当主线程被创建时，它必须进入就绪态；否则它永远不会被调度。在一个单处理机上，它必须放弃处理机为了让它的线程运行。在主线程被重新调度之前，子线程们接下来可以完成运行。一旦孩子们完成，主线程可以完成运行。<strong>因此最小的次数是 2</strong>.</p>
<p><strong>最大的次数则是接近于无穷大</strong>。一个运行的线程可以被抢占然后被重新调度若干次，而不影响执行的正确性。</p>
<h1 id="p-stylecolorred5-实现内核线程p"><p style="color:red">5. 实现内核线程</p></h1>
<p>我们介绍内核线程的实现。这是所有线程实现中最基础的，也是最简单的。</p>
<h2 id="p-stylecolorreda-创建内核线程代码不要求但后面介绍的基本步骤需要掌握p"><p style="color:red">a. 创建内核线程（代码不要求，但后面介绍的基本步骤需要掌握）</p></h2>
<pre><code>// func 是一个指向线程要运行的过程的指针.
// arg 是传递给这个过程的参数.
void thread_create(thread_t *thread, void (*func)(int), int arg) {
  // Allocate TCB and stack TCB *tcb = new TCB();
  thread -&gt;tcb = tcb;
  tcb-&gt;stack_size = INITIAL_STACK_SIZE;
  tcb-&gt;stack = new Stack(INITIAL_STACK_SIZE);
  // 初始化寄存器使得当线程继续执行的时候，它从 stub 开始执行。
  //栈从分配的区域的顶端开始，然后向下增长. tcb-&gt;sp = tcb-&gt;stack + INITIAL_STACK_SIZE; tcb-&gt;pc = stub;
  // 通过把 stub 的参数压栈来创建一个栈帧
  *(tcb-&gt;sp) = arg; tcb-&gt;sp--;
  *(tcb-&gt;sp) = func; tcb-&gt;sp--;
  // 创建另一个栈帧使得 thread_switch 正确工作. 这个 routine 在本章后面解释. thread_dummySwitchFrame(tcb);
  tcb-&gt;state = READY;
  readyList.add(tcb); // 把 TCB 放在就绪队列
}
void stub(void (*func)(int), int arg) {
  (*func)(arg); // 执行函数 func()
  thread_exit(0); // 如果 func()不调用 exit,在这里调用 exit.
}


</code></pre>
<p><strong>图 4.13</strong>创建线程的伪代码。对栈的初始化和传参给初始函数是和机器相关的。在 intel x86 架构中，栈从搞地址开始然后向下增长，而参数被传递到栈上。在其他系统，栈能够向上增长，参数是通过寄存器传递。图 4.14 提供了thread_dummySwitchFrame 的伪代码<br>
图 4.13 展示了创建一个新线程的伪代码。thread_create 的目标是执行一个异步的过程调用给 func，其参数为 arg。当线程运行时，它执行 func(arg)【与父进程并发执行】</p>
<p><strong>创建一个线程有 3 个步骤</strong></p>
<ol>
<li><strong>分配每个线程的状态</strong>. 第一步是为线程的每个线程的状态分配空间：TCB 和栈。正如我们所提到的，TCB 是操作系统用于管理线程的数据结构。</li>
<li><strong>初始化每个线程的状态</strong>. 为了初始化TCB，需要初始化各个寄存器的值。当该线程被调度时，我们想要我们想要它运行 func(arg)。然而，是先从一个 dummy 函数, stub, 运行，stub 接着调用func。我们需要这个步骤是因为 func 是返回而不是调用 thread_exit。没有这个 stub 的话，func 会返回栈顶的一个随机的位置。，有了 stub，函数 func 返回到stub，然后再由 stub 调用 thread_exit 来完成线程。在伪代码中，我们给 stub 压入两个参数进栈：func 和 arg。当线程开始运行，stub 的代码就会访问它的代码就行一个普通的procedure。</li>
<li><strong>将TCB 放到就绪队列</strong>. 创建一个线程的最后一步就是将它的状态设置为就绪态，然后把新的 TCB 放到就绪队列， 使得该线程能够被调度。</li>
</ol>
<h2 id="p-stylecolorred-b-一个自愿的内核线程切换代码不要求但线程上下文切换的基本步骤需要掌握即保存旧线程的寄存器的值到tcb-中把新线程的tcb-中寄存器的值加载到cpu-的寄存器中p"><p style="color:red"> b. 一个自愿的内核线程切换（代码不要求，但线程上下文切换的基本步骤需要掌握，即：保存旧线程的寄存器的值到TCB 中，把新线程的TCB 中寄存器的值加载到CPU 的寄存器中</p></h2>
<p>图 4.14 展示了在Intel x86 硬件架构下，thread_yiled 的简单实现的伪代码.一个线程调用 thread_yield 自愿地放弃处理机给另一个线程用. 调用的线程的寄存器被拷贝到它的 TCB 和栈中，便于当调度器再次选择它的时候，可以继续运行.</p>
<pre><code>//我们以一个旧线程进入，而以新线程返回.
//以新线程的寄存器和栈返回.
void thread_switch(oldThreadTCB, newThread TCB) { 
    pushad; //把通用寄存器的值压入旧的栈中. 
    oldThreadTCB-&gt;sp = esp; //保存旧线程的栈指针. 
    esp = newThreadTCB-&gt;sp; // 切 换 到 新 的 栈 . 
    popad; // 从新的栈弹出寄存器的值.
    return;
}
void thread_yield() {
  TCB *chosenTCB, *finishedTCB;
  // 在切换的中间过程中阻止有中断暂停. disableInterrupts();
  // 从 就 绪 队 列 中 选 择 另 一 个 TCB. chosenTCB = readyList.getNext 线程(); 
  if (chosenTCB == NULL) {
    // 没有什么可以运行的，回去运行原始的线程.
  } else {
    // 将运行的线程移动到就绪队列. runningThread-&gt;state = ready; readyList.add(runningThread);
    thread_switch(runningThread, chosenTCB); // 切换到新的线程. runningThread -&gt;state = running;
  }
  //删除完成队列上的任意线程.
  while ((finishedTCB = finishedList-&gt;getNextThread()) != NULL) {
    delete finishedTCB-&gt;stack;
    delete finishedTCB;
  }
  enableInterrupts();
}
//thread_create 必须在它的栈顶放一个 dummy frame:
// 返回的 PC 和给 pushad 的空间来存储寄存器的备份.
// 这样的话，当某人切换到一个新创建的线程, thread_switch 的最后两行能正确工作.
void thread_dummySwitchFrame(new 线程) {
  *(tcb-&gt;sp) = stub; //返回到 stub 的开头. tcb-&gt;sp--;
  tcb-&gt;sp -= SizeOfPopad;
}
</code></pre>
<p><strong>图 4.14</strong>: 在 Intel x86 架构上 thread_switch 和 thread_yield 的伪代码。注意， thread_yield 是一个空操作如果没有其他线程可以运行。否则，它保存旧线程的状态并恢复新线程的状态。当旧线程被重新调度，它从thread_switch 返回到正在运行的线程.</p>
<hr>
<p>thread_yield 的伪代码首先关闭中断来阻止线程系统试图在同一时间做两个上下文切换. 伪代码接着把下一个线程拉出就绪队列(如果有的话)，然后切换到它. thread_switch 代码也许看上去有点不易理解, 由于它是在旧线程的上下文中被调用，而完成的时候是在新线程的上下文. 为了完成切换，thread_switch 把寄存器的状态保存到栈上，然后把栈指针保存到 TCB 中。接着它切换到新的线程的栈，从新线程的栈来恢复新线程的状态，然后返回到存储在新栈中的程序计数器的位置. 一个比较扭曲的地方是返回的位置可能不是 thread_yield!  返回到了新线程之前被暂停的地方.</p>
<hr>
<p><strong>一个 0-线程的内核</strong></p>
<p>我们不仅可以有一个单线程的内核或者一个多线程的内核，还有可能有一个没有线程的内核——0 线程的内核。实际上，这也是常见的。因为几乎内核中所有事情都是事件驱动的，例如响应一个中断，处理机异常或者系统调用。</p>
<p>在一个简单的操作系统中，就没有必要创建内核线程或者内核线程控制块来追踪正在进行的计算。而是，当发生一个中断，陷阱或者异常，栈指针就设置为指向中断栈的栈底，指令指针设置为处理程序的地址。接着，处理程序开始执行，要不就立即返回到用户级的进程要不就暂停用户级的进程，然后返回到其他用户级进程。</p>
<hr>
<h1 id="p-stylecolorred6-实现多线程的进程p"><p style="color:red">6. 实现多线程的进程</p></h1>
<p>所有广泛被应用的操作系统既支持内核线程也支持多线程进程。编程语言，例如 Java，和标准库接口例如 POSIX 用操作系统的这种支持来为编程者提供线程的抽象。</p>
<ul>
<li><strong>用内核线程实现多线程的进程</strong></li>
</ul>
<p>支持多线程进程的最简单的方式是使用内核线程的实现。当一个用户级线程访问线程库要做同样的事情，它用系统调用来请求内核做同样的操作。</p>
<p>如图 4.12 所示，一个进程的线程有：</p>
<ul>
<li>一个用户级的栈用于执行用户代码</li>
<li>一个内核中断栈：当该线程做系统调用时，或者引发了一次处理机异常，或者被中断</li>
<li>一个内核TCB：用于保存和恢复每个线程的状态</li>
</ul>
<p>为了创建一个线程，<strong>用户线程库</strong>分配一个用户级的栈给新的线程，然后做一个系统调用进入内核。内核分配一个TCB 和内核栈，设置线程的状态使其用用户级栈从被请求的过程的开始处开始执行。内核需要在<strong>进程控制块</strong>（<strong>PCB</strong>） 中保存一个指向该TCB 的指针；如果进程退出，内核必须终止在这个进程内的任意线程。在创建了线程后，内核把新的线程放到就绪队列上，就像其他线程一样可以被调度，然后返回一个唯一的标识符给用户程序，以便于以后想要指定这个新创建的线程的时候使用（例如，for join）。线程的 join, yield,和 exit 用同样的方式实现：<strong>通过系统调用进入内核来执行所请求的函数</strong>。</p>
<h1 id="p-stylecolorred7-实现用户级线程没有内核支持p"><p style="color:red">7. 实现用户级线程（没有内核支持）</p></h1>
<p>也可以实现一个完全在用户级的线程（作为库函数），不需要任何操作系统的支持。早期线程库函数采用这种纯用户级方法的原因是：因为极少有操作系统支持多线程的进程。在 JAVA 虚拟机中，也被称为绿线程。</p>
<p>基本思想比较简单。线程库函数在进程中初始化线程的所有数据结构：TCB，就绪队列，完成队列，等待队列，这些全部在进程的用户地址空间。对线程库函数的调用就是普通的过程调用。</p>
<p>在操作系统内核看来，一个用户级多线程的应用程序就是一个普通的单线程进程。绿线程的限制是操作系统<strong>内核不知道用户级就绪队列</strong>。如果应用程序的某个线程执行一个系统调用需要等待 I/O，内核不知道还有别的用户级线程可以运行。就会<strong>把整个进程都阻塞</strong>。类似的，在一个多处理机上，内核也不能让一个进程的多个线程在不同的处理机上运行。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[进程]]></title>
        <id>https://epitomm.github.io/post/jin-cheng/</id>
        <link href="https://epitomm.github.io/post/jin-cheng/">
        </link>
        <updated>2020-03-29T02:28:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="p-stylecolorred1-为什么引入进程p"><p style="color:red">1. 为什么引入进程？</p></h1>
<p>操作系统需要一种统一的方法监视、管理、控制处理器中不同程序的动态执行过程，“进程”的概念被引入！</p>
<h1 id="p-stylecolorred2-进程的定义p"><p style="color:red">2. 进程的定义</p></h1>
<p>进程没有严格的定义，但可以通过不同的角度去描述：计算机中正在运行的程序的一个实例（Instance。它包含（内存中的）代码段，数据段，堆，栈（用户栈和内核栈）；和当前的执行上下文（PC，SP 和其他寄存器），操作系统通过维护数据结构——进程控制块（PCB）来管理每个进程。</p>
<p><strong>进程控制块（Process Control Block——PCB</strong>：PCB 是是操作系统用来管理进程的数据结构，是进程存在的唯一标识。每当操作系统创建一个进程，就是由操作系统为该进程设置一个 PCB；进程执行完成时，由系统收回其 PCB， 该进程便消亡了。PCB 的内容包括：</p>
<ul>
<li>进程的状态（就绪，执行，等待，完成）</li>
<li>进程的 ID</li>
<li>进程的名字</li>
<li>进程的执行上下文（PC，SP，ELFAGS，其他寄存器）</li>
<li>调度需要的信息（优先级，调度参数，使用的 CPU 时间，进程开始的时间…）</li>
<li>内存管理的信息（基址和界限…）</li>
<li>I/O 状态信息（打开的文件，占用的 I/O 设备…）</li>
</ul>
<h1 id="p-stylecolorred3-内核线程和用户进程放到一起p"><p style="color:red">3. 内核线程和用户进程放到一起</p></h1>
<p>下面两个图展示了包含用户进程（上图是单线程进程，下图是多线程进程）和内核线程的内存空间信息。</p>
<ul>
<li>所有<strong>内核线程</strong>都<strong>共享</strong>内核的代码段（Code），全局变量(Globals)，堆(Heap)，和自己<strong>专门</strong>的 TCB 和内核栈。</li>
<li><strong>单线程的用户进程</strong>在用户空间有自己的代码段，数据段，堆，栈，在内核空间有内核用于管理该进程使用的 PCB和内核栈。</li>
<li>多线程的用户进程在用户空间有自己的代码段，数据段，堆和多个线程。每个线程有自己的用户栈，和内核空间的内核栈以及内核用于管理该线程的TCB。</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B-%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.11</strong>:一个多线程的内核：有 3 个内核线程和两个单线程的用户级进程. 每个内核线程 有它自己的 TCB 和它自己的栈. 每个用户进程有一个用户级的栈用于执行用户的代码和一个内核中断栈用于执行系统调用和中断.</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%86%85%E6%A0%B8.jpg" alt="图片" loading="lazy"></figure>
<p><strong>图 4.12</strong>: 一个多线程的内核：有 3 个内核线程和两个用户级的进程, 每个进程有 2 个线程. 每个用户级线程有一个用户级栈和一个内核中的中断栈用于执行系统调用和中断.</p>
<h1 id="p-stylecolorred4-进程的状态及其变迁p"><p style="color:red">4. 进程的状态及其变迁</p></h1>
<h2 id="a-三状态变迁图">a)  三状态变迁图</h2>
<p><strong>运行中的</strong>进程至少具有以下三种基本状态（如下图所示）：</p>
<ol>
<li><strong>就绪状态</strong>– 在某时刻，进程已获得除处理机以外的所有资源，一旦分到了处理机就可以立即执行</li>
<li><strong>运行状态</strong>– 进程已经获得必要资源，并占有处理机运行</li>
<li><strong>等待状态</strong>（也叫<strong>阻塞状态</strong>） – 正在执行的进程，由于发生某事件而暂时无法执行下去</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%B8%89%E7%8A%B6%E6%80%81.png" alt="图片" loading="lazy"></figure>
<p>例如，下图展示了 3 个进程的状态的变迁。其中调度程序是操作系统内核中用于从就绪队列中选择下一个占用CPU 执行的进程的调度程序。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%BA%8F%E5%88%97%E5%9B%BE%E4%B8%BE%E4%BE%8B-%E4%B8%89%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<h2 id="b-五状态变迁图">b)  五状态变迁图</h2>
<p>其状态变迁图如下图所示，比 3 状态图多了两个状态：新建和退出。</p>
<ul>
<li><strong>新建状态</strong>– 至少建立PCB，但进程相关的其他内容可能未调入主存</li>
<li><strong>退出状态</strong>– 进程已经终止，但资源等待父进程或系统回收</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%BA%94%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<p><strong>触发进程状态变迁的事件</strong>描述如下：</p>
<ul>
<li><strong>创建</strong>→<strong>就绪</strong>：(1)系统初始化，(2)用户请求创建一个新进程，(3)进程执行了创建进程的系统调用</li>
<li><strong>就绪</strong>→<strong>执行</strong>：内核的调度程序(scheduler)选择了一个就绪的进程，让它占用处理机执行</li>
<li><strong>运行</strong>→<strong>等待</strong>: 需要等待某个事件发生才可以继续执行，例如 I/O 请求或者某个共享数据被锁住不能访问</li>
<li><strong>运行</strong>→<strong>就绪</strong>（被<strong>抢占</strong>）：高优先级的进程进入就绪态，进程的时间片用完</li>
<li><strong>等待</strong>→<strong>就绪</strong>(被<strong>唤醒</strong>)：等待的事件发生，例如 I/O 请求完成，共享数据可以访问</li>
<li><strong>运行</strong>→<strong>结束</strong>：可能是正常退出（调用 exit 系统调用），可能是出错（异常，由操作系统强制终止）</li>
</ul>
<h2 id="c-七状态变迁图">c.) 七状态变迁图</h2>
<p>当内存不够的时候，执行状态的进程，就绪状态的进程和等待状态的进程都有可能因为优先级较低而被从内存移出放到外存，如果是执行态和就绪态的进程被移出到外存，则被称为<strong>就绪挂起</strong>；如果是等待态的进程被移出到外存，则被称为<strong>等待挂起</strong>。</p>
<ul>
<li><strong>等待挂起</strong>：进程在外存等待某事件的出现</li>
<li><strong>就绪挂起</strong>：进程在外存，但只要进入内存就可以运行新加入的<strong>状态变迁</strong>有两类：挂起和激活。</li>
<li><strong>挂起：把一个进程从内存移到外存</strong>
<ul>
<li><strong>等待</strong>→<strong>等待挂起</strong>：没有进程处于就绪状态或者就绪进程要求更多的内存</li>
<li><strong>就绪</strong>→<strong>就绪挂起</strong>：当有高优先级等待的进程和低优先级的就绪进程</li>
<li><strong>运行</strong>→<strong>就绪挂起</strong>：当有高优先级等待挂起进程因为等待的事件发生了而进入就绪挂起</li>
<li><strong>等待挂起</strong>→<strong>就绪挂起</strong>：当有等待挂起的进程所等待的事件发生了</li>
</ul>
</li>
<li><strong>激活：把一个进程从外存移到内存</strong>
<ul>
<li><strong>就绪挂起</strong>→<strong>就绪</strong>：没有就绪进程或挂起就绪进程优先级高于就绪进程</li>
<li><strong>等待挂起</strong>→<strong>等待</strong>：当一个进程释放足够内存，并有高优先级等待挂起进程</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE-%E4%B8%83%E7%8A%B6%E6%80%81.jpg" alt="图片" loading="lazy"></figure>
<h1 id="p-stylecolorred5-进程状态的队列p"><p style="color:red">5. 进程状态的队列</p></h1>
<p>进程控制块根据不同状态被放到不同的队列中，如下图所示</p>
<ul>
<li>就绪队列：状态为就绪的PCB 队列，该队列可以是链表也可以是索引，还可以多个队列</li>
<li>执行队列：状态为执行的PCB 队列</li>
<li>等待队列：状态为等待的PCB 队列，不同的等待事件对应不同的等待队列</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E9%98%9F%E5%88%97.jpg" alt="图片" loading="lazy"></figure>
<h1 id="p-stylecolorred6-进程状态切换的实现p"><p style="color:red">6. 进程状态切换的实现</p></h1>
<p>我们用下图来说明两个进程之间的切换过程。</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E5%88%87%E6%8D%A2.png" alt="图片" loading="lazy"></figure>
<p>如上图所示，有两个并发执行的进程，P0 和 P1.首先是 P0 执行，当出现一个中断或系统调用，硬件开始执行相应的处理程序，假设该处理程序调用了 scheduler（调度程序），该调度程序决定让进程 P1 执行，于是需要切换进程的上下文。具体地，(1)先将进程 P0 的进程上下文（PC，SP 和其他寄存器信息）保存到 PCB0，(2)如果是时钟中断，将PCB0 加入就绪队列中等待下一次被 scheduler 调度；如果是一次 I/O 系统调用，则将 PCB0 放入相应的等待队列中， (3)把进程 P1 的 PCB1 从就绪队列中移除，放进执行队列中，(4)将进程上下文从 PCB1 中恢复到寄存器中，此时 PC 指向了进程 P1 要执行的指令，SP 指向了进程 P1 的执行栈，于是 P1 开始执行。当再次出现时钟中断或者系统调用，再用同样的方式保存 P1 的状态到 PCB1 中。不再赘述。</p>
<h1 id="p-stylecolorred7-windows-的进程管理p"><p style="color:red">7. Windows 的进程管理</p></h1>
<p>进程管理之一就是增加一个系统调用，用于创建一个进程。这个理论上很简单但实际实现却比较复杂。在Windows 中，有一个程序，称为CreateProcess，它的简化形式如下</p>
<pre><code>Boolean CreateProcess(char *prog, char *args);
</code></pre>
<p>我们称创建进程的进程为<strong>父亲</strong>，而被创建的进程被称为<strong>孩子</strong>。</p>
<p>CreateProcess 需要执行哪些步骤呢？我们之前已有介绍，内核需要</p>
<ul>
<li>创建并初始化内核中的 PCB</li>
<li>创建和初始化一个新的地址空间</li>
<li>加载程序prog 进入地址空间</li>
<li>将参数 args 拷贝到地址空间的内存中</li>
<li>初始化硬件上下文来从第一条指令开始执行</li>
<li>通知调度程序有新的进程准备运行了<br>
不幸的是，实际的实现要复杂的多，CreateProcess 有十个参数需要设置，如下图所示。<br>
<img src="https://epitomm.github.io/post-images/CreateProcess.png" alt="**Figure 3.3**: 一个如何用 Windows 的系统调用 CreateProcess 的例子. 前两个参数指定程序和它的参数；剩下的关心进程的运行环境." loading="lazy"><br>
Figure 3.3: 一个如何用 Windows 的系统调用 CreateProcess 的例子. 前两个参数指定程序和它的参数；剩下的关心进程的运行环境.</li>
</ul>
<h1 id="p-stylecolorred-8-unix-的进程管理p"><p style="color:red"> 8. UNIX 的进程管理</p></h1>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>创建和管理进程的 API</strong></th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">fork()</td>
<td style="text-align:left">创建一个子进程作为当前进程的一个克隆。fork 调用有两个  返回，一个是返回到父进程，另一个返回到子进程.</td>
</tr>
<tr>
<td style="text-align:left">exec(prog, args)</td>
<td style="text-align:left">在当前进程中运行应用程序 prog.</td>
</tr>
<tr>
<td style="text-align:left">exit()</td>
<td style="text-align:left">告诉内核当前的进程完成了，它的数据结构需要被垃圾回收.</td>
</tr>
<tr>
<td style="text-align:left">wait(processID)</td>
<td style="text-align:left">暂停一直到该子进程结束.</td>
</tr>
<tr>
<td style="text-align:left">signal(processID, type)</td>
<td style="text-align:left">发送一个特定类型的中断给其他一个进程.</td>
</tr>
</tbody>
</table>
<p><strong>Figure 3.7</strong>: UNIX 中管理和创建进程的 API.</p>
<p>UNIX 用一种不同的方法来创建进程，这种实现是在理论上复杂，但实现上却比较简单。UNIX 把 CreateProcess 分割成两个阶段，分别称为 fork 和 exec，如下图所示</p>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/fork-exec.jpg" alt="图片" loading="lazy"></figure>
<p><strong>Figure 3.4</strong>: UNIX 的系统调用 fork 和 exec 的操作. UNIX 的 fork 对父进程做了一个拷贝; UNIX 的 exec 将子进程改变成新运行的程序.</p>
<p><strong>UNIX 的 fork</strong>创建一个和父进程完全一致的拷贝，只有一项例外（我们需要某种方法来区分父进程和孩子）。一旦上下文设置好，子进程就调用 UNIX 的 exec 程序。exec 加载新的可执行镜像进入内存并开始执行。看上去先拷贝父进程，然后又用一个新的可执行镜像覆盖看上去有些没必要。实际上 fork 和 exec 来创建新进程的实现确是非常快速的，其中所使用的技术我们会在后面介绍。</p>
<p>在这个设计中, UNIX 的 fork 不接受参数，并返回一个整数。UNIX 的 exec 接受两个参数(要运行的程序的名字和传递给该程序的参数的数组). 这里是 CreateProcess 需要 10 个参数. 部分是因为 UNIX 的 fork 和 exec 的简洁性， 这个接口从 70 年代初期被设计出来到现在几乎没有改变.</p>
<p><strong>UNIX 的 fork</strong>程序包含以下步骤：</p>
<ul>
<li>创建和初始化内核中的 PCB</li>
<li>创建一个新的地址空间</li>
<li>初始化地址空间，将父进程的地址空间完全拷贝过来</li>
<li>继承父进程的执行上下文</li>
<li>通知调度程序有新的进程可以运行</li>
</ul>
<p>比较诡异的一点就是 fork 这个系统调用返回会返回两次：一个是返回给父亲进程，一个是返回给子进程。对于父进程，UNIX 返回子进程的 ID，对于子进程，返回 0 来表示成功。显然，当你克隆了你自己，你需要有某种方式来分辨谁是克隆者，谁是你本身。UNIX 就通过 fork 这个系统调用的返回值来区分这两个进程。Fork 的 sample code 如下图所示</p>
<pre><code>int child_pid = fork();
if (child_pid == 0) { //我是子进程.
  printf(&quot;I am process #   d\n&quot;, getpid()); return 0;
} else { //我是父进程.
  printf(&quot;I am the parent of process #   d\n&quot;, child_pid); return 0;
}
</code></pre>
<p>可能的输出有两种：<br>
<strong>I am the parent of process 495 I am process 495</strong></p>
<p>另一种概率小但仍可能的输出是:</p>
<p><strong>I am process 456</strong></p>
<p><strong>I am the parent of process 456</strong></p>
<p><strong>Figure 3.5</strong>: fork 一个进程的 UNIX 代码, 和运行这个代码的可能的输出。。getpid 是一个系统调用，用来获取当前进程的 ID.</p>
<p>如果我们运行图 3.5 的程序会发生什么？UNIX fork 返回两次，一次是从子进程返回，结果是 0，一次从父进程返回， 结果是子进程的 ID。然而，我们不知道是父进程还是子进程先运行。父进程已经在运行了，看上去它更可能先打印输出。然而，一个时钟中断(timer interrupt)可能在父进程fork 了进程后出现，因此会出现进程切换。或者，我们在多核系统上运行，父进程和子进程是同时运行。无论哪种情况子进程都可能在父进程之前输出。</p>
<p><strong>UNIX 的exec 和wait</strong></p>
<p>UNIX 的系统调用 exec 完成需要运行一个新成效的步骤。一旦子进程从 UNIX fork 返回并设置了新进程的执行环节后，子进程调用 UNIX exec. 在我们下一节讨论UNIX 管道的时候，我们会描述更多这个如何工作的.</p>
<p>Exec 包含如下步骤：</p>
<ul>
<li>加载程序prog 到当前的地址空间</li>
<li>拷贝参数 args 到地址空间中</li>
<li>初始化硬件上下文来从开头开始执行  到此为止，exec 就创建了一个新的进程</li>
</ul>
<p>另一方面，父进程常常需要暂停直到子进程完成运行为止，例如下一步骤是依赖于上一步骤的输出。所以 UNIX 还有一个系统调用，很自然地被叫做wait，它会暂停父进程知道子进程完成或者崩掉或者终止。由于父进程可能创建了许多的子进程，wait 需要设定子进程的 ID 作为参数，来确定要等待的子进程。然而，这个对wait 的调用在 UNIX 中是可选的。</p>
<h1 id="p-stylecolorred9-案例实现一个简单的-shellp"><p style="color:red">9. 案例：实现一个简单的 Shell</p></h1>
<p>图 3.7 列出的UNIX 系统调用已经足以构建一个灵活和强大的命令行 shell，该 shell 完全在用户级运行，不需要特殊权限.</p>
<pre><code>main() {
  char *prog = NULL; char **args = NULL;
  // 一次读取输入的一行，并解析每一行为程序名字和程序参数
  while (readAndParseCmdLine(&amp;prog, &amp;args)) {
    // 创建一个子进程来运行命令. int child_pid = fork();
    if (child_pid == 0) {
      //我是子进程，用父进程的输入来运行程序exec(prog, args);
      // 这里不会到达。。
      } else {
        // 我是父进程，等待子进程完成. wait(child_pid);
        return 0;
    }
  }
}
</code></pre>
<p><strong>Figure 3.8</strong>: 一个简单的 UNIX shell 的代码.<br>
图 3.8 展示了一个shell 的基本操作的代码。这个 shell 从输入读取一个命令行, 然后它 fork 一个进程来执行指令.父进程(shell)在读取下一个要执行的命令行之前必须等待子进程完成。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— MySQL 数据库]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-mysql-shu-ju-ku/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-mysql-shu-ju-ku/">
        </link>
        <updated>2020-03-27T07:15:29.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1存储引擎">1.存储引擎</h1>
<ul>
<li>MySQL 默认的存储引擎是 InnoDB</li>
</ul>
<h2 id="myisam-和-innodb-的区别">MyISAM 和 InnoDB 的区别</h2>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">MyISAM</th>
<th style="text-align:left">InnoDB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>是否支持行级锁</strong></td>
<td style="text-align:left">只有<strong>表级锁</strong></td>
<td style="text-align:left">支持<strong>行级锁和表级锁</strong>，默认为行级锁</td>
</tr>
<tr>
<td style="text-align:left">查询性能</td>
<td style="text-align:left">强调的是性能，每次查询具有原子性，执行速度快</td>
<td style="text-align:left">使用了聚簇索引、或需要访问的数据可以放入内存的应用下速度快</td>
</tr>
<tr>
<td style="text-align:left"><strong>是否支持事务</strong></td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持</td>
</tr>
<tr>
<td style="text-align:left"><strong>是否支持崩溃后的安全恢复</strong></td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持。事务、回滚、崩溃修复能力和事务安全型表</td>
</tr>
<tr>
<td style="text-align:left">是否支持外键</td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持</td>
</tr>
<tr>
<td style="text-align:left">是否支持 MVCC</td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持。应对高并发事务，MVCC比单纯的加锁更高效。MVCC只在READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作；MVCC 可以使用乐观锁和悲观锁来实现。</td>
</tr>
<tr>
<td style="text-align:left">其他功能</td>
<td style="text-align:left">全文索引、压缩、空间函数</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<h1 id="2索引">2.索引</h1>
<h2 id="1-聚簇索引与非聚簇索引">(1) 聚簇索引与非聚簇索引</h2>
<ul>
<li>MyISAM：B+ 树叶子节点的 data 域存放的是<strong>数据记录的地址</strong>。在索引检索的时候，首先按照 B+ 树搜索算法搜索索引，如果指定的 key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为 “<strong>非聚簇索引</strong>”。</li>
<li>InnoDB：其数据本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按照 B+ 树组织的一个索引结构。B+ 树叶子节点的 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 <strong>InnoDB 表数据文件本身就是主索引</strong>。这被称为“<strong>聚簇索引</strong>”（或“聚集索引”）。而其余的索引都作为辅助索引，<strong>辅助索引的 data 域存储相应记录主键的值</strong>而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。</li>
</ul>
<h2 id="2-hash-索引与-b-数索引">(2) Hash 索引与 B+ 数索引</h2>
<h3 id="hash-索引">Hash 索引</h3>
<ul>
<li>Hash 索引仅仅能满足 &quot;=&quot;、“IN” 的等值查询，不能使用范围查询。</li>
<li>Hash 索引不能利用组合索引的部分索引键查询。</li>
<li>Hash 索引遇到大量 Hash 值相等的情况后性能不一定就会比 B+ 树高。</li>
</ul>
<h3 id="b-树索引">B+ 树索引</h3>
<p>B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，<strong>在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题</strong>。</p>
<h1 id="3什么是事务">3.什么是事务？</h1>
<p>事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>
<h1 id="4事务的四大特征">4.事务的四大特征</h1>
<ul>
<li>原子性（Atomicity）：事务被视为不可分割的最小单元。事务的所有操作要么全部成功提交，要么全部失败回滚。</li>
<li>一致性（Consistency）：数据库在事务执行前后保持一致性状态，多个事务对同一个数据读取的结果是相同的。</li>
<li>隔离性（Isolation）：一个事务所做的修改在最终提交以前，对其他事务是不可见的。</li>
<li>持久性（Durability）：一旦事务提交，则其所做的修改将永远保存在数据库中。即使系统发生崩溃，事务执行的结果页不能丢失。</li>
</ul>
<hr>
<ul>
<li>只有满足一致性，事务的执行结果才是正确的。</li>
<li>在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要满足原子性，就一定能满足一致性。</li>
<li>在并发的情况下，多个失误并行执行，事务不仅要满足原子性，还要满足隔离性，才能满足一致性。</li>
<li>事务满足持久化是为了能应对数据库崩溃的情况。</li>
</ul>
<p><strong>AUTOCOMMIT</strong></p>
<p>MySQL 默认采用自动提交模式。也就是说，如果不显式使用 START TRASACTION 语句来开启一个事务，那么每个查询都会被当作一个事务自动提交。</p>
<h1 id="5并发事务带来哪些问题">5.并发事务带来哪些问题？</h1>
<h2 id="1-丢失修改">(1) 丢失修改</h2>
<p>T1 和 T2 两个事务都对一个数据进行修改， T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/%E4%B8%A2%E5%A4%B1%E4%BF%AE%E6%94%B9.png" alt="图片" loading="lazy"></figure>
<h2 id="2-读脏数据">(2) 读脏数据</h2>
<p>T1 修改一个数据，T2 随后读取这个数据，如果 T1 撤销了这次修改，那么 T2 读取到的数据是脏数据。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E8%84%8F%E8%AF%BB.png" alt="图片" loading="lazy"></figure>
<h2 id="3-不可重复读">(3) 不可重复读</h2>
<p>T2 读取一个数据，T1 对这个数据进行了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。</p>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png" alt="图片" loading="lazy"></figure>
<h2 id="4-幻影读">(4) 幻影读</h2>
<p>T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围内的数据，此时读取的结果和第一次读取的结果不同。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/%E5%B9%BB%E8%AF%BB.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>不可重复读和幻读的区别：<br>
不可重复读的重点是修改，比如多次读取一条记录发现其中的某些列的值被修改；幻读的重点在于新增或者删除，比如多次读取同一范围发现记录增多或减少了。</p>
</blockquote>
<hr>
<p>产生并发不一致问题主要原因是破坏了事务的隔离性，解决方法时通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。</p>
<h1 id="6事务的隔离级别有哪些">6.事务的隔离级别有哪些？</h1>
<h2 id="1-读未提交read-uncommitted">(1) 读未提交（READ UNCOMMITTED）</h2>
<p>事务中的修改，即使没有提交，对其他事务也是可见的。</p>
<h2 id="2-读已提交read-committed">(2) 读已提交（READ COMMITTED）</h2>
<p>一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。</p>
<h2 id="3-可重复读repeatable-read">(3) 可重复读（REPEATABLE READ）</h2>
<p>一个事务在第一次读取过某条记录后，即使其他事务修改了该记录的值并且提交，该<strong>事物之后再读该条记录时，读到的仍是第一次读到的值</strong>。而不是每次都读到不同的数据，这就是可重复读。</p>
<h2 id="4-可串行化serializable">(4) 可串行化（SERIALIZABLE）</h2>
<p>强制事务串行执行。</p>
<p>需要加锁实现，而其它隔离级别通常不需要。</p>
<table>
<thead>
<tr>
<th style="text-align:left">隔离级别</th>
<th style="text-align:left">脏读</th>
<th style="text-align:left">不可重复读</th>
<th style="text-align:left">幻影读</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读未提交</td>
<td style="text-align:left">√</td>
<td style="text-align:left">√</td>
<td style="text-align:left">√</td>
</tr>
<tr>
<td style="text-align:left">读已提交</td>
<td style="text-align:left">×</td>
<td style="text-align:left">√</td>
<td style="text-align:left">√</td>
</tr>
<tr>
<td style="text-align:left">可重复读</td>
<td style="text-align:left">×</td>
<td style="text-align:left">×</td>
<td style="text-align:left">√</td>
</tr>
<tr>
<td style="text-align:left">可串行化</td>
<td style="text-align:left">×</td>
<td style="text-align:left">×</td>
<td style="text-align:left">×</td>
</tr>
</tbody>
</table>
<p>MySQL InnoDB 存储引擎默认的隔离级别是<strong>可重复读</strong>。InnoDB 存储引擎在可重读事务隔离级别下使用的是 Next-Key Lock 算法，因此可以避免幻读的产生。</p>
<h1 id="7-锁机制与-innodb-锁算法">7. 锁机制与 InnoDB 锁算法</h1>
<p>MyISAM 和 InnoDB 存储引擎使用的锁</p>
<ul>
<li>MyISAM 使用表级锁</li>
<li>InnoDB 支持行级锁和表级锁，默认使用表级锁</li>
</ul>
<p>行级锁和表级锁的对比：</p>
<ul>
<li>表级锁：MySQL 中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源耗费也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发率最低，MyISAM 和 InnoDB 引擎都支持表级锁。</li>
<li>行级锁：MySQL 中锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。</li>
</ul>
<p>InnoDB 存储引擎的锁的算法有三种：</p>
<ul>
<li>Record Lock：单个行记录上的锁</li>
<li>Gap Lock：间隙锁，锁定一个范围，不包括记录本身。GAP锁的⽬的，是为了防⽌同⼀事务的两次当前读，出现幻读的情况。</li>
<li>Next-key Lock：Record + Gap 锁定一个范围，包含记录本身。对于⾏的查询，都是采⽤该⽅ 法，主要⽬的是解决幻读的问题。</li>
</ul>
<p>相关知识点：</p>
<p>1.innodb对于行的查询使用next-key lock</p>
<p>2.Next-locking keying为了解决Phantom Problem幻读问题</p>
<p>3.当查询的索引含有唯一属性时，将next-key lock降级为record key</p>
<p>4.Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生5.有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock）A.将事务隔离级别设置为RCB.将参数innodb_locks_unsafe_for_binlog设置为1</p>
<h1 id="8介绍一下两段锁协议">8.介绍一下两段锁协议</h1>
<ul>
<li>阶段一：<strong>加锁阶段</strong>。在这阶段，事务可以申请获得任何数据项上的任何类型的锁，但是不能释放任何锁。</li>
<li>阶段二：<strong>解锁阶段</strong>。在这阶段，事务可以释放任何数据项上的任何类型的琐，但是不能再申请任何锁。</li>
</ul>
<blockquote>
<p>注意：两段锁协议可能会导致死锁。<br>
<img src="https://epitomm.github.io/post-images/%E4%B8%A4%E6%AE%B5%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84%E6%AD%BB%E9%94%81.png" alt="图片" loading="lazy"></p>
</blockquote>
<h1 id="9介绍一下多版本并发控制mvcc">9.介绍一下多版本并发控制（MVCC）</h1>
<p>多版本并发控制（MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现读已提交和可重复读这两种隔离级别。而读未提交总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。</p>
<p>对于使用 InnoDB 存储引擎的表来说，它的聚簇索引记录中都包三个隐藏列：</p>
<table>
<thead>
<tr>
<th style="text-align:center"><strong>列名</strong></th>
<th style="text-align:center"><strong>是否必须</strong></th>
<th style="text-align:center"><strong>占用空间</strong></th>
<th style="text-align:center"><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">row_id</td>
<td style="text-align:center">否</td>
<td style="text-align:center">6字节</td>
<td style="text-align:center">行ID，唯一标识一条记录</td>
</tr>
<tr>
<td style="text-align:center">transaction_id</td>
<td style="text-align:center">是</td>
<td style="text-align:center">6字节</td>
<td style="text-align:center">事务ID</td>
</tr>
<tr>
<td style="text-align:center">roll_pointer</td>
<td style="text-align:center">是</td>
<td style="text-align:center">7字节</td>
<td style="text-align:center">回滚指针</td>
</tr>
</tbody>
</table>
<ul>
<li>trx_id：每次对某条记录进行改动时，都会把对应的 <strong>事务 id</strong> 赋值给 trx_id 列。</li>
<li>roll_pointer：每次对某条记录进行改动时，这个隐藏列都会存一个指针，可以通过这个指针找到该记录修改前的信息（<strong>回滚指针</strong>）。</li>
</ul>
<h2 id="readview">ReadView</h2>
<p>对于使用READ UNCOMMITTED隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用 SERIALIZABLE隔离级别的事务来说，使用加锁的方式来访问记录。对于使用READ COMMITTED 和 REPEATABLE READ 隔离级别的事务来说，就需要用到我们上边所说的版本链了，核心问题就是：<strong>需要判断一<strong><strong>下</strong></strong>版本链中的哪个版本是<strong><strong>当</strong></strong>前事务可见的</strong>。</p>
<p>ReadView 中主要包含4个比较重要的内容：</p>
<ol>
<li>m_ids：表示在生成 ReadView 时当前系统中<strong>活****跃的（未提交的）读写事务的事务id列表</strong>。</li>
<li>min_trx_id：表示在生成 ReadView 时当前系统中<strong>活跃的读写<strong><strong>事</strong></strong>务中最小的事务id</strong>，也就是m_ids 中的最小值。</li>
<li>max_trx_id：表示生成 ReadView 时系统中应该**分配给下一个事务的 id**** **<strong>值</strong>。</li>
<li>creator_trx_id：表示<strong>生<strong><strong>成</strong></strong>该 ReadView 的事务的事务id</strong>。</li>
</ol>
<blockquote>
<p>注意max_trx_id并不是m_ids中的最大值，事务id是递增分配的。比方说现在有id为1，2，3这三个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，m_ids就包括1和2，min_trx_id的值就是1，max_trx_id的值就是4。</p>
</blockquote>
<h2 id="read-commited-实现方式">READ COMMITED 实现方式</h2>
<p><strong>每次读取数据前都生成一个ReadView</strong></p>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E8%AF%BB%E5%B7%B2%E6%8F%90%E4%BA%A4MVCC.png" alt="图片" loading="lazy"></figure>
<h2 id="repeatable-read-实现方式">REPEATABLE READ 实现方式</h2>
<p><strong>在第一次读取数据时生成一个ReadView，第二次读取数据时使用第一次生成的 ReadView。</strong></p>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BBMVCC.png" alt="图片" loading="lazy"></figure>
<h2 id="mvcc总结">MVCC总结</h2>
<p>MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 READ COMMITTD、 REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程。可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ 这两个隔离级别的一个很大不同就是：<strong>生成ReadView 的时机不同</strong>，READ COMMITTD 在每一次进行普通 SELECT 操作前都会</p>
<p>生成一个 ReadView，而 REPEATABLE READ 只在第一次进行普通 SELECT 操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。</p>
<h1 id="10next-key-locks">10.Next-Key Locks</h1>
<p>Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。</p>
<p>MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。</p>
<h2 id="record-locks">Record Locks</h2>
<p>锁定一个记录上的索引，而不是记录本身。</p>
<p>如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。</p>
<h2 id="gap-locks">Gap Locks</h2>
<p>锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。</p>
<pre><code>SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
</code></pre>
<h2 id="next-key-locks">Next-Key Locks</h2>
<p>它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间，例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：</p>
<pre><code>(-∞, 10]
(10, 11]
(11, 13]
(13, 20]
(20, +∞)
</code></pre>
<h1 id="11大表优化">11.大表优化</h1>
<p>当 MySQL 单表记录数过大时，数据库的 CRUD 性能会明显下降，一些常见的优化措施如下：</p>
<h2 id="限定数据的范围">限定数据的范围</h2>
<p>务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询历史订单的时候，我们可以控制在一个月的范围内；</p>
<h2 id="读写分离">读/写分离</h2>
<p>经典的数据库拆分方案，主库负责写，从库负责读；</p>
<h2 id="垂直分区">垂直分区</h2>
<p>根据数据库里面数据表的相关性进行拆分。例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。</p>
<p>简单来说垂直拆分是指数据表<strong>列的拆分</strong>，把一张列比较多的表拆分为多张表。如下图所示，这样来说大家应该就更容易理解了。</p>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E5%9E%82%E7%9B%B4%E5%88%86%E5%8C%BA.png" alt="图片" loading="lazy"></figure>
<ul>
<li>垂直拆分的优点：可以使得列数据变小，在查询时减少读取的 Block 数，减少 I/O 次数。此外，垂直分区可以简化表的结构，易于维护。</li>
<li>垂直拆分的缺点：主键会出现冗余，需要管理冗余列，并会引起 join 操作，可以通过在应用层进行 join 来解决。此外，垂直分区会让食物变得更加复杂。</li>
</ul>
<h2 id="水平分区">水平分区</h2>
<p>保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。水平拆分可以支撑非常大的数据量。</p>
<p>水平拆分是指数据表<strong>行的拆分</strong>，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。</p>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E6%B0%B4%E5%B9%B3%E5%88%86%E5%8C%BA.png" alt="图片" loading="lazy"></figure>
<p>水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库。</p>
<p>水平拆分能够支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。</p>
<p>下面补充一下数据库分片的两种常见方案：</p>
<ul>
<li>客户端代理：分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。当当网的Sharding-JDBC、阿里的TDDL是两种比较常用的实现。</li>
<li>中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。我们现在谈的Mycat、360的Atlas、网易的DDB等等都是这种架构的实现。</li>
</ul>
<p>详细内容可以参考：MySQL大表优化方案：<a href="https://segmentfault.com/a/1190000006158186">https://segmentfault.com/a/1190000006158186</a></p>
<h1 id="12分库分表之后id-主键如何处理">12.分库分表之后，id 主键如何处理？</h1>
<p>因为要分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要一个全剧唯一的 id 来支持。</p>
<p>生成全局 id 有一下这几种方式：</p>
<ul>
<li><strong>UUID</strong>：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标识，比如文件的名字。</li>
<li><strong>数据库自增 id</strong>：两台数据库分别设置不同步长，生成不重复 ID 的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。</li>
<li><strong>利用 redis 生成 id</strong>：性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。</li>
<li>......</li>
</ul>
<h1 id="13查询语句不同元素where-join-limit-group-by-having等的先后执行顺序">13.查询语句不同元素（where、join、limit、group by、having等）的先后执行顺序？</h1>
<p>查询中使用到的关键字主要包含六个，并且它们的书写顺序依次为：</p>
<p>select —— from —— where —— group by —— having  —— order by</p>
<p>其中 select 和 from 是必须的，其他关键词是可选的，这六个关键词的执行顺序与 sql 语句的书写顺序并不是一样的，而是按照下面的顺序来执行。</p>
<ul>
<li>from：需要从哪个数据库表检索数据</li>
<li>where：过滤表中的数据条件</li>
<li>group by：如何将上面过滤出的数据进行分组</li>
<li>having：对上面已经分组的数据进行过滤的条件</li>
<li>select：查看结果集中的哪个列，或者列的计算结果</li>
<li>order by：按照什么顺序来查看返回的数据</li>
</ul>
<p>from 后面的表关联，是自右向左解析，而 where 条件的解析顺序是自下向上的。</p>
<p>也就是说，在写 SQL 的时候，尽量把数据量小的表放在最右边来进行关联（用小表去匹配大表），而把筛选出销量数据的条件尽量放在 where 语句的最左边（用小表去匹配大表）。</p>
<h1 id="14关系型数据库与非关系型数据库">14.关系型数据库与非关系型数据库</h1>
<p>(1) 关系型数据库</p>
<ul>
<li>使用 SQL 语句方便的在一个表以及多个表之间做非常<strong>复杂的数据查询</strong>。</li>
<li>支持事务，对于<strong>安全性能很高</strong>的数据访问要求得以实现。</li>
</ul>
<p>(2) 非关系型数据库</p>
<ul>
<li>NoSQL 基于键值对，不需要经过 SQL 层的解析，<strong>性能高</strong>。</li>
<li>给予减会对，数据之间没有耦合性，<strong>容易水平扩展</strong>。</li>
</ul>
<h1 id="15b-树的数据结构">15.B+ 树的数据结构？</h1>
<p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。</p>
<p>B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。</p>
<p>在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。</p>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/B+%E6%A0%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="图片" loading="lazy"></figure>
<h1 id="16为什么使用-b-树索引而不用红黑树">16.为什么使用 B+ 树索引，而不用红黑树？</h1>
<p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：</p>
<p>（一）更少的查找次数</p>
<p>平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。</p>
<p>红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。</p>
<p>（二）利用磁盘预读特性</p>
<p>为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。</p>
<p>操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。</p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s/IZpRNTKs3EHiXO-vYphk1w">为什么MySQL的索引要使用B+树而不是其它树形结构?比如B树？</a><br>
因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变（有些资料也称为扇出）<br>
指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；</p>
</blockquote>
<h1 id="17mysql-读写分离-主从复制">17.MySQL 读写分离、主从复制</h1>
<h2 id="读写分离-2">读写分离</h2>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB.png" alt="图片" loading="lazy"></figure>
<p>MySQL 读写分离基本原理是让 <strong>master 数据库处理写操作，slave 数据库处理读操作</strong>。master 将写操作的变更同步到各个 slave 节点。</p>
<h2 id="主从复制原理">主从复制原理</h2>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt="图片" loading="lazy"></figure>
<ul>
<li>master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；</li>
<li>slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件</li>
<li>同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。</li>
</ul>
<p>参考链接：</p>
<p><a href="https://cyc2018.github.io/CS-Notes/#/notes/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86">https://cyc2018.github.io/CS-Notes/#/notes/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86</a></p>
<p><a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/MySQL.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/MySQL.md</a></p>
<blockquote>
<p>MyBatis如何防止SQL注入的？<br>
mybatis的#{}和<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;#&#039; at position 21: …以及order by注入问题
#̲{}：相当于JDBC中的Pre…'>{}的区别以及order by注入问题
#{}：相当于JDBC中的PreparedStatement
</span>{}：是输出变量的值<br>
简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— JVM]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-jvm/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-jvm/">
        </link>
        <updated>2020-03-25T11:36:10.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-比较-jvm-jre-jdk">1. 比较 JVM 、JRE、JDK</h1>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/jre-jvm-jdk.png" alt="图片" loading="lazy"></figure>
<ul>
<li>JVM：Java Virtual Machine：Java 虚拟机</li>
<li>JRE：Java Runtime Environment：Java 运行环境（JVM + 基础类库）</li>
<li>JDK：JVM + 基础类库 + 编译工具（java、javac、javap）</li>
</ul>
<h1 id="2-介绍下-java-内存区域-结构运行时数据区">2. 介绍下 Java 内存区域 / 结构（运行时数据区）</h1>
<h2 id="线程私有的">线程私有的：</h2>
<h3 id="程序计数器">程序计数器</h3>
<ul>
<li>作用：记录正在执行的虚拟机<strong>字节码指令的地址</strong>（如果正在执行的是本地方法则为空）</li>
<li>唯一一个<strong>不会 OutOfMemory</strong> 的内存区域</li>
</ul>
<h3 id="虚拟机栈线程栈">虚拟机栈（线程栈）</h3>
<ul>
<li>组成：<strong>栈帧</strong>（每个方法有一个栈帧）
<ul>
<li>局部变量表</li>
<li>操作数栈</li>
<li>动态链接</li>
<li>出口信息</li>
</ul>
</li>
</ul>
<blockquote>
<p>ps：几个小问题</p>
</blockquote>
<ul>
<li><strong>垃圾回收是否涉及栈内存？</strong>
<ul>
<li>栈内存放的是栈帧，每一次方法调用结束后（或抛出异常后）栈帧都会自动弹出栈，所以不需要垃圾回收来管理栈内存。</li>
</ul>
</li>
<li><strong>栈内存分配越大越好吗</strong>？
<ul>
<li>不，物理内存的大小是一定的，每个线程都有一个栈，如果栈内存过大，会让线程数变少。</li>
</ul>
</li>
<li><strong>方法内的局部变量是否线程安全</strong>？
<ul>
<li>如果方法内局部变量没有逃逸出方法，线程安全</li>
<li>如果方法内局部变量逃逸出方法的作用范围，
<ul>
<li>基本数据类型存在<strong>栈帧</strong>内，其他线程无法访问，线程安全。</li>
<li>引用数据类型存在于<strong>堆</strong>内，如果逃逸出方法（方法参数、返回值），其他线程拿到对象的引用，就可以通过引用找到堆内存中的对象进行修改，线程不安全。</li>
</ul>
</li>
</ul>
</li>
<li><strong>栈内存溢出：</strong>
<ul>
<li>栈帧过多：递归调用中没有设置正确的结束条件。</li>
<li>栈帧过大</li>
</ul>
</li>
</ul>
<h3 id="本地方法栈">本地方法栈</h3>
<ul>
<li>JVM 在调用本地方法（native 修饰的方法）时，需要为本地方法提供的内存空间。</li>
</ul>
<h2 id="线程共有的">线程共有的</h2>
<h3 id="堆">堆</h3>
<ul>
<li>通过 <strong>new</strong> 关键字创建出来的对象存放在堆内存中。</li>
<li>有<strong>垃圾回收</strong>机制。</li>
</ul>
<h3 id="方法区方法区内有常量池">方法区（方法区内有常量池）</h3>
<p>存储类结构相关的信息：成员变量、成员方法和构造器方法的代码部分、包括一些特殊方法。</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/%E6%96%B9%E6%B3%95%E5%8C%BA1.6.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>HotSpot 1.6 虚拟机内存结构：<br>
方法区是一个概念，用一个<strong>永久代</strong>作为方法区的实现。永久代包括：Class 类信息、类加载器、运行时常量池。StringTable 存在于运行时常量池中。<br>
方法区与永久代：方法区是一种<strong>概念</strong>，永久代是 HotSpot 虚拟机对虚拟机规范中方法区的一种<strong>实现</strong>。</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/%E6%96%B9%E6%B3%95%E5%8C%BA.png" alt="图片" loading="lazy"></figure>
<blockquote>
<p>HotSpot 1.8 虚拟机内存结构：<br>
方法区还是一个概念上的东西，方法区的实现使用<strong>元空间</strong>。元空间内包含了：Class 类信息、类加载器、常量池，不过他已经不再占用堆内存了（不是由 JVM 管理它的内存结构），移出到本地内存（<strong>操作系统内存</strong>）中。本地内存中还会放一些其他进程，有一块是元空间。StringTable 串被移动到了堆中。</p>
</blockquote>
<h1 id="3-介绍下-java-内存模型">3. 介绍下 Java 内存模型</h1>
<ul>
<li>JMM：Java Memory Mmodel</li>
<li>Java 内存模型定义了一套在<strong>多线程</strong>读写共享数据时，对数据的可见性、有序性和原子性的保障。</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/jmm.png" alt="图片" loading="lazy"></figure>
<h1 id="4-如何判断对象是否死亡">4. 如何判断对象是否死亡？</h1>
<h2 id="引用计数法">引用计数法</h2>
<p>为每个对象添加一个<strong>引用计数器</strong>，每当有一个引用指向这个对象，就把引用计数器的值 +1，当引用失效，计数器值 -1，直到引用计数器的值为 0，表示不再有引用指向这个对象，就可判定这个对象已死亡。</p>
<p>因为无法解决对象间<strong>循环引用</strong>的问题，所以主流的 Java 虚拟机中没有采用这种方法来管理内存。</p>
<h2 id="可达性分析法">可达性分析法</h2>
<p>以 GC Root 为起点向下搜索，搜索过的路径称为引用链，当一个对象到 GC Root 没有任何引用链相连时，则证明这个对象是不可用的。</p>
<h3 id="哪些对象可以作为-gc-root">哪些对象可以作为 GC Root？</h3>
<ul>
<li>虚拟机栈中局部变量引用的对象</li>
<li>本地方法栈中 JNI 中引用的对象</li>
<li>方法区静态属性引用的对象</li>
<li>方法区中的常量引用的对象</li>
</ul>
<h1 id="5-介绍一下-强引用-软引用-弱引用-虚引用">5. 介绍一下 强引用、软引用、弱引用、虚引用</h1>
<h2 id="强引用">强引用</h2>
<p>只要一个对象还有<strong>强引用</strong>指向它，它就不会被回收。</p>
<p>使用 **new **一个对象的方式来创建强引用。</p>
<pre><code>Object obj = new Object();
</code></pre>
<h2 id="软引用">软引用</h2>
<p>仅有软引用指向该对象时，在<strong>垃圾回收后，内存仍不足</strong>就会再次触发垃圾回收，回收<strong>软引用对象</strong>。可配合引用队列回收软引用本身。</p>
<p>使用<code>SoftReference</code> 类来创建软引用。</p>
<pre><code>Object obj = new Object();
SoftReference&lt;Ojbect&gt; sf = new SoftReference&lt;Object&gt;(obj);
obj = null; // 使对象只被软引用关联
</code></pre>
<h2 id="弱引用">弱引用</h2>
<p>当仅有弱引用指向该对象时，在<strong>垃圾回收</strong>时，无论内存是否充足，都会回收弱引用对象。可配合引用队列回收软引用本身。</p>
<p>使用 <code>WeakReference</code>类来创建弱引用。</p>
<pre><code>Object obj = new Object();
WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);
obj = null;
</code></pre>
<h2 id="虚引用">虚引用</h2>
<p>一个对象是否有虚引用的存在，不会对其生存时间造成影响，也<strong>无法通过虚引用得到一个对象</strong>。</p>
<p>为一个对象设置虚引用的唯一目的就是能<strong>在这个对象被回收时收到一个系统通知</strong>。</p>
<p>使用 <strong>PhantomReference</strong> 来创建虚引用。</p>
<pre><code>Object obj = new Object();
PhantomReference &lt;Object&gt; wf = new PhantomReference &lt;Object&gt;(obj, null);
obj = null;
</code></pre>
<h1 id="6-垃圾收集有哪些算法各自的特点">6. 垃圾收集有哪些算法？各自的特点？</h1>
<h2 id="标记清除算法">标记清除算法</h2>
<figure data-type="image" tabindex="5"><img src="https://epitomm.github.io/post-images/%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4.png" alt="图片" loading="lazy"></figure>
<p>过程：</p>
<ul>
<li><strong>标记</strong>：从 GC Root 开始向下找，如果某个对象没有经过任意一条引用链，则把这个对象标记为垃圾对象</li>
<li><strong>清除</strong>：清除标记为垃圾的对象，并不是把内存中每个字节都清零，只是把这段内存的起始、结束地址放入一个空闲地址列表，下次分配内存时从空闲地址列表选择一块空闲内存进行分配。</li>
</ul>
<p>特点：</p>
<ul>
<li>速度快</li>
<li>易造成内碎片</li>
</ul>
<h2 id="标记整理算法">标记整理算法</h2>
<figure data-type="image" tabindex="6"><img src="https://epitomm.github.io/post-images/%E6%A0%87%E8%AE%B0%E6%95%B4%E7%90%86.png" alt="图片" loading="lazy"></figure>
<p>过程：</p>
<ul>
<li><strong>标记</strong>：由 GC Root 向下找，经过的路径称为引用链，如果某个对象没有经过任何一条引用链，将其标记为垃圾对象。</li>
<li><strong>整理</strong>：清理垃圾的过程中，将非垃圾对象依次向前移动，使内存更加紧凑。</li>
</ul>
<p>特点：</p>
<ul>
<li>涉及到大量对象的移动，<strong>速度慢</strong>。对象在整理的过程中，如果有其他引用指向这个对象，需要更改这些引用。</li>
<li>没有内碎片</li>
</ul>
<h2 id="复制算法">复制算法</h2>
<figure data-type="image" tabindex="7"><img src="https://epitomm.github.io/post-images/%E5%A4%8D%E5%88%B61.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://epitomm.github.io/post-images/%E5%A4%8D%E5%88%B62.png" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://epitomm.github.io/post-images/%E5%A4%8D%E5%88%B63.png" alt="图片" loading="lazy"></figure>
<p>过程：</p>
<ul>
<li>标记：将不经过引用链的对象标记垃圾对象。</li>
<li>复制：将非垃圾对象从 FROM 区域复制到 TO 区域，在复制的过程中完成了整理，FROM 区域存在的都是垃圾对象，全部清除，交换 FROM 区域和 TO 区域。</li>
</ul>
<p>特点：</p>
<ul>
<li>不会有内碎片</li>
<li>需要占用双倍空间</li>
</ul>
<h2 id="分代收集算法">分代收集算法</h2>
<p>将堆划分为新生代和老年代</p>
<ul>
<li>新生代使用：复制算法</li>
<li>老年代使用：标记-清除 算法 或 标记-整理 算法</li>
</ul>
<h1 id="7-hotspot-为什么要分为新生代和老年代">7. HotSpot 为什么要分为新生代和老年代？</h1>
<p>HotSpot 根据对象存活周期的不同将内存划分为新生代和老年代，<strong>新生代</strong>在垃圾回收后，只有少部分对象会被保留，所以采用<strong>复制算法</strong>；而<strong>老年代则</strong>有大部分对象被保留，使用<strong>标记-清除</strong> 或 <strong>标记-整理</strong> 算法。</p>
<h1 id="8-方法区的回收">8. 方法区的回收</h1>
<p>主要是对常量池的回收和类的回收。</p>
<p>类的回收需要满足三个条件：</p>
<ul>
<li>该类的所有实例已经被回收，此时堆中不存在该类的任何实例。</li>
<li>该类的类加载器已经被回收。</li>
<li>该类的类对象没有在任何地方被引用，且通过反射也无法获得该类方法。</li>
</ul>
<h1 id="9-hotspot-gc-的触发条件">9. HotSpot GC 的触发条件</h1>
<h2 id="minor-gc">Minor GC</h2>
<p>新生代中的 Eden 区域内存不足时触发 Minor GC。</p>
<blockquote>
<p>Minor GC 会回收新生代，因为新生代对象存活时间较短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快</p>
</blockquote>
<h2 id="full-gc">Full GC</h2>
<ul>
<li>调用 System.gc() 建议虚拟机执行 Full GC</li>
<li>老年代空间不足（大对象或长期存活的对象进入老年代导致老年代空间不足）时触发 Full GC</li>
<li>空间分配担保失败</li>
<li>JDK1.7 及以前的永久代空间不足</li>
<li>Concurrent Mode Failure<br>
执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。</li>
</ul>
<blockquote>
<p>Full GC 回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。</p>
</blockquote>
<h1 id="10-什么情况下新生代对象会晋升到老年代">10. 什么情况下新生代对象会晋升到老年代？</h1>
<ul>
<li>晋升年龄达到阈值的对象，会晋升到老年代。</li>
<li>大对象直接进入老年代：避免在 Eden 和 Survior 之间来回进行大量复制。</li>
<li>Minor GC 后，如果对象太大无法进入 Suirior 区，则直接进入老年代。</li>
<li>如果在 Survior 区中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄对象就可以直接进入老年代，无须等年龄达到晋升阈值。</li>
</ul>
<h1 id="11-常见的垃圾收集器有哪些">11. 常见的垃圾收集器有哪些？</h1>
<figure data-type="image" tabindex="10"><img src="https://epitomm.github.io/post-images/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="图片" loading="lazy"></figure>
<p>以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。</p>
<ul>
<li>单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程。</li>
<li>串行与并行：串行指的是垃圾收集器工作的时候必须停止用户线程；并行指的是垃圾收集器和用户线程同时工作。除了 CMS 和 G1之外，其他垃圾收集器都是以串行的方式执行的。</li>
</ul>
<h2 id="serial串行单线程收集器">Serial（串行单线程）收集器</h2>
<ul>
<li><strong>串行</strong>方式执行</li>
<li><strong>单线程</strong>收集器，只使用一个线程进行垃圾手机工作</li>
<li><strong>简单高效</strong>，单个 CPU 没有进程切换的开销。</li>
</ul>
<p>它是 Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大。它收集一两百兆垃圾的停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿时间是可以接受的。</p>
<h2 id="parnew串行多线程-收集器">ParNew（串行多线程） 收集器</h2>
<ul>
<li><strong>串行</strong></li>
<li><strong>多线程</strong>垃圾收集器</li>
</ul>
<p>它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。</p>
<h2 id="parallel-scavenge串行多线程吞吐量-收集器">Parallel Scavenge（串行多线程吞吐量） 收集器</h2>
<ul>
<li><strong>多线程</strong>垃圾收集器</li>
<li><strong>吞吐量优先</strong>。吞吐量：CPU 用于运行用户程序的时间与总时间的比值。</li>
</ul>
<p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。</p>
<p><strong>缩短停顿时间是以牺牲吞吐量和新生代空间来换取的</strong>：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。</p>
<p>可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。</p>
<h2 id="serial-old串行单线程老年代-收集器">Serial Old（串行单线程老年代） 收集器</h2>
<p>是 Serial 收集器的老年代版本，也是给 Client 场景下的虚拟机使用。如果用在 Server 场景下，它有两大用途：</p>
<ul>
<li>在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。</li>
<li>作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。</li>
</ul>
<h2 id="parallel-old多线程吞吐量老年代-收集器">Parallel Old（多线程吞吐量老年代） 收集器</h2>
<p>是 Parallel Scavenge 收集器的老年代版本。</p>
<p>在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。</p>
<h2 id="cms-收集器">CMS 收集器</h2>
<p>CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。</p>
<p>分为以下四个流程：</p>
<ul>
<li>初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。</li>
<li>并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。</li>
<li>重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。</li>
<li>并发清除：不需要停顿。</li>
</ul>
<p>在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。</p>
<p>具有以下缺点：</p>
<ul>
<li>吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。</li>
<li>无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。</li>
<li>标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。</li>
</ul>
<h2 id="g1-收集器">G1 收集器</h2>
<p>G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。 HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。</p>
<p>堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。</p>
<figure data-type="image" tabindex="11"><img src="https://epitomm.github.io/post-images/heap.png" alt="图片" loading="lazy"></figure>
<p>G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。</p>
<figure data-type="image" tabindex="12"><img src="https://epitomm.github.io/post-images/G1.png" alt="图片" loading="lazy"></figure>
<p>通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。</p>
<p>每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用</p>
<p>Remembered Set，在做可达性分析的时候就可以避免全堆扫描</p>
<figure data-type="image" tabindex="13"><img src="https://epitomm.github.io/post-images/G1_2.png" alt="图片" loading="lazy"></figure>
<p>如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：</p>
<ul>
<li>初始标记</li>
<li>并发标记</li>
<li>最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。</li>
<li>筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</li>
</ul>
<p>具备如下特点：</p>
<ul>
<li>空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复 制”算法实现的，这意味着运行期间不会产生内存空间碎片。</li>
<li>可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒</li>
</ul>
<h1 id="12-类加载的过程">12. 类加载的过程</h1>
<p>包含了加载、验证、准备、解析和初始化这 5 个阶段。</p>
<p><strong>1. 加载</strong></p>
<p>加载是类加载的一个阶段，注意不要混淆。</p>
<p>加载过程完成以下三件事：</p>
<ul>
<li>通过类的完全限定名称获取定义该类的二进制字节流。</li>
<li>将该字节流表示的静态存储结构转换为方法区的运行时存储结构。</li>
<li>在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。</li>
</ul>
<p>其中二进制字节流可以从以下方式中获取：</p>
<ul>
<li>从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。</li>
<li>从网络中获取，最典型的应用是 Applet。</li>
<li>运行时计算生成，例如动态代理技术，在 java.lang.reflflect.Proxy 使用 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。</li>
<li>由其他文件生成，例如由 JSP 文件生成对应的 Class 类。</li>
</ul>
<p><strong>2. 验证</strong></p>
<p>确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p>
<p><strong>3. 准备</strong></p>
<p>类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。</p>
<p>实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中。应该注意到，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。</p>
<p>初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。</p>
<pre><code>public static int value = 123; 
</code></pre>
<p>如果类变量是常量，那么它将初始化为表达式所定义的值而不是 0。例如下面的常量 value 被初始化为 123 而不是 0。</p>
<pre><code>public static final int value = 123; 
</code></pre>
<p><strong>4. 解析</strong><br>
将常量池的符号引用替换为直接引用的过程。</p>
<p>其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。</p>
<p><strong>5. 初始化</strong></p>
<p>初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段是虚拟机执行类构造器 <clinit>() 方法的过程。在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。</p>
<p><clinit>() 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码：</p>
<pre><code>public class Test { 
    static { 
        i = 0; // 给变量赋值可以正常编译通过 
        System.out.print(i); // 这句编译器会提示“非法向前引用” 
    }
    static int i = 1; 
} 
</code></pre>
<p>由于父类的 <clinit>() 方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。例如以下代码：</p>
<pre><code>static class Parent { 
    public static int A = 1; 
    static { 
        A = 2; 
    } 
}
static class Sub extends Parent { 
    public static int B = A; 
}
public static void main(String[] args) { 
    System.out.println(Sub.B); // 2 
} 
</code></pre>
<p>接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 <clinit>() 方法。但接口与类不同的是，执行接口的 <clinit>() 方法不需要先执行父接口的 <clinit>() 方法。只有当父接口中定义的变量使<br>
用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 <clinit>() 方法。</p>
<p>虚拟机会保证一个类的 <clinit>() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 <clinit>() 方法，其它线程都会阻塞等待，直到活动线程执行 <clinit>() 方法完毕。如果在一 个类的 <clinit>() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。</p>
<h1 id="13-类初始化时机">13. 类初始化时机</h1>
<p><strong>1. 主动引用</strong></p>
<p>虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：</p>
<ul>
<li>遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 fifinal 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。</li>
<li>使用 java.lang.reflflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。</li>
<li>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；</li>
<li>当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；</li>
</ul>
<p><strong>2. 被动引用</strong></p>
<p>以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引 用。被动引用的常见例子包括：</p>
<ul>
<li>通过子类引用父类的静态字段，不会导致子类初始化。</li>
</ul>
<pre><code>System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 
</code></pre>
<p>通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。</p>
<pre><code>SuperClass[] sca = new SuperClass[10]; 
</code></pre>
<p>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</p>
<pre><code>System.out.println(ConstClass.HELLOWORLD);
</code></pre>
<h1 id="14-java-虚拟机中有哪些类加载器">14. Java 虚拟机中有哪些类加载器？</h1>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>名称</strong></th>
<th style="text-align:left"><strong>加载哪的类</strong></th>
<th style="text-align:center"><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Bootstrap ClassLoader（启动类加载器）</td>
<td style="text-align:left">JAVA_HOME/jre/lib</td>
<td style="text-align:center">无法直接访问</td>
</tr>
<tr>
<td style="text-align:left">Extension ClassLoader（扩展类加载器）</td>
<td style="text-align:left">JAVA_HOME/jre/lib/ext</td>
<td style="text-align:center">上级为 Bootstrap，显示为 null</td>
</tr>
<tr>
<td style="text-align:left">Application ClassLoader（应用程序类加载器）</td>
<td style="text-align:left">classpath</td>
<td style="text-align:center">上级为 Extension</td>
</tr>
<tr>
<td style="text-align:left">自定义类加载器</td>
<td style="text-align:left">自定义</td>
<td style="text-align:center">上级为 Application</td>
</tr>
</tbody>
</table>
<h1 id="15-什么是双亲委派模型">15. 什么是双亲委派模型？</h1>
<p>如果一个类加载器收到了类加载请求，它首先不会自己去尝试加载这个类，而是把类加载的请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都会传送到顶层的启动类加载器中，只有当父类无法处理这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。</p>
<h1 id="16-使用双亲委派模型有什么好处">16. 使用双亲委派模型有什么好处？</h1>
<p>双亲委派模型保证了 Java 程序的稳定运行，可以<strong>避免类的重复加载</strong>（JVM 区分类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也<strong>保证了 Java 的核心 API 不被篡改</strong>。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。</p>
<h1 id="17-内存分配策略">17. 内存分配策略</h1>
<h2 id="对象优先在-eden-分配">对象优先在 Eden 分配</h2>
<p>大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不足时，触发 Minor GC。</p>
<h2 id="大对象直接进入老年代">大对象直接进入老年代</h2>
<p>大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。<br>
经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。<br>
-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。</p>
<h2 id="长期存活的对象进入老年代">长期存活的对象进入老年代</h2>
<p>为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。<br>
-XX:MaxTenuringThreshold 用来定义年龄的阈值。</p>
<h2 id="动态对象年龄不判定">动态对象年龄不判定</h2>
<p>虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到MaxTenuringThreshold 中要求的年龄。</p>
<h2 id="空间分配担保">空间分配担保</h2>
<p>在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。<br>
如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。</p>
<h1 id="18-说一下-java-对象的创建过程">18. 说一下 Java 对象的创建过程</h1>
<p><img src="https://epitomm.github.io/post-images/java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B.png" alt="图片" loading="lazy"><br>
① <strong>类加载检查</strong>：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。<br>
② <strong>分配内存</strong>：在类加载检查通过后，接下来虚拟机将为新生代对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。</p>
<blockquote>
<p>内存分配的两种方式：选择哪种空间分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由 GC 收集器的算法是 “标记-清除”，还是“标记-整理”/ &quot;复制&quot;。<br>
<img src="https://epitomm.github.io/post-images/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.png" alt="图片" loading="lazy"><br>
内存分配并发问题：在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：</p>
<ul>
<li>CAS+失败重试：CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突重试就失败，直到成功为止。虚拟机采用 CAS 配上失败重试的方式来保证更新操作的原子性。</li>
<li>TLAB：为每个线程预先在 Eden 区分配一块内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配。</li>
</ul>
</blockquote>
<p>③ <strong>初始化零值</strong>：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。<br>
④ <strong>设置对象头</strong>：初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。<br>
⑤ <strong>执行 init 方法</strong>：在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚开始，&lt; init &gt;方法还没有执行，所有的字段都还为零。所以一般来说，执行new指令之后会接着执行&lt; init &gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Java 集合]]></title>
        <id>https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-ji-he/</id>
        <link href="https://epitomm.github.io/post/mian-shi-ti-xi-lie-java-ji-he/">
        </link>
        <updated>2020-03-24T11:57:19.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-说一说-list-set-map-三者的区别">1. 说一说 List、Set、Map 三者的区别</h1>
<ul>
<li><code>List</code> 是存储<strong>有序</strong>的集合</li>
<li><code>Set</code> 集合元素<strong>不可重复</strong></li>
<li><code>Map</code> 是存储<strong>键值对</strong>的集合</li>
</ul>
<h1 id="2-arraylist-与-linkedlist-的区别">2. ArrayList 与 LinkedList 的区别</h1>
<ol>
<li>底层存储数据结构：</li>
</ol>
<ul>
<li><code>ArrayList</code> 初始容量时 10，底层是<strong>Object 数组</strong>，所以具有数组的特性，可<strong>随机访问</strong>，并且实现了<code>RandomAccess</code> 接口标识支持随机访问。</li>
<li><code>LinkedList</code> 底层是<strong>双向链表</strong>，所以具有链表的特性，<strong>增删速度快</strong>，但每个节点都有维护前后两个指针，占用<strong>存储空间较大</strong>。</li>
</ul>
<ol start="2">
<li>增删查效率：</li>
</ol>
<ul>
<li><code>ArrayList</code> 如果添加到<strong>末尾</strong>，时间复杂度<strong>O(1)</strong>；如果添加<strong>中间</strong>到指定 i 位置，需要把 i ~ n 位置的元素统一向后移动，时间复杂度 <strong>O(n-i)</strong>。如果<strong>按下标查找</strong>，时间复杂度<strong>O(1)</strong>。</li>
<li><code>LinkedList</code> 如果添加<strong>末尾</strong>，时间复杂度 <strong>O(1)</strong>，如果插入到<strong>中间</strong>第 i 个位置，需要先查找到到 i 个位置的元素，查找效率 <strong>O(n)</strong>，然后执行添加操作，修改指针指向，复杂度<strong>O(1)</strong>。如果<strong>按下标查找</strong>，需要判断下标是否大于当前 <code>size/2</code> ，如果大于则从末尾向中间查找；否则从头向中间查找，时间复杂度<strong>O(n)</strong>。</li>
</ul>
<h1 id="3-arraylist-扩容机制">3. ArrayList 扩容机制</h1>
<pre><code>private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);
    if (newCapacity - minCapacity &lt; 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
</code></pre>
<blockquote>
<p>上述代码基于 JDK1.8</p>
</blockquote>
<h1 id="4-arraylist-和-vector-的区别">4. ArrayList 和 Vector 的区别</h1>
<p>线程安全</p>
<ul>
<li><code>ArrayList</code> 线程不安全</li>
<li><code>Vector</code> 方法都使用 <code>synchronized</code> 修饰，所以线程安全，同时效率也低。正因为 <code>Vector</code> 效率低，所以一般不会使用，如果想实现同步，可以使用 <code>Collections.synchronizedList(new ArrayList&lt;&gt;());</code></li>
</ul>
<p>扩容机制：</p>
<ul>
<li><code>ArrayList</code> 扩容后的容量为原来的 1.5 倍</li>
<li><code>Vector</code> 扩容后的容量 是原来的 2 倍</li>
</ul>
<h1 id="5-hashmap-和-hashtable的区别">5. HashMap 和 Hashtable的区别</h1>
<p>线程安全：</p>
<ul>
<li><code>HashMap</code> 线程不安全</li>
<li><code>Hashtable</code> 的方法使用 <code>synchronized</code> 修饰，所以线程安全，也是正因为用 <code>synchronized</code> 修饰，所以效率较低。</li>
</ul>
<p>初始大小扩容机制：</p>
<ul>
<li><code>HashMap</code> 的默认初始容量为 16（2 &lt;&lt; 4）；如果指定了初始容量，会把它扩充为 2 的幂次。扩容后容量为原来的 2n</li>
<li><code>Hashtable</code> 默认初始容量时 11，如果指定初始容量，使用初始容量。扩容后容量为原来的 2n+1</li>
</ul>
<p>是否允许 null 键值</p>
<ul>
<li><code>HashMap</code> 允许 null 键值</li>
<li><code>Hashtable</code> 不允许 null 键值</li>
</ul>
<h1 id="6-hashmap-的-put-方法的具体流程">6. HashMap 的 put 方法的具体流程</h1>
<pre><code>public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/put.png" alt="图片" loading="lazy"></figure>
<ol>
<li>如果散列表为 null，<code>resize()</code> 初始化散列表</li>
<li>没有发生碰撞，直接添加元素到散列表中</li>
<li>如果发生碰撞，判断时红黑树还是链表，然后调用相应的插入方法</li>
<li>HashMap 的 resize() 扩容方法</li>
</ol>
<h1 id="7-hashmap-的-resize-扩容方法">7. HashMap 的 resize() 扩容方法</h1>
<p>如果当前容量 &gt; 阈值（容量 * 装填因子），则扩容</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/resize.png" alt="图片" loading="lazy"></figure>
<h1 id="8-hashmap-容量为什么是-2-的幂次">8. HashMap 容量为什么是 2 的幂次</h1>
<p>减少 <code>hash</code> 冲突，因为要用 <code>hash &amp; (n-1)</code> 确定元素存在数组中的下标位置，如果 n 是 2 的幂（1000），那么 n-1 得到的结果就全为 1 （10000 - 1 = 1111），这样 <code>(n-1) &amp; hash</code> 的值就是 hash。如果 n-1 中有某位为 0，那么 0 与任何数 &amp; 结果都为0，增加了hash 冲突的概率。</p>
<h1 id="9-hashmap-17-18-对比">9. HashMap 1.7 1.8 对比</h1>
<ul>
<li>JDK1.7</li>
</ul>
<p>数据结构：数组+链表</p>
<p>JDK1.7 hash 方法：9 次扰动（4 次位运算，5 次异或运算）</p>
<pre><code>static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).
    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);
    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);
}
</code></pre>
<ul>
<li>JDK 1.8</li>
</ul>
<p>数据结构：数组 + 链表 + 红黑树</p>
<p>JDK 1.8 hash 方法：2 次扰动（1 次位运算，1 次异或运算）</p>
<pre><code>static final int hash(Object key) {
    int h;
    // key.hashCode()：返回散列值也就是hashcode
    // ^ ：按位异或
    // &gt;&gt;&gt;:⽆符号右移，忽略符号位，空位都以0补⻬
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
}
</code></pre>
<p>贴一张比较详细的图：<br>
<img src="https://epitomm.github.io/post-images/hashmap.png" alt="图片" loading="lazy"></p>
<p>图片来源；<a href="https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485685&amp;idx=2&amp;sn=b393e444487c88e8c204821faddff370&amp;chksm=ebd749f4dca0c0e257e15c656f4504f224456495ad78e8aeb9ea370214ebd4b5c455b15e6045&amp;token=1948873548&amp;lang=zh_CN#rd">https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247485685&amp;idx=2&amp;sn=b393e444487c88e8c204821faddff370&amp;chksm=ebd749f4dca0c0e257e15c656f4504f224456495ad78e8aeb9ea370214ebd4b5c455b15e6045&amp;token=1948873548&amp;lang=zh_CN#rd</a></p>
<h1 id="10-hashmap-是怎么解决哈希冲突的">10. HashMap 是怎么解决哈希冲突的</h1>
<p>什么是哈希冲突：两个不同的输入值，根据同一散列函数，计算出相同的散列值。</p>
<ul>
<li>使用<strong>拉链法</strong>来链接具有相同 hash 值的数据</li>
<li>使用<strong>两次扰动函数</strong>（hash 函数）来降低哈希冲突的概率，使得<strong>数据分布更均匀</strong></li>
<li>引入<strong>红黑树</strong>降低查找的时间复杂度</li>
</ul>
<h1 id="11-hashmap-17-18多线程操作导致死循环问题">11. HashMap 1.7 1.8多线程操作导致死循环问题</h1>
<p>参考链接：<a href="https://coolshell.cn/articles/9606.html">https://coolshell.cn/articles/9606.html</a></p>
<h1 id="12-hashmap-的-key-值要是为类对象则该类需要满足什么条件">12. HashMap 的 key 值要是为类对象则该类需要满⾜什么条件？</h1>
<p><strong>重写 hashCode() 和 equals() 方法。</strong></p>
<p><code>Hashmap</code> 中放入相同的 <code>key</code>，会覆盖 <code>value</code> 值，而不是重新添加一个 <code>key-value</code> 对，这就要求我们判断 <code>key</code> 是否相同。</p>
<p>以下为 <code>HashMap</code> 的 <code>final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)</code> 方法：</p>
<pre><code>if (p.hash == hash &amp;&amp;
    ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
</code></pre>
<p>从源码得知判断分为三个步骤：①判断 <code>key</code> 的 <code>hash</code> 值是否相同，这就要求我们重写 <code>hashCode()</code> 方法；② 通过 <code>==</code> 判断 <code>key</code> 对象引用是否相等；③ 使用 <code>equals()</code> 判断对象是否相等，这就要求我们重写 <code>equals()</code> 方法。</p>
<h1 id="13-concurrenthashmap-的底层实现方式">13. ConcurrentHashMap 的底层实现方式</h1>
<p>JDK1.7</p>
<ul>
<li>数据结构：分段数组（<code>Segment</code> 继承了 <code>ReentrantLock</code>，每个段都有一个锁） + 链表（<code>HashEntry</code>）</li>
<li>线程安全：对整个桶数组进行了分割分段，每把锁只锁住一<strong>段</strong>，多线程访问其他段的数据时不会产生冲突。</li>
</ul>
<p>JDK1.8</p>
<ul>
<li>数据结构：数组 + 链表 + 红黑树</li>
<li>线程安全：部分锁定 + CAS。<code>synchronized</code> 只锁定<strong>当前链表或红黑二叉树的首节点</strong>，这样只要 hash 不冲突，就不会产生并发。</li>
</ul>
<h1 id="14-concurrenthashmap-和-hashtable-的区别">14. ConcurrentHashMap 和 Hashtable 的区别</h1>
<p><code>Hashtable</code> 数据结构：数组 + 链表</p>
<p><code>Hashtable</code> 实现线程安全：会锁住整个数组，某个线程在进行 put 操作时，其他线程只能阻塞。</p>
<h1 id="15-如何选用集合">15. 如何选用集合</h1>
<ul>
<li>如果存储键值对，选 <code>Map</code> 接口下的集合
<ul>
<li>如果需要排序，选择 <code>TreeMap</code></li>
<li>如果不需要排序，优先选择 <code>HashMap</code></li>
<li>如果需要线程安全，选择 <code>ConcurrentHashMap</code></li>
</ul>
</li>
<li>只需要存放元素值时，选择 <code>Collection</code> 接口下的集合
<ul>
<li>如果需要顺序放取，选择 <code>ArrayList</code></li>
<li>如果需要频繁增删，选择 <code>LinkedList</code></li>
<li>如果需要元素不重复且排序，选择 <code>TreeSet</code></li>
<li>如果需要元素不重复但无需排序，优先选择 <code>HashSet</code></li>
</ul>
</li>
</ul>
<p>参考链接：</p>
<p><a href="https://github.com/ZhongFuCheng3y/3y">https://github.com/ZhongFuCheng3y/3y</a></p>
<p><a href="https://github.com/Snailclimb/JavaGuide">https://github.com/Snailclimb/JavaGuide</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试题系列 —— Zookeeper]]></title>
        <id>https://epitomm.github.io/post/zookeeper-mian-shi-ti/</id>
        <link href="https://epitomm.github.io/post/zookeeper-mian-shi-ti/">
        </link>
        <updated>2020-03-14T15:40:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-谈谈你对-zookeeper-的认识">1. 谈谈你对 Zookeeper 的认识</h1>
<p><code>Zookeeper</code> 是一个<strong>分布式协调服务</strong>的开源框架。主要用来解决分布式集群中应用系统的<strong>一致性</strong>问题，例如怎样避免同时操作同一数据造成脏读的问题。</p>
<p><strong><code>ZooKeeper</code> 本质上是一个分布式的小文件存储系统</strong>。提供基于类似于文件系统的目录树方式的数据存储，并且可以对树中的节点进行有效管理。从而用来维护和监控你存储的数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。诸如：统一命名服务、分布式配置管理、分布式消息队列、分布式锁、分布式协调等功能。</p>
<h1 id="2-zookeeper-特性">2. ZooKeeper 特性</h1>
<ol>
<li><strong>全局数据一致</strong>：集群中每个服务器保存一份相同的数据副本，<code>client</code> 无论连接到哪个服务器，展示的数据都是一致的，这是最重要的特征；</li>
<li><strong>可靠性</strong>：如果消息【<strong>增、删、改、查</strong>】被其中一台服务器接受，那么将被所有的服务器接受。</li>
<li><strong>顺序性</strong>：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息 a 在消息 b 前发布，则在所有 <code>Server</code> 上消息 a 都将在消息 b 前被发布；偏序是指如果一个消息 b 在消息 a 后被同一个发送者发布，a 必将排在 b 前面。</li>
<li><strong>数据更新原子性</strong>：一次数据更新要么成功（半数以上节点成功），要么失败，不存在中间状态。</li>
<li><strong>实时性</strong>：<code>Zookeeper</code> 保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。</li>
</ol>
<h1 id="3-zookeeper-数据模型">3． ZooKeeper 数据模型</h1>
<p><code>ZooKeeper</code> 的数据模型，在结构上和标准文件系统的非常相似，拥有一个层次的命名空间，都是采用<strong>树形层次结构</strong>，<code>ZooKeeper</code> 树中的每个节点被称为— <strong><code>Znode</code></strong>。和文件系统的目录树一样，<code>ZooKeeper</code> 树中的每个节点可以拥有子节点。但也有不同之处：</p>
<ol>
<li><strong><code>Znode</code> 兼具文件和目录两种特点</strong>。既像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分，并可以具有子 <code>Znode</code>。用户对 <code>Znode</code> 具有增、删、改、查等操作（权限允许的情况下）。</li>
<li><strong><code>Znode</code> 具有原子性操作</strong>，读操作将获取与节点相关的所有数据，写操作也将替换掉节点的所有数据。另外，每一个节点都拥有自己的 ACL(访问控制列表)，这个列表规定了用户的权限，即限定了特定用户对目标节点可以执行的操作。</li>
<li><strong><code>Znode</code> 存储数据大小有限制</strong>。<code>ZooKeeper</code> 虽然可以关联一些数据，但并没有被设计为常规的数据库或者大数据存储，相反的是，它用来管理调度数据，比如分布式应用中的配置文件信息、状态信息、汇集位置等等。这些数据的共同特性就是它们都是很小的数据，<strong>通常以 KB 为大小单位</strong>。ZooKeeper 的服务器和客户端都被设计为严格检查并限制每个 Znode 的数据大小至多 1M，当时常规使用中应该远小于此值。</li>
<li><strong><code>Znode</code> 通过路径引用</strong>，如同 <code>Unix</code> 中的文件路径。<strong>路径必须是绝对的</strong>，因此他们必须<strong>由斜杠字符来开头</strong>。除此以外，他们必须是唯一的，也就是说每一个路径只有一个表示，因此这些路径不能改变。在 <code>ZooKeeper</code> 中，路径由 <code>Unicode</code> 字符串组成，并且有一些限制。字符串&quot;/zookeeper&quot;用以保存管理信息，比如关键配额信息。</li>
</ol>
<h2 id="31数据结构图">3.1．数据结构图</h2>
<p><img src="https://epitomm.github.io/post-images/1584240732240.jpg" alt="" loading="lazy"><br>
图中的每个节点称为一个 <code>Znode</code>。 每个 <code>Znode</code> 由 3 部分组成:</p>
<ul>
<li><code>stat</code>：此为状态信息, 描述该 <code>Znode</code> 的版本, 权限等信息</li>
<li><code>data</code>：与该 <code>Znode</code> 关联的数据</li>
<li><code>children</code>：该 <code>Znode</code> 下的子节点</li>
</ul>
<h2 id="32节点类型">3.2．节点类型</h2>
<p><code>Znode</code> 有两种，分别为<strong>临时节点</strong>和<strong>永久节点</strong>。</p>
<p>节点的类型<strong>在创建时即被确定，并且不能改变。</strong></p>
<p><strong>临时节点</strong>：该节点的生命周期依赖于创建它们的会话。一旦<strong>会话结束，临时节点将被自动删除</strong>，当然可以也可以手动删除。<strong>临时节点不允许拥有子节点</strong>。</p>
<p><strong>永久节点</strong>：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。</p>
<p><code>Znode</code> 还有一个<strong>序列化</strong>的特性，如果创建的时候指定的话，该 <code>Znode</code> 的名字后面会<strong>自动追加一个不断增加的序列号</strong>。序列号对于此节点的父节点来说是唯一的，这样便会<strong>记录每个子节点创建的先后顺序</strong>。它的格式为“%10d”(10 位数字，没有数值的数位用 0 补充，例如“0000000001”)。</p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/1584240804281.jpg" alt="" loading="lazy"></figure>
<p>这样便会存在四种类型的 <code>Znode</code> 节点，分别对应：</p>
<ul>
<li><code>PERSISTENT</code>：永久节点</li>
<li><code>EPHEMERAL</code>：临时节点</li>
<li><code>PERSISTENT_SEQUENTIAL</code>：永久节点、序列化</li>
<li><code>EPHEMERAL_SEQUENTIAL</code>：临时节点、序列化</li>
</ul>
<h1 id="4-zookeeper-watcher">4． ZooKeeper Watcher</h1>
<p><code>ZooKeeper</code> 提供了分布式数据<strong>发布/订阅功能</strong>，一个典型的发布/订阅模型系统定义了一种一对多的订阅关系，能让多个订阅者同时监听某一个主题对象，当这个主题对象自身状态变化时，会通知所有订阅者，使他们能够做出相应的处理。</p>
<p><code>ZooKeeper</code> 中，引入了 <strong>Watcher 机制来实现这种分布式的通知功能</strong> 。 <code>ZooKeeper</code> 允许客户端向服务端注册一个 <code>Watcher</code> 监听，当服务端的一些事件触发了这个 <code>Watcher</code>，那么就会向指定客户端发送一个事件通知来实现分布式的通知功能。</p>
<p>触发事件种类很多，如：节点创建，节点删除，节点改变，子节点改变等。</p>
<p>总的来说可以概括 <code>Watcher</code> 为以下三个过程：<strong>客户端向服务端注册 <code>Watcher</code>、服务端事件发生触发 <code>Watcher</code>、客户端回调 <code>Watcher</code> 得到触发事件情况</strong></p>
<h2 id="41-watch-机制特点">4.1． Watch 机制特点</h2>
<h3 id="一次性触发"><strong>一次性触发</strong></h3>
<p>事件发生触发监听，一个 <code>watcher event</code> 就会被发送到设置监听的客户端，这种效果是一次性的，后续再次发生同样的事件，不会再次触发。</p>
<h3 id="事件封装"><strong>事件封装</strong></h3>
<p><code>ZooKeeper</code> 使用 <code>WatchedEvent</code> 对象来封装服务端事件并传递。</p>
<p><code>WatchedEvent</code> 包含了每一个事件的三个基本属性：</p>
<p><strong>通知状态（<code>keeperState</code>），事件类型（<code>EventType</code>）和节点路径（<code>path</code>）</strong></p>
<h3 id="event-异步发送"><strong>event 异步发送</strong></h3>
<p><code>watcher</code> 的通知事件从服务端发送到客户端是异步的。</p>
<h3 id="先注册再触发"><strong>先注册再触发</strong></h3>
<p><code>Zookeeper</code> 中的 <code>watch</code> 机制，必须客户端先去服务端注册监听，这样事件发送才会触发监听，通知给客户端。</p>
<h1 id="5-zookeeper-选举机制">5． ZooKeeper 选举机制</h1>
<p><code>zookeeper</code> 默认的算法是 <code>FastLeaderElection</code>，采用投票数大于半数则胜出的逻辑。</p>
<h2 id="51-概念">5.1． 概念</h2>
<p><strong>服务器 ID</strong></p>
<ul>
<li>比如有三台服务器，编号分别是 1,2,3。</li>
<li>编号越大在选择算法中的权重越大。</li>
</ul>
<p><strong>选举状态</strong></p>
<ul>
<li><code>LOOKING</code>，竞选状态。</li>
<li><code>FOLLOWING</code>，随从状态，同步 <code>leader</code> 状态，参与投票。</li>
<li><code>OBSERVING</code>，观察状态,同步 <code>leader</code> 状态，不参与投票。</li>
<li><code>LEADING</code>，领导者状态。</li>
</ul>
<p><strong>数据 ID</strong></p>
<ul>
<li>服务器中存放的最新数据 <code>version</code>。</li>
<li>值越大说明数据越新，在选举算法中数据越新权重越大。</li>
</ul>
<p><strong>逻辑时钟</strong></p>
<p>也叫投票的次数，同一轮投票过程中的逻辑时钟值是相同的。每投完一次票这个数据就会增加，然后与接收到的其它服务器返回的投票信息中的数值相比，根据不同的值做出不同的判断。</p>
<h2 id="52-全新集群选举">5.2． 全新集群选举</h2>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/1584240883089.png" alt="" loading="lazy"></figure>
<p>假设目前有 5 台服务器，<strong>每台服务器均没有数据</strong>，它们的编号分别是1,2,3,4,5,<strong>按编号依次启动</strong>，它们的选择举过程如下：</p>
<ul>
<li>服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器 1 的状态一直属于 <code>Looking</code>。</li>
<li>服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是 <code>LOOKING</code>。</li>
<li>服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器 1,2 成为小弟。</li>
<li>服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。</li>
<li>服务器 5 启动，后面的逻辑同服务器 4 成为小弟。</li>
</ul>
<h2 id="53-非全新集群选举">5.3． 非全新集群选举</h2>
<p>对于运行正常的 <code>zookeeper</code> 集群，中途有机器 <code>down</code> 掉，需要重新选举时，选举过程就需要加入<strong>数据 ID</strong>、<strong>服务器 ID</strong> 和<strong>逻辑时钟</strong>。</p>
<p>数据 ID：数据新的 <code>version</code> 就大，数据每次更新都会更新 <code>version</code>。</p>
<p>服务器 ID：就是我们配置的 <code>myid</code> 中的值，每个机器一个。</p>
<p>逻辑时钟：这个值从 0 开始递增,每次选举对应一个值。 如果在同一次选举中,这个值是一致的。</p>
<p>这样选举的标准就变成：</p>
<p>1、逻辑时钟小的选举结果被忽略，重新投票；</p>
<p>2、统一逻辑时钟后，数据 id 大的胜出；</p>
<p>3、数据 id 相同的情况下，服务器 id 大的胜出；根据这个规则选出 <code>leader</code>。</p>
<h1 id="6-zookeeper-典型应用">6． ZooKeeper 典型应用</h1>
<h2 id="61-数据发布与订阅配置中心">6.1． 数据发布与订阅（配置中心）</h2>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/1584241030128.png" alt="" loading="lazy"></figure>
<p>发布与订阅模型，即所谓的配置中心，顾名思义就是<strong>发布者将数据发布到 ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新</strong>。</p>
<p>应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个 <code>Watcher</code>，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。比如：</p>
<p>分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在 ZK 的一些指定节点，供各个客户端订阅使用。</p>
<p>注意：适合<strong>数据量很小的场景</strong>，这样数据更新可能会比较快。</p>
<h2 id="62-命名服务naming-service">6.2． 命名服务(Naming Service)</h2>
<p>在分布式系统中，<strong>通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息</strong>。<strong>被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）</strong>。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用 ZK 提供的创建节点的 API，能够很容易创建一个<strong>全局唯一的 path</strong>，这个 path 就可以作为一个名称。</p>
<p>阿里巴巴集团开源的分布式服务框架 <strong>Dubbo 中使用 ZooKeeper 来作为其命名服务</strong>，维护全局的服务地址列表。</p>
<h2 id="63-分布式锁">6.3． 分布式锁</h2>
<p>分布式锁，这个主要得益于 <code>ZooKeeper</code> 保证了数据的强一致性。锁服务可以分为两类，一个是<strong>保持独占</strong>，另一个是<strong>控制时序</strong>。</p>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/1584241059824.png" alt="" loading="lazy"></figure>
<p>所谓<strong>保持独占</strong>，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把 zk 上的一个 <code>znode</code> 看作是一把锁，通过 <code>create znode</code> 的方式来实现。所有客户端都去创建 <code>/distribute_lock</code> <strong>临时非序列化</strong>节点，最终成功创建的那个客户端也即拥有了这把锁。</p>
<p><strong>控制时序</strong>，就是所有试图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里<code>/distribute_lock</code> 已经预先存在，客户端在它下面创建<strong>临时有序</strong>节点（这个可以通过节点的属性控制：<code>CreateMode.EPHEMERAL_SEQUENTIAL</code> 来指定）。Zk 的父节点（<code>/distribute_lock</code>）</p>
<p>维持一份 <code>sequence</code>,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gridea 检测远程连接失败]]></title>
        <id>https://epitomm.github.io/post/gridea-jian-ce-yuan-cheng-lian-jie-shi-bai/</id>
        <link href="https://epitomm.github.io/post/gridea-jian-ce-yuan-cheng-lian-jie-shi-bai/">
        </link>
        <updated>2020-02-18T16:09:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="问题一">问题一</h1>
<h3 id="我的环境">我的环境</h3>
<table>
<thead>
<tr>
<th>名称</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>操作系统</td>
<td>Windows10</td>
</tr>
<tr>
<td>软件版本</td>
<td>0.9.1</td>
</tr>
<tr>
<td>主题名称</td>
<td>Notes</td>
</tr>
</tbody>
</table>
<h2 id="问题描述">问题描述</h2>
<p>根据教程设置好一系列信息，经测试域名可访问，并且确保其他信息均正确</p>
<p>检查远程连接错误：<strong>远程连接失败,请检查仓库、用户名和 token 设置</strong></p>
<h2 id="问题分析">问题分析</h2>
<ol>
<li>先查看 <code>Gridea</code> 文件存储目录：C:\Users\Only\Documents\Gridea\output.git 下的 config 文件，看是否有 [remote &quot;origin&quot;] 信息，如果没有自行添加</li>
</ol>
<pre><code>[remote &quot;origin&quot;]
	url = https://你的github用户名:Token@github.com/你的github用户/仓库名
	fetch = +refs/heads/*:refs/remotes/origin/*
</code></pre>
<p>附：查看<code>Gridea</code>文件存储目录<br>
<img src="https://epitomm.github.io/post-images/1582604204611.png" alt="" loading="lazy"></p>
<ol start="2">
<li>检查错误信息：<br>
<img src="https://epitomm.github.io/post-images/1582041933549.png" alt="" loading="lazy"></li>
</ol>
<blockquote>
<p>[<em>&quot;fatal: unable to access 'https://github.com/Epitom…led to connect to github.com port 443: Timed out↵&quot;</em>]</p>
</blockquote>
<h2 id="问题解决">问题解决</h2>
<ol>
<li>谷歌 433 错误，得知是<strong>没有设置代理服务器</strong>的原因。</li>
</ol>
<p>以下为网上一高赞解决方式，可自行尝试，（不过对我的问题无效果）<br>
参考链接：<a href="https://blog.csdn.net/runningman2012/article/details/54633677">https://blog.csdn.net/runningman2012/article/details/54633677</a></p>
<figure data-type="image" tabindex="1"><img src="https://epitomm.github.io/post-images/1582604339501.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>再次谷歌 git 如何设置代理服务器</li>
</ol>
<pre><code>git config --global http.proxy 'socks5://127.0.0.1:1080'

git config --global https.proxy 'socks5://127.0.0.1:1080'
</code></pre>
<p>参考：<a href="https://blog.csdn.net/isea533/article/details/84748009">https://blog.csdn.net/isea533/article/details/84748009</a></p>
<ol start="3">
<li>再次尝试检测远程连接成功</li>
</ol>
<p>接下来同步查看效果完成后就可以开启开心的写作之旅啦~</p>
<h1 id="问题二">问题二</h1>
<h3 id="我的环境-2">我的环境</h3>
<table>
<thead>
<tr>
<th>名称</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>操作系统</td>
<td>Windows10</td>
</tr>
<tr>
<td>软件版本</td>
<td>0.9.2</td>
</tr>
<tr>
<td>主题名称</td>
<td>Notes</td>
</tr>
</tbody>
</table>
<h2 id="问题描述-2">问题描述</h2>
<p>版本更新到 0.9.2 后重新安装了 Gridea ，再次检测远程连接失败</p>
<figure data-type="image" tabindex="2"><img src="https://epitomm.github.io/post-images/1582604400732.png" alt="" loading="lazy"></figure>
<p>错误信息</p>
<pre><code>connect ETIMEDOUT 140.82.114.4:443
</code></pre>
<h2 id="问题分析-2">问题分析</h2>
<ol>
<li>cmd 命令行 ping github.com 失败。代理问题</li>
</ol>
<h2 id="问题解决-2">问题解决</h2>
<ol start="2">
<li>
<p>使用 ping 检测工具找一个能够 ping 通 github.com 的 IP，检测工具网址如下：</p>
<p><a href="http://ping.chinaz.com/github.com">http://ping.chinaz.com/github.com</a></p>
</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://epitomm.github.io/post-images/1582041969896.png" alt="" loading="lazy"></figure>
<ol start="3">
<li>选择一个响应较快的 IP，添加到 C:\Windows\System32\drivers\etc\host 文件末尾：</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://epitomm.github.io/post-images/1582041983918.png" alt="" loading="lazy"></figure>
<pre><code>140.82.113.3 github.com
</code></pre>
<ol start="4">
<li>再次检测远程连接，成功。</li>
</ol>
]]></content>
    </entry>
</feed>